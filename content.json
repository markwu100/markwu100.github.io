{"meta":{"title":"Cloud Service一站通","subtitle":null,"description":null,"author":"Mark Wu","url":"http://blog.ozairs.com"},"pages":[{"title":"about","date":"2019-02-01T00:08:11.000Z","updated":"2019-02-01T03:08:11.104Z","comments":true,"path":"about/index.html","permalink":"http://blog.ozairs.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-02-01T07:41:48.000Z","updated":"2019-03-08T23:14:56.361Z","comments":true,"path":"categories/index.html","permalink":"http://blog.ozairs.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-02-01T07:41:48.000Z","updated":"2019-03-08T23:14:56.361Z","comments":true,"path":"tags/index.html","permalink":"http://blog.ozairs.com/tags/index.html","excerpt":"","text":""},{"title":"Azure","date":"2020-02-02T07:01:59.000Z","updated":"2020-02-02T07:01:59.474Z","comments":true,"path":"Azure/index.html","permalink":"http://blog.ozairs.com/Azure/index.html","excerpt":"","text":""},{"title":"about","date":"2019-02-01T04:12:13.000Z","updated":"2019-02-01T07:12:13.040Z","comments":true,"path":"about/index-1.html","permalink":"http://blog.ozairs.com/about/index-1.html","excerpt":"","text":""}],"posts":[{"title":"Another Test Blog","slug":"Another-Test-Blog","date":"2020-03-24T03:14:26.000Z","updated":"2020-03-24T03:15:14.109Z","comments":true,"path":"uncategorized/Another-Test-Blog/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Another-Test-Blog/","excerpt":"","text":"This is a test blog!!!","categories":[],"tags":[],"keywords":[]},{"title":"How to pass AWS Certified Security - Speciality","slug":"How-to-pass-AWS-Certified-Security-Speciality","date":"2020-02-12T09:53:35.000Z","updated":"2020-02-12T09:54:15.593Z","comments":true,"path":"Security/How-to-pass-AWS-Certified-Security-Speciality/","link":"","permalink":"http://blog.ozairs.com/Security/How-to-pass-AWS-Certified-Security-Speciality/","excerpt":"","text":"AWS Certified Security — Specialty I have documented my experience with AWS Security Exam Be aware of SMPT Port for SES NACL/SG requirement to allow/deny traffic for many situations Understand which service to use for specific situations among GuardDuty/Inspector/Macie/WAF/Shield/Trusted Advisor Requirements for end-to-end SSL (TCP/SSL listeners, ALB vs ELB) also how to use CloudFront and ALB and still have end-to-end SSL in transit How to configure AD for Corporate LDAP Access (Especially how to configure * Trust between AWS/On-Prem) Map Corp users to IAM roles Giving access to external auditors access to your AWS Account (Role./Trust/External ID) CloudTrail configuration for multi-region, single bucket How to automate a specific finding (Use CloudTrail or VPC Flow logs orCloudwatch logs, then use the metric filter, an event to call a lambda) When to use CloudTrail log, CW log, VPC Flow logs How to leverage Athena to view Flow logs When to use Cognito Know AWS Organizations, OU and how to use Service Control Policies to control child organizations incl. Root accounts Be able to Read KMS Key policy / IAM Policies to select what is exactly allowed or denied Know in and outs of KMS Key rotation for AWS Managed Keys, AWS Manager Customer keys, Customer managed Keys How to rotate KMS keys, re-encrypt when? You cannot import key material into existing key Know that AWS Artifact is the place where you can get compliance reports for your services for PCI/HIPAA etc. Know when to use AWS Config (timeline-driven configuration drift) vs Cloudtrail (API calls) and integrate with Lambda functions Secrets Manager vs AWS SSM based encrypted parameters (I believe the choice should be based on limit which tends to be high for Secrets Manager) Know that VPC Endpoints are the secure way for S3 and DynamoDB to connect from private subnets without internet access Use VPC Endpoints policy as an additional measure to control access to buckets Some services not available in AWS — you need to go to Market place/OSS (Packet inspection, Controlling egress using URLs (Squid Proxy for e.g.))Know how to isolate a compromised EC2 instance and keep it aside for Forensic inspection How to take action if your root user leaves the company (clean up what items, how to find what all could have changed) My study materials acloud.guru course All FAQs under AWS Security section in https://aws.amazon.com/faqs/ plus config/cloudtrail/trusted advisor whizlabs practice exams AWS official practice exam — which I got 95% but the actual exam was much tougher White papers (DDoS, KMS best practices, Encryption in AWS, AWS Well Architected Framework Security Pillar) It took me 2:20 hrs to finish for 65 questions longer than I expected","categories":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}]},{"title":"Big Data Analytics Options on AWS","slug":"Big-Data-Analytics-Options-on-AWS","date":"2020-02-12T09:12:49.000Z","updated":"2020-02-12T09:54:15.591Z","comments":true,"path":"AWS/Big-Data-Analytics-Options-on-AWS/","link":"","permalink":"http://blog.ozairs.com/AWS/Big-Data-Analytics-Options-on-AWS/","excerpt":"","text":"This article is an abstraction for the documentation of “Amazon Web Service - Big Data Analytics Options on AWS” 1. Lambda - Durability and AvailabilityAWS Lambda is designed to use replication and redundancy to provide high availability for both the service itself and for the Lambda functions it operates. There are no maintenance windows or scheduled downtimes for either. On failure, Lambda functions being invoked synchronously respond with an exception. Lambda functions being invoked asynchronously are retried at least 3 times, after which the event may be rejected. 2. Lambda - Scalability and ElasticityThere is no limit on the number of Lambda functions that you can run. However, Lambda has a default safety throttle of 1,000 concurrent executions per account per region. 3. Amazon EMRAmazon EMR is a highly distributed computing framework to easily process and store data quickly in a cost-effective manner. Amazon EMR uses Apache Hadoop, an open source framework, to distribute your data and processing across a resizable cluster of Amazon EC2 instances and allows you to use the most common Hadoop tools such as Hive, Pig, Spark, and so on. Hadoop provides a framework to run big data processing and analytics. Amazon EMR does all the work involved with provisioning, managing, and maintaining the infrastructure and software of a Hadoop cluster. 4. Kinesis ConnectorThe Kinesis Connector enables EMR to directly read and query data from Kinesis Data Streams. You can perform batch processing of Kinesis streams using existing Hadoop ecosystem tools such as Hive, Pig, MapReduce, Hadoop Streaming, and Cascading. 5. AWS GlueAWS Glue is a fully managed extract, transform, and load (ETL) service that you can use to catalog your data, clean it, enrich it, and move it reliably between data stores. With AWS Glue, you can significantly reduce the cost, complexity, and time spent creating ETL jobs. AWS Glue is Serverless, so there is noinfrastructure to setup or manage. You pay only for the resources consumed while your jobs are running. Ideal Usage PatternsAWS Glue is designed to easily prepare data for extract, transform, and load (ETL) jobs. Using AWS Glue gives you the following benefits: • AWS Glue can automatically crawl your data and generate code to execute or data transformations and loading processes. • Integration with services like Amazon Athena, Amazon EMR, and Amazon Redshift • Serverless, no infrastructure to provision or manage • AWS Glue generates ETL code that is customizable, reusable, and portable, using familiar technology – Python and Spark. 6. Amazon AthenaAmazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is serverless, so there is no infrastructure to setup or manage, and you can start analyzing data immediately. You don’t need to load your data into Athena, as it works directly with data stored in S3. Just log into the Athena Console, define your table schema, and start querying. Amazon Athena uses Presto with full ANSI SQL support and works with a variety of standard data formats, including CSV,JSON, ORC, Apache Parquet, and Apache Avro.","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://blog.ozairs.com/tags/Big-Data/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"SLI,SLO和SLA之间的区别","slug":"SLI-SLO和SLA之间的区别","date":"2020-02-12T04:30:36.000Z","updated":"2020-02-12T04:35:39.737Z","comments":true,"path":"Security/SLI-SLO和SLA之间的区别/","link":"","permalink":"http://blog.ozairs.com/Security/SLI-SLO和SLA之间的区别/","excerpt":"","text":"尽管SLA，SLO和SLI是不同的概念，但它们之间确有很多相关性。 SLA： Service Lever Agreement是一份由服务提供商向客户承诺的服务可用性，性能等方面的合同。 SLO：Service Level Objective是服务提供商想要达到的更好的性能目标。 SLI： Service Level Indicator，服务提供商用于测量服务目标的一种指标。 服务提供商需要基于SLI收集指标，基于SLO定义指标阈值，并监视指标阈值，以免破坏SLA。在实践中，SLI是监视系统中的指标。 SLO是警报规则，SLA是应用于SLO的监视指标的数量。 通常，SLO和SLA是相似的，而SLO比SLA更紧密。 SLO通常仅用于内部，而SLA仅用于外部。如果服务可用性违反了SLO，则运营人员需要迅速做出反应以避免违反SLA，否则，公司可能需要向客户退款。 SLA，SLO和SLI基于这样的假设，即无法确保该服务100％可用，而是，我们保证该系统将可用性大于某一百分比，例如99.5％。","categories":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}],"tags":[{"name":"SlA","slug":"SlA","permalink":"http://blog.ozairs.com/tags/SlA/"}],"keywords":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}]},{"title":"DDoS简介","slug":"DDoS简介","date":"2020-02-08T12:58:49.000Z","updated":"2020-02-08T13:02:10.211Z","comments":true,"path":"Security/DDoS简介/","link":"","permalink":"http://blog.ozairs.com/Security/DDoS简介/","excerpt":"","text":"本文翻译了AWS Security白皮书《DDoS弹性防护技术最佳实践》，原文链接：https://mark-41.gitbook.io/aws-ddos/。 以下是原文节选： 拒绝服务（DoS）攻击是故意使用户无法使用您的网站或应用程序的尝试，例如通过向网络流量泛洪来进行。 为此，攻击者使用了各种技术，这些技术消耗大量网络带宽或占用其他系统资源，从而破坏了合法用户的访问权限。 以最简单的形式，单一的攻击者使用单个源对目标执行DoS攻击。 在分布式拒绝服务（DDoS）攻击中，攻击者使用多个源（例如，受恶意软件感染的计算机，路由器，IoT设备和其他终结点的分布式组）来组织针对目标的攻击。 受到攻击的主机网络会参与攻击，从而产生大量的数据包或请求使目标不堪重负。 DDoS攻击最常见于OSI模型的第3、4、6和7层。第3层和第4层攻击对应于OSI模型的网络和传输层。 我们将这些统称为基础架构层攻击。 第6层和第7层攻击对应于OSI模型的Presentation和Application层。 我们将它们作为应用程序层攻击一起解决。 以下各节讨论了这些攻击类型的示例。","categories":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}],"tags":[{"name":"AWS, Security","slug":"AWS-Security","permalink":"http://blog.ozairs.com/tags/AWS-Security/"}],"keywords":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}]},{"title":"如何选择合适的EC2实例","slug":"如何选择合适的EC2实例","date":"2020-02-02T09:09:19.000Z","updated":"2020-02-02T09:24:47.795Z","comments":true,"path":"Security/如何选择合适的EC2实例/","link":"","permalink":"http://blog.ozairs.com/Security/如何选择合适的EC2实例/","excerpt":"","text":"原文链接：https://mark-41.gitbook.io/-1/ 【概述】 正确调整实例大小是使实例类型和大小与您的工作负载性能和容量要求相匹配的过程，并且成本要尽可能低。 这也是查看已部署实例并确定在不损害容量或其他要求的情况下消除或缩减规模的过程，从而降低了成本。 正确调整实例大小是优化AWS成本的关键机制，但组织在首次迁移到AWS云时通常会忽略它。 他们举起并改变了他们的环境，并期望稍后再调整大小。 速度和性能通常要优先于成本，这会导致实例过大并浪费大量未使用的资源。","categories":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}],"tags":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/tags/Security/"}],"keywords":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}]},{"title":"AWS云安全介绍","slug":"AWS云安全介绍","date":"2020-02-01T11:22:16.000Z","updated":"2020-02-01T11:29:27.706Z","comments":true,"path":"Security/AWS云安全介绍/","link":"","permalink":"http://blog.ozairs.com/Security/AWS云安全介绍/","excerpt":"","text":"这是AWS官方提供的关于AWS云安全的介绍文档，具体链接参见：https://156709406.gitbook.io/aws-1/","categories":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}],"tags":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/tags/Security/"}],"keywords":[{"name":"Security","slug":"Security","permalink":"http://blog.ozairs.com/categories/Security/"}]},{"title":"Why We Moved to Apache Pulsar","slug":"Why-We-Moved-to-Apache-Pulsar","date":"2019-10-25T11:35:44.000Z","updated":"2019-10-25T11:59:34.248Z","comments":true,"path":"Apache/Why-We-Moved-to-Apache-Pulsar/","link":"","permalink":"http://blog.ozairs.com/Apache/Why-We-Moved-to-Apache-Pulsar/","excerpt":"","text":"Nowadays, we may need to interact with millions of consumers every day through the retailers we serve. Consumers rely on us for timely reminders and updates on their accounts, on the state of their orders and packages, and on the status of their returns. On the other hand, our business customers — hundreds of the biggest retailers and brands in the world — rely on us for flexibility to configure Narvar’s product for the needs of their consumers. Our platform helps retailers and brands by processing data and events to ensure timely and accurate communication with their customers. To handle that, we built our platform using a variety of messaging and processing technologies over time, from Kafka to Amazon SQS, Kinesis Streams to Kinesis Firehose, RabbitMQ to AWS Lambda. Many of these systems were native to AWS and easy to adopt and get up and running. These systems worked well and they served our needs…for a while. Our ChallengesAs the company grew and new business use cases began to emerge, we found these systems didn’t quite work as well as needed to address the new and expanded requirements of those use cases. As we grew our customer base it became clear it was not easy to process events in configurable ways that scaled accordingly. As we saw more applications needing to consume events, it required spinning up new services that entailed maintenance overhead or using expensive Amazon Lambdas. For other business cases that emerged, we saw that Kinesis Firehose did not provide the flexibility needed to output data in the form and structure that was required. As we saw a growing number of use cases that required strong in-order guarantees and topic scalability, it became clear that many of the solutions we were using were not suited for those new challenges. In addition to these challenges from emerging business use cases, we also saw challenges of scale. As our traffic grew, it became apparent that the growing amount of DevOps and developer support required to maintain and scale these systems was unsustainable. Many of them were not containerized, making infrastructure configuration and management burdensome, and required frequent manual intervention. Systems like Kafka — while reliable, popular and open source — had significant maintenance overhead as we scaled. For example, increasing throughput required increasing partitions, tuning consumers, and required a large amount of manual intervention by developers and DevOps. At the same time, solutions like Kinesis Streams and Kinesis Firehose were not cloud-agnostic, making it hard to decouple the choice of cloud solutions from functionality and making it difficult to leverage technologies in other clouds, and to support customers who needed to run in other clouds. Faced with the challenges of these emerging business cases and the hassles that we were encountering as we scaled, we decided to move to Apache Pulsar. Why Apache PulsarLike Kafka, Pulsar was reliable, cloud-agnostic and open-sourced. Unlike Kafka, Pulsar entailed very little maintenance overhead and scaled with minimal manual intervention. Pulsar was containerized and built on Kubernetes (ie. is ‘cloud native’) from the outset, and while it had multiple complex components within, it was easy to spin up and scale with the help of the Streamlio team. Version upgrades were easy to apply to a given cluster without much incurred downtime. Streamlio provided us with system monitoring dashboards (based on Grafana) making it easy to monitor out of the box. In addition to being scalable and much more maintainable, Pulsar came with differentiating features that made several of our business use cases possible. For example, we gained access to Pulsar Functions, which helped us scale up the number of things we did with the consumed events while eliminating the need for expensive Lambda functions or standing up additional services. Stronger support for in-order guarantees within a topic enabled several more business use cases. Finally, Pulsar provided a broad set of features and functionalities all in one system, thus eliminating the need for many of the point solutions we had been using. It eliminated the need for multiple messaging technologies — Kafka for pub/sub and RabbitMQ and Amazon SQS for queueing. Also, we no longer required Kinesis Streams for processing nor Kinesis Firehose to load streaming data into data stores. Moving from this list of technologies to Pulsar helped us reduce cost and complexity as well as make it easier to support other cloud infrastructure providers. Narvar has been using Pulsar live in production for close to a year now and it has proven to be a very reliable workhorse. 【译文】 现今，我们正日益面临着每天需要通过服务的零售商与数百万消费者互动的情形。消费者依赖我们的及时提醒和更新其帐户，订单和包裹的状态以及退货的状态。另一方面，我们的商业客户-世界上数百个最大的零售商和品牌- 依靠我们来灵活地配置产品以满足其消费者的需求。 我们的平台通过处理数据和事件来帮助零售商和品牌，以确保与他们的客户及时，准确地沟通。为了解决这个问题，我们随着时间的推移使用了各种消息传递和处理技术来构建平台，从Kafka到Amazon SQS，从Kinesis Streams到Kinesis Firehose，从RabbitMQ到AWS Lambda。这些系统中的许多系统是AWS固有的，易于采用，启动和运行。这些系统运行良好，可以在一段时间内满足我们的需求。 我们的挑战但是，随着公司的发展和新业务用例的发展，我们发现这些系统不能很好地满足那些用例的新需求和扩展需求。随着我们扩大客户群，很明显，想要使用可扩展的方式配置事件并不容易。随着我们看到更多需要消耗事件的应用程序，它需要分解新的服务，这需要维护费用或使用昂贵的Amazon Lambda。对于出现的其他业务案例，我们看到Kinesis Firehose没有提供以所需形式和结构输出数据所需的灵活性。随着我们看到越来越多的用例需要强大的有序保证能力和主题可伸缩性，很明显，我们使用的许多解决方案都不适合这些新挑战。 除了新兴业务用例带来的这些挑战之外，我们还需要应对快速增长的业务规模所带来的挑战。随着流量的增长，很明显，维持和扩展这些系统所需的DevOps和开发人员支持的增长是不可持续的。其中许多没有进行容器化，使得基础结构配置和管理负担沉重，需要频繁的手动干预。 像Kafka这样的系统虽然可靠，流行且开源，但维护费用却很大。例如，增加吞吐量需要增加分区，调整使用者，并需要开发人员和DevOps进行大量手动干预。同时，诸如Kinesis Streams和Kinesis Firehose之类的解决方案都与云密切相关，这使得很难将云解决方案的选择与功能脱钩，并且难以利用其他云的技术，难以为需要在除AWS以外其他云上运行服务的客户提供技术支持。。 面对这些新兴业务案例的挑战以及在扩展过程中遇到的麻烦，我们决定迁移到Apache Pulsar。 为什么选择Apache Pulsar像Kafka一样，Pulsar是可靠的，支持多种云平台，并且是开源的。与Kafka不同，Pulsar的维护费用非常少，并且只需很少的人工干预即可扩展。Pulsar从一开始就被容器化并构建在Kubernetes上（即“云原生”），尽管其中包含多个复杂组件，但在Streamlio团队的帮助下很容易扩展和扩展。 版本升级很容易 应用于给定集群，而不会造成大量停机。Streamlio为我们提供了系统监视仪表板（基于Grafana），可轻松进行开箱即用的监视。 除了具有可扩展性和可维护性之外，Pulsar还具有与众不同的功能，这些功能使我们的多个业务用例成为可能。例如，我们获得了对Pulsar函数的访问权限，这有助于我们扩展已处理事件的处理数量，同时消除了对昂贵的Lambda函数或者启动的其他服务的需求。主题内部对于顺序保证的强大支持能力使更多的业务用例得以实现。 最终，Pulsar在一个系统中提供了广泛的特性和功能，从而消除了我们一直在使用的许多解决方案的需求。它消除了对多种消息传递技术的需求-用于发布/订阅和RabbitMQ的Kafka和用于队列的Amazon SQS。同样，我们不再需要Kinesis Streams进行处理，也不再需要Kinesis Firehose将流数据加载到数据存储中。将技术堆栈转移到Pulsar，不仅帮助我们降低了成本和复杂性，而且使得支撑其他云平台的工作变得更加轻松。我们在生产中使用Pulsar已有近一年的时间，事实证明它是非常可靠的主力。","categories":[{"name":"Apache","slug":"Apache","permalink":"http://blog.ozairs.com/categories/Apache/"}],"tags":[{"name":"Apache Pulsar","slug":"Apache-Pulsar","permalink":"http://blog.ozairs.com/tags/Apache-Pulsar/"}],"keywords":[{"name":"Apache","slug":"Apache","permalink":"http://blog.ozairs.com/categories/Apache/"}]},{"title":"什么是Kops?","slug":"什么是Kops","date":"2019-09-25T12:27:50.000Z","updated":"2019-09-25T12:36:53.182Z","comments":true,"path":"Kubernetes/什么是Kops/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/什么是Kops/","excerpt":"","text":"今天，我们将以我们最近对Kubernetes生态系统的报道为基础，以更深入地讨论Kops。这篇文章是对我们今年早些时候的Kubernetes网络研讨会的补充，并且是在之前的文章中介绍的，这些文章涵盖了 使用Helm部署应用程序 以及使用Kops 创建和维护Kubernetes集群。让我们首先解决一个基本问题：什么是Kops？ 什么是Kops？Kops是Kubernetes的官方项目，用于管理生产级Kubernetes集群。Kops当前是将Kubernetes集群部署到Amazon Web Services的最佳工具。该项目将自己描述为集群的kubectl。 (Kops is an official Kubernetes project for managing production-grade Kubernetes clusters. Kops is currently the best tool to deploy Kubernetes clusters to Amazon Web Services. The project describes itself as kubectl for clusters.) 如果您熟悉kubectl，那么Kops会让您感到宾至如归。它具有创建集群，更新集群设置和应用更改的命令。Kops使用声明性配置，因此足够聪明，知道如何将基础结构更改应用于现有集群。它还支持集群操作任务，例如扩展节点或水平扩展集群。Kops可以在AWS上自动运行大部分Kubernetes。 在继续进行示例之前，让我们看一下它的主要功能： 将群集部署到现有的虚拟私有云（VPC）或从头开始创建新的VPC 支持公共和私有拓扑 设置单个或多个主群集 可配置的堡垒机器，用于通过SSH访问单个群集节点 建立在状态同步模型上以实现空运行和自动幂等 直接基础架构操纵，或与CloudFormation和Terraform一起使用 滚动集群更新 通过创建多个实例组来支持异构集群 请查看此 简短的ASCII转换演示 以获取更多信息。现在，我们将解决一个常见的情况：创建一个集群并为您的用例进行配置。 在AWS上创建第一个Kubernetes集群您需要配置IAM权限和的S3存储桶KOPS_STATE_STORE。KOPS_STATE_STORE是Kops管理的所有集群的真实来源。您需要适当的IAM权限，以便Kops可以代表您进行API调用。我不会在这篇文章中介绍它，但是您可以按照此处的说明进行操作。 您还需要配置DNS。Kops支持多种配置。每个都有自己的设置说明。具有现有HostedZone的AWS Route53是最简单的。slashdeploy.com在这些示例中，我们假设有一个现有的AWS Route53 HostedZone 。Kops群集必须是有效的DNS名称。让我们创建demo.slashdeploy.com集群。Kops还将在api.demo.slashdeploy.com和处为Kubernetes API服务器创建DNS记录bastion.demo.slashdeploy.com。请记住，DNS名称可能只有这么长，因此请勿使用太长的基本群集名称。一切始于kops create。您可以将选项直接传递给命令或编写集群规范文件。在本练习中，我们将使用命令行选项。使用专用文件非常适合源代码控制和其他形式的配置管理。kops create接受很多选择。我们将从最简单的情况开始，仅提供所需的选项。 1234$ kops create cluster \\ --yes \\ --zones=eu-west-1a,eu-west-1b,eu-west-1c \\ demo.slashdeploy.com 有两个必需的值。--zones指出GCP区域/ AWS地区在何处创建基础架构。在此，指定了eu-west-1a，eu-west-1b，eu-west-1c。这指示Kops在每个eu-west-1可用区中创建基础结构。这很重要，因为Kops旨在创建高可用性生产集群。多个可用区通过防止一个可用区中的故障使群集更加可靠。 您还必须指定群集名称。--yes确认通常提示确认的操作。为新集群kops create 添加一个kubectl配置条目，因此您可以立即使用它。该命令是异步的。它会触发基础结构的创建，但不会完全阻止它。幸运的是，Kops包含用于验证集群的命令。您可以 重新运行此命令，直到成功为止。 1$ kops validate demo.slashdeploy.com 一切完成后，您应该会看到类似以下内容的内容： 123456789101112131415$ kops validate cluster demo.slashdeploy.comValidating cluster demo.slashdeploy.comINSTANCE GROUPSNAME ROLE MACHINETYPE MIN MAX SUBNETSmaster-eu-west-1a Master m3.medium 1 1 eu-west-1amaster-eu-west-1b Master m3.medium 1 1 eu-west-1bmaster-eu-west-1c Master m3.medium 1 1 eu-west-1cnodes Node t2.medium 2 2 eu-west-1a,eu-west-1b,eu-west-1cNODE STATUSNAME ROLE READYip-172-20-120-240.eu-west-1.compute.internal master Trueip-172-20-50-132.eu-west-1.compute.internal master Trueip-172-20-66-106.eu-west-1.compute.internal master Trueip-172-20-75-89.eu-west-1.compute.internal node TrueYour cluster demo.slashdeploy.com is ready 现在，您可以运行任何kubectl命令，例如kubectl get pods -n kube-system。集群有点奇怪，因为它有三个主服务器，只有一个从服务。让我们更新节点实例组。 修改集群基础架构记住，kops行为就像kubectl。这意味着您可以kops edit在编辑器中编辑配置文件。下一步是运行kops update。这将应用配置更改，但不会修改正在运行的基础结构。kops rolling-update管理更新或重新创建基础结构。 此过程适用于各种配置更改。首先edit，然后update，最后 rolling-update。让我们通过编辑节点实例组以增加辅助节点的数量来尝试一下。 1$ kops edit instancegroup nodes 这将在编辑器中打开一个YAML文件。您将看到类似于以下内容： 1234567891011121314151617apiVersion: kops/v1alpha2kind: InstanceGroupmetadata: creationTimestamp: &quot;2017-04-05T15:33:52Z&quot; labels: kops.k8s.io/cluster: demo.slashdeploy.com name: nodesspec: image: kope.io/k8s-1.5-debian-jessie-amd64-hvm-ebs-2017-01-09 machineType: t2.medium maxSize: 1 minSize: 1 role: Node subnets: - eu-west-1a - eu-west-1b - eu-west-1c 我们需要做的就是替换minSize 并maxSize 使用适当的值。我将两个值都设置为3 并保存文件。这会将更新的文件写回到KOPS_STATE_STORE。现在，我们需要update 集群。同样，我们将提供--yes 确认更改。 123456789101112131415$ kops update cluster --yesUsing cluster from kubectl context: demo.slashdeploy.comI0422 07:34:58.458492 26834 executor.go:91] Tasks: 0 done / 114 total; 35 can runI0422 07:34:59.990241 26834 executor.go:91] Tasks: 35 done / 114 total; 26 can runI0422 07:35:01.211466 26834 executor.go:91] Tasks: 61 done / 114 total; 36 can runI0422 07:35:04.215344 26834 executor.go:91] Tasks: 97 done / 114 total; 10 can runI0422 07:35:04.845173 26834 dnsname.go:107] AliasTarget for &quot;api.demo.slashdeploy.com.&quot; is &quot;api-demo-1201911436.eu-west-1.elb.amazonaws.com.&quot;I0422 07:35:05.045363 26834 executor.go:91] Tasks: 107 done / 114 total; 7 can runI0422 07:35:05.438759 26834 executor.go:91] Tasks: 114 done / 114 total; 0 can runI0422 07:35:05.438811 26834 dns.go:140] Pre-creating DNS recordsI0422 07:35:06.707548 26834 update_cluster.go:204] Exporting kubecfg for clusterWrote config for demo.slashdeploy.com to &quot;/home/ubuntu/.kube/config&quot;Kops has set your kubectl context to demo.slashdeploy.comCluster changes have been applied to the cloud.Changes may require instances to restart: kops rolling-update cluster 最后，应用rolling-update。 123456789$ kops rolling-update cluster --yesUsing cluster from kubectl context: demo.slashdeploy.comNAME STATUS NEEDUPDATE READY MIN MAX NODESbastions Ready 0 1 1 1 0master-eu-west-1a Ready 0 1 1 1 1master-eu-west-1b Ready 0 1 1 1 1master-eu-west-1c Ready 0 1 1 1 1nodes Ready 0 3 3 3 3No rolling-update required 有点奇怪 Kops说，不需要滚动更新。这是正确的，因为我们仅更改了nodes 自动伸缩组中的最小实例数和最大实例数。这不需要对现有基础架构进行任何更改。AWS仅触发两个实例的创建。让我们进行另一项需要更改基础结构的更改。想象一下，现有的t2 .medium 实例没有削减它。我们需要扩大规模以满足工作量要求。为此，我们需要更改实例类型。同样的edit，update和rolling-update 流程适用于此处。让我们升级到m4.large。重复练习，将t2替换为.medium ，m4.large 然后应用rolling-update。现在，Kops杀死每个节点以触发创建最新节点。 1234567891011$ kops rolling-update cluster --yesUsing cluster from kubectl context: demo.slashdeploy.comNAME STATUS NEEDUPDATE READY MIN MAX NODESbastions Ready 0 1 1 1 0master-eu-west-1a Ready 0 1 1 1 1master-eu-west-1b Ready 0 1 1 1 1master-eu-west-1c Ready 0 1 1 1 1nodes NeedsUpdate 3 0 3 3 3I0422 07:42:31.615734 659 rollingupdate_cluster.go:281] Stopping instance &quot;i-038cbac0aeaca24d4&quot; in AWS ASG &quot;nodes.demo.slashdeploy.com&quot;I0422 07:44:31.920426 659 rollingupdate_cluster.go:281] Stopping instance &quot;i-046fe9866a3b51fe6&quot; in AWS ASG &quot;nodes.demo.slashdeploy.com&quot;I0422 07:46:33.539412 659 rollingupdate_cluster.go:281] Stopping instance &quot;i-07f924becaa46d2ab&quot; in AWS ASG &quot;n 注意！当前版本（&lt;= 1.6）尚未执行真正的滚动更新。将会发生停机。问题＃37我们实现了一项新功能，该功能可以耗尽并验证节点。此功能是实验性的，您可以通过设置使用新功能export KOPS_FEATURE_FLAGS=&quot;+DrainAndValidateRollingUpdate&quot;。此问题应在将来的版本中修复。 此过程适用于基础结构和配置（例如kubelet 标志或API服务器标志）。该文档涵盖以下特定情况： 更改根卷大小 使用竞价型实例 配置kubelet标志 配置api服务器标志 与往常一样，您可以参考文档以获取完整信息。 自定义集群基础架构我们的示例涵盖了最简单的情况，但这并不适用于所有情况。让我们逐步了解可用的不同选项 kops create cluster。 12345678910111213141516171819202122232425262728293031323334353637$ kops create cluster --helpCreates a k8s cluster.Usage: kops create cluster [flags]Flags: --admin-access stringSlice Restrict access to admin endpoints (SSH, HTTPS) to this CIDR. If not set, access will not be restricted by IP. (default [0.0.0.0/0]) --associate-public-ip Specify --associate-public-ip=[true|false] to enable/disable association of public IP for master ASG and nodes. Default is &apos;true&apos;. --bastion Pass the --bastion flag to enable a bastion instance group. Only applies to private topology. --channel string Channel for default versions and configuration to use (default &quot;stable&quot;) --cloud string Cloud provider to use - gce, aws --dns string DNS hosted zone to use: public|private. Default is &apos;public&apos;. (default &quot;Public&quot;) --dns-zone string DNS hosted zone to use (defaults to longest matching zone) --image string Image to use --kubernetes-version string Version of kubernetes to run (defaults to version in channel) --master-count int32 Set the number of masters. Defaults to one master per master-zone --master-security-groups stringSlice Add precreated additional security groups to masters. --master-size string Set instance size for masters --master-zones stringSlice Zones in which to run masters (must be an odd number) --model string Models to apply (separate multiple models with commas) (default &quot;config,proto,cloudup&quot;) --network-cidr string Set to override the default network CIDR --networking string Networking mode to use. kubenet (default), classic, external, cni, kopeio-vxlan, weave, calico. (default &quot;kubenet&quot;) --node-count int32 Set the number of nodes --node-security-groups stringSlice Add precreated additional security groups to nodes. --node-size string Set instance size for nodes --out string Path to write any local output --project string Project to use (must be set on GCE) --ssh-public-key string SSH public key to use (default &quot;~/.ssh/id_rsa.pub&quot;) --target string Target - direct, terraform (default &quot;direct&quot;) -t, --topology string Controls network topology for the cluster. public|private. Default is &apos;public&apos;. (default &quot;public&quot;) --vpc string Set to use a shared VPC --yes Specify --yes to immediately create the cluster --zones stringSlice Zones in which to run the cluster--vpc and --newtork-cidr can be used when deploying to an existing AWS VPC.--bastion generates a dedicated SSH jump host for SSH access to cluster instances. This is best used with --associate-public-ip=false.--master-zones specifies all of the zones where masters run. This is key for HA setups.--networking sets the default network. Note that your particular choice depends on your requirements and may work with the specified --topology.--topology is the internal networking state. I prefer --bastion --topology=private --associate-public-ip=false --networking=weave to keep the clusters inaccessible on the public internet. --vpc 并且--newtork-cidr 可以在部署到现有的AWS VPC时使用。 --bastion 生成专用的SSH跳转服务器，以SSH访问群集实例。最好与--associate-public-ip=false. --master-zones 指定主服务器运行的所有区域。这是HA设置的关键。 --networking 设置默认网络。请注意，您的特定选择取决于您的要求，并且可以与指定的--topology. --topology 是内部联网状态。我更喜欢--bastion --topology=private --associate-public-ip=false --networking=weave使群集无法在公共互联网上访问。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Kops","slug":"Kops","permalink":"http://blog.ozairs.com/tags/Kops/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"如何一次性通过AWS DevOps Professional认证考试！","slug":"如何一次性通过AWS-DevOps-Professional认证考试！","date":"2019-09-15T01:18:53.000Z","updated":"2019-09-15T01:24:56.878Z","comments":true,"path":"uncategorized/如何一次性通过AWS-DevOps-Professional认证考试！/","link":"","permalink":"http://blog.ozairs.com/uncategorized/如何一次性通过AWS-DevOps-Professional认证考试！/","excerpt":"","text":"我最近有机会参加AWS DevOps专业认证考试，并在第一次尝试时设法清除它。我已经在第一次尝试时提供了清除AWS DevOps Professional认证考试所需的一些AWS服务的一些信息。 首先要了解考试中包含的各个领域及其在考试中的相关百分比，简要地从理论上了解了域中列出的所有服务，如果您没有任何实践所有这些服务的经验，那么您必须了解服务在理论上如何在各种情况下工作。 1）Code Commit：了解用户如何创建repo，使用SSH / HTTPS从相应的repo克隆并使用正确的IAM权限，确保用户不在没有他/她在正确的IAM组的情况下提交master分支，了解如何您可以使用正确的IAM策略限制该用户。 2）Code Build：首先在所需的Ec2实例中构建一个示例hello world应用程序，通过从源获取文件以及如何构建推送到任何所需目标的工件来了解代码构建的工作原理。创建自己的buildspec.yaml文件。 3）Code Deploy：了解与AWS代码部署相关的各种部署类型，如何根据应用程序要求和兼容性在不同场景中使用它们，不能强调这一点代码部署部署类型对于考试非常重要。创建自己的appspec.yaml文件。 4）Code Pipeline：了解CI / CD管道的工作原理，如何与上述三种服务集成并触发管道。有关最佳实践，请了解如何使用AWS警报机制添加批准阶段并向所需组触发警报，了解如何基于代码提交提交触发管道。 5）Elastic Beanstalk：非常非常……对于考试来说很重要，请确保掌握这项服务的知识，创建示例应用程序，了解Elastic Beanstalk提供的各种部署类型。熟悉eb cli和.ebextensions文件夹及其文件结构。获取有关eb基本和增强监控的知识。使用eb练习蓝色/绿色部署，获取有关金丝雀部署的知识。熟悉与eb相关的docker。 6）Lambda：深入了解如何创建lambda函数，如何创建不可变版本以及将流量路由到不同版本。了解Lambda Edge的云端缓存和源。 7）OpsWorks：非常非常……对于考试来说很重要，了解与opsworks相关的不同阶段，获得有关厨师及其文件夹结构的知识。获取有关opsworks生命周期事件的知识。练习如何使用OpsWorks图层创建多层体系结构。 8）Elastic Container Service：不要求如此深入，了解ECS的机制，其任务和服务，如何创建任务和服务，如何使用与ECS的私有注册表的docker镜像。 9）CloudFormation：非常非常……对于考试来说很重要，了解云形成的IN和OUT，无法描述与云形成有关的考试的重要性，你需要知道IN和OUT，练习用不同的语法创建模板功能可用，练习云形成帮助脚本。 10）CloudWatch：CloudWatch是一个很大的主题，可以通过事件，警报，指标和触发器尽可能多地了解。了解其他服务如何触发CloudWatch警报以及警报可以执行的操作，您可以与之关联的钩子，了解与云监视及其相关应用程序日志记录关联的一些示例用例和方案。 https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html 11）VPC Flow logs：获取有关流日志概念的基本知识，并了解示例日志中关联的所有元素，例如，日志包含Vpc流日志的版本，accountID，interfaceID，sourceIP，目标地址等等，获取基本知识了解整个日志的外观。 https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html 12）CloudTrail：了解云跟踪API日志如何帮助审核，谁可以查看日志，如何使用IAM策略限制日志，以及如何防止日志被篡改。 13）X Ray：只要知道这项服务是什么，如何使用这个X射线sdk识别app中的瓶颈。 https://github.com/aws-samples/aws-xray-cloudwatch-event 14）Delegation Access：获取该服务如何工作的基本知识，如何存储其他帐户密钥以及如何使用此服务访问其他帐户，如何从一个帐户登录并切换到其他帐户，需要具备哪些权限这个角色。 15）AWS SAM：获取非常基础的知识。 16）EC2系 System Manager：非常非常重要……对于考试而言，您将在许多问题中获得与EC2 System Manager服务相关的概念，了解如何使用此系统管理器服务同时在多个实例上运行脚本，如何补丁服务器，如何添加本地服务器和EC2实例，如何使用标记区分它们并通过分组对其进行修补。 17）AWS License Manager，**Data Lifecycle Management, Secret Manager, AWS Catalog, AWS organizations, EC2 Auto recovery, Parameter Store**：了解这些服务如何工作，与使用这些服务相关的最佳实践是什么以及如何将它们集成在一起在所需的场景中，您不会对这些服务如何工作有疑问，而是如何在不同场景中使用它们。 18）DynamoDB：对于考试很重要，您将会遇到如何使用DynamoDB提高应用程序性能的问题，使用DynamoDB的最佳实践是什么，如何在高可用性和容错性下工作，了解DynamoDB流概念。了解什么是DynamoDB加速器，读取容量单位，写入容量单位，排序键和分区键。 19）RDS：需要深入了解RDS读取副本，RDS multiAZ和RDS快照。 20）Elastic Load Balancer，Route53，Auto Scaling Groups，EBS Volumes，S3：在您尝试DevOps专业考试之前，请确保您对这些服务有深入的了解，可以给您足够的压力，了解这些服务的IN和OUT，在您了解这些服务之前不要尝试此考试，因为它们是您将在许多问题中看到的基本AWS服务，这些服务就像先决条件。 21）AWS Kinesis：知道AWS Kinesis用于实时数据分析，这是您可以记住的关键词，知道Kinesis Data Analytics，Firehose，Streams和视频流如何工作以及如何用于处理和分析。 22）了解IAM Access advisor, AWS cost explorer, Trusted Advisor, GuardDuty, Inspector的基本知识**。这些服务在考试中并不多，但它们将作为选项出现。 专业提示：为了更好地理解概念和服务，请观看acloudguru，linuxacademy视频教程，完成kplabs来自Udemy的AWS devops专业认证课程，从Whizlabs获得练习考试。主要的AWS DevOps专业认证考试包括一些技术复杂性，冗长的问题以及冗长的选项。由于大问题，很难集中精力直到最后。避免在任何给定问题上花费超时，根据问题中要求的服务进行关键字匹配。当您为任何给定问题选择正确的选项时，请确保考虑具有成本效益且包含最佳实践的选项。 祝好运！ 希望你喜欢这篇文章，发现它很有帮助！","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[]},{"title":"How to pass Azure103: Miscrosoft Azure Administrator","slug":"How-to-pass-Azure103-Miscrosoft-Azure-Administrator","date":"2019-06-19T12:09:22.000Z","updated":"2019-06-19T12:16:45.662Z","comments":true,"path":"Azure/How-to-pass-Azure103-Miscrosoft-Azure-Administrator/","link":"","permalink":"http://blog.ozairs.com/Azure/How-to-pass-Azure103-Miscrosoft-Azure-Administrator/","excerpt":"","text":"Manage Azure subscriptions and resources (15-20%)Manage Azure subscriptions assign administrator permissions configure cost center quotas and tagging configure Azure subscription policies at Azure subscription level Analyze resource utilization and consumption configure diagnostic settings on resources create baseline for resources create and rest alerts analyze alerts across subscription analyze metrics across subscription create action groups monitor for unused resources monitor spend report on spend utilize Log Search query functions view alerts in Log Analytics Manage resource groups use Azure policies for resource groups configure resource locks configure resource policies identify auditing requirements implement and set tagging on resource groups move resources across resource groups remove resource groups Managed role based access control (RBAC) create a custom role configure access to Azure resources by assigning roles configure management access to Azure, troubleshoot RBAC, implement RBAC policies, assign RBAC Roles Implement and manage storage (15-20%)Create and configure storage accounts configure network access to the storage account create and configure storage account generate shared access signature install and use Azure Storage Explorer manage access keys monitor activity log by using Log Analytics implement Azure storage replication Import and export data to Azure create export from Azure job create import into Azure job Use Azure Data Box configure and use Azure blob storage configure Azure content delivery network (CDN) endpoints Configure Azure files create Azure file share create Azure File Sync service create Azure sync group troubleshoot Azure File Sync Implement Azure backup configure and review backup reports perform backup operation create Recovery Services Vault create and configure backup policy perform a restore operation Deploy and manage virtual machines (VMs) (15-20%)Create and configure a VM for Windows and Linux configure high availability configure monitoring, networking, storage, and virtual machine size deploy and configure scale sets Automate deployment of VMs modify Azure Resource Manager (ARM) template configure location of new VMs configure VHD template deploy from template save a deployment as an ARM template deploy Windows and Linux VMs Manage Azure VM add data discs add network interfaces automate configuration management by using PowerShell Desired State Configuration (DSC) and VM Agent by using custom script extensions manage VM sizes; move VMs from one resource group to another redeploy VMs Manage VM backups configure VM backup define backup policies implement backup policies perform VM restore Azure Site Recovery Configure and manage virtual networks (30-35%)Create connectivity between virtual networks create and configure VNET peering create and configure VNET to VNET verify virtual network connectivity create virtual network gateway Implement and manage virtual networking configure private and public IP addresses, network routes, network interface, subnets, and virtual network Configure name resolution configure Azure DNS configure custom DNS settings configure private and public DNS zones Create and configure a Network Security Group (NSG) create security rules associate NSG to a subnet or network interface identify required ports evaluate effective security rules Implement Azure load balancer configure internal load balancer, configure load balancing rules, configure public load balancer, troubleshoot load balancing Monitor and troubleshoot virtual networking monitor on-premises connectivity, use Network resource monitoring, use Network Watcher, troubleshoot external networking, troubleshoot virtual network connectivity Integrate on premises network with Azure virtual network create and configure Azure VPN Gateway, create and configure site to site VPN, configure Express Route, verify on premises connectivity, troubleshoot on premises connectivity with Azure Manage identities (15-20%)Manage Azure Active Directory (AD) add custom domains Azure AD Join configure self-service password reset manage multiple directories Manage Azure AD objects (users, groups, and devices) create users and groups manage user and group properties manage device settings perform bulk user updates manage guest accounts Implement and manage hybrid identities install Azure AD Connect, including password hash and pass-through synchronization use Azure AD Connect to configure federation with on-premises Active Directory Domain Services (AD DS) manage Azure AD Connect manage password sync and password writeback Implement multi-factor authentication (MFA) configure user accounts for MFA, enable MFA by using bulk update, configure fraud alerts, configure bypass options, configure Trusted IPs, configure verification methods 【翻译】 ###管理Azure订阅和资源（15-20％） 管理Azure订阅 分配管理员权限 配置成本中心配额和标记 在Azure订阅级别配置Azure订阅策略 分析资源利用率和消耗量 配置资源的诊断设置 为资源创建基线 创建和休息警报 分析订阅中的警报 分析订阅中的指标 创建行动小组 监控未使用的资源 监控支出 报告支出 利用日志搜索查询功能 在Log Analytics中查看警报 管理资源组 对资源组使用Azure策略 配置资源锁 配置资源策略 确定审计要求 在资源组上实现和设置标记 跨资源组移动资源 删除资源组 基于托管角色的访问控制（RBAC） 创建自定义角色 通过分配角色配置对Azure资源的访问 配置对Azure的管理访问，对RBAC进行故障排除，实施RBAC策略，分配RBAC角色 ###实施和管理存储（15-20％） 创建和配置存储帐户 配置对存储帐户的网络访问 创建和配置存储帐户 生成共享访问签名 安装和使用Azure Storage Explorer 管理访问密钥 使用Log Analytics监控活动日志 实施Azure存储复制 将数据导入和导出到Azure 从Azure作业创建导出 创建导入Azure作业 使用Azure数据框 配置和使用Azure blob存储 配置Azure内容传送网络（CDN）端点 配置Azure文件 创建Azure文件共享 创建Azure文件同步服务 创建Azure同步组 解决Azure文件同步问题 实施Azure备份 配置和查看备份报告 执行备份操作 创建Recovery Services Vault 创建和配置备份策略 执行还原操作 ###部署和管理虚拟机（VM）（15-20％） 为Windows和Linux创建和配置VM 配置高可用性 配置监控，网络，存储和虚拟机大小 部署和配置规模集 自动部署VM 修改Azure资源管理器（ARM）模板 配置新VM的位置 配置VHD模板 从模板部署 将部署保存为ARM模板 部署Windows和Linux VM 管理Azure VM 添加数据光盘 添加网络接口 使用自定义脚本扩展，使用PowerShell所需状态配置（DSC）和VM代理自动执行配置管理 管理VM大小;将VM从一个资源组移动到另一个资源组 重新部署VM 管理VM备份 配置VM备份 定义备份策略 实施备份策略 执行VM还原 Azure Site Recovery ###配置和管理虚拟网络（30-35％） 在虚拟网络之间建立连接 创建和配置VNET对等 创建和配置VNET到VNET 验证虚拟网络连接 创建虚拟网络网关 实施和管理虚拟网络 配置私有和公共IP地址，网络路由，网络接口，子网和虚拟网络 配置名称解析 配置Azure DNS 配置自定义DNS设置 配置私有和公共DNS区域 创建和配置网络安全组（NSG） 创建安全规则 将NSG关联到子网或网络接口 确定所需的端口 评估有效的安全规则 实施Azure负载均衡器 配置内部负载均衡器，配置负载均衡规则，配置公共负载均衡器，解决负载均衡问题 监控和排除虚拟网络故障 监控本地连接，使用网络资源监控，使用网络监控程序，排除外部网络故障，排除虚拟网络连接故障 使用Azure虚拟网络集成本地网络 创建和配置Azure VPN网关，创建和配置站点到站点VPN，配置Express Route，验证内部连接，使用Azure进行内部连接故障排除 ###管理身份（15-20％） 管理Azure Active Directory（AD） 添加自定义域名 Azure AD加入 配置自助密码重置 管理多个目录 管理Azure AD对象（用户，组和设备） 创建用户和组 管理用户和组属性 管理设备设置 执行批量用户更新 管理访客帐户 实施和管理混合身份 安装Azure AD Connect，包括密码哈希和传递同步 使用Azure AD Connect配置与本地Active Directory域服务（AD DS）的联合 管理Azure AD Connect 管理密码同步和密码回写 实施多重身份验证（MFA） 为MFA配置用户帐户，使用批量更新启用MFA，配置欺诈警报，配置旁路选项，配置可信IP，配置验证方法","categories":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}],"tags":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/tags/Azure/"}],"keywords":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}]},{"title":"通过Powershell 登陆Azure（Azure MoonCake为例）一般常见的有两种方式","slug":"通过Powershell-登陆Azure（Azure-MoonCake为例）一般常见的有两种方式","date":"2019-06-19T12:03:16.000Z","updated":"2019-06-19T12:04:53.099Z","comments":true,"path":"Azure/通过Powershell-登陆Azure（Azure-MoonCake为例）一般常见的有两种方式/","link":"","permalink":"http://blog.ozairs.com/Azure/通过Powershell-登陆Azure（Azure-MoonCake为例）一般常见的有两种方式/","excerpt":"","text":"1. 用户交互式登陆前提条件：有一个AAD account此种登陆方式会弹出一个登陆框，让你输入一个.onmschina.cn的账号，然后根据选择的订阅操作相应的资源。 123456789# set Azure Enviroment into China Mooncake. $EnvironmentName =&quot;AzureChinaCloud&quot; # Give your subcriptionID here. $SubscriptionId=&quot;*********&quot; ##login Login-AzureRmAccount -EnvironmentName &apos;AzureChinaCloud&apos; Set-AzureRmContext -SubscriptionId $SubscriptionId 缺点：会弹出登陆框，让你输入账号密码进行登陆，不适合自动化场景。 此处也能改成隐式登陆的。具体参考https://stackoverflow.com/questions/37249623/how-to-login-without-prompt 123456789Read-Host &quot;Enter Password&quot; -AsSecureString | ConvertTo-SecureString `-AsPlainText -Force | ConvertFrom-SecureString | Out-File &quot;C:\\Password.txt&quot;# The azure account here must not be a Live ID.$username = &quot;&lt;your Azure account&gt;&quot;$SecurePassword = Get-Content &quot;C:\\Password.txt&quot; | ConvertTo-SecureString$cred = new-object -typename System.Management.Automation.PSCredential ` -argumentlist $username, $SecurePasswordLogin-AzureRmAccount -Credential $cred -EnvironmentName &apos;AzureChinaCloud&apos; 2. AAD Service Principal登陆 前提条件：需要在Azure AD 中去注册一个app（service principal），并拿到这个app的Appliaction和key。此处你需要为app添加相应的权限。运行完，直接根据选定的订阅就能操作Azure 订阅资源了。 1234567891011121314151617# the AAD app applicationID $ServicePrincipalApplicationId=&quot;9059226d-******&quot; # AAD app key $ServicePrincipalPassword=&quot;********************&quot; # the AAD directory ID = tenantID $TenantId= &quot;*********************&quot; # set Azure to Mooncake $EnvironmentName =&quot;AzureChinaCloud&quot; $SubscriptionId=&quot;*******************************&quot; $spPassword = ConvertTo-SecureString $ServicePrincipalPassword -AsPlainText -Force $AzureServicePrincipalCreds = New-Object System.Management.Automation.PSCredential ($ServicePrincipalApplicationId, $spPassword) Add-AzureRmAccount -Credential $AzureServicePrincipalCreds -ServicePrincipal -TenantId $TenantId -Environment $EnvironmentName Set-AzureRmContext -SubscriptionId $SubscriptionId 缺点：泄露AAD app 的applicationID 和key 会比较麻烦。","categories":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}],"tags":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/tags/Azure/"}],"keywords":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}]},{"title":"How-to-get-started-with-Minikube-on-Mac-OS","slug":"How-to-get-started-with-Minikube-on-Mac-OS","date":"2019-05-05T07:13:54.000Z","updated":"2019-05-05T07:18:20.204Z","comments":true,"path":"Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/","excerpt":"","text":"目标：本文介绍了如何在Mac OS上开始使用Minikube的详细步骤。 这是学习Kubernetes的一个很好的起点。 操作环境：Mac OS 10.14 Minikube v0.30.0 解决方案：1.先决条件在Mac上安装xcode： 1`xcode-``select` `--``install` 然后安装 Homebrew： 1`/usr/bin/ruby` `-e ``&quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;` 所以基本上Homebrew会将软件包安装到他们自己的目录中，然后将他们的文件符号链接到/ usr / local。 2.安装Minikube使用Homebrew，我们可以在Mac上轻松安装Minikube： 1`brew cask ``install` `minikube` 3.在VM中启动单个节点Kubernetes群集默认情况下，Minikube使用“virtualbox”作为VM驱动程序，您也可以将其更改为其他驱动程序： 1`$ minikube start -h |``grep` `vm-driver`` ``--vm-driver string VM driver is one of: [virtualbox vmwarefusion kvm xhyve hyperv hyperkit kvm2 none] (default ``&quot;virtualbox&quot;``)` 现在启动VM中的单节点Kubernetes集群（默认内存大小为2G）： 1`minikube start` 4.启动Kubernetes Web Dashboard1`minikube dashboard` 只有一个节点显示： 5.将hello world Node.js应用程序部署到Minikube中1`kubectl run hello-minikube --image=k8s.gcr.io``/echoserver``:1.4 --port=8080` 显示在仪表板的“部署”中： 或者在CLI中显示： 1`$ kubectl get deployments``NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE``hello-minikube 1 1 1 1 15m` 6.将部署公开为服务1`kubectl expose deployment hello-minikube --``type``=NodePort` 在仪表板中显示服务信息： 或者在CLI中显示服务信息： 1`$ kubectl get services hello-minikube``NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE``hello-minikube NodePort xxx.xxx.xxx.xxx &lt;none&gt; 8080:31978``/TCP` `3m` 7.等待pod启动并运行继续在命令下运行，直到pod的状态正在运行并准备就绪。 1`$ kubectl get pods``NAME READY STATUS RESTARTS AGE``hello-minikube-6c47c66d8-gv7n2 1``/1` `Running 0 31m` 8.访问服务1`curl $(minikube service hello-minikube --url)` 或直接转到浏览器中的网址： 1`$ minikube service hello-minikube --url``http:``//192``.168.99.100:31978` 9.关闭群集删除服务（服务在此之后消失）： 1`kubectl delete service hello-minikube` 删除部署（之后部署和pod都消失了）： 1`kubectl delete deployment hello-minikube` 停止minikube集群： 1`minikube stop`","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Minikube","slug":"Minikube","permalink":"http://blog.ozairs.com/tags/Minikube/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"深入探讨AKS和AAD","slug":"深入探讨AKS和AAD","date":"2019-04-30T10:24:17.000Z","updated":"2019-04-30T10:30:47.610Z","comments":true,"path":"Cloud-Service/深入探讨AKS和AAD/","link":"","permalink":"http://blog.ozairs.com/Cloud-Service/深入探讨AKS和AAD/","excerpt":"","text":"【译文】 本快速研讨将指导您使用AAD配置AKS以使用RBAC对用户进行身份验证。 介绍开发团队成员需要访问Kubernetes集群以部署应用程序并配置集群。但是，并非所有成员都需要相同级别的访问权限。这甚至是最佳实践，或者必须授予成员不同的访问级别。例如，开发人员可以在自己的命名空间内获取，创建和删除部署。并且，Ops人员可以配置群集以添加或删除用户，扩展群集或升级它。这将保护k8s群集并降低不良操作的风险。 您需要安装Azure订阅，az和kubectl cli。 本研讨会将首先创建Azure AD客户端和服务器应用程序。然后我们将创建一个配置了AAD的AKS集群。我们将通过创建Role和RoleBinding k8s清单文件来完成。 1.创建Azure AD服务器和客户端应用程序我们需要创建服务器和客户端应用程序，这些应用程序将用于通过AAD验证连接到AKS的用户。这意味着应首先在AAD中创建用户以访问群集。这是身份验证部分。对于授权部分，它将由第3节中的Role和RoleBinding k8s对象管理。 请按照此处链接（在创建群集部分之前）中描述的步骤创建客户端和服务器应用程序：https：//docs.microsoft.com/en-us/azure/aks/aad-integration 最后，我们应该有AAD租户ID，客户端应用ID，服务器应用ID和服务器应用秘密。我们将使用这些来配置AKS与AAD。 2.创建使用Azure Active Directory配置的AKS群集Azure使用资源组对与同一应用程序或服务相关的资源进行分组。Azure中的所有资源都必须位于资源组内，包括AKS。让我们从使用az命令行创建资源组开始。 1$ az group create -name aks- aad -rg -location westeurope 如果您有多个Azure订阅，则可以设置一个默认订阅，以便az命令始终指向它，方法是： az帐户设置“Your_Azure_Subscription_Id_Or_Name” 然后我们可以创建AKS集群。Kubernetes使用OpenId Connect（OIDC）对用户进行身份验证。并且，AKS可以配置为使用AAD作为OIDC的实现。az cli工具提供了在创建群集期间（但不是之后）进行此配置的选项。确保替换AAD中的值。这将需要大约5分钟才能运行。 12345678$ az aks create -resource-group aks- aad- rg \\ -name aks-aad \\ -generate-ssh-keys \\ -aad-server-app-id cbb2efcb-9b3c-4441-b58f-9c6cca37 \\ -aad-server- app-secret VBnbw1gEhxtRVfKTv8dYD + MyraLF5jn = \\ -aad-client-app-id 4c2a05a5-7ed1-4a2c-b4aa-b78bc \\ -aad-tenant-id 72f988bf-0000-0000-0000-2d7cd011db47 现在，来自AAD帐户的所有用户都可以向AKS群集进行身份验证。但是，他们不能做任何操作，因为他们还没有做任何事情的许可。我们需要通过Role和RoleBinding授予他们访问k8s资源的权限。在此之前，我们需要以管理员身份访问群集，以便分配角色。 3.连接到AKS群集我们需要连接到AKS，以便作为管理员对新集群运行kubectl命令。 12345$ az aks get-credentials \\ -resource-group aks- aad- rg \\ -name aks- aad --admin将 “aks- aad -admin”合并为/Users/houssem/.kube/config中的当前上下文 顺便说一下，所有命令的源代码都在这里：github.com/HoussemDellai/rbac-aks-aad 4.创建角色和RoleBinding让我们创建一个角色，它将定义对某些资源的访问权限。例如，仅从pod中读取信息。 123456789kind： Role apiVersion： rbac.authorization.k8s.io/v1 metadata： namespace：默认 名称： pod-reader 规则：- apiGroups： [“”]＃“”表示核心API组 资源： [“pods”] 动词： [“get”，“watch”，“list”] 要将角色分配给用户，我们需要使用RoleBinding。 12345678910111213kind： RoleBinding apiVersion： rbac.authorization.k8s.io/v1 metadata： name： read-pods namespace：默认主题：- kind：用户 名： “houssem.dellai@live.com”#Name是区分大小写的 apiGroup： rbac。 authorization.k8s.io roleRef： kind：角色#this必须是Role或ClusterRole 名称： pod-reader＃必须匹配角色 apiGroup的名称： rbac.authorization.k8s.io 我们可以使用Group而不是User来绑定AAD组中的所有用户。 然后我们使用kubectl部署这两个文件： 1234$ kubectl apply -f role.yaml role.rbac.authorization.k8s.io/pod-reader created $ kubectl apply -f role- binding.yaml rolebinding.rbac.authorization.k8s.io/read-pods created 我们可以检查Role和RoleBinding是否已成功创建： 123456$ kubectl get roles NAME AGE pod-reader 2m $ kubectl get rolebindings NAME AGE read-pods 2m 5.测试对AKS的认证和授权现在一切都已配置好，我们将伪装成RoleBinding中使用的用户。我们将从另一台机器连接到AKS集群。这是使用登录Azure，而不是使用群集。 1234$ az aks get-credentials \\ -resource-group aks- aad- rg \\ -name aks- aad将“aks-aad”合并为/Users/houssem/.kube/config中的当前上下文 然后我们将尝试允许的命令： 1$ kubectl get pods 因为我们添加了身份验证，所以要求登录群集。我们将以RoleBinding中指定的用户身份登录。我们需要在指定的url地址中启动浏览器并使用给定的代码。 然后我们按继续。 确保RoleBinding中使用的用户也存在于Azure AD中。 在这里，我们来到最令人兴奋的部分，即登录AKS集群！ 我们可以使用用户的电子邮件和密码登录。 此网页表示您已成功登录！ 我们再次运行允许的命令： 1$ kubectl get pods 如果我们尝试运行其中一个非允许的操作，那么它将失败！ 1$ kubectl get deploymentments 如果我们尝试从所有命名空间中获取pod，那么也会失败。因为我们在Role中配置用户以仅从默认命名空间获取pod。 1$ kubectl get pods --all-namespaces 结论我们已将用户配置为登录并访问特定的AKS资源。我们也可以为整个AAD组做这件事。 【原文】 This quick workshop will walk you through configuring AKS with AAD to use RBAC to authenticate users. IntroductionThe development team members needs to access Kubernetes cluster to deploy apps and configure the cluster. But, not all members needs the same level of access rights. It is even a best practice or a must have to grant members different access levels. For example, developers can get, create and delete deployments inside their own namespace. And, Ops guys can configure the cluster to add or remove users, scale the cluster or upgrade it. This will secure the k8s cluster and reduce the risk of bad manipulations. You will need an Azure subscription, az and kubectl cli installed. This workshop will start by creating Azure AD client and server apps. Then we’ll create an AKS cluster configured with AAD. And we’ll finish by creating the Role and RoleBinding k8s manifest files. 1. Create Azure AD server and client appsWe need to create a server and client apps, those will be used to authenticate the users connecting to AKS through AAD. This means the user should be first created in AAD to have access to the cluster. This is the authentication part. For the authorisation part, it will be managed by Role and RoleBinding k8s objects in section 3. Please follow the steps described in the link here (just before section Create Cluster) to create client and server apps: https://docs.microsoft.com/en-us/azure/aks/aad-integration At the end, we should have the AAD tenant Id, client app Id, server app Id and server app secret. We’ll use those to configure AKS with AAD. 2. Create AKS cluster configured with Azure Active DirectoryAzure uses Resource Group to group resources related to the same application or service. All resources in Azure must live inside a resource group, including AKS. Let’s start by creating a resource group using the az command line. 1$ az group create -name aks-aad-rg -location westeurope If you have multiple Azure subscriptions, you can set a default one so that az commands points always to it, by using: az account set “Your_Azure_Subscription_Id_Or_Name” Then we can create the AKS cluster. Kubernetes uses OpenId Connect (OIDC) to authenticate users. And, AKS could be configured to use AAD as an implementation of OIDC. The az cli tool provide the options to make this configuration during (but not after) the creation of the cluster. Make sure to replace the values from your AAD. This will take about 5 minutes to run. 12345678$ az aks create -resource-group aks-aad-rg \\ -name aks-aad \\ -generate-ssh-keys \\ -aad-server-app-id cbb2efcb-9b3c-4441-b58f-9c6cca37 \\ -aad-server-app-secret VBnbw1gEhxtRVfKTv8dYD+MyraLF5jn= \\ -aad-client-app-id 4c2a05a5–7ed1–4a2c-b4aa-b78bc \\ -aad-tenant-id 72f988bf-0000–0000–0000–2d7cd011db47 Now, all users from the AAD account can authenticate to the AKS cluster. But, they can not do any operation as they don’t have yet any permission to do whatever. We need to grant them access to k8s resources through Role and RoleBinding. Before that, we need to access the cluster as admin, in order to assign the roles. 3. Connect to AKS clusterWe need to connect to AKS in order to run kubectl commands against the new cluster, as an admin. 12345$ az aks get-credentials \\ -resource-group aks-aad-rg \\ -name aks-aad --adminMerged &quot;aks-aad-admin&quot; as current context in /Users/houssem/.kube/config By the way, the source code for all the commands are here: github.com/HoussemDellai/rbac-aks-aad And this workshop is available as a video. 4. Create the Role and RoleBindingLet’s create the Role which will define access to certain resources. For example, only reading information from pods. 123456789kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: default name: pod-readerrules:- apiGroups: [“”] # “” indicates the core API group resources: [“pods”] verbs: [“get”, “watch”, “list”] To assign the role to a user, we need to use RoleBinding. 12345678910111213kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: read-pods namespace: defaultsubjects:- kind: User name: &quot;houssem.dellai@live.com&quot; # Name is case sensitive apiGroup: rbac.authorization.k8s.ioroleRef: kind: Role #this must be Role or ClusterRole name: pod-reader # must match the name of the Role apiGroup: rbac.authorization.k8s.io We can use a Group instead of User, to bind to all users within the AAD group. Then we deploy both files using kubectl: 1234$ kubectl apply -f role.yamlrole.rbac.authorization.k8s.io/pod-reader created$ kubectl apply -f role-binding.yamlrolebinding.rbac.authorization.k8s.io/read-pods created We can check if the Role and RoleBinding were successfully created: 123456$ kubectl get rolesNAME AGEpod-reader 2m$ kubectl get rolebindingsNAME AGEread-pods 2m 5. Test authentication and authorisation to AKSNow that everything is configured, we will pretend to be the user used in RoleBinding. We’ll connect to the AKS cluster from another machine. This is using login to Azure, not to to the cluster. 1234$ az aks get-credentials \\ -resource-group aks-aad-rg \\ -name aks-aadMerged &quot;aks-aad&quot; as current context in /Users/houssem/.kube/config Then we’ll try the allowed command: 12$ kubectl get podsTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code CL7DWV3P2 to authenticate. Because we added authentication, it is asking to login to the cluster. We’ll login as the user specified in RoleBinding. We need to launch the browser in the specified url address and use the given code. Then we press continue. And here we come to the most exciting part, the login to the AKS cluster! We can login with the email and password for the user. We run again the allowed command: 12$ kubectl get podsNo resources found. # we didn&apos;t created a Pod yet ! If we try to run one of the non allowed operations, then it will fail! 12$ kubectl get deploymentsError from server (Forbidden): deployments.extensions is forbidden: User “f97fc9ba-ebda-439e-825a-..” cannot list deployments.extensions in the namespace “default” If we try to get the pods from all the namespaces, that will also fail. Because we configured the user in Role to get pods from only the default namespace. 12$ kubectl get pods --all-namespacesError from server (Forbidden): pods is forbidden: User &quot;f97fc9ba-ebda-439e-825a-0e25801cb32c&quot; cannot list pods at the cluster scope ConclusionWe have configured a user to login and get access to specific AKS resources. We could also do this for an entire AAD group.","categories":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}],"tags":[{"name":"GCP","slug":"GCP","permalink":"http://blog.ozairs.com/tags/GCP/"}],"keywords":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}]},{"title":"关于Google Professional Cloud Architect考试-GCP2019","slug":"关于Google-Professional-Cloud-Architect考试-GCP2019","date":"2019-04-30T10:14:21.000Z","updated":"2019-04-30T10:22:15.309Z","comments":true,"path":"Cloud-Service/关于Google-Professional-Cloud-Architect考试-GCP2019/","link":"","permalink":"http://blog.ozairs.com/Cloud-Service/关于Google-Professional-Cloud-Architect考试-GCP2019/","excerpt":"","text":"【译文】 这个月，我参加了专业云架构师考试，我通过了，现在我已经通过了Google Cloud认证。因此，现在是时候反思认证，我喜欢什么，我不喜欢什么，或者对我来说如何通过这个认证之旅。如果您打算获得认证，也许您会在这里获得一些见解以做好准备。 我喜欢这一认证的地方1. 认证中出现的都是场景题我真正喜欢的专业云架构师认证（PCA）是它主要是基于场景的考试。这意味着对于几乎所有问题，都会描述业务问题，您的任务是找到解决问题的最佳解决方案。对于这些场景，谷歌记录了三个案例研究（Mountkirk，Dress4Win和TerramEarth））。他们每个人都介绍了一个虚构的公司，他们的解决方案，他们的目标和挑战。强烈建议在考试前花时间研究这些文件，我也鼓励人们考虑每个案例研究的目标GCP架构。在考试中，案例研究存在大量问题（可能&gt; 20％）。但是，如果它们与案例研究没有直接关系，那么大多数其他问题也是基于情景的事件。 我非常喜欢这种基于场景的方法，因为它需要一些思考才能找到正确的答案。专业架构师认证不是考试补习。您不必认真地学习大量信息，并且在测试当天重新学习所学内容（然后在后一天忘记所有内容）。该认证需要一些实践和一些云背景。 2. 这是个关于架构师认证该认证的另一个有趣的方面是它要求您作为架构师思考。我的意思是，许多认证只需要您成为工具专家，了解很多产品功能。如果GCP产品和服务知识对于通过PCA测试很重要，我认为这还不够。许多问题要求您找到问题的解决方案，而不是向您询问产品功能。这种方法让我想起了架构师（2000年初的J2EE认证企业架构师）的旧Sun Microsystem认证，你不仅需要通过考试（多项选择题），还需要定义和记录架构，然后写一篇文章。 在PCA考试中，据我所知，绝大多数问题都是关于GCP能力以最好地解决特定挑战。您不会经常被问及具体的产品功能。您将在更广泛的背景下测试本机或混合云解决方案。如果您了解Compute Engine的所有信息，那对您有好处，但如果您对测试方法，持续交付，GDPR或PCI DSS一无所知，那么您就会被搞砸。请记住，对于某些问题，最佳答案并不总是包含Google产品的问题（谷歌对此表示赞赏）。与现实生活中一样，商业问题的最佳选择可能包括GCP服务，……或者不包括。也许开源解决方案可以更好地满足技术和业务需求。再次，作为一名架构师，而不是作为工具专家。 3. 认证覆盖范围很广Professional Architect认证的范围很广：IaaS，PaaS，SaaS，网络，存储，安全，测试，监控等。因此它涵盖了许多不同的云计算领域。 这意味着当您准备考试时，您很可能不得不触及您没有掌握的主题。我个人不得不走出我的舒适区域，了解有关网络和防火墙的更多信息。我不是在谈论GCP的具体情况，而是谈到我过去从未处理过的一些重要的网络概念。所以我学到了很多，而且由于认证的范围很广，我认为这是一个真正的机会，可以回顾你已经知道的东西，提高你的一些技能，并学习全新的东西。此外，我觉得我大多数都经过了重要的测试，而不是非常具体的产品细节。 我不喜欢这个考试的地方现在让我们来探讨认证中一些不太令人兴奋的方面。第一个与考试范围有关。 认证范围太广如果认证是一个很好的学习机会，那么也存在被大量淹没的风险……很多信息。 请查看下面的图片，了解认证涵盖的内容（或使用此链接）。 如果您删除了PCA主题之外的内容（G Suite，移动设备，地图，其他资源。），则学习材料仍然很大。测试准备耗时并且需要真正的努力和承诺。 有限的学习材料因此，认证很难，因为它涵盖了所有产品。但我能理解这一点。PCA是经验丰富的云专业人员的高级认证。所以它必须非常广泛。但我真正不喜欢的PCA认证是缺乏相关的学习材料。 除GCP文档外，没有任何研究书籍或在线资料。Google似乎依赖Coursera或其他人进行自定进度的培训。在与谷歌云平台架构专业化（Coursera）是很有趣的，但还不够。它没有适当地涵盖BigQuery。最近准备Google Cloud Professional Cloud架构考试与实际考试内容更加一致，但不会深入研究。据我所知，现有的Udemy课程并不相关。Google提供讲师指导的培训，因此这可能是接受Google专业人员培训的最佳方式。但这对我来说不是一个选择（需要自定进度的训练）。 幸运的是，Qwiklabs对GCP架构的挑战非常好，但它们不是免费的，并且它们没有附带的伴随学习材料。就个人而言，如果没有Qwiklabs，我绝不会通过测试，所以如果你能负担得起，我强烈推荐订阅。我认为GCP架构，Kubernetes和BigQuery Qwiklabs任务非常重要。如果您认为BigQuery超出了范围，因为它是更多的数据分析（这是Coursera培训有时会说的……），请三思而后行。您将有关于BigQuery的多个问题。 没有官方通过分数据我所知，通过考试的最低分数不公开。这可能是80％左右，但我不认为谷歌正式就这一点进行沟通。坦率地说，我不确定我理解为什么。我认为这是谷歌更灵活的一种方式，可以动态改变成功因素。但由于没有及格分数，也没有考试成绩。这意味着考试的结果是二进制：通过或失败。如果失败（谷歌称之为“非熟练”），你不知道你是否错过了它或者你是否足够接近。如果你通过，也一样。在我所知道的其他认证中，您通常会按类别获得全局分数和分数。我认为这有助于更好地了解您需要改进的地方，以便真正完全熟练（无论您是否通过了考试）。 还有一些棘手的测试问题我相信Professional Cloud Architect考试总体上是一个很好的考试。根据我与人们的一些交流，与2018年11月之前的情况相比，它似乎也有所改善。我无法分辨，因为我只接触过“2018年11月后”版本的考试。 但是在考试的这里和那里，仍然有一些可以避免的愚蠢问题。作为云架构师，不要测试我记住gcloud命令行的能力。在现实生活中，我总能通过简单的互联网搜索或使用gcloud帮助找到合适的语法。最重要的是，我不认为这是PCA考试中的一个问题，但是可以避免的轻微刺激。 关于认证的另一个棘手方面与Dress4Win案例研究有关。或者我应该说“ 相关”因为它似乎已经解决了这个问题。我没有证据（如屏幕截图）但我很肯定Dress4Win技术环境直到最近才提到MySQL 5.8（事实上，至少到4月的第一周）。为什么这很重要？好吧，我不是MySQL专家，但似乎5.8版本不存在（5.7之后的版本是8.0）。所以这听起来像个伎俩。此外，Google Cloud SQL仅支持5.7版本。因此，任何与Dress4win MySQL可移植性相关的问题都会产生误导，因为如果不支持数据库版本，则无法利用Cloud SQL。但正如我所说，这已经修复，Dress4Win描述现在提到MySQL 5.7 摘要我持有Sun Microsystems（Oracle），IBM，Open Group和Google等几家公司的认证。我的第一个认证是从2002年开始，作为Java开发人员（恕我直言，不是一个好的认证考试）。我也参与了认证考试的开发。如果您参加过IBM Cloud认证测试，您可能会遇到我创建的一些问题。我提到这一切的原因是因为我相信我的职业生涯中已经接触过大量的认证。根据我目前所看到的情况，我认为Google Professional Cloud Architect是我最喜欢的认证之一。这不仅是因为它测试了你解决业务问题的能力，还因为如果你想成功，它会迫使你练习很多。 当然，认证就是认证。它不会取代现场经验，也不能证明您是专业人士。认证只能证明你具有通过认证的能力。因此，对我来说，认证过程只是GCP激动人心的旅程的开始。 【原文】 This month, I took the Professional Cloud Architect exam, I passed, and I am now Google Cloud Certified. So it is time to reflect on the certification, what I liked, what I did not like, or how it has been useful for me to go through this certification journey. And if you plan to get certified as well, maybe you will get some insights here to get better prepared. What I liked about the examScenario-basedWhat I really like about the Professional Cloud Architect certification (PCA) is that it is mostly a scenario-based exam. It means that for almost all questions, a business problem is described and your task is to find the best solution to address the problem. For those scenarios, Google has documented three Case Studies (Mountkirk, Dress4Win and TerramEarth). Each one of them introduces a fictitious company, their solution, their objectives and their challenges. It is strongly recommended to spend time studying these documents before the exam, and I would also encourage people to think about a target GCP architecture for each case study. In the exam, there is a significant amount of questions on the case studies (probably &gt;20%). But most other questions are also scenario-based event if they don’t directly relate to the case studies. I like this scenario-based approach a lot as it requires some thinking to be able to identify the correct answer. The Professional Architect certification is not an exam cram. You don’t have to learn a huge amount of information by heart and regurgitate what you learned the day of the test (and then forget everything the day after). The certification requires some practice and some cloud background. A certification for architectsAnother interesting aspect of the certification is that it asks you to think as an architect. What I mean is that a lot of certifications just require you to be a tool specialist, to know a lot of product features. If GCP products and services knowledge is important to pass the PCA test, I think it is not sufficient. Many questions ask you to find a solution to a problem instead of asking you about product capabilities. This approach reminds me a bit of the old Sun Microsystem certification for architects (Certified Enterprise Architect for J2EE in early 2000) where you needed not only to pass an exam (multiple-choice questions) but also to define and document an architecture, and then write an essay. In the PCA exam, as far as I can remember, a vast majority of the questions are about GCP capabilities to best address a given challenge. You will not often be asked about specific product features. You will be tested about native or hybrid cloud solutions in an broader context. If you know everything about Compute Engine, that’s good for you, but if you know nothing about testing approaches, continuous delivery, GDPR or PCI DSS, you’re are screwed. And keep in mind that for some questions, the best answer is not always the one that includes Google products (kudos to Google for this). As in real life, the best option to a business problem may include GCP services, … or not. Maybe an open source solution will better address technical and business requirements. Again, think as an architect, not as a tool specialist. Broad certificationThe scope of the Professional Architect certification is broad: IaaS, PaaS, SaaS, Networking, Storage, Security, Testing, Monitoring, etc…. So it covers a lot of different cloud computing domains. Which means that when you prepare for the exam, you will most likely have to touch upon topics that you’re not mastering. I personally had to go outside of my comfort zone and learn more about networking and firewalls. And I am not talking about GCP specificities here but about some important networking concepts I never had to deal with in the past. So I learned a lot, and because the scope of the certification is so wide, I think this is a real opportunity to review what you already know, to sharpen some of your skills, and to learn brand new stuff. Moreover, I feel I have mostly been tested on stuff that matters, not on very specific product details. What I did not like about the examSo now let’s explore some less exciting aspects of the certification. The very first one is related to the scope of the exam. Broad certification…. the other side of the coinIf the certification is a great opportunity to learn, there is also a risk of being overwhelmed by a lot… A LOT… of information. Take a look at the picture below to get a sense of what the certification covers (or use this link). If you remove stuff that is out of the PCA topics (G Suite, Mobile, Maps, Additional resources.), the study material is still huge. The test preparation is time consuming and requires real effort and commitment. Limited study materialSo the certification is difficult because of all the products it covers. But I can understand that. The PCA is an advanced certification for experienced cloud professionals. So it has to be quite extensive. But what I really did not like about the PCA certification is the lack of relevant study material. There is no study book or online material other than the GCP documentation. It seems that Google relies on Coursera or others for self-paced training. The Architecting with Google Cloud Platform Specialization (Coursera) is quite interesting but not sufficient. And it does not properly cover BigQuery. The more recent Preparing for the Google Cloud Professional Cloud Architect Exam is more aligned with real exam content, but does not go deep dive. The existing Udemy courses are, according to me, not relevant. Google offers instructor-led training, so this is probably the best way to get trained by Google professional. But it was not an option for me (self-paced training was needed). Fortunately, the Qwiklabs Challenge on GCP Architecture is very good, but they are not free and they don’t come with companion study material. Personally, I would never have passed the tests without Qwiklabs, so I strongly recommend a subscription if you can afford it. I think GCP architecture, Kubernetes and BigQuery Qwiklabs Quests are important. And if you believe BigQuery is out of scope because it is more data analytics (this is what the Coursera training is sometime saying…), think twice. You will have multiple questions on BigQuery. No official passing scoreAs far as I know, the minimum score to pass the exam is not public. It is probably something around 80% but I don’t think Google officially communicates on this. Frankly, I am not sure I understand why. I suppose it is a way for Google to be a bit more flexible and change success factors on the fly. But because there is no passing score, there is no exam score either. Which means that the result of the exam is binary: Passed or Failed. In case of failure (Google calls this “Non proficient”), you don’t know if you miserably missed it or if you were close enough. Same if you passed. In other certifications I am aware of, you usually get a global score and a score by category. I think this is useful to better understand where you need to improve in order to really become fully proficient (whether or not you passed the exam). Still some tricky test questionsI believe that Professional Cloud Architect exam is overall a good one. Based on some exchanges I had with people, it also seems it has improved compared to what it was before November 2018. I cannot really tell as I was only exposed to the “Post Nov 2018” version of the exam. But here and there in the exam, there are still some silly questions that may be avoided. As a Cloud Architect, don’t test me on my ability to remember a gcloud command line. In real life, I can always find the proper syntax with a simple internet search or using gcloud help. Bottom line, I don’t think it is an issue in the PCA exam, but a minor irritant that could be avoided. Another tricky aspect about the certification is related to the Dress4Win case study. Or I should say “was related” because it seems the issue has been solved quite recently. I don’t have proof (like a screen shot) but I am positive that Dress4Win technical environment was mentioning MySQL 5.8 until recently (in fact, until first week of April at least). Why is this important? Well, I am not a MySQL expert but it seems that the 5.8 version does not exist (the one after 5.7 is 8.0). So it sounded like a trick. Moreover, Google Cloud SQL only supports up to version 5.7. So any question related to Dress4win MySQL portability would have been misleading, as you cannot leverage Cloud SQL if the database version is not supported. But as I said, this has been fixed and Dress4Win description now mentions MySQL 5.7 Summary….I hold certifications from a couple of entities such as Sun Microsystems (Oracle), IBM, the Open Group, and now Google. My first certification is from 2002, as a Java Developer (IMHO, not a good certification exam). I have also been involved in the development of certification exams. If you ever take IBM Cloud certification tests, you may get some questions that I created. The reason I am mentioning all this is because I believe I have been exposed to a significant amount of certifications in my career. And based on what I have seen so far, I really think that the Google Professional Cloud Architect is one of my favourite certifications. Not only because it tests you on you ability to solve business problems, but also because it forces you to practice a lot if you want to succeed. Of course, a certification is just that…a certification. It does not replace field experience, and it does not prove that you are a professional. A certification is only as good as what you do with it. For me, the certification process was just the beginning of an exciting journey on GCP.","categories":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}],"tags":[{"name":"GCP","slug":"GCP","permalink":"http://blog.ozairs.com/tags/GCP/"}],"keywords":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}]},{"title":"使用GitBook编写文档书籍","slug":"使用GitBook编写文档书籍","date":"2019-04-28T12:54:43.000Z","updated":"2019-04-28T13:09:48.430Z","comments":true,"path":"gitbook/使用GitBook编写文档书籍/","link":"","permalink":"http://blog.ozairs.com/gitbook/使用GitBook编写文档书籍/","excerpt":"","text":"GitBook 是一个基于 Node.js 的命令行工具，可使用 Github/Git 和 Markdown 来制作精美的电子书。GitBook支持输出以下几种文档格式： 静态站点：GitBook默认输出该种格式PDF：需要安装gitbook-pdf依赖eBook：需要安装ebook-convertGitBook可以用来写书、API文档、公共文档，企业手册，论文，研究报告等。 一、GitBook安装在安装之前，我们还需要配置一下 nodejs 插件安装的下载镜像地址。因为默认的镜像地址在国外，需要翻墙才可以访问，因此我们需要设置国内的镜像地址。这里使用阿里巴巴的镜像地址 http://registry.npm.taobao.org 。使用下面的命令，进行配置。 npm config set registry http://registry.npm.taobao.org1、NMP安装Gitbook 1npm install gitbook -g //安装命令 1npm install -g gitbook-cli //卸载命令 1npm uninstall -g gitbook 2、检验下是否安装成功 //显示gitbook以及gitbook-cli版本号 1gitbook -V 二、基本使用Gitbook需要2个基本文件： README.md SUMMARY.md README.md是关于你的书的介绍，而SUMMARY.md中则包含了书的目录。我们还可以添加“book.json（电子书配置文件）”、“GLOSSARY.md（书尾词汇表）”以及“封面图片”等，默认文件树中没有这些，需要自行添加。 生成图书目录结构创建一个目录test， 使用gitbook init命令就可以在目录下生产这两个文件。一个SUMMARY.md文件的格式大致如下，每一行对应一个相应的文件。 Summary Introduction 第一章 第一节 第二节 第二章 第一节 第二节 结束 执行 gitbook init 会根据 SUMMARY.md 目录生成对应的文件夹和 md 文件，每一个 md 文件对应每一章节，每一章节的内容在对应的 md 文件里编辑，你可以使用本地支持Markdown语法的编辑器编辑，例如Markdown Pad。 如果想要新增章节，可以在 SUMMARY.md 里面新增，然后执行 gitbook init 就会新增对应的 md 文件，原有文件不会变化；如果想要删除章节，在 SUMMARY.md 里面删除，然后执行 gitbook init 想要删除的 md 文件并不会删除，需要手动删除。 生成图书2.1 输出为静态网站执行下面的命令 1$ gitbook serve 然后浏览器中输入 http://localhost:4000 就可以预览生成的以网页形式组织的书籍。 这里你会发现，你在你的图书项目的目录中多了一个名为_book的文件目录，而这个目录中的文件，即是生成的静态网站内容。 使用build参数生成到指定目录 与直接预览生成的静态网站文件不一样的是，使用这个命令，你可以将内容输入到你所想要的目录中去： $ mkdir /tmp/gitbook​$ 1gitbook build --output=/tmp/gitbook 文档写好以后，你可以把Gitbook源目录下面的所有文件都复制到你项目下(app_root/docs/api/gitbook_api_dir)。这样，你的项目就多了一份漂亮的文档。 2.2 输出为PDF输出为PDF文件，需要先使用NPM安装上gitbook pdf： 1$ sudo npm install gitbook-pdf -g 三、Gitbook的插件支持新建book.json，可以做一些配置，比如标题，作者，指定readme文件，关闭分享链接等。 1234567891011121314151617181920212223&#123; &quot;title&quot;: &quot;gitbook tutorial&quot;, &quot;description&quot;: &quot;Webpack 是当下最热门的前端资源模块化管理和打包工具，本书大部分内容翻译自 Webpack 官网。&quot;, &quot;structure&quot;: &#123; &quot;readme&quot;: &quot;README.md&quot; &#125;, &quot;links&quot;: &#123; &quot;gitbook&quot;: false, &quot;sharing&quot;: &#123; &quot;google&quot;: false, &quot;facebook&quot;: false, &quot;twitter&quot;: false, &quot;all&quot;: false &#125; &#125;, &quot;plugins&quot;: [&quot;disqus&quot;,&quot;advanced-emoji&quot;], &quot;pluginsConfig&quot;: &#123; &quot;disqus&quot;: &#123; &quot;shortName&quot;: &quot;gitbookuse&quot; &#125; &#125;&#125; 安装插件1$ gitbook install ./ gitbook命令 12345678910111213gitbook init //初始化目录文件gitbook help //列出gitbook所有的命令gitbook --help //输出gitbook-cli的帮助信息gitbook build //生成静态网页gitbook serve //生成静态网页并运行服务器gitbook build --gitbook=2.0.1 //生成时指定gitbook的版本, 本地没有会先下载gitbook ls //列出本地所有的gitbook版本gitbook ls-remote //列出远程可用的gitbook版本gitbook fetch 标签/版本号 //安装对应的gitbook版本gitbook update //更新到gitbook的最新版本gitbook uninstall 2.0.1 //卸载对应的gitbook版本gitbook build --log=debug //指定log的级别gitbook builid --debug //输出错误信息 四、托管到GitBook.com1、注册 GitBook.com 账号 首先进入 GitBook.com 注册一个账号，并新建一个项目。在“Setting（设置）”页面获取到“Git URL（Git 链接）”，如下所示： 1、https://git.gitbook.com/charmingfst/mytest.git2、使用Git上传电子书项目 在本地新建一个文件夹，并通过 Git 命令把刚才新建的远程项目抓取到本地，如下所示： 1234mkdir FirstBookcd FirstBookgit initgit pull https://git.gitbook.com/charmingfst/mytest.git 然后把本地电子书项目“test”中的所有内容拷贝到刚才新建的文件夹中，如上面的“FirstBook”。然后使用 Git 命令把本地的项目上传到远程，如下所示： 1234git add -Agit commit -m &quot;提交说明&quot;git remote add gitbook https://git.gitbook.com/charmingfst/mytest.gitgit push -u gitbook master git push 命令中的 -u 表示将本地 master 分支的上游分支设置为 github/master，下次直接使用git push命令即可。","categories":[{"name":"gitbook","slug":"gitbook","permalink":"http://blog.ozairs.com/categories/gitbook/"}],"tags":[{"name":"gitbook","slug":"gitbook","permalink":"http://blog.ozairs.com/tags/gitbook/"}],"keywords":[{"name":"gitbook","slug":"gitbook","permalink":"http://blog.ozairs.com/categories/gitbook/"}]},{"title":"100条你需要知道的英语俚语","slug":"100条你需要知道的英语俚语","date":"2019-04-27T10:25:21.000Z","updated":"2019-04-27T10:30:28.275Z","comments":true,"path":"English-Skills/100条你需要知道的英语俚语/","link":"","permalink":"http://blog.ozairs.com/English-Skills/100条你需要知道的英语俚语/","excerpt":"","text":"100+ Common sayings everyone must know\\1. Curiosity Killed the Cat \\2. World is Your Oyster \\3. You Need Money to Make Money \\4. All good things come to those who wait \\5. If at first you don’t succeed, try, try again. \\6. Never put off till tomorrow what you can do today. \\7. Don’t cross the bridge until you come to it. \\8. Two heads are better than one. \\9. Paddle your own canoe. \\10. Save for a rainy day. \\11. Life is what we make it. \\12. Opposite attracts. \\13. Faint heart never won fair lady. \\14. The meek shall inherit the earth. \\15. With age comes wisdom. \\16. Two is company, three is a crowd. \\17. It’s better to be safe than sorry. \\18. Don’t look a gift horse in the mouth. \\19. Do unto others as you would have others do unto you. \\20. Hitch your wagon to a star. \\21. Many hands make light work. \\22. You’re never too old to learn. \\23. A word to the wise is sufficient. \\24. Don’t judge a book by its cover. \\25. The squeaking wheel gets the grease. [ \\26. A stitch in time saves nine \\27. Look before you leap. See Also: Wise Sayings, Wisdom Sayings and Life \\28. Haste makes waste. \\29. Fools rush in where angels fear to tread. \\30. Seek and ye shall find. \\31. The best things in life are free. \\32. The Apple Doesn’t Fall Far From the Tree More Common Sayings – Slangs\\33. Root of the Problem \\34. Say Your Piece \\35. Screw the Pooch \\36. Shoot the Breeze \\37. Sit on the Fence \\38. Speak of the Devil \\39. Ace in the Hole \\40. Lose Your Marbles \\41. Luck of the Irish \\42. Make a Big To Do \\43. Make a Fuss \\44. Miss the Boat \\45. Off the Hook \\46. On the Ball \\47. Out of Sight, Out of Mind \\48. Out of the Picture \\49. Out of Touch \\50. Over the Hill [o \\51. Paint a Picture \\52. Perfect Stranger \\53. Piece of Cake \\54. Add Insult to Injury \\55. All Ears \\56. All Thumbs \\57. All Your Eggs in One Basket \\58. Axe to Grind \\59. Barking Up the Wrong Tree \\60. Basket Case See Also: Family Saying – Things To Say About Family \\61. Beat Around the Bush \\62. Beck and Call \\63. Bend Over Backwards \\64. The Best of Both Worlds \\65. Bite Off More Than One Can Chew \\66. Bite the Bullet \\67. A Bitter Pill \\68. Bring Home the Bacon \\69. Burn the Midnight Oil \\70. Call It a Day \\71. Can’t Hold a Candle \\72. Caught Between Two Stools \\73. Chew the Fat \\74. Chickens Come Home to Roost \\75. Chip On His Shoulder \\76. Cold Shoulder \\77. Costs an Arm and a Leg \\78. Couch Potato \\79. Cut a Rug \\80. Cut Corners \\81. Cut the Cheese \\82. Cut the Mustard \\83. Cut to the Chase \\84. A Dime a Dozen \\85. Dodge a Bullet \\86. A Dog’s Breakfast \\87. Down for the Count \\88. High and Mighty \\89. Hit the Road \\90. Have a Blast \\91. Higher Than a Kite \\92. Honest to Goodness \\93. Hot and Bothered \\94. A Hot Potato \\95. If the Shoe Fits, Wear It \\96. In the Bag \\97. Jog Your Memory \\98. Joke Is On You \\99. Jump At the Chance \\100. Jump To Conclusion.","categories":[{"name":"English Skills","slug":"English-Skills","permalink":"http://blog.ozairs.com/categories/English-Skills/"}],"tags":[{"name":"Slang","slug":"Slang","permalink":"http://blog.ozairs.com/tags/Slang/"}],"keywords":[{"name":"English Skills","slug":"English-Skills","permalink":"http://blog.ozairs.com/categories/English-Skills/"}]},{"title":"14种令人难以置信的提高英语口语的方法","slug":"14种令人难以置信的提高英语口语的方法","date":"2019-04-27T10:13:50.000Z","updated":"2019-04-27T10:16:34.064Z","comments":true,"path":"English-Skills/14种令人难以置信的提高英语口语的方法/","link":"","permalink":"http://blog.ozairs.com/English-Skills/14种令人难以置信的提高英语口语的方法/","excerpt":"","text":"我们都想知道如何提高英语口语。 但是对于我们中的一些人来说，这是一个很大的障碍。 为了提高英语口语，最好的办法是与母语人士交谈。但并非所有人都有这个选择！ 如果你不认识讲英语的人怎么办？如果你没有时间怎么办？如果你根本没有足够的信心与本地人一起练习怎么办？ 如何在没有其他人帮助的情况下练习英语口语 ？ 别担心。即使没有说话伴侣，您仍然可以提高英语口语。 我们将解释如何。 没有说话伙伴？没问题！ 1.用英语思考有时候讲英语的困难不是语言本身，而是你如何思考。 如果您用您的母语思考然后尝试说英语，您将始终必须在不同语言之间进行翻译。翻译不是一件容易的事！即使是精通两种或多种语言的人也难以在语言之间切换。 解决方案是用英语思考。 你可以随时随地做到这一点。当你想到你的一天，或者当你想要决定要点什么食物时，尝试使用英语。甚至尝试使用英语 - 英语词典来查找单词。这样你就不必使用母语和翻译单词。你会注意到，当你用英语思考时，你会更容易用英语说话。 2.和自己说话无论何时在家（或在其他地方独自一人），您都可以与自己喜欢的人一起提高英语口语：自己。 如果您已经在用英语思考，请尝试大声说出您的想法。大声读出来。练习就是练习，即使你没有任何人可以纠正你的错误，只要大声说话就可以帮助你更好地说英语。 3.使用镜子每当你可以的时候，花几天时间站在镜子面前说话。选择一个主题，设置一个计时器两到三分钟，然后说话。 这个练习的目的是在你说话时注意你的嘴，脸和肢体语言。这也让你觉得你在和别人说话，所以你可以假装你和一个学习伙伴讨论过。 说说整整两三分钟。不要停止！如果你遇到一个你不知道的单词，试着以不同的方式表达你的想法。你总是可以在两到三分钟结束后查看如何说出这个单词。这肯定会帮助您找出您遇到问题的单词或句子。 4.专注于英语流利，而不是语法当你说英语时，你多久停一次？ 你停的越多，你的声音就越不自信，你变得越不舒服。尝试上面的镜子练习，但挑战自己说话时不要停止或口吃（在你的话语之间停顿）整个时间。 这可能意味着你的句子在语法上不完美，那没关系！如果你专注于流利地说话而不是正确说话，你仍然会被理解，你会听起来更好。当您更好地学习它们时，您可以填写正确的语法和单词规则。 5.试试英语绕口令绕口令是一系列很难说的话。一个例子是：“三十三个小偷认为他们在整个星期四激动了宝座。”试着这几次！这是不容易的。 像这样的文字游戏将帮助您找到适合您口腔和舌头的位置，甚至可以帮助您发音。你可以在这里找到一个很好的绕口令列表。 6.倾听并重复你用英语看电视节目或YouTube视频吗？用它们来提高你的流利程度。选择节目的一小部分并逐行重复。尝试匹配音调，速度甚至重音（如果可以）。如果你错过几句话没关系，重要的是继续说话。尝试听起来像节目中的母语人士。 FluentU是练习聆听和重复的好方法。 FluentU采用真实世界的视频，如音乐视频，电影预告片，新闻和鼓舞人心的演讲，并将其转化为个性化的语言学习课程。 每当您在此处观看视频时，您都会在屏幕上看到所有语音消息。 这使得倾听和重复变得更加容易。当你想要挑战时，只需关闭字幕即可！ 如果您看到一个您不知道的单词，请点击该单词以查看使用该单词的图像，定义，示例和其他视频。 例如，如果点击“带”这个词，那么你会看到： FluentU可让您点按以查找任何单词。 您可以使用FluentU学习任何视频的词汇。向左或向右滑动以查看您正在学习的单词的更多示例。 FluentU可帮助您快速学习有用的问题和多个示例。学到更多。 在FluentU，您可以决定学习方式。您可以自由选择哪些视频对您的个人 学习体验最有趣。 你听这个真正的英语越多，你就越能理解如何自然地说英语。 使用 计算机或平板电脑在网站上开始 使用FluentU，或 从iTunes商店 或Google Play商店下载FluentU应用程序。 7.注意强调的声音英语在单词和句子中使用压力。这意味着当你说英语时，你需要强调或强调某些单词和音节（声音）来赋予单词和句子不同的含义。 聆听母语人士说话时强调的地方。尝试以同样的方式重复它，以提高自己演讲中的英语压力。 这不仅可以帮助你说英语，甚至可以减少误解。有时将压力放在错误的音节上会完全改变这个词。例如，ADdress这个词与adDRESS这个词不同。ADdress指的是某人居住的物理位置，adDRESS意味着正式与一群人交谈。 学会听到差异！ 8.唱英文歌和你最喜欢的英文歌曲一起唱歌会让你变得更流畅。这是一种经过验证的语言学习方法，它以科学为后盾。 一旦你可以和Taylor Swift和Jason Mraz一起唱歌，你可以用更难的东西测试你的技能：说唱！ 说唱是练习英语的好方法，因为这些单词通常像普通句子一样说。然而，说唱歌手使用更强的节奏和更快的速度。有些单词可能没有意义，但是如果你能跟上说唱歌手的话，那么你就可以开始流利了！ 9.用新词学习单词形式在你张开嘴之前，有些练习。通过学习您学习的任何单词的不同形式，使说话更容易。你应该在学习新词汇时这样做。例如，如果您刚刚学习了写单词，您还应该学习其他一些形式，如 写和写。 知道在任何一种句子中使用单词的正确方法很重要。这种知识可以帮助你说话。你不必停下来想想不同的词 - 你会确切地知道你何时需要在讲话时使用这个词。 10.学习短语，而不是单词提高英语水平的一个更好的想法是学习单词短语，而不仅仅是单词。 你可能正在使用正确的语法和词汇，但它仍然不是母语人士会说的。 例如，你可以说“你今天感觉如何？”但是母语人士可能会说“你在做什么？”或者“怎么了？”。当您说话时，短语和表达可以帮助您发出更自然的声音。 11.学习你最常见的谚语花一些时间来真正注意你的母语怎么说。 你经常使用哪些单词和短语？ 了解如何用英语说出最常用的短语和单词。用英语了解它们将帮助您用英语和您的母语一样用英语说话。 12.为特定情况做好准备您是否因特定原因学习英语口语？例如，您是否正在学习英语，以便在英语公司找到工作？在这种情况下，练习英语将帮助您在面试中。你在学习英语，这样你就可以在美国交朋友吗？那你需要一种不同的英语。 在你去一个你必须说英语的地方之前，你可以练习你可能要说的话。如果你准备去餐厅，餐馆里的谈话听起来像什么？回答服务员可能会问你的问题。尝试谈论食物和菜单。 如果你做好准备，你会感到更自信！ 13.放松！在学会流利说话时，你可以成为你最好的帮手或最大的敌人！我们知道这很难，但你应该尽量不要担心发言时的声音。放轻松！ 如果你陷入困境或困惑，只需大口气然后重新开始。如果必须，请说慢一点。花些时间停下来思考你的下一句话。 尽情享受说英语会变得更加舒适。 14.用英语讲述你的语言故事这是一种有趣的方式来测试你的英语口语的发展程度：选择一个你熟悉的故事并用英语讲述。 当你讲述你的故事时，记得用英语思考。专注于说流利而不是正确。对自己大声说出每一句话。 即使你没有人用英语交谈，你仍然可以在自己的时间建立信心和掌握流利。 在某些方面，练习口语 自己更容易 ！现在你知道如何自己提高英语口语，并且应该有信心这样做！","categories":[{"name":"English Skills","slug":"English-Skills","permalink":"http://blog.ozairs.com/categories/English-Skills/"}],"tags":[{"name":"Speaking","slug":"Speaking","permalink":"http://blog.ozairs.com/tags/Speaking/"}],"keywords":[{"name":"English Skills","slug":"English-Skills","permalink":"http://blog.ozairs.com/categories/English-Skills/"}]},{"title":"如何提升英语技能","slug":"如何提升英语技能","date":"2019-04-27T10:12:32.000Z","updated":"2019-04-27T10:16:34.061Z","comments":true,"path":"uncategorized/如何提升英语技能/","link":"","permalink":"http://blog.ozairs.com/uncategorized/如何提升英语技能/","excerpt":"","text":"","categories":[],"tags":[],"keywords":[]},{"title":"作为领导者，时间是您最有价值的资源","slug":"作为领导者，时间是您最有价值的资源","date":"2019-04-27T06:25:34.000Z","updated":"2019-04-27T06:56:41.615Z","comments":true,"path":"评论/作为领导者，时间是您最有价值的资源/","link":"","permalink":"http://blog.ozairs.com/评论/作为领导者，时间是您最有价值的资源/","excerpt":"","text":"【译文】 在亚马逊的面试过程中，最后我们会留出五分钟，由面试者进行提问。有些人询问他们将与之合作的团队，而其他人询问他们将使用的技术。 有时一位候选人说，“我听说亚马逊可能是一个非常难以工作的地方。有些人茁壮成长，有些人失败。为什么会这样，我怎么能避免加入失败者的行列呢？“ 这是一个很好的问题。多年来，我在亚马逊多次听到很多次类似这样的问题： 我几乎要疯了！我有14个直接报告和一个关键项目在同时进行，我的日历已完全占满。我可以取得任何进展的唯一方法是在我的团队回家后继续工作。我不确定我能忍受多久。 我对受访者的通常回答如下： 亚马逊有无数的工作。需要救火的工作永远不会减少。没有人会为你扼杀你的工作。如果你很难说不，或者很难确定工作的优先顺序的花，那么你一定会被工作所淹没。你会工作越来越多，直到你最终退出。另一方面，如果你的工作并不糟糕，而且你可以选择正确的事情去做，并对其他一切说不的话，那么你会喜欢上它。 如果你把这个建议付诸实践的话，它将为你的余生带来诸多好处。你可以将“亚马逊”替换为任何其他公司、副业或甚至是你的个人生活。你的时间是你最宝贵的资源。你不能做得更多。你不能暂停它。你只能分配它。以下教你如何去分配时间： 确定你最重要的任务在我在亚马逊的职业生涯早期，我获准在一个紧迫的截止日期前为一个重要项目雇用五名额外的工程师。我在亚马逊的内部系统中开设了职位，并与一些人讨论了内部调动。我还开始编写项目计划，创建要开始工作的主要故事，并安排与我们的工程师进行设计审查会议。几个星期后，我和我的经理讨论过这个问题： 经理：招聘怎么样？如你所知，项目截止日期十分紧迫。 我：这有点慢。我可能会填补一个职位。 经理：你认为这是你最重要的任务吗？ 我：我尽可能多地花时间，但我的工作日历排的很满。我有这个关键项目，我现有的工作，以及一个非常大的团队。有很多事情要做，我会更加努力。 经理：我认为你同意如果没有这五位工程师的话，你就无法完成项目。总会有很多事情发生。努力尝试不是一种解决问题的办法。如果你没有花费至少50％的时间在这上面，那么你的计划很有可能会失败。您需要每天花费至少四小时的时间来招聘。咖啡加上可能候选人，组织招聘会议，更新职位描述。没有这个你就不会成功。没有其他一切，你还有可能成功。 那天我的经理教了我一堂非常有价值的课。我尝试去认真思考，那时那刻我必须做的重要的事情。但是我需要退后一步，评估我是否将时间分配到了我想去的地方。我很努力地低头拉车，但显然没有做到抬头看路。 我内化了我的经理说的话。我认识到我在整体上取得了进步，但并没有朝着我最重要的目的地迈进。我的工作主要集中在我的大部分工作上，但我需要将注意力集中在我最重要的工作上。 意识到一切照旧都行不通几年前，我是一只非常忙碌的蜜蜂。我有多个团队，有数十名工程师和经理向我汇报。我有长期的项目规划，架构和设计讨论，每周几十次一对一的会议，广泛的组织会议，运营审查会议等等。我的日历总是每周预约至少40小时的会议，我每周至少工作50-60小时。我很开心，但似乎我在透支我的精力。 然后我被要求进行大规模的跨组织规划过程。我被清楚地告知，这将是我未来三个月的首要任务。在此期间，我预计每周至少花20个小时来完成这个规划过程。这个过程将有助于确定我们的组织明年将关注的重点，因此它可以利用数百名工程师。在亚马逊一如既往，我没有被剥夺任何我已经管理过的东西。我刚刚获得了这个重要的角色，并期望解决这个问题。 选择性地选择一些东西，并去掉其他一切，只关注并处理你认为最重要的事情。 我对这个职业机会感到非常兴奋，但似乎我每周还需要至少在多工作10-20小时。 我还记得那天晚上坐在办公室里喝啤酒（不要评判我），盯着被排的满满的日历。我开始寻找任何明显可切割的东西。我每周例行的一对一面谈拉升到2周一次。我盯着我的日历，最后，我认识到必须改作出一些重大的改变，否则日程表依然会排的满满当当。 直面惨淡的人生当我试图将事情从我们的生活中剔除时，我们经常会提出错误的问题。我们会问一些事情是否重要，或者我们是否重视。答案肯定很容易回答。相反，我们应该问这两个问题： “如果我精简掉这个，最糟糕的结果是什么？” “从长远来看，这会让我想要去哪里吗？” 想想如果你精简这个项目/工作/任务/会议你会遇到的痛苦。最糟糕的结果是什么？你能处理吗？同样重要的是，这个项目/工作/任务/会议是否与您最重要的长期目标相关？ 那天晚上，我喝完了啤酒，我把我的日程表精简到不能再精简。我让我的一位经理参加了每周的运营会议，然后放弃了。我让我的一位高级工程师负责架构会议系列，然后放弃它。我让所有初级员工都参加两周一次的会议。我让几位员工直接向经理报告。我放弃了每周项目状态会议。我放弃了几个员工。 我每周开会15个小时。我能够轻松地将计划流程安排到我的日历中，同时减少每周的工作时间。 检查结果和后果当我完成计划过程时，我的日历突然变成了半空。这对于像我这样的职位来说非常罕见。我当然没有经历过。 首先，我完全删除了一些工作。这些会议很有用，但还不足以证明它们需要占用我或者其他人的时间。空闲时间给予无限的投资回报。 其次，我已经为我的经理和一些高级工程师委派了一些高可见和重要的工作。双方都取得了巨大的成功。我知道我该怎么开展我的工作。这不是具有成长性的工作，而仅仅只是在维持工作。我给了他人成长的机会，他们茁壮成长。新的所有者改变了一些流程并进行了改进。他们受到新机遇的挑战，对所有参与者来说都是令人兴奋的。 具有挑战性的工作才是具有成长性的工作，坚持这些领导职位，我一直试图在剥夺别人自己成长的机会。授权是一项双赢的工作。你有更多的时间，而其他人获得了宝贵的经验。 我预计一旦项目结束，我会可能会需要弥补短暂的痛苦。相反，我做了一个健康的切割，大多数变化是永久性的。我现在有时间重新评估对我和我的团队来说重要的是什么，从长远来看，我已经可以安排这项工作了。 定期精简当您从日程表中精简某些内容时，通常会从重要性堆栈排名的底部选择一个项目。你说，“我每天需要30分钟完成这项任务，所以我会放弃这项任务。”它的投资回报率有限，因为你只是将一件物品交换成另一件物品。 相反，你需要最大程度精简你的日程表。切换你的工作流程，而不是从重要性堆栈排名的底部进行删减。选择性地选择一些东西，并删减掉其他一切。只处理你最重要的事情。 看看你正在做的每一件事。确定你是否需要每个人实现最重要的长期目标。如果没有，问问自己如果精简掉它的话，会带来多少痛苦。考虑将这段时间花在最高优先级上是否有意义。 你的首要任务几乎总是那些在你生活中发挥作用的东西，在这些东西上花费的时间才是最最宝贵的。 【原文】 During interviews at Amazon, we allow five minutes for questions at the end. Some people ask about the team they’ll be working with, while others inquire about the technology they’ll be using. Occasionally a candidate says, “I’ve heard Amazon can be a really hard place to work. Some people thrive and some people fail. Why is that, and how can I avoid joining the ranks of those who fail?” This is a great question. I have heard a variation of this statement at Amazon dozens of times over the years: I’m going to lose my mind! I have 14 direct reports and one critical project on fire, and my calendar is completely packed. The only way I can make any progress is by working after my team goes home. I’m not sure how much longer I can take it. My usual answer to the interviewee is this: Amazon has an infinite amount of work. The fire hose of work will never abate. No one will throttle your work for you. If you have a hard time saying no, or a hard time prioritizing your tasks, you are guaranteed to drown. You will work more and more hours until you eventually quit. On the other hand, if you aren’t terrible at your job, and you can pick the right things to work on and say no to everything else, you’ll love it here. If you put this advice into practice, it will pay dividends for the rest of your life. You can replace “Amazon” with any modern company, a side business, or even your personal life. Your time is your most valuable resource. You can’t make more. You can’t pause it. You can only allocate it. Here’s how. Identify your most important taskEarly in my career at Amazon, I received approval to hire five additional engineers for an important project with a tight deadline. I opened the positions in Amazon’s internal system and talked to a few people about transferring. I also began writing up a project plan, creating the major stories to begin working on, and scheduling design review meetings with our engineers. I had a discussion with my manager a few weeks later, which went something like this: Manager: How’s the hiring going? As you’re aware, you have a tight deadline. Me: It’s a bit slow. I might have one position filled. Manager: Are you treating this as your most important task? Me: I’m spending as much time on it as I can, but I have a pretty full calendar. I have this critical project, my existing work, and a pretty big team. There’s a lot going on. I’ll try harder. Manager: I assume you agree that you can’t finish the project without those five engineers. There will always be a lot going on. Trying harder is not a mechanism. If you’re not literally spending at least 50% of your time on this, you’re planning to fail. You need to spend at least four hours a day on hiring. Coffees with potential hires. Meetings with recruiting. Updating job descriptions. You can’t succeed without this. You can succeed without almost everything else. My manager taught me a very valuable lesson that day. I was looking one level deep at the seemingly important things I had to do right then and there. But I needed to take a step back and assess whether I was allocating my time to take me to where I wanted to go. I was pedaling my bike as hard as I could, but I wasn’t looking at the street signs. I internalized what my manager said. I recognized I was making progress in general, but not toward my most important destination. I was broadly focused on the bulk of my work, but I needed to focus narrowly on my most important work. Realize that business as usual won’t workA number of years ago, I was a very busy bee. I had multiple teams, with dozens of engineers and managers reporting to me. I had long-term project planning, architecture and design discussions, a couple of dozen one-on-one meetings a week, broad organizational meetings, operation review meetings, and more. My calendar was always booked with at least 40 hours of meetings a week, and I tended to spend at least another 10 to 20 hours at work per week. I was having fun, but I was also burning the candle at both ends. I was then asked to run a massive cross-organizational planning process. I was told very clearly that this would be my top priority for the next three months. During that time, I would be expected to spend at least 20 hours per week on this planning process. The process would help determine what our organization would focus on for the next year, so it had leverage over hundreds of engineers. As is always true at Amazon, I wasn’t being taken off anything I already managed. I was just offered this important role, and expected to solve the problem. Selectively pick a few things, and cut everything else. Work on only your most important things. I was excited for the career opportunity, but I also had to fit another 20 hours into my 50- to 60-hour workweek. I can still remember sitting in my office that evening with a beer (don’t judge me), staring at my completely full calendar. I started by looking for anything obvious to cut. I switched one weekly one-on-one to biweekly. Then I stared at my calendar some more. Finally I recognized that something drastic had to change. Business as usual was not going to cut it. Cut to the bone and measure the painWhen trying to cut things out of our lives, we often ask the wrong questions. We ask whether something is important, or if we value it. It is far too easy to answer in the affirmative. Instead, we should ask these two questions: “What is the worst case result if I cut this?” “Is this going to get me where I want to go in the long run?” Think of the pain you’ll experience if you cut this item/work/task/meeting. What is the worst result? Can you handle it? And, equally important, is this item/work/task/meeting related to your most important long-term goals? That night I finished my beer and cut my schedule to the bone. I asked one of my managers to attend the weekly operations meeting, then dropped it. I asked one of my senior engineers to take charge of the architecture meeting series, then dropped it. I moved all junior employees to biweekly meetings. I moved a couple of direct employees to report to a manager. I dropped the weekly project status meeting. I dropped a couple of mentees—with apologies. I was down to perhaps 15 hours of meetings a week. I was able to easily schedule the planning process into my calendar, and at the same time cut down my hours worked each week. Examine results and aftermathWhen I completed the planning process, my calendar was suddenly half-empty. This was very rare for those in positions like mine. I had certainly never experienced it. First, I had completely removed some work. These meetings were useful, but not enough to justify their time on my or anyone else’s calendar. Free time back gives an infinite return on investment. Second, I had delegated some high visibility and critical work to my managers and a few senior engineers. It was a wild success for both parties. I was delegating work I knew how to do. This wasn’t growth work; it was maintenance. I gave people growth opportunities, and they thrived. The new owners changed some processes and made improvements. They were challenged by the new opportunities, and it was exciting for all involved. Challenging work is growth work, and by holding on to those leadership positions I had been depriving someone else of their own opportunity to grow. Delegating is a gift with two recipients. You get more time, and someone else gains valuable experience. I expected temporary pain that I would remedy once the project was over. Instead, I had made a healthy cut, and most of the changes were permanent. I now had the time to re-evaluate what was important to me and my group in the long run, and I could schedule that work instead. Make regular cutsWhen you remove something from your schedule, you’re usually picking a single item from the bottom of your importance stack rank. You’re saying, “I need 30 minutes more per day, so I’ll drop this single 30-minute task.” It has limited return on investment, because you’re swapping one item for another. Instead, make regular cuts to the bone with your schedule, your possessions, and the like. Instead of cutting from the bottom of your stack rank, switch your process. Selectively pick a few things, and cut everything else. Work on only your most important things. Look at every single thing you’re doing. Determine whether you need each one to achieve your most important long-term goals. If not, ask yourself how much pain you’d feel if you cut it. Consider whether it makes sense to spend that time on your top priorities instead. Your top priorities are almost always the things that move the needle in your life, and time spent there is the most precious.","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"时间","slug":"时间","permalink":"http://blog.ozairs.com/tags/时间/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"AWS的生产环境准备清单","slug":"AWS的生产环境准备清单","date":"2019-04-25T10:26:39.000Z","updated":"2019-04-25T10:28:04.880Z","comments":true,"path":"DevOps/AWS的生产环境准备清单/","link":"","permalink":"http://blog.ozairs.com/DevOps/AWS的生产环境准备清单/","excerpt":"","text":"你刚刚建立了你的惊人的新应用程序 它会改变一切。但首先，您需要将其部署到AWS。你究竟是怎么做到的？ 事实证明，有很多步骤。事实上几百个。你可能错过了一些。例如： 您是否记得加密所有应用程序机密，或者您是否在某处以纯文本形式存在数据库密码或API密钥？ 您的数据库是否已备份？你怎么知道的？我的意思是，你真的试过从其中一个备份中恢复吗？ 您团队中的每个开发人员是否共享一个到服务器SSH的EC2 KeyPair？如果其中一个开发者离开公司，你打算做什么？ 您是否在EC2实例中使用IAM角色？您是否记得锁定EC2元数据端点以便只能root访问它？ 您的实例是否在ASG中运行，启用了ELB运行状况检查，部署在多个AZ，私有子网中，受NACL保护？ 我敢打赌，至少有一些人在阅读上面的一些项目时感到畏缩。也许你对所有人都感到畏缩。你们中的一些人可能会觉得这样： 好吧，我们为您提供解决方案。在Gruntwork，我们通过全面的检查表帮助数百家公司在AWS上运行。今天，我们很高兴与大家分享清单： AWS的生产准备清单 此核对表是您在AWS中部署安全，可扩展且高度可用的基础架构的最佳实践的指南。它涵盖了一系列主题，包括服务器端应用程序，客户端应用程序，持续集成，持续交付，架构，安全性，监控以及利用现代DevOps和云原生实践所需的一切。在您上线之前，请仔细检查每个项目，并确保您没有错过任何重要的内容！ 哦，如果所有这些基础设施工作感觉有点压倒性，请记住道格拉斯亚当斯的话：不要恐慌。创建一个生产就绪的基础设施是很多工作，但我们已经为您提供了保障。清单中的所有内容都已作为代码库的Gruntwork Infrastructure的一部分，并且可作为参考体系结构的一部分在1天内部署在您的AWS账户中。 因此，请开始使用清单并让您的应用程序正常运行！ 整个基础设施，定义为代码，大约需要一天。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"Gruntwork 2018年回顾","slug":"Gruntwork-2018年回顾","date":"2019-04-25T10:19:35.000Z","updated":"2019-04-25T10:26:11.025Z","comments":true,"path":"评论/Gruntwork-2018年回顾/","link":"","permalink":"http://blog.ozairs.com/评论/Gruntwork-2018年回顾/","excerpt":"","text":"在Gruntwork，我们在冬季关闭了几个星期，让每个人都回家，与家人共度时光，庆祝节日，放松，并花些时间思考。我发现这是暂停和思考这一年的好时机。 很容易迷失在细节中，为眼前的失败而感到到沮丧，并沉迷于没有完成的事情，所以你经常忘记环顾四周，看看你到底有多远。今年，我们开始在Gruntwork开始写一篇年度评论博客文章作为一种停止方式的传统，花一些时间欣赏去年发生的一切，并开始考虑明年。 该团队于2018年我们从2018年开始只有3人; 我们今年结束了9名全职员工和3名员工。作为一家100％的自助公司，这是一个非凡的增长率。此外，无论他们在世界的哪个地方，包括英国，德国，芬兰，尼日利亚和整个美国，我们都通过雇用我们能找到的最有才能的人来充分利用成为100％分布式公司的优势（有关所有详细信息，请参阅我们的关于页面 这就是现代公司的样子： 能够每天与这样的团队一起工作，我感到非常荣幸和非常幸运。该团队拥有丰富的经验，从初创公司到各行各业的财富500强公司，包括医疗保健，旅游，电信，基础设施管理，社交网络，FinTech，EdTech，零售，游戏等等。最重要的是，他们是善良，诚实，有趣的人。 公司成立于2018年我们在2018年达到了一个重要的里程碑：年度经常性收入100万美元（全年总收入约160万美元）。我们以筹集资金0美元和债务0美元来实现这一里程碑，我们实现了盈利，为每个人支付了不错的薪水和奖金，并且增长迅速。 今年我们的用户群增长了近4倍，我们有幸与世界上一些最大的品牌合作。我们已经完成了所有这一切，只有2人的销售团队，Josh和我，Josh加紧处理大部分销售工作。 我为我们的营销方式感到特别自豪，这几乎完全包括制作高质量的内容 - 特别是博客文章，演讲和开源代码 - 向全世界讲述DevOps。以下是一些亮点： 编写超过300,000行基础设施代码的5个经验教训 在命令行上对AWS进行身份验证的综合指南 AWS的生产准备清单 我们还在2018年发布了一些开源项目，我将在下一节中讨论。 我们在2018年建造的在2018年，我们写了很多代码。以下是一些亮点（您可以在我们的月刊中获得所有血腥细节）： Gruntwork Houston：我们推出了Gruntwork Houston的第一个版本！私有测试版提供了一种更好的方式来处理AWS上的身份验证，允许您使用现有的身份提供商（例如，ADFS，Google，Okta等）通过Web，命令行，VPN和SSH访问您的AWS账户。私有alpha提供了一个简单的Web界面，您的开发团队可以使用它来部署和管理基础架构，而在幕后，Web界面以及它如何管理基础架构完全由您的Ops团队定义和控制为代码。 Kubernetes：我们在基础架构中添加了一组模块作为代码库，以使用EKS 在AWS中部署和管理Kubernetes集群。 ELK堆栈：我们创建了一组模块，用于在AWS上运行您自己的Elasticsearch，Logstash和Kibana（ELK）集群。 InfluxDB企业版：我们与InfluxData团队合作，构建和开源一组模块，以在AWS上运行InfluxDB企业。 Couchbase：我们与Couchbase团队合作，构建并开源了一组模块，以在AWS上运行Couchbase和Sync Gateway。 Lambda + API网关：我们创建了一组模块，使您可以使用AWS Lambda，API Gateway和Swagger构建无服务器的Web应用程序。 ECS改进：我们更新了ECS模块以支持Fargate，服务发现，守护程序服务和部署检查。 NLB：我们添加了模块来部署和管理亚马逊的网络负载均衡器（NLB）。 Terratest：我们开源Terratest，我们用于测试基础设施代码的瑞士军刀，并对该库进行了大量改进，包括添加对Google Cloud，Kubernetes，日志解析和日志文件收集的支持。 Terragrunt：我们做了很多的改进Terragrunt，我们的开源Terraform包装，包括增加支持的错误重试，前/挂机后，和许多改进的init命令和缓存。 cloud-nuke：我们开源的cloud-nuke是一个用于删除AWS账户中所有资源的CLI工具，我们用它来大大减少用于自动化测试的账户的AWS账单。 bash-commons：我们开源bash-commons，一组可重复使用的bash实用程序，包括文档和自动化测试。 Redis：我们重构了我们的Redis模块，以使用最新的Terraform资源，并增加了对身份验证，加密和分片的支持。 还有更多：我们对AWS和GCP的Consul和Vault模块进行了大量更新（增加了对Consul和Vault Enterprise，Auto Pilot，Auto Unseal和Auth方法的支持），更新了所有模块以与Terraform 0.11配合使用，添加了ip-lockdown模块可以在使用IAM角色时显着提高安全性，还有更多。 期待2019年我们对明年非常兴奋。以下是我们所关注的内容： Gruntwork Houston：休斯顿是2019年我们的首要任务，我们将尽可能地加大开发力度，因为我们相信它提供了一个从根本上更好的DevOps体验。最初，我们将继续与私人测试版和阿尔法客户一起测试休斯顿（如果您有兴趣，请发送电子邮件至info@gruntwork.io），但只要我们确定了用户体验，我们就会将休斯顿公之于众。给大家。 Google Cloud和Azure： 2019年，我们将扩展Gruntwork Infrastructure作为代码库，为Google Cloud和Azure提供一流的支持！今天，图书馆主要关注AWS，但在明年，我们可以在大约一天内将您的整个基础架构定义为任何（或所有！）主要公共云的代码！我们正在寻找与我们合作的公司，所以如果您有兴趣，请发送电子邮件至info@gruntwork.io！ AWS：我们当然也将继续投资我们的AWS产品，包括改善使用Lambda和API Gateway构建无服务器应用程序的端到端体验，对CloudWatch监控，警报和日志聚合工具的主要更新，添加ECS集群调整大小/重新部署工具，更新所有模块以支持Amazon Linux 2和systemd，将Kafka模块更新为Kafka 2.x，改进ZooKeeper模块的运行状况检查等等。 Kubernetes：我们将使用可重复使用的模块扩展我们的Kubernetes代码，用于定义和管理您的Kubernetes服务作为代码，一流（安全！）Helm / Tiller支持，以及Gruntwork参考架构中的一流支持。此外，我们将浏览现有的基于VM的模块库，并开始添加在Kubernetes上运行的类似基于Docker的模块。这将允许公司使用Kubernetes定义和管理其大部分基础架构，使其基础架构更加一致，可在云之间移植，并且更易于测试。 支持和维护：公司成为Gruntwork客户的主要原因是，我们不仅可以访问基础设施作为代码库中的300,000多个经过实战检验的代码，还可以访问该库的持续支持和维护。我们将在2019年继续这样做，包括更新整个库以支持和利用Terraform 0.12中的所有更改，添加对新的最佳实践的支持，并修复我们发现的任何错误。 战略计划：我们将扩展Gruntwork合作伙伴计划，使我们的客户更容易找到DevOps顾问和托管服务提供商，与熟悉Gruntwork代码的人员合作，并使我们的合作伙伴更轻松地使用和转售Gruntwork Infrastructure作为代码库作为自己产品的一部分。我们还将对Gruntwork网站进行重大更改，包括提供试用期以及使订阅和用户管理完全自助服务和自动化。 我们正在接受请求！在Gruntwork，我们没有在真空中提出我们的路线图，并在洞穴中消失了6个月来构建它。我们在Gruntwork建立的每一件事都是客户提出并付费的事情（看我们如何引导公司）。如果您希望我们在2019年建立一些不在列表中的东西，我们提供定制模块开发，请发送电子邮件至info@gruntwork.io告诉我们您的需求！ 2018年是地狱般的一年，预祝2019年一帆风顺！","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/tags/DevOps/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"Azure服务之旅","slug":"Azure服务之旅","date":"2019-04-22T09:56:57.000Z","updated":"2019-04-22T10:11:10.479Z","comments":true,"path":"Cloud-Service/Azure服务之旅/","link":"","permalink":"http://blog.ozairs.com/Cloud-Service/Azure服务之旅/","excerpt":"","text":"Azure服务以下是Azure中可用服务和功能的全景图。 让我们仔细看看最常用的类别： 计算 联网 存储 移动 数据库 卷筒纸 物联网 大数据 人工智能 DevOps的 计算计算服务通常是公司迁移到Azure平台的主要原因之一。Azure为托管应用程序和服务提供了一系列选项。以下是Azure中计算服务的一些示例： 服务名称 服务功能 Azure Vitual Machines Azure中托管的Windows或Linux虚拟机（VM） Azure Vitual Machine Scale Sets 扩展Azure中托管的Windows或Linux VM Azure Kubernetes Service 支持管理运行容器化服务的VM群集 Azure Service Fabric 分布式系统平台。在Azure或本地运行 Azure Batch 为并行和高性能计算应用程序提供托管服务 Azure Container Instances 在Azure上运行容器化应用程序而无需配置服务器或VM Azure Functions 事件驱动的无服务器计算服务 联网链接计算资源和提供对应用程序的访问是Azure网络的关键功能。Azure中的网络功能包括一系列选项，用于将外部世界连接到全局Microsoft Azure数据中心中的服务和功能。 Azure网络设施具有以下功能： 服务名称 服务功能 Azure Virtual Network 将VM连接到传入的虚拟专用网络（VPN）连接 Azure Load Balancer 平衡到应用程序或服务端点的入站和出站连接 Azure Application Gateway 优化应用服务器场传输，同时提高应用安全性 Azure VPN Gateway 通过高性能VPN网关访问Azure虚拟网络 Azure DNS 提供超快的DNS响应和超高域可用性 Azure VPN Gateway 为全球客户提供高带宽内容 Azure DDoS Protection 保护Azure托管的应用程序免受分布式拒绝服务（DDOS）攻击 Azure Traffic Manager 分布全球Azure区域的网络流量 Azure ExpressRoute 通过高带宽专用安全连接连接到Azure Azure Network Watcher 使用基于场景的分析监控和诊断网络问题 Azure Firewall 实现具有无限可扩展性的高安全性，高可用性防火墙 Azure Virtual WAN 创建统一的广域网（WAN），连接本地和远程站点 存储Azure提供四种主要类型的存储服务。这些服务是： 服务名称 服务功能 Azure Blob Storage 用于非常大的对象的存储服务，例如视频文件或位图 Azure FIle Storage 您可以像文件服务器一样访问和管理的文件共享 Azure Queue Storage 用于在应用程序之间排队并可靠地传递消息的数据存储 Azure Table Storage 存储非结构化数据的NoSQL存储，独立于任何模式 这些服务都有几个共同特征： 耐用且高度可用，具有冗余和复制功能。 通过自动加密和基于角色的访问控制来保护安全。 可扩展，几乎无限存储。 管理，处理维护和任何关键问题。 可通过HTTP或HTTPS从世界上任何地方访问。 移动Azure使开发人员能够快速，轻松地为iOS，Android和Windows应用程序创建移动后端服务。过去需要花费时间并增加项目风险的功能（例如添加公司登录，然后连接到SAP，Oracle，SQL Server和SharePoint等本地资源）现在很容易包含在内。 该服务的其他功能包括： 离线数据同步。 与本地数据的连接。 广播推送通知。 自动缩放以满足业务需求。 数据库Azure提供多种数据库服务来存储各种数据类型和卷。通过全球连接，这些数据可立即供用户使用。 服务名称 服务功能 Azure Cosmos DB 支持NoSQL选项的全局分布式数据库 Azure SQL Database 完全托管的关系数据库，具有自动扩展，集成智能和强大的安全性 Azure Database for MySQL 完全托管和可扩展的MySQL关系数据库，具有高可用性和安全性 Azure Database for PostgreSQL 完全托管和可扩展的PostgreSQL关系数据库，具有高可用性和安全性 SQL Server on VMs 在云中托管企业SQL Server应用程序 Azure SQL Data Warehouse 完全管理的数据仓库，无需额外费用即可在各种规模上实现完整的安全性 Azure Database Migration Service 无需更改应用程序代码即可将数据库迁移到云 Azure Redrest for Redis 缓存经常使用的静态数据以减少数据和应用程序延迟 Azure Database for MariaDB 完全托管且可扩展的MariaDB关系数据库，具有高可用性和安全性 Web拥有出色的网络体验对于当今的商业世界至关重要。Azure包括构建和托管Web应用程序以及基于HTTP的Web服务的一流支持。专注于Web托管的Azure服务包括： 服务名称 描述 Azure App Service 快速创建功能强大的基于Web的云应用程序 Azure Notification Hubs 从任何后端向任何平台发送推送通知。 Azure API Management 安全且大规模地向开发人员，合作伙伴和员工发布API。 Azure Search 完全托管的搜索即服务。 Web Apps feature of Azure App Service 大规模创建和部署任务关键型Web应用程序。 Azure SignalR Service 轻松添加实时Web功能。 物联网人们能够获得比以往更多的信息。它始于个人数字助理（PDA），然后演变为智能手机。现在有智能手表，智能恒温器，甚至智能冰箱。个人电脑曾经是常态。现在互联网允许任何在线能够访问有价值信息的项目。设备获取然后中继信息以进行数据分析的这种能力被称为物联网（IoT）。 有许多服务可以为Azure上的物联网提供协助和驱动端到端解决方案。 服务名称 描述 IoT Central 全面管理的全球物联网软件即服务（SaaS）解决方案，可轻松连接，监控和管理您的物联网资产 Azure IoT Hub 消息中心，提供数百万个物联网设备之间的安全通信和监控 IoT Edge 将您的数据分析推送到您的IoT设备而不是云中，使他们能够更快地对状态变化做出反应。 大数据数据有各种格式和大小。当我们谈论大数据时，我们指的是大量数据。来自天气系统，通信系统，基因组研究，成像平台和许多其他场景的数据会产生数百GB的数据。这些数据使得分析和制定决策变得困难。它往往是如此之大，以至于传统形式的处理和分析已不再合适。 已经开发了开源集群技术来处理这些大型数据集。Microsoft Azure支持广泛的技术和服务，以提供大数据和分析解决方案。 服务名称 描述 Azure SQL Datawarehouse 使用基于云的企业数据仓库（EDW）大规模运行分析，该数据仓库利用大规模并行处理（MPP）在数PB的数据中快速运行复杂查询 Azure HDInsight 使用云中的Hadoop集群托管集群处理大量数据 Azure Databricks（preview） 协作的基于Apache Spark的分析服务，可与Azure中的其他大数据服务集成。 人工智能在云计算的背景下，人工智能基于广泛的服务，其核心是机器学习。机器学习是一种数据科学技术，它允许计算机使用现有数据来预测未来的行为，结果和趋势。使用机器学习，计算机无需明确编程即可学习。 机器学习的预测或预测可以使应用和设备更加智能。例如，当您在线购物时，机器学习会根据您购买的产品帮助推荐您可能喜欢的其他产品。或者，当刷卡时，机器学习会将交易与交易数据库进行比较，并有助于检测欺诈行为。当您的机器人吸尘器吸尘房间时，机器学习可帮助它确定工作是否完成。 Azure中一些最常见的人工智能和机器学习服务类型是： 服务名称 描述 Azure机Azure Machine Learning Service 基于云的环境，您可以使用它来开发，培训，测试，部署，管理和跟踪机器学习模型。它可以自动生成模型并为您自动调整模型。它将允许您开始在本地计算机上进行培训，然后扩展到云 Azure Machine Learning Studio 协作，拖放式可视化工作区，您可以使用预先构建的机器学习算法和数据处理模块构建，测试和部署机器学习解决方案 一组密切相关的产品是认知服务。这些是您可以在应用程序中利用的预构建API，以解决复杂问题。 服务名称 描述 Vision 图像处理算法，可以智能识别，标题，索引和调节您的图片和视频。 Speech 将语音转换为文本，使用语音进行验证，或在应用中添加说话人识别。 Knowledge mapping 映射复杂的信息和数据，以解决智能推荐和语义搜索等任务。 Bing Search 将Bing搜索API添加到您的应用中，并利用单个API调用功能来梳理数十亿个网页，图片，视频和新闻。 Natural Language processing 允许您的应用使用预先构建的脚本处理自然语言，评估情绪并学习如何识别用户想要的内容。 DevOpsDevOps（开发和运营）汇集了人员，流程和技术，自动化软件交付，为您的用户提供持续的价值。Azure DevOps Services允许您创建构建和发布为您的应用程序提供持续集成，交付和部署的管道。您可以集成存储库和应用程序测试，执行应用程序监视，以及使用构建工件。您还可以使用和积压项目进行跟踪，自动化基础架构部署以及集成一系列第三方工具和服务，例如Jenkins和Chef。所有这些功能以及更多功能都与Azure紧密集成，以便为您的应用程序提供一致，可重复的部署，从而提供简化的构建和发布流程。 Azure提供的一些主要DevOps服务是Azure DevOps Services和Azure DevTest Labs。 服务名称 描述 Azure DevOps Azure DevOps Services（以前称为Visual Studio Team Services，或VSTS）提供开发协作工具，包括高性能管道，免费的私有Git存储库，可配置的看板，以及广泛的自动化和基于云的负载测试 Azure DevTest Labs 快速创建按需Windows和Linux环境，您可以使用它们直接从部署管道测试或演示应用程序","categories":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}],"tags":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/tags/Azure/"}],"keywords":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}]},{"title":"Azure实战应用","slug":"Azure实战应用","date":"2019-04-22T06:21:53.000Z","updated":"2019-04-22T10:11:10.478Z","comments":true,"path":"Cloud-Service/Azure实战应用/","link":"","permalink":"http://blog.ozairs.com/Cloud-Service/Azure实战应用/","excerpt":"","text":"","categories":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}],"tags":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/tags/Azure/"}],"keywords":[{"name":"Cloud Service","slug":"Cloud-Service","permalink":"http://blog.ozairs.com/categories/Cloud-Service/"}]},{"title":"Azure Cosmos DB简介","slug":"Azure-Cosmos-DB简介","date":"2019-04-22T03:58:55.000Z","updated":"2019-04-22T04:12:42.045Z","comments":true,"path":"Azure/Azure-Cosmos-DB简介/","link":"","permalink":"http://blog.ozairs.com/Azure/Azure-Cosmos-DB简介/","excerpt":"","text":"Azure Cosmos DB 是由 Microsoft 提供的全球分布式多模型数据库。 只需单击一个按钮，即可通过 Azure Cosmos DB 跨任意数量的 Azure 地理区域弹性且独立地缩放吞吐量和存储。 它通过综合服务级别协议 (SLA) 提供吞吐量、延迟、可用性和一致性保证，这是其他数据库服务无法提供的。 Azure Cosmos DB 提供关系数据库和非关系数据库的最佳功能下表比较了关系DB，非关系DB和Cosmos DB的关系 功能 关系 DB 非关系 (NoSQL) DB Azure Cosmos DB全球分布 否 否 统包式解决方案，目前在中国有 2 个区域，多宿主，全球超过30个区域横向缩放 否 是 独立缩放存储和吞吐量延迟保证 否 是 在 99% 的情况下，读取操作的延迟 &lt; 10 毫秒，写入操作的延迟 &lt; 15 毫秒高可用性 否 是 始终可用，PACELC 权衡，自动和手动故障转移数据模型 + API关系 关系+SQL 多模型+OSS API 多模型 + SQL + OSS API（即将推出更多）SLA 是 否 有关延迟、吞吐量、一致性和可用性的综合 SLA*PACELC 解释：https://en.wikipedia.org/wiki/PACELC_theorem#Database_PACELC_ratings *OSS:对象存储（Object Storage Service，简称OSS） 关键功能作为一种全球分布式数据库服务，Azure Cosmos DB 提供以下功能，帮助构建可缩放的、具有高响应性的全球分布式应用程序： 统包式全球分布 应用程序在任何地方都可以即时提供给用户使用。 现在，数据也可以这样。 不必担心硬件以及添加节点、VM 或内核等问题。 只需点击一下，即可获得数据。 多个数据模型和用于访问及查询数据的常用 API 支持多个数据模型，包括键值、文档和列式数据模型。 用于 Node.js、Java、.NET、.NET Core、Python 和 MongoDB 的可扩展 API。 用于查询的 SQL。 在全球范围内按需求弹性缩放吞吐量和存储 以秒和分钟为时间粒度轻松缩放吞吐量，并可以随时对其进行更改。 透明且自动地缩放存储以满足现在和将来对大小的要求。 构建具有高响应性的任务关键型应用程序 在全球任意位置均可访问你的数据，99% 的情况下延迟仅为几毫秒。 确保“始终可用”可用性 在单个区域内可用性为 99.99%。 部署到任意数量的 Azure 区域可提高可用性。 模拟一个或多个区域的故障而保证不丢失任何数据。 编写全球分布式应用程序的正确方式 五个一致性模型提供类似于 SQL 的非常一致性到类似于 NoSQL 的最终一致性，以及介于两者之间的一致性。 退款保证 要么数据快速到达，要么退款。 有关可用性、延迟、吞吐量和一致性的服务级别协议。 无数据库架构/索引管理 无需担心将数据库架构和索引与应用程序架构保持同步的问题。 我们免架构。 拥有成本低廉 比非托管解决方案的成本效益高五到十倍。 比 DynamoDB 便宜三倍。 创建Comos DB点击Azure CosomosDB，出现如下界面，点击ID ，选择API，API目前有三种选择：MongoDB、SQL (DocumentDB) 和表（键/值），这里创建了一个 SQL(DocumentDB)测试。 创建成功后，点击：数据资源管理器 点击New Collection，创建数据集 ，输入数据库ID ,数据集的ID ， 容量，吞吐量，这里创建了 每秒400个的吞吐量， 400ru/s的能力。 这里创建了2个数据集，结果如下： 可以看到配置了区域是北京和上海，如果使用国际版意味着可以创建超过30个区域的配置。这就是DBA的梦想啊！！！ 也可以进行缩放配置，也就是说可以进行某个区域的性能进行调整。 浏览数据 应用使用数据 .Nets示例，如何使用程序读取 https://docs.azure.cn/zh-cn/cosmos-db/documentdb-dotnet-samples 其他示例： https://docs.azure.cn/zh-cn/cosmos-db/documentdb-nodejs-samples https://docs.azure.cn/zh-cn/cosmos-db/documentdb-python-samples 总结Cosmos DB 采用本机方式对数据进行分区，实现高可用性和可伸缩性。 Cosmos DB 在可用性、吞吐量、低延迟和一致性方面提供 99.99% 保证。 Cosmos DB 采用由 SSD 提供支持的存储，具有低延迟毫秒级响应时间。 Cosmos DB 支持最终、一致前缀、会话和有限过期等一致性级别，从而实现最大的灵活性和很高的性价比。 在一致性级别方面，没有任何数据库服务的灵活性比 Cosmos DB 更高。 Cosmos DB 提供灵活的数据友好型定价模式，独立测量存储和吞吐量。 Cosmos DB 保留的吞吐量模型使你可以考虑读取/写入数量而不考虑基础硬件的 CPU/内存/IOP。 Cosmos DB 的设计允许扩展到每天约数十亿个请求的大规模请求量。 Cosmos DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。","categories":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}],"tags":[{"name":"Cosmos DB","slug":"Cosmos-DB","permalink":"http://blog.ozairs.com/tags/Cosmos-DB/"}],"keywords":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}]},{"title":"Azure入门","slug":"Azure入门","date":"2019-04-22T03:28:48.000Z","updated":"2019-04-22T04:10:39.811Z","comments":true,"path":"Azure/Azure入门/","link":"","permalink":"http://blog.ozairs.com/Azure/Azure入门/","excerpt":"","text":"Azure 有两种无服务器计算实现： Azure Functions：可以执行几乎任何现代语言的代码 Azure 逻辑应用：在基于 Web 的设计器中设计，可执行由 Azure 服务触发的逻辑而无需编写代码。 Azure Functions若只关心运行服务的代码，而不关心基础平台或基础结构，Azure Functions 是理想选择。 需要执行工作以响应事件（通常通过 REST 请求、计时器或来自其他 Azure 服务的消息），并且该工作可在几秒钟或更短时间内快速完成时，通常会用到它们。 Azure Functions 会自动按需缩放，所以当需求变化时，它们是可靠的选择。 例如，你可能收到来自用于监控运输车队的 IoT 解决方案的消息。 可能会在工作时间内收到更多数据。 使用基于 VM 的方法将产生成本，即使 VM 处于空闲状态。 借助函数，Azure 会在触发代码时运行代码，并在函数完成时自动释放资源。 在此模型中，只需为函数运行时使用的 CPU 时间付费。 此外，Azure Functions 可以是无状态的（默认值），其行为就像每次响应事件时都要重新启动一样；也可以是有状态的（称为“Durable Functions”），其中通过函数传递上下文来跟踪之前的活动。 Azure 逻辑应用Azure 逻辑应用类似于函数 - 两者都使你能够基于事件触发逻辑。 Functions 执行代码时，逻辑应用执行从预定义逻辑块构建的工作流。 具体而言，它们旨在将业务流程自动化。 可以在 Azure 门户或 Visual Studio 中使用可视化设计器创建逻辑应用工作流。 工作流将保留为具有已知工作流架构的 JSON 文件。 Azure 提供了 200 多个不同的连接器和处理块与不同服务交互 - 包括最受欢迎的企业应用。 如果未涵盖需要与之进行交互的服务，还可以构建自定义连接器和工作流步骤。 然后使用可视化设计器将连接器和块链接在一起，通过工作流传递数据进行自定义处理 - 通常不需要编写任何代码。 例如，假设 ZenDesk 收到一个票证。 你可以： 使用认知服务检测消息的意图 在 Sharepoint 中创建一个项目来跟踪问题 如果客户不在数据库中，则将其添加到 Dynamics 365 CRM 系统 发送跟进电子邮件以确认他们的请求 所有这些都可以在可视化设计器中进行设计，这让看到逻辑流变得非常容易，因而是业务分析师角色的理想选择。 Azure Functions与Azure逻辑应用函数和逻辑应用都可以创建复杂的业务流程。 业务流程是函数或步骤的集合，将执行这些函数或步骤来完成复杂任务。 使用 Azure Functions，可以编写代码来完成每个步骤，使用逻辑应用，可以使用 GUI 来定义操作以及它们之间的关联方式。 在构建业务流程、从逻辑应用中调用函数以及从函数中调用逻辑应用时，可以混合使用各种服务。 下面是两者之间的一些常见差异。 - Functions 逻辑应用 状态 通常是无状态的，但 Durable Functions 会提供状态 有状态 开发 代码优先（命令性） 设计器优先（声明性） 连接 有关十多个内置的绑定类型，为自定义绑定编写代码 大型连接器集合、适用于 B2B 方案的 Enterprise Integration Pack、构建自定义连接器 操作 每个活动都是一个 Azure 函数；为活动函数编写代码 现成操作的大型集合 监视 Azure Application Insights Azure 门户、Log Analytics 管理 REST API、Visual Studio Azure 门户、REST API、PowerShell、Visual Studio 执行上下文 可以在本地或在云中运行 只能在云中运行。","categories":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}],"tags":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/tags/Azure/"}],"keywords":[{"name":"Azure","slug":"Azure","permalink":"http://blog.ozairs.com/categories/Azure/"}]},{"title":"谈谈澳洲找工作心得","slug":"谈谈澳洲找工作心得","date":"2019-04-14T09:34:05.000Z","updated":"2019-04-14T11:50:08.778Z","comments":true,"path":"评论/谈谈澳洲找工作心得/","link":"","permalink":"http://blog.ozairs.com/评论/谈谈澳洲找工作心得/","excerpt":"","text":"2月初登陆澳洲，在经历了忙忙碌碌2个多月的学习、求职生涯后，终于在本周，我和一家Local Consultancy公司签订了正式合同。虽然在海外找工作的这段周期并不算太长，但是这其中也并非一番风顺，所以在即将开启一段新的职业生涯的时候，也想对过往的这段经历做个总结。 曾经有人说：“失败的原因只有一个，就是自己放弃了。可以说，过去的这2个多月，也是我从长登澳洲-初涉职场-尝试失败-重新开始-再次失败-重复失败-失败失败再失败-直至最终完成临门一脚的过程。这期间，我想主要可以分成三个阶段： 文化隔阂阶段，初涉职场阶段，和最终实现目标阶段。 一、文化隔阂期2月初刚登陆澳洲的时候，我对自己和前途还是充满了希望和憧憬。为了准备这次的登陆，前前后后我已经花了几年的时间在磨练自己的英语技能上。同时，为了能够提升自己的职业技能，逐步完成职业转型，去年我已经陆续通过了AWS SAA和SAP考试，对于时下如火如荼的Cloud Service基本也算是“门内汉”了。 但是，单单凭借几张业内职业资格PASS，显然是不足以叩开澳洲的Job Market的大门的。在经历了短暂的登陆海外的蜜月期之后，很快我就体会到了衣食无着，海投了N多简历，但是收到的Feedback寥寥，甚至有些过了很长时间，还收到了用人公司的婉拒邮件。这段时间，可以说对我的自信心是一种不断的蚕食。原本以为已经对澳洲足够的了解，对于在澳洲求职找工作做了充分的准备，但是倒头来却发现，在自己的技能、背景和澳洲的Job Market之间存在着无形的屏障，而随着时间的推移，这层屏障似乎变得越来越厚。 这期间，在某个周五的下午，突然从新西兰的Christchurch传来了恐怖袭击的噩耗，一名“土澳”极右主义分子，手持Machine Gun闯入Christchurch的一所清真寺进行疯狂扫射，导致了50名无辜穆斯林死亡。这一突如其来的消息，再加上到澳洲这段时间来所遇到的种种，让我越来越觉得自己对于西方社会，对于西方文化的了解是多么的匮乏，美好的理想和残酷的现实之间的距离是多么的遥远。那段时间，火车站的警察人数明显增多了，学校里的印度人，伊斯兰人都会不时地讨论这次的恐怖袭击，似乎大家对于这次的事件都心有余悸。我甚至一度认为，伊斯兰的极端分子将会采取报复行动。而行动的最佳地点，莫过于墨尔本的地标性建筑：Flinder Railway Startion了。 二、初涉职场期虽然文化，习惯，语言的落差让我一度觉得很难适应，但好在在这段时期，我参加了墨尔本当地的OQP课程。说起OQP课程，之前曾经透过知乎，得到的一些过来的人的推荐。正如推荐的前辈所说，这门课程对于我们这些技术移民的专业人士来说，帮助是全方面的。她给予了我们一个很好的“Handle”，使我们这些刚刚涉足澳洲，但是并不了解澳洲的Work Practice 的专业人士，有了一个很好的缓冲期，透过缓冲期，我们可以逐渐养成一些新的习惯，这些习惯也在日后帮助我们在求职、应聘、面试的过程中，变得更加的从容和自信。就像在结业之际最后一堂课上，老师给我们总结的，OQP对于我们最显著的帮助来自以下几个方面： 1、关于简历这里要特别感谢我OQP的负责老师Rosie，她是我来澳洲遇到的第一位教师，也是我非常尊敬的一份师长。她为我定义了澳洲教师这一职业的标准和要求，让我感受到了澳洲教师的责任心和专业的素质。在课程当中，Rosie对于我的简历给予了多次的指导和修改，使我有了一份在澳洲的Job Market拿的出手的“产品说明书”，也帮我逐步拓展了澳洲公司的渠道，为日后的面试打下了良好的基础。 2、关于人脉在参加OQP课程之前，我在澳洲仅有的人脉可能就是我的初中同学兼好友毛毛了。但是透过OQP课程，她在潜移默化中，帮我逐步积累了澳洲本地的人脉，包括课堂中认识的来自五湖四海（主要还是“印度”和“伊朗”）的兄弟姐妹，Linkedin上的猎头、中介、公司HR。虽然，在一开始的时候某些猎头看上去并不起眼，公司也不是十分的出名，但是有些确实在我求职的过程当中起到了十分重要的催化剂的作用。得益于OQP课程中一位同学的推荐，我结识了某猎头A，他们作为中间人，把我推荐给了猎头B，之后我作为猎头B的Cousultant，参加了澳洲4大银行之一的某家Bank的多轮面试，并顺利拿到了自己的第一个Offer（虽然最终因为其他原因，我没能和这家公司签约）。但是可以说OQP还是为我提供了很好的人脉资源，使我有机会能在看似无从下手的澳洲职场之中，找到一丝缝隙，并逐步将他扩展成了突破口。 3、关于求职面试OQP的课程中，还有2个非常经典的环节，模拟面试问题和Mock Interview。特别是Mock Interview，有三位“面试官”参加，并且全程进行录像，最真实的还原面试现场的情形，使我们这些英语还不过关，对于澳洲的面试方式不十分习惯的“攻城狮”们多了一份实战的经验，帮助我们了解自身面试过程中存在的问题和不足，极大地积累了自信心，可以说也为我日后通关最终签订合同那家Consultancy的三轮面试，打下了坚实的基础。 三、屡败屡战，最终顺利拿到Offer时期屈指算来，在过去的这2个多月的时间里，包括电面，Face-to-face interview，累计我也参加大大小小将近20场面试。其中，除了后期的几家公司面试外，之前的绝大多数面试都以失败告终。失败的原因多种多样，有的是Need more technical（虽然我至今搞不明白如何才算够Technical），有的是无法在电话里给出命令行公式，有的是因为没有在面试的时候， 在白板上画出系统架构图，还有许多根本无从知晓失败原因的。。。尽管如此，随着时间的推移，虽然失败的次数仍在增加，但是失败的效果似乎已是越来越好，我能感觉到自己在面试中的表现再不断的提升。 终于又到了某个星期五下午，和最终签约公司约了三面，是Team Leader和技术负责人面试环节。这次的环节也让我看到了国外面试的专业性的地方。面试的全过程，两位面试官都是按照事先准备好的问题进行提问，并且记录下我的回答要点。问题方向涵盖了专业知识、团队协作、冲突解决、自我意识、沟通技能等多个维度，可以说通过这样全方位的评估，基本可以对候选人得出一个比较公平、客观的评价了。 幸运的是，虽然某些技术环节还有欠缺，但好在Team Lead对我的表现还是比较认可，觉得我是个很好的Team Player，所以最终顺利地拿到了这家Offer。 总结还记得刚来澳洲的时候，对于自己的职业生涯，一切都还是个未知数，甚至一度觉得十分的虚无缥缈。但就是在这段不稳定的时期内，我通过借助各种外力，试图在飘忽不定的职场的汪洋大海中，找寻前行的方向。很幸运，自己能够坚持既定的策略和方向，最终得以跨越非连续性，找到心仪的工作。 明天将是入职的第一天，似乎一切都又回到了初登澳洲的起点。把祝福送给自己，希望自己能调整状态，重新起航，能够做到知行合一，在新的征途上把前行的道路越走越宽，越走越远。 “Stay Hungry! Stay Foolish!”","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/tags/Jobs/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"永远记得- Always Remember","slug":"永远记得-Always-Remember","date":"2019-04-11T01:25:11.000Z","updated":"2019-04-11T01:28:42.151Z","comments":true,"path":"评论/永远记得-Always-Remember/","link":"","permalink":"http://blog.ozairs.com/评论/永远记得-Always-Remember/","excerpt":"","text":"Published on March 30, 2019 Francisco D’Souza Influencer Executive Vice Chairman at Cognizant 这个星期天是我作为Cognizant首席执行官的最后一天。星期一，Brian Humphries将接替我领导Cognizant的增长和成功的下一章。我知道Cognizant面临最好的日子，我对未来充满乐观。当我们大胆前进时，我希望我们永远不会忘记过去的教训 - 毕竟，这些教训使我们成为今天的我们。所以，在我作为首席执行官发给你的最后一封电子邮件中，我想我会在过去的25年中分享一些经验教训。 前线; 不是会议室 - 我们从未制定战略，做出决策或采取行动离前线太远。在像我们这样的竞争市场中，战斗是在战斗中取得胜利并且接近行动。永远不要陷入在“象牙塔”或会议室做出决定的陷阱。现实更接近实际。 我们团结一致** - 我们的团队运动在执行方面很重要。我们互相依赖，相互支持。当我们中的任何一个人跌倒时，我们其他人都会选择那个人。彼此做正确的事情总是我们如何保持强大，每天将我们的A-game带到现场。 道德和善良比以往任何时候都更重要 -世界变得越来越复杂，社会似乎比以往任何时候都更加分裂。面对这种复杂性，我们始终首先将决策建立在我们核心价值观所描述的道德指南针上。这样做可以让我们以统一的目的行事。对彼此的善意和对待我们的核心价值观比以往任何时候都更重要。 挑选最好的人 -我从我的老朋友兼同事Raj Mehta那里学到了这一课。Raj是一位杰出的人才开发者。他的理念是，如果我们每个人都雇用比我们小的人，那么我们就会迅速变得无关紧要。但如果我们每个人都雇用比我们更大的人，那么没有任何障碍太大而无法克服。 未来第一 - 未来总是比我们预期的要快。我们通过比竞争对手更快地拥抱未来来驾驭每一波技术，规模和复杂性。永远不要害怕未来。它会在这里比我们想象的更快，我们可以塑造它比过去更好！ 祝大家好运！在接下来的几个月里，我将与Brian合作以确保顺利过渡。而且我会在场边为队友Cognizant加油！我们建立了一个对世界很重要的强国。这是超越我们所有人的目标和使命。向前！ 【原文】 This Sunday is my last day as the CEO of Cognizant. On Monday, Brian Humphries will take over from me to lead Cognizant’s next chapter of growth and success. I know that the best days for Cognizant lie ahead and I have great optimism for our future. As we march boldly forward, I hope that we never forget the lessons of the past – which, after all, made us who we are today. So, in my last email to you as CEO, I thought I’d share a few lessons from the last 25 years. Front lines; not conference rooms – We never developed strategy, made decisions or took action too far from the front lines. In competitive markets like ours, battles are fought and won close to the action. Never fall into the trap of making decisions in the “ivory tower” or conference room. Reality is much closer to the ground. United we stand strong – Ours is a team sport where execution matters. We rely on each other and stand by one another. When any one of us falls, the rest of us pick that person up. Doing the right thing by each other always is how we stay strong and bring our A-game to the field every day. Morals and kindness matter more than ever – The world is becoming more complicated and societies seem more divided than ever. In the face of this complexity, we have always based our decisions first and foremost on the moral compass described in our core values. Doing so allows us to act with unified purpose. Kindness to one another and living our core values matters more than ever. Pick the best people – I learned this lesson from my long-time friend and colleague Raj Mehta. Raj is an outstanding people developer. He lives the philosophy that if each of us hires people who are smaller than we are, then we rapidly become irrelevant. But if each of us hires people who are bigger than we are, then no obstacle is too large to overcome. Future first – The future always comes faster than we expect. We navigated each wave of technology, scale, and complexity by always embracing the future faster than the competition. Never fear the future. It will be here faster than we think, and we can shape it to be better than the past! Good luck to all of you! Over the coming months, I’ll be working with Brian to ensure a smooth transition. And I’ll be cheering team Cognizant from the sidelines! We’ve built a powerhouse that matters to the world. That’s a purpose and mission that transcends all of us. Onward!","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"Cognizant","slug":"Cognizant","permalink":"http://blog.ozairs.com/tags/Cognizant/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"Helm：强大的Kubernetes包管理工具","slug":"Helm：强大的Kubernetes包管理工具","date":"2019-04-10T00:36:34.000Z","updated":"2019-04-10T00:41:07.428Z","comments":true,"path":"Kubernetes/Helm：强大的Kubernetes包管理工具/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/Helm：强大的Kubernetes包管理工具/","excerpt":"","text":"前言Helm是Kubernetes生态系统中的一个软件包管理工具。本文将介绍为何要使用Helm进行Kubernetes软件包管理，澄清Helm中使用到的相关概念，并通过一个具体的示例学习如何使用Helm打包，分发，安装，升级及回退Kubernetes应用。 Kubernetes应用部署的挑战让我们首先来看看Kubernetes，kubernetes提供了基于容器的应用集群管理，为容器化应用提供了部署运行、资源调度、服务发现和动态伸缩等一系列完整功能。 kubernetes的核心设计理念是: 用户定义应用程序的规格，而kubernetes则负责按照定义的规则部署并运行应用程序，如果应用系统出现问题导致偏离了定义的规格，kubernetes负责对其进行自动修正。例如应用规格要求部署两个实例，其中一个实例异常终止了，kubernetes会检查到并重新启动一个新的实例。 用户通过使用kubernetes API对象来描述应用程序规格，包括Pod，Service，Volume，Namespace，ReplicaSet，Deployment，Job等等。一般这些对象需要写入一系列的yaml文件中，然后通过kubernetes命令行工具kubectl进行部署。 以下面的wordpress应用程序为例，涉及到多个kubernetes API对象，这些kubernetes API对象分散在多个yaml文件中。 可以看到，在进行kubernetes软件部署时，我们面临下述问题： 如何管理，编辑和更新这些这些分散的kubernetes应用配置文件？如何把一套的相关配置文件作为一个应用进行管理？如何分发和重用kubernetes的应用配置？Helm的引入很好地解决上面这些问题。 Helm是什么？很多人都使用过Ubuntu下的ap-get或者CentOS下的yum, 这两者都是Linux系统下的包管理工具。采用apt-get/yum,应用开发者可以管理应用包之间的依赖关系，发布应用；用户则可以以简单的方式查找、安装、升级、卸载应用程序。 我们可以将Helm看作Kubernetes下的apt-get/yum。Helm是Deis (https://deis.com/) 开发的一个用于kubernetes的包管理器。 对于应用发布者而言，可以通过Helm打包应用，管理应用依赖关系，管理应用版本并发布应用到软件仓库。 对于使用者而言，使用Helm后不用需要了解Kubernetes的Yaml语法并编写应用部署文件，可以通过Helm下载并在kubernetes上安装需要的应用。 除此以外，Helm还提供了kubernetes上的软件部署，删除，升级，回滚应用的强大功能。 Helm组件及相关术语开始接触Helm时遇到的一个常见问题就是Helm中的一些概念和术语非常让人迷惑，我开始学习Helm就遇到这个问题。 因此我们先了解一下Helm的这些相关概念和术语。 Helm Kubernetes的应用打包工具，也是命令行工具的名称。 Tiller Helm的服务端，部署在Kubernetes集群中，用于处理Helm的相关命令。 Chart Helm的打包格式，内部包含了一组相关的kubernetes资源。 Repoistory Helm的软件仓库，repository本质上是一个web服务器，该服务器保存了chart软件包以供下载，并有提供一个该repository的chart包的清单文件以供查询。在使用时，Helm可以对接多个不同的Repository。 Release 使用Helm install命令在Kubernetes集群中安装的Chart称为Release。 需要特别注意的是， Helm中提到的Release和我们通常概念中的版本有所不同，这里的Release可以理解为Helm使用Chart包部署的一个应用实例。 其实Helm中的Release叫做Deployment更合适。估计因为Deployment这个概念已经被Kubernetes使用了，因此Helm才采用了Release这个术语。 下面这张图描述了Helm的几个关键组件Helm（客户端），Tiller（服务器），Repository（Chart软件仓库），Chart（软件包）之前的关系。 安装Helm下面我们通过一个完整的示例来介绍Helm的相关概念，并学习如何使用Helm打包，分发，安装，升级及回退kubernetes应用。 可以参考Helm的帮助文档https://docs.helm.sh/using_helm/#installing-helm 安装Helm 采用二进制的方式安装Helm下载 Helm https://github.com/kubernetes/helm/releases解压 tar -zxvf helm-v2.0.0-linux-amd64.tgz拷贝到bin目录 mv linux-amd64/helm /usr/local/bin/helm然后使用下面的命令安装服务器端组件Tiller 通过 homebrew（macOS）Kubernetes 社区的成员为 Homebrew 贡献了 Helm。这个通常是最新的。 1brew install kubernetes-helm （注意：emacs-helm 也是一个软件，这是一个不同的项目。） Helm init构建一个Helm chart让我们在实践中来了解Helm。这里将使用一个Go测试小程序，让我们先为这个小程序创建一个Helm chart。 git clone https://github.com/zhaohuabing/testapi.git;cd testapi首先创建一个chart的骨架 helm create testapi-chart该命令创建一个testapi-chart目录，该目录结构如下所示，我们主要关注目录中的这三个文件即可: Chart.yaml，values.yaml 和 NOTES.txt。 testapi-chart├── charts├── Chart.yaml├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── NOTES.txt│ └── service.yaml└── values.yamlChart.yaml 用于描述这个chart，包括名字，描述信息以及版本。values.yaml 用于存储templates目录中模板文件中用到的变量。 模板文件一般是Go模板。如果你需要了解更多关于Go模板的相关信息，可以查看Hugo (https://gohugo.io) 的一个关于Go模板的介绍 (https://gohugo.io/templates/go-templates/)。NOTES.txt 用于向部署该chart的用于介绍chart部署后的一些信息。例如介绍如何使用这个chart，列出缺省的设置等。打开Chart.yaml, 填写你部署的应用的详细信息，以testapi为例： apiVersion: v1description: A simple api for testing and debuggingname: testapi-chartversion: 0.0.1然后打开并根据需要编辑values.yaml。下面是testapi应用的values.yaml文件内容。 replicaCount: 2image: repository: daemonza/testapi tag: latest pullPolicy: IfNotPresentservice: name: testapi type: ClusterIP externalPort: 80 internalPort: 80resources: limits: cpu: 100m memory: 128Mi requests: cpu: 100m memory: 128Mi在 testapi_chart 目录下运行下面命令以对chart进行校验。 helm lint==&gt; Linting .[INFO] Chart.yaml: icon is recommended 1 chart(s) linted, no failures如果文件格式错误，可以根据提示进行修改；如果一切正常，可以使用下面的命令对chart进行打包： helm package testapi-chart –debug这里添加了 –debug 参数来查看打包的输出，输出应该类似于： Saved /Users/daemonza/testapi/testapi-chart/testapi-chart-0.0.1.tgz to current directorySaved /Users/daemonza/testapi/testapi-chart/testapi-chart-0.0.1.tgz to /Users/daemonza/.helm/repository/localchart被打包为一个压缩包testapi-chart-0.0.1.tgz，该压缩包被放到了当前目录下，并同时被保存到了helm的本地缺省仓库目录中。 Helm Repository虽然我们已经打包了chart并发布到了helm的本地目录中，但通过Helm search命令查找，并不能找不到刚才生成的chart包。 helm search testapiNo results found这是因为repository目录中的chart还没有被Helm管理。我们可以在本地启动一个Repository Server，并将其加入到Helm repo列表中。 通过helm repo list命令可以看到目前helm中只配置了一个名为stable的repo，该repo指向了google的一个服务器。 helm repo listNAME URLstable https://kubernetes-charts.storage.googleapis.com使用helm serve命令启动一个repo server，该server缺省使用’$HELM_HOME/repository/local’目录作为chart存储，并在8879端口上提供服务。 helm serve&amp;Now serving you on 127.0.0.1:8879启动本地repo server后，将其加入helm的repo列表。 helm repo add local http://127.0.0.1:8879“local” has been added to your repositories现在再查找testapi chart包，就可以找到了。 helm search testapi NAME CHART VERSION APP VERSION DESCRIPTIONlocal/testapi-chart 0.0.1 A Helm chart for Kubernetes在kubernetes中部署Chartchart被发布到仓储后，可以通过Helm instal命令部署chart，部署时指定chart名及Release（部署的实例）名： helm install local/testapi-chart –name testapi该命令的输出应类似: NAME: testapiLAST DEPLOYED: Mon Apr 16 10:21:44 2018NAMESPACE: defaultSTATUS: DEPLOYED RESOURCES:==&gt; v1/ServiceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEtestapi-testapi-chart ClusterIP 10.43.121.84 80/TCP 0s ==&gt; v1beta1/DeploymentNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEtestapi-testapi-chart 1 1 1 0 0s ==&gt; v1/Pod(related)NAME READY STATUS RESTARTS AGEtestapi-testapi-chart-9897d9f8c-nn6wd 0/1 Pending 0 0s NOTES: Get the application URL by running these commands:export POD_NAME=$(kubectl get pods –namespace default -l “app=testapi-testapi-chart” -o jsonpath=”{.items[0].metadata.name}”)echo “Visit http://127.0.0.1:8080 to use your application”kubectl port-forward $POD_NAME 8080:80使用下面的命令列出所有已部署的Release以及其对应的Chart。 helm ls该命令的输出应类似: NAME REVISION UPDATED STATUS CHART NAMESPACEtestapi 1 Mon Apr 16 10:21:44 2018 DEPLOYED testapi-chart-0.0.1 default可以看到在输出中有一个Revision（更改历史）字段，该字段用于表示某一Release被更新的次数，可以用该特性对已部署的Release进行回滚。 升级和回退修改Chart.yaml，将版本号从0.0.1 修改为 1.0.0, 然后使用Helm package命令打包并发布到本地仓库。 查看本地库中的Chart信息，可以看到在本地仓库中testapi-chart有两个版本 helm search testapi -lNAME CHART VERSION APP VERSION DESCRIPTIONlocal/testapi-chart 0.0.1 A Helm chart for Kuberneteslocal/testapi-chart 1.0.0 A Helm chart for Kubernetes现在用helm upgrade将已部署的testapi升级到新版本。可以通过参数指定需要升级的版本号，如果没有指定版本号，则缺省使用最新版本。 helm upgrade testapi local/testapi-chart已部署的testapi release被升级到1.0.0版本 helm listNAME REVISION UPDATED STATUS CHART NAMESPACEtestapi 2 Mon Apr 16 10:43:10 2018 DEPLOYED testapi-chart-1.0.0 default可以通过Helm history查看一个Release的多次更改。 helm history testapiREVISION UPDATED STATUS CHART DESCRIPTION1 Mon Apr 16 10:21:44 2018 SUPERSEDED testapi-chart-0.0.1 Install complete2 Mon Apr 16 10:43:10 2018 DEPLOYED testapi-chart-1.0.0 Upgrade complete如果更新后的程序由于某些原因运行有问题，我们则需要回退到旧版本的应用，可以采用下面的命令进行回退。其中的参数1是前面Helm history中查看到的Release的更改历史。 helm rollback testapi 1使用Helm list命令查看，部署的testapi的版本已经回退到0.0.1 helm listNAME REVISION UPDATED STATUS CHART NAMESPACEtestapi 3 Mon Apr 16 10:48:20 2018 DEPLOYED testapi-chart-0.0.1 default总结 Helm作为kubernetes应用的包管理以及部署工具，提供了应用打包，发布，版本管理以及部署，升级，回退等功能。Helm以Chart软件包的形式简化Kubernetes的应用管理，提高了对用户的友好性。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Helm","slug":"Helm","permalink":"http://blog.ozairs.com/tags/Helm/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"Kops：更便捷的使用Kubernetes","slug":"Kops：更便捷的使用Kubernetes","date":"2019-04-10T00:09:23.000Z","updated":"2019-04-10T00:11:43.969Z","comments":true,"path":"Kubernetes/Kops：更便捷的使用Kubernetes/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/Kops：更便捷的使用Kubernetes/","excerpt":"","text":"对于那些第一次接触Kubernetes（通常被称为k8s）并且想独自运行他们自己的第一个pods，services和deployments的人来说，通常存在很多的指南，例如可以使用Minikube在他们自己的电脑上设置和安装k8s。这也被认为是初次接触Kubernetes时的一种比较好的方式，到最后，这些文章会介绍如何将他们的应用栈发布到生产环境中。通常运行在一个类似Google Cloud Platform（GCP）或者Amazon Web Services（AWS）的云环境中可能会更利于使用kops。 介绍一下KopsKops 被描述为“用最容易的方式启动和运行生产级别的k8s集群” ，正好与Kelsey Hightower的文章 “ Kubernetes the Hard Way ”相对。 相对而言，我建议如果你想更倾向于使用，或想更好地了解使用k8s的容器编排，那么就应该尝试一下该教程，并在设置过程中执行每一个步骤。 虽然用户创建Kubernetes的高可用性集群的过程经常会被认为是“困难的方式”，但是kops可以将大部分流程自动化。它将执行至少8个任务，这其中包括在集群中创建子网和DHCP参数，自动分组你的主节点和工作节点，为这些节点读取配置文件信息， IAM定义和创建属于你的实例的EBS卷，进行网络设置安全组的配置。 安装Kops和创建一个集群使用本教程，首先需要在AWS上 创建一个账户 ，然后安装 AWS CLI 。同样你也可以安装kops在你自己的机器上。针对MacOS的用户，可以使用Homebrew： 1$ brew update &amp;&amp; brew install kops 针对Linux用户： 123$ wget https://github.com/kubernetes/kops/releases/download/1.6.1/kops-linux-amd64$ chmod +x kops-linux-amd64$ mv kops-linux-amd64 /usr/local/bin/kops 现在，我们将基于AWS Route53 DNS服务使用k8s来创建一个子域名。我使用的子域名是 kubernetes.mydomain.com，并且创建了一个主机区域： 1$ aws route53 create-hosted-zone --name kubernetes.mydomain.com --caller-reference 1 这将返回关于主机区域的信息，包括域名服务器的DelegationSet.。我选择了.com作为顶级域名，并且输入我们的域名注册为NS记录。 我们同样需要创建一个S3存储，使kops可以为我们的集群存储配置信息： 1$ aws s3 mb s3://clusters.kubernetes.mydomain.com 现在，如果你只控制一个集群，我们应该在你的当前shell环境或者你的bash设置中声明一个变量： 1$ export KOPS_STATE_STORE=s3://clusters.kubernetes.mydomain.com 酷！我们已经准备好配置和运行集群： 1$ kops create cluster --zones=us-west-2c us-west-2c.kubernetes.mydomain.com 你也可以指定特殊的参数例如使用–network-cidr来设置子网参数，或者使用—vpc参数来设置你的AWS VPC。 使Kops开始工作当一切都可以脚本化和自动化操作时，可以在不需要任何输入的情况下让Kops去执行这些任务。然而，如果你想去尝试自己做一些配置，通过”kops edit cluster $CLUSTER_NAME”命令，将会在你的电脑上打开Vim编辑器，允许你去编辑那些用于创建集群的.yml配置文件。同上，使用命令”kops edit ig –name=$CLUSTER_NAME”将会设置节点的分组，或者使用”using kops edit ig –name=$CLUSTER_NAME $ZONE”命令来设置主节点的分组。 你将会为现在的结果而感到高兴，因为现在不会使创建基础设施的费用超过你的预期，输入命令”kops update cluster”，并且使用参数–yes将会执行任务并且创建已经配置好的集群。再花费些时间将你的DNS记录指向其他的DNS服务器后，Route53将会响应请求的结果。当输入命令”kubectl get pods”后，可以看到你的k8s集群基础设施已经运行起来。当你看到没有找到任何资源时，你可以准备开始去创建deployments/replica sets。 任何人如果第一次去尝试在GCP或者AWS创建k8s集群时，可以去看看这个文章 “ Kubernetes the Hard Way ”，能够获得一些关于在云中创建k8s集群的准确方法。这将会使一个新手去学习k8s中基于DNS的服务依赖或者基于Etcd的K/V存储。到那时，小小的失望和一时兴起之后会产生更多的兴趣去理解k8s，你可能会发现去使用kops的话可以简化流程，并尝试使用pod，服务配置和其他应用程序问题，而不是操作问题。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Kops","slug":"Kops","permalink":"http://blog.ozairs.com/tags/Kops/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"Docker ENTRYPOINT和CMD：Dockerfile最佳实践","slug":"Docker-ENTRYPOINT和CMD：Dockerfile最佳实践","date":"2019-04-09T23:18:05.000Z","updated":"2019-04-09T23:25:26.016Z","comments":true,"path":"Docker/Docker-ENTRYPOINT和CMD：Dockerfile最佳实践/","link":"","permalink":"http://blog.ozairs.com/Docker/Docker-ENTRYPOINT和CMD：Dockerfile最佳实践/","excerpt":"","text":"本文重点介绍Docker的CMD和ENTRYPOINT命令，以及如何使用Dockerfiles和Docker Compose文件来配置运行Docker容器。本教程将解释它们之间的差异以及如何在Dockerfiles中更好地使用他们。 Entrypoint CMD 最佳实践 摘要 EntrypointEntrypoint设置在运行容器时将首先执行的命令和参数。 传递给的任何命令行参数docker run &lt;image&gt;都将附加到entrypoint命令，并将覆盖使用的所有指定元素CMD。例如，docker run &lt;image&gt; bash将命令参数添加bash到Entrypoint的末尾。 Dockerfile ENTRYPOINTDockerfiles使用全部大写字母作为Entrypoint指令。有几种方法可以定义它。 exec语法该高管的形式是，您所指定的命令和参数作为一个JSON数组。这意味着您需要使用双引号而不是单引号。 1ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 使用此语法，Docker将不使用命令shell，这意味着不会发生正常的shell处理。如果需要shell处理功能，则可以使用shell命令启动JSON数组。 1ENTRYPOINT [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 使用Entrypoint脚本另一种选择是使用脚本来运行容器的Entrypoint命令。按照惯例，它通常包含名称中的Entrypoint。在此脚本中，您可以设置应用程序以及加载任何配置和环境变量。下面是一个如何使用ENTRYPOINT exec语法在Dockerfile中运行它的示例。 123COPY ./docker-entrypoint.sh /ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]CMD [&quot;postgres&quot;] 例如，Postgres官方图像使用以下脚本作为其ENTRYPOINT： 12345678910#!/bin/bashset -eif [ &quot;$1&quot; = &apos;postgres&apos; ]; then chown -R postgres &quot;$PGDATA&quot; if [ -z &quot;$(ls -A &quot;$PGDATA&quot;)&quot; ]; then gosu postgres initdb fi exec gosu postgres &quot;$@&quot;fiexec &quot;$@&quot; Docker撰写Entrypoint您在Docker Compose文件中使用的指令是相同的，除了您使用小写字母。 1entrypoint: /code/entrypoint.sh 您还可以在docker-compose.yml中使用列表定义Entrypoint。 1234567entrypoint: - php - -d - zend_extension=/usr/local/lib/php/xdebug.so - -d - memory_limit=-1 - vendor/bin/phpunit 覆盖Entrypoint您可以使用docker run --entrypoint或docker-compose run --entrypoint标记覆盖Entrypoint指令。 CMD /命令CMD（Dockerfiles）/ command（Docker Compose文件）的主要目的是在执行容器时提供默认值。这些将在Entrypoint之后执行。 例如，如果运行docker run &lt;image&gt;，则将执行Dockerfiles中CMD/ command中指定的命令和参数。 Dockerfiles在Dockerfiles中，您可以定义CMD包含可执行文件的默认值。例如： 1CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 如果它们省略了可执行文件，则还必须指定一条ENTRYPOINT指令。 CMD [&quot;param1&quot;,&quot;param2&quot;] （作为ENTRYPOINT的默认参数） 注意：a中只能有一条CMD指令Dockerfile。如果列出多个CMD，则只有最后一个CMD生效。 Docker Compose命令使用Docker Compose时，您可以在docker-compose.yml中定义相同的指令，但它以小写形式写成完整的单词command。 1command: [&quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot;] 覆盖CMD您可以覆盖CMD运行容器时指定的命令。 1docker运行rails_app rails console 如果用户指定了参数docker run，那么它们将覆盖指定的默认值CMD。 最佳做法尽管使用这些指令有不同的方法，但Docker会就其使用和语法的最佳实践提供一些指导。 使用最佳做法Docker建议使用ENTRYPOINT设置图像的主命令，然后使用CMD默认标志。这是一个使用这两个指令的示例Dockerfile。 123FROM ubuntuENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]CMD [&quot;-c&quot;] 语法最佳实践还有EXEC语法，泊坞窗允许shell语法两个另一个有效的选项ENTRYPOINT和CMD。这将以字符串形式执行此命令并执行变量替换。 ENTRYPOINT command param1 param2 CMD command param1 param2 但是，本教程没有强调它，因为exec语法被视为最佳实践。 *CMD*应该几乎总是以形式使用*CMD [“executable”, “param1”, “param2”…]*。因此，如果图像是用于服务的，例如Apache和Rails，那么你可以运行类似的东西*CMD [&quot;apache2&quot;,&quot;-DFOREGROUND&quot;]*。实际上，建议将这种形式的指令用于任何基于服务的图像。 这个Dockerfile详细解释了一些问题。 所述*ENTRYPOINT*壳形式防止任何*CMD*或*run*被使用命令行参数，但是具有你的缺点*ENTRYPOINT*将被开始作为一个子命令*/bin/sh -c*，其不通过信号。这意味着可执行文件不会是容器*PID 1*- 并且不会收到Unix信号 - 因此您的可执行文件将不会收到*SIGTERM*来自*docker stop &lt;container&gt;* 如果*CMD*用于为*ENTRYPOINT*指令提供默认参数，则应使用JSON数组格式指定*CMD*和*ENTRYPOINT*指令。 摘要在使用 CMD和ENTRYPOINTinstructions指定运行容器时执行的命令。很少有规则描述它们如何相互作用。 Dockerfiles应至少指定一个CMD或ENTRYPOINT命令。 ENTRYPOINT 应该在将容器用作可执行文件时定义。 CMD应该用作定义ENTRYPOINT命令的默认参数或在容器中执行ad-hoc命令的方法。 CMD 在使用备用参数运行容器时将覆盖。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"Git Workflow 工作指南","slug":"Git-Workflow-工作指南","date":"2019-04-06T12:01:52.000Z","updated":"2019-04-06T10:03:27.342Z","comments":true,"path":"DevOps/Git-Workflow-工作指南/","link":"","permalink":"http://blog.ozairs.com/DevOps/Git-Workflow-工作指南/","excerpt":"","text":"分支策略 代码库的常设分支始终只有 master 和 develop，临时分支最后都删除。 临时分支合并到常用分支时，必须发起 Pull / Merge Requset ，并指定一个人 code review。 远程临时分支由发起者追踪和维护， reviewer 负责删除。 所有的开发和迭代尽量都在临时分支上。 开发记录、功能集成、测试历史由 develop 分支管理，正式发布记录由 master 分支管理。 发布和部署时，必须新建发布分支。（发布分支基于 develop 分支） 发布和部署完成后，必须将发布分支合并回 develop / master 分支，然后删除发布分支。 合并到 master 分支的代码必须打上 Tag。（Tag：版本号、描述、日期） 常用分支 master develop master: 正式发布master 分支上存放的应该是随时可供在生产环境中部署的代码（Production Ready state）。当开发活动告一段落，产生了一份新的可供部署的代码时，master 分支上的代码会被更新。同时，每一次更新，需要添加对应的版本号标签（TAG）。 develop: 日常开发develop 分支是保存当前最新开发成果的分支。通常这个分支上的代码也是可进行每日夜间发布的代码（Nightly build）。因此这个分支有时也可以被称作“integration branch”。 临时分支 功能分支（feature） 发布分支（release） 修补分支（hotfix） 功能分支功能分支，开发新功能都从 develop 分支出来，从 develop 分支上面分出来的。开发完成后，要再并入 develop。 123456789# 创建一个功能分支：git checkout -b feature-x develop# 开发完成后，将功能分支合并到develop分支：git checkout developgit merge --no-ff feature-x# 删除feature 分支：git branch -d feature-x 发布分支发布分支，准备要 release 的版本，只修 bugs。从 develop 分支上面分出来，发布结束以后，必须合并进 develop 和 master 分支。 12345678910111213141516# 创建一个发布分支：git checkout -b release-1.2 develop# 确认没有问题后，合并到master分支：git checkout mastergit merge --no-ff release-1.2# 对合并生成的新节点，做一个标签git tag -a 1.2# 再合并到develop分支：git checkout developgit merge --no-ff release-1.2# 最后，删除发布分支：git branch -d release-1.2 修补分支修补分支，是指等不及 release 版本就必须马上修 master 赶上线的情况。它是从 master 分支上面分出来的。修补结束以后， 再合并进 master 和 develop 分支。 1234567891011121314# 创建一个修补bug分支：git checkout -b hotfix-0.1 master# 修补结束后，合并到master分支：git checkout mastergit merge --no-ff hotfix-0.1git tag -a 0.1.1# 再合并到develop分支：git checkout developgit merge --no-ff hotfix-0.1# 最后，删除&quot;修补bug分支&quot;：git branch -d hotfix-0.1 Pull / Merge Request代码合并到 master/develop 分支： 将需要合并到 master / develop 的分支 push 到 gitlab。 进入工程 -&gt; merge request -&gt; create new merge request 。 选择源分支、目标分支，确定。 review 负责人进入 merge request，确认没有问题之后选择 Auto Merge（或者手动在本地合并之后再 push 到 gitlab），并关闭这个 merge request，完成。 如果发现问题那么在有问题的行下注释，并提醒 request 的发起人及时修改。 删除本地临时分支，本地 master / develop 更新到最新状态。 Code Review 提交 Pull / Merge Request 时， Commit 和 Message 要足够清晰详细。 切记，如果一次提交的内容包含很多 Commit，请不要使用自动生成的描述。 请用简短且足够说明问题的语言（理想是控制在3句话之内）来描述： 你改动了什么，解决了什么问题，需要代码审查的人留意那些影响比较大的改动。特别需要留意，如果对基础、公共的组件进行了改动，一定要另起一行特别说明。 审核人员邀请原则：项目参与人员 &amp; 团队同事 &amp; 团队 Leader。（对项目足够了解，对项目足够了解，对项目足够了解，重要的事情说三遍）； 评论中至少出现一个 lgtm 且保证代码评审通过之后 Pull / Merge Request 才可以被合并；（注：lgtm 即 looks good to me 的缩写） Git Commandgit tag1234567891011121314151617181920212223242526272829303132333435363738394041424344# 创建一个带版本有描述的 taggit tag -a v0.1.0 -m &apos;commit&apos;# 覆盖该版本已有 v0.1.0 git tag -f v0.1.0 # 推送服务器git push origin --tags# 服务器已有 v0.1.0，强制推到服务器git push origin -f v0.1.0 # 服务器获取刚刚的 v0.1.0git fetch --tag# 删除本地版本git tag -d v0.1.0# 删除服务器上的taggit push origin :v0.1.0git merge# 不使用 fast-forward 方式合并，保留分支的 commit 历史git merge --no-ff develop# 使用 squash 方式合并，把多次分支commit历史压缩为一次git merge --squash developgit checkout# 放弃在 file.txt 的修改，恢复成未修改时的样子git checkout file.txt# 当前目录所有修改的文件，恢复成未修改时的样子git checkout .# 创建新的分支，并切换过去git checkout -b branchnamegit reset# 回退指定的 commit git reset 0c5602affd27d2224d151284bd1c6e033fd9023f# 回退上次修改git reset --hardgit flow# git flow 初始化git flow init# 创建一个新的 feature 分支git flow feature start name# 将 feature 分支推送到远程仓库git flow feature publish name# 当特性开发完毕，需要将此分支合并到 develop 分支git flow feature finish name","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://blog.ozairs.com/tags/Git/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"接收了工作Offer之后可以拒绝吗？","slug":"接收了工作Offer之后可以拒绝吗？","date":"2019-04-05T23:15:44.000Z","updated":"2019-04-10T00:22:44.553Z","comments":true,"path":"评论/接收了工作Offer之后可以拒绝吗？/","link":"","permalink":"http://blog.ozairs.com/评论/接收了工作Offer之后可以拒绝吗？/","excerpt":"","text":"嗯，哦。那发生了吗？你把自己的心投入了工作 - 你让招聘经理着迷 - 你突破了面试过程，你获得了这个职位。当然你拿走了它！你努力工作以获得这份工作！在发生完全出乎意料的事情之前，一切都很美好，突然间你无法接受这份工作。 首先 - 不要压力。这事儿常常发生。请考虑以下方案： 你从第一个选择中被拒绝了，但随后接到了招聘经理的电话，解释说他们选择的候选人已经不再可用，现在他们想要你。 你随机偶然发现了一份招聘广告，听起来比你刚刚提供的工作更好，你参加了他们的面试，但事实证明他们也想要你。 一场重大的生活事件发生了，你需要快速改变位置，或者只是改变职业方向。 您可以找到有关角色或公司的更多信息，而且您不再那么热衷了。也许你听说老板是可怕的奴隶主，或者公司的表现非常糟糕。 你有一个中年危机，任何时候的危机或意外的顿悟 - 你意识到这项工作不适合你。 不管是什么原因，拒绝你已经接受的工作永远不会有趣。谁喜欢让人失望呢？但它不需要压力，甚至是一个大问题。当然，招聘经理可能会在一段时间内感到不安或不方便 - 但这与你被困在错误的工作中会如何影响你的生活相比毫无意义。 如果您知道自己无法通过，有办法拒绝提供，并希望仍然与雇主保持积极的关系。以下提示和示例信函将使您尽可能顺利地完成整个体验，甚至可能将其变为积极的。 不要等待 - 一旦你意识到你不再需要这份工作，就让雇主知道。你越早告诉他们，他们就能越早开始寻找你的替代品。如果你接受这份工作仅过了几天，你可能认为你不必费心，但这样做绝对是礼貌的，因为雇主已投入时间和金钱来帮助你。 诚实但机智 - 让雇主知道你改变主意的原因，但不要侮辱他们或公司。如果您认为自己不会与其他员工相处，那就简单地说您认为自己不符合公司文化。如果您找到了一份您更感兴趣的工作，请说明您获得的工作更符合您的技能。摆脱这种尴尬局面的最佳方式是确保您与招聘经理的所有互动都是礼貌的，所以不要对雇主或公司说任何负面的话。 亲自或通过电话进行 -好的，所以亲自可能有点可怕，所以如果你对打电话更舒服，那很好。只是不要使用电子邮件或社交媒体来告知他们您的决定。表达你的决定，并表示遗憾，说明你有不便之处。提及您在公司或招聘过程中发现的一些积极因素也很有帮助，并提及您对这些因素的赞赏。你可以说拒绝工作是一个艰难的决定。最好不要和任何雇主过河拆桥， 你永远不知道你是否希望将来与他们合作。一旦你面对面或通过电话告诉他们，你可能想要用正式的信件（下面的模板）来跟进。 了解您的底线 - 招聘经理可能会尝试与您协商以让您留下来。在和他们沟通之前，确定你的底线是什么。你会留下更多的工资或某些福利吗？如果您决定不想谈判，如果他们开始引导那个方向的对话，请与雇主明确这一点。 你能通过电子邮件拒绝工作机会吗？ 是的，你可以，尽管大多数经理都会喜欢打个电话。对于招聘经理来说，面试过程很漫长。首先，他们需要做广告，然后将最佳候选人列入候选名单，然后进行多次面试，然后才有兴趣提供这份工作。如果您决定在接受工作后通过电子邮件拒绝工作机会，请使用以下示例： 电子邮件样本 亲爱的琼斯女士， 非常感谢您为我提供Smith Industries的市场经理职位。很高兴与您交谈并了解您的公司。 不幸的是，在对这个职业机会进行了大量的思考之后，我认为拒绝你的优雅工作是符合我的最大利益和公司的利益。我最近决定接受另一个我认为更适合我的能力和技能的职位。 对于此决定可能造成的任何不便，我深感抱歉。我继续对史密斯工业的发展和市场地位留下深刻印象。 祝你未来的事业一切顺利。我希望在即将到来的6月营销会议上见到你。 亲切的问候， 你的名字 如何在接受工作后通过电话拒绝工作机会 在通过电话接受工作机会后拒绝工作可能是一项非常艰巨的经历，但事实并非如此。我们已经汇总了一个关于如何开始对话的脚本，以及招聘经理可能表达的任何问题或评论的答案： 嗨，达吉先生， 我只是想说谢谢你对我进行面试并告诉我公司的情况。这不是一个简单的对话，但是，我决定拒绝提供工作机会。 达吉先生：但你已经接受了这个提议。这真的很令人失望。 回应： 是的，我确实接受了这个提议，但我完全理解你的失望，但经过仔细考虑，我无法继续前进。我非常感谢你有机会，我希望你能为能够接受这份工作的人提供这个职位。 达吉先生：你为什么要拒绝这份工作呢？ 回应:( 老实说，这始终是最好的方法。）我得到了另一份更合适的工作。再次感谢您考虑我的职位。如果我知道任何适合这个角色的人，我一定会把它们推荐给你。祝你好运。 最后但同样重要的是，你不应该对自己的决定感到不满。到目前为止，公司投资的金额与如果您在上岗和培训几周后就离开了，所投资金额相比微不足道。 积极思考，保持诚实。如果你有充分的理由，招聘经理可能会理解。尽力保持良好的条件，并在您的网络中保持便捷的联系。 【原文】 Uh-oh. So this happened? You had your heart set on a job – you charmed the hiring manager – you smashed the interview process, and you were offered the position. Of course you took it! You worked hard to get that job! Everything is rosy until something entirely unexpected happens and suddenly you are not in a position to take that job. Firstly – don’t stress. This happens all the time. Consider the following scenarios: You were turned down from your first pick, but then received a phone call from the hiring manager, explaining that the candidate they chose was no longer available…and now they want you. You randomly stumble across a job advertisement that sounds WAY better than the job you’ve just been offered…you interview with them for the hell of it, and it turns out they want you too. A big life event happens and you either need to change location, or just career direction, fast. You find out more about the role or the company and you’re not so keen anymore. Maybe you hear the boss is a slave-driver from hell, or the company is performing really poorly. You have a mid-life crisis, an any-time crisis or an unexpected epiphany – and you realise that this job is just not right for you. Whatever the reason, turning down a job you’ve already accepted is never fun. Who likes letting people down? But it needn’t be stressful, or even a big deal. Sure, the hiring manager might be upset or inconvenienced for a short while – but that’s nothing compared to how you being stuck in the wrong job can impact your life. If you know you can’t follow through, there are ways to turn down the offer and hopefully still maintain a positive relationship with the employer. The following tips and sample letter will allow you to make the whole experience as smooth as possible…and maybe even turn it into a positive. Don’t Wait – Let the employer know as soon as you realise you no longer want the job. The sooner you let them know, the sooner they can start looking for your replacement. If only a few days have passed since you accepted the job, you may think you needn’t bother, but it’s definitely common courtesy to do so, as the employer has already invested time and money into trying to help you. Be honest but tactful – Let the employer know why you changed your mind, but do so without insulting them, or the company. If you don’t think you’ll get along with the other employees, simply say you don’t think you would fit in with the company culture. If you found a job that you are much more interested in, explain that you were offered a job that is more in line with your skill set. The best way to come out of an awkward situation like this is to make sure all your interactions with the hiring manager are polite, so don’t say anything negative about the employer or the company. Do it in person or over the phone – Ok, so in person can be kinda scary, so if you’re more comfortable with a phone call, that’s fine. Just don’t use email or social media to inform them of your decision. Own your decision and express your regret that you have inconvenienced them. It’s also helpful to mention some of the positive factors you noticed in the company or during the recruitment process, and mention your appreciation for those. Explain that turning down the job was a tough decision. It’s best not to burn bridges with any employer – you never know if you might want to work with them in the future. Once you’ve told them face to face or over the phone, you may want to follow this up with a formal letter (template below). Know your bottom line – The hiring manager may try to negotiate with you to get you to stay. Before approaching them, decide what your bottom line is. Would you stay for more pay or certain benefits? If you decide you do not want to negotiate, be clear about this with the employer if they start to steer the conversation in that direction. Can you reject a job offer by email? Yes, you can, although most managers would appreciate a phone call. The interview process is a lengthy one for hiring managers. First, they need to advertise, then shortlist the best candidates, followed by multiple interviews, before they have the pleasure to offer the job. If you do decide to turn down a job offer by email after you have accepted it, here is a sample to use: Sample email Dear Ms Jones, Thank you so much for offering me the position of Marketing Manager at Smith Industries. It has been a pleasure speaking with you and learning more about your company. Unfortunately, after giving a great deal of thought to this career opportunity, I have decided that it is in my best interest, as well as the company’s, to turn down your gracious job offer. I have recently decided to accept another position that I believe is a better fit for my abilities and skill set. I am truly sorry for any inconvenience this decision may cause. I continue to be impressed with Smith Industries growth and standing in the marketplace. I wish you all the best in your future endeavors. I hope to see you at the upcoming Marketing conference in June. Kind regards, Your name How to reject a job offer over the phone after you have accepted the job Turning down a job offer after you have accepted it over the phone can be a massively daunting experience, but it doesn’t have to be. We have put together a script of how you should start the conversation, as well as answers to any questions or remarks the hiring manager might express: Hi Mr. Dargie, I just wanted to say thank you for the time you spent interviewing me and telling me about the company. This isn’t an easy conversation to have, but, I have decided to turn down the job offer. Mr. Dargie: But you have already accepted the offer. This is really disappointing. Response: Yes, I did accept the offer, and I completely understand your disappointment, however, after careful consideration I cannot move forward in the position. I am very grateful to you for the opportunity and I hope you can offer the position to someone in a better position to accept the job. Mr. Dargie: Why are you turning it down? Response: (Just be honest here, it is always the best approach.) I have been offered another job that is more suitable. Once again, thank you for considering me for the position. If I know of anyone suitable for the role, I will be sure to refer them to you. Best of luck. Last but not least, you shouldn’t feel bad about your decision. The amount of money the company has invested in you so far is insignificant compared to the amount of money it would have invested, had you left after a few weeks of induction and training. Think positive and stay honest. If you have a good reason, the hiring manager is likely to understand. Do your best to leave on good terms and keep a handy contact in your network.","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"Job","slug":"Job","permalink":"http://blog.ozairs.com/tags/Job/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"主流CI/CD工具比较：Jenkins vs Bamboo vs Teamcity","slug":"主流CI-CD工具比较：Jenkins-vs-Bamboo-vsTeamcity","date":"2019-04-01T02:29:11.000Z","updated":"2019-04-05T23:32:06.749Z","comments":true,"path":"Jenkins/主流CI-CD工具比较：Jenkins-vs-Bamboo-vsTeamcity/","link":"","permalink":"http://blog.ozairs.com/Jenkins/主流CI-CD工具比较：Jenkins-vs-Bamboo-vsTeamcity/","excerpt":"","text":"你有没有看过1924年的奥运世界纪录？我知道你在这里可以获得一个很好的CI / CD工具，但请听我说。 如果将1924年的记录与2016年的记录进行比较，那些奥林匹克运动员甚至不会成为他们的国家队。这就是今天运动员的表现更好，更快，更强。 1924年夏季奥运会男子100米短跑结果 2016年美国奥运选拔赛男子100米春季成绩。 大多数这种改进是更好的表现技巧和练习方案的结果。这是我们回到CI / CD的地方：部署软件的旧方式就像1924年试图在21世纪竞争的奥运选手。没有成功的机会。你会被留在尘土中。 持续集成和持续交付是当今软件部署的最佳实践。这些技术可帮助您更快地部署更好的软件，减少错误并提供更快的反馈循环。这对公司，客户和开发人员来说是一个双赢的局面。所需要的只是一套工具来实现它。 我们将看看今天市场上的3种顶级CI / CD工具：Jenkins，TeamCity和Bamboo。在本文结束时，您应该有信心为您的团队选择一个工具。如果您已经使用其中一种工具并希望进行更改，那么本文将为您提供做出正确决策所需的洞察力。 在我们进入下降之前，让我们简要介绍一下每个工具的基础知识。 Jenkins是什么？Jenkins是当今市场上最受欢迎的开源CI / CD工具。Jenkins允许开发人员在将代码提交到源存储库后自动构建，集成和测试代码。这使开发人员能够快速捕获错误并最终部署得更快。 最初创建的是用于Java应用程序的构建自动化工具，它已经发展成为具有1400多个其他软件工具插件的多方面平台。据InfoWorld称，这些插件将Jenkins扩展到五个领域：平台，UI管理，源代码管理和构建管理。 什么是Bamboo？Bamboo是Atlassian的CI / CD服务器。与其他CI / CD服务器一样，Bamboo允许开发人员自动构建，集成和测试源代码，然后准备应用程序以进行部署。Bamboo还可以与Atlassian的其他工具（如Jira（项目管理）和Hipchat（团队沟通））无缝协作。 什么是TeamCity？TeamCity是另一个商业CI / CD服务器，这次来自JetBrains公司。它以其极其简单的设置和漂亮的用户界面而闻名。它具有开箱即用的强大功能和不断增长的插件生态系统。 CI / CD工具Throwdown女士们，先生们，为主要景点做好准备。现在是时候让这些CI / CD工具发出隆隆声了！我们将查看CI / CD最重要的属性，并了解这些工具如何叠加。到本节结束时，您将确切知道哪种CI / CD工具适合您。 在我们看看这些工具的不同之处之前，重要的是要指出它们是如何相似的。 Jenkins，TeamCity和Bamboo都是持续集成，自动构建，自动化测试和持续交付的绝佳工具。虽然工具之间的集成数量不同，但它们都提供了进一步扩展其功能的集成。这三者也提供了很好的支持和文档，但同样在深度和质量上也存在差异。 简而言之，我们比较这些工具的原因是它们是商业中最好的。 好的，足够的细节。让我们隆隆声！ 开源与商业Jenkins是一个由世界各地的开发人员支持的开源项目。Bamboo和TeamCity都是由其母公司开发和维护的商业工具。用户最大的不同之处在于Jenkins周围的社区规模与其他两个工具相比。 易于设置和使用TeamCity可以轻松设置和使用。它以其开箱即用的可用性而闻名，尤其是其安全的默认配置。它还拥有华丽的用户界面，使CI新手更容易陷入困境。Bamboo具有可比性且易于使用，但用户界面并不是那么漂亮，而G2 Crowd将TeamCity列为高于Bamboo的“易于安装”。 Jenkins在这一类别中没有TeamCity和Bamboo。Jenkins的UI是一个更古老的学校，但新的Blue Ocean界面是一个重大升级。尽管如此，开源软件本身具有较低的可用性和易于设置。 开箱即用的功能TeamCity的自带堆叠开箱，具有优良的建设历史，源头控制，建立连锁的工具。Bamboo具有较少的开箱即用功能，但与Atlassian的其他工具堆本身集成。这使Bamboo感觉功能更丰富，而不具备自身功能。Jenkins是三者中功能最稀疏的工具，但它可以通过庞大的插件生态系统弥补它，我们将在下面讨论。 集成和插件在集成和插件方面，竞争甚至不是很接近。Jenkins拥有庞大的插件生态系统，可实现前所未有的自定义和可扩展性。Bamboo和TeamCity正在慢慢增长他们的生态系统，但按照这个速度，他们可能永远不会赶上。 支持作为一个开源项目，Jenkins拥有一个庞大而有用的贡献者社区，可以为彼此提供支持。因此，Jenkins拥有大量文档，但您只需自己梳理文档即可学习或解决问题。另一方面，Bamboo和TeamCity提供其母公司以及不断增长的用户社区的专业支持。Bamboo和TeamCity用户可以找到来自企业的实际支持以及来自社区的众包支持。 在云上运行？许多中小型软件团队专门在云基础架构上运行。因此，当Atlassian停止使用Bamboo云时，一些Bamboo用户感到困惑，迫使团队在内部运行它。他们用BitBucket Pipelines取代了这项服务，但很多人认为它不是一个完美的替代品。Jenkins和TeamCity仍可在云服务器上运行。 价钱作为开源软件，Jenkins完全免费使用，无论您的规模如何。TeamCity提供了一个相当实用的免费版本，可为您提供100个构建配置和无限构建。之后，定价从每年299美元起。 Bamboo是最昂贵的工具。它的起价仅为10美元，但这个价格的体验非常有限。对于整个体验，您必须为一个远程代理一次性支付880美元的Bamboo费用。 哪种CI / CD工具最适合您？显然，这次失败的赢家是一个折腾。要选择正确的CI / CD工具，您需要仔细查看预算，内部资源以及学习和设置所需的时间。如果你有DIY的态度并想要最大的功能，那么Jenkins可能就是你的工具。如果您更喜欢更简单的用户体验以及与现有技术堆栈集成的工具，请查看Bamboo。为了获得漂亮的界面和出色的开箱即用功能，TeamCity是您的最佳选择。 请记住，您的CI / CD工具只是赢得软件开发竞赛所需的工具之一。部署和应用程序监视是敏捷开发的同等重要元素。永远不要满足你的过程; 不断探索升级技术和实践的方法。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}],"tags":[{"name":"CI","slug":"CI","permalink":"http://blog.ozairs.com/tags/CI/"}],"keywords":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}]},{"title":"Terraform简介","slug":"Terraform简介","date":"2019-03-30T05:24:43.000Z","updated":"2019-03-30T06:36:19.919Z","comments":true,"path":"Terraform/Terraform简介/","link":"","permalink":"http://blog.ozairs.com/Terraform/Terraform简介/","excerpt":"","text":"这是Terraform系列综合指南的第2部分。在第1部分中，我们解释了为什么我们选择Terraform作为我们选择的IAC工具而不是Chef，Puppet，Ansible，SaltStack或CloudFormation。在这篇文章中，我们将介绍如何使用Terraform定义和管理基础架构的基础知识。 该官员Terraform入门文档不会引入Terraform的各个要素（即资源，输入变量，输出变量等）的一个很好的工作，所以在本指南中，我们将重点放在如何把这些元素结合在一起创建一个相当现实的例子。特别是，我们将在集群中的AWS上配置多个服务器，并部署负载均衡器以在该集群中分配负载。您将在此示例中创建的基础结构是运行可扩展，高可用性Web服务和微服务的基本起点。 本指南面向AWS和Terraform新手，所以如果您以前没有使用过任何一个，请不要担心。我们将逐步指导您完成整个过程： 设置您的AWS账户 安装Terraform 部署单个服务器 部署单个Web服务器 部署Web服务器集群 部署负载均衡器 清理 您可以在以下网址找到以下示例的完整示例代码：https：//github.com/gruntwork-io/intro-to-terraform。请注意，所有代码示例都是为Terraform 0.7.x编写的。 设置您的AWS账户Terraform可以为许多不同类型的云提供商提供基础架构，包括AWS，Azure，Google Cloud，DigitalOcean 等等。在本教程中，我们选择了Amazon Web Services（AWS），因为： 它提供了大量可靠且可扩展的云托管服务，包括弹性计算云（EC2），Auto Scaling组（ASG）和Elastic Load Balancing（ELB）。如果您发现AWS术语令人困惑，请务必以简明英语查看AWS。 到目前为止，AWS是最受欢迎的云基础架构提供商。 AWS提供了一个丰富的免费套餐，允许您免费运行所有这些示例。 首次注册AWS时，您最初以root用户身份登录。此用户帐户具有对所有内容的访问权限，因此从安全角度来看，我们建议仅使用它来创建权限更有限的其他用户帐户（请参阅IAM最佳实践）。要创建更有限的用户帐户，请转到身份和访问管理（IAM）控制台，单击“用户”，然后单击蓝色的“创建新用户”按钮。输入用户的名称，并确保选中“为每个用户生成访问密钥”： 单击“创建”按钮，您将能够看到该用户的安全凭证，其中包括访问密钥ID和秘密访问密钥。你必须立即保存这些，因为它们永远不会再显示。我们建议将它们存储在安全的地方（例如密钥管理器，如Keychain或1Password），这样您可以在本教程中稍后使用它们。 将凭据保存在安全的地方。切勿与任何人分享。别担心，上面截图中的内容是假的。 保存凭据后，单击“关闭”（两次），您将进入用户列表。单击刚刚创建的用户，然后选择“权限”选项卡。默认情况下，新的IAM用户无权在AWS账户中执行任何操作。为了能够将Terraform用于本教程中的示例，请添加AmazonEC2FullAccess权限（在此处了解有关托管IAM策略的更多信息）： 安装Terraform按照此处的说明安装Terraform。完成后，您应该能够运行terraform命令： 123&gt; terraform 用法：terraform [--version] [ - help] &lt;command&gt; [args]（......） 为了使Terraform能够在您的AWS账户中进行更改，您需要为之前创建的用户设置AWS凭证作为环境变量： 12导出AWS_ACCESS_KEY_ID =（您的访问密钥ID）导出AWS_SECRET_ACCESS_KEY =（您的密钥访问密钥） 部署单个服务器Terraform代码使用扩展名为“.tf”的文件中名为HCL的语言编写。它是一种声明性语言，因此您的目标是描述您想要的基础架构，Terraform将弄清楚如何创建它。Terraform可以在各种平台上创建基础架构，或称为提供商，包括AWS，Azure，Google Cloud，DigitalOcean和许多其他平台。使用Terraform的第一步通常是配置您要使用的提供程序。创建一个名为“main.tf”的文件并将以下代码放入其中： 123提供者“aws”&#123; region =“us-east-1” &#125; 这告诉Terraform您将使用AWS提供商并希望在“us-east-1”区域部署您的基础架构（AWS在全球范围内拥有数据中心，分为区域和可用区域，以及我们-east-1是美国弗吉尼亚州数据中心的名称。您可以为AWS提供程序配置其他设置，但是对于此示例，由于您已将凭据配置为环境变量，因此您只需指定该区域。 对于每个提供程序，您可以创建许多不同类型的“资源”，例如服务器，数据库和负载平衡器。在我们部署整个服务器集群之前，让我们首先弄清楚如何部署一个运行简单“Hello，World”Web服务器的服务器。在AWS lingo中，服务器称为“EC2实例”。要部署EC2实例，请将以下代码添加到main.tf： 1234资源“aws_instance”“example”&#123; ami =“ami-2d39803a” instance_type =“t2.micro” &#125; 每个资源指定一个类型（在本例中为“aws_instance”），一个名称（在本例中为“example”）用作Terraform代码中的标识符，以及一组特定于该资源的配置参数。该aws_instance资源文件列出了它所支持的所有参数。最初，您只需要设置以下内容： ami：要在EC2实例上运行的Amazon Machine Image。上面的示例将此参数设置为us-east-1中Ubuntu 14.04 AMI的ID 。 instance_type：要运行的EC2实例的类型。每个EC2实例类型具有不同的CPU，内存，磁盘空间和网络规格。上面的示例使用“t2.micro”，它具有1个虚拟CPU，1GB内存，并且是AWS免费层的一部分。 在终端中，进入创建main.tf的文件夹，然后运行“terraform plan”命令： 123456789101112131415161718192021222324&gt; terraform计划在计划之前刷新Terraform内存状态...（......）+ aws_instance.example ami：“ami-2d39803a” availability_zone：“&lt;computed&gt;” ebs_block_device。＃：“&lt;computed&gt;” ephemeral_block_device。＃：“&lt;computed&gt;” instance_state：“&lt;computed&gt;” instance_type：“t2.micro” key_name：“&lt;computed&gt;” network_interface_id：“&lt;computed&gt;” placement_group：“&lt;computed&gt;” private_dns：“&lt;computed&gt;” private_ip：“&lt;computed&gt;” public_dns：“&lt;computed&gt;” public_ip：“&lt;computed&gt;” root_block_device。＃：“&lt;computed&gt;” security_groups。＃：“&lt;computed&gt;” source_dest_check：“true” subnet_id：“&lt;computed&gt;” 租期：“&lt;computed&gt;” vpc_security_group_ids。＃：“&lt;计算&gt;”计划：1添加，0改变，0破坏。 plan命令可让您在实际执行之前查看Terraform将执行的操作。这是一种很好的方法，可以在将更改释放到世界之前检查您的更改。plan命令的输出有点像diff命令的输出：将创建带有加号（+）的资源，带有减号（ - ）的资源将被删除，带有波浪号的资源将被删除符号（〜）将被修改。在上面的输出中，您可以看到Terraform正计划创建单个EC2实例，而不是其他任何内容，这正是我们想要的。 要实际创建实例，请运行“terraform apply”命令： 12345678910111213141516171819202122232425&gt; terraform apply aws_instance.example：Creating ... ami：“”=&gt;“ami-2d39803a” availability_zone：“”=&gt;“&lt;computed&gt;” ebs_block_device。＃：“”=&gt;“&lt;computed&gt;” ephemeral_block_device。＃： “”=&gt;“&lt;计算&gt;”“ instance_state：”“=&gt;”&lt;计算&gt;“ instance_type：”“=&gt;”t2.micro“ key_name：”“=&gt;”&lt;计算&gt;“ network_interface_id：”“=&gt;”&lt; computed&gt;“ placement_group：”“=&gt;”&lt;computed&gt;“ private_dns：“”=&gt;“&lt;计算&gt;” private_ip：“”=&gt;“&lt;计算&gt;”“ public_dns：”“=&gt;”&lt;计算&gt;“ public_ip：”“=&gt;”&lt;计算&gt;“ root_block_device。＃：“”=&gt;“&lt;计算&gt;”“ security_groups。＃：”“=&gt;”&lt;计算&gt;“ source_dest_check：”“=&gt;”true“ subnet_id：”“=&gt;”&lt;计算&gt;“ 租期：”“ &gt;&gt; &lt;计算&gt;“ vpc_security_group_ids。＃：”“=&gt;”&lt;计算&gt;“ aws_instance.example：仍在创建...（已过去10秒）aws_instance.example：仍在创建...（已过20秒）aws_instance.example：创作完成申请完成！资源：1添加，0更改，0销毁。 恭喜，您刚刚部署了Terraform服务器！要验证这一点，您可以登录EC2控制台，您将看到如下内容： 这是有效的，但这不是最激动人心的例子。首先，Instance没有名称。要添加一个，您可以向EC2实例添加标记： 1234567资源“aws_instance”“example”&#123; ami =“ami-2d39803a” instance_type =“t2.micro” 标签&#123; Name =“terraform-example” &#125; &#125; 再次运行计划命令以查看这将执行的操作： 1234567&gt; terraform计划aws_instance.example：刷新状态...（ID：i-6a7c545b）（......）~aws_instance.example tags。％：“0”=&gt;“1” tags.Name：“”=&gt;“terraform-example”计划：0添加，1更改，0销毁。 Terraform会跟踪它为这组模板创建的所有资源，因此它知道您的EC2实例已经存在（注意Terraform在运行计划命令时如何说“刷新状态…”），它可以显示两者之间的差异当前部署的内容以及Terraform代码中的内容（这是使用声明性语言而不是程序性语言的优势之一）。上面的差异显示Terraform想要创建一个名为“Name”的单个标签，这正是我们想要的，所以你应该再次运行“apply”命令。刷新EC2控制台时，您会看到： 部署单个Web服务器下一步是在此实例上运行Web服务器。在一个真实的用例中，您可能会安装一个功能齐全的Web框架，如Ruby on Rails或Django，但为了保持这个简单的示例，我们将运行一个简单的Web服务器，它始终返回文本“Hello，World”使用从http静态服务器单行列表中借来的代码： 123＃！/ bin / bash echo“Hello，World”&gt; index.html nohup busybox httpd -f -p 8080＆ 这是一个bash脚本，它将文本“Hello，World”写入index.html，并使用busybox（在Ubuntu上默认安装）在端口8080上运行Web服务器，以便在URL“/”处提供该文件。我们使用nohup包装busybox命令，以确保即使在此脚本退出后Web服务器仍在运行，并在命令末尾添加“＆”，以便Web服务器在后台进程中运行，因此脚本实际上可以退出而不是被阻止永远是由Web服务器。 如何让EC2实例运行此脚本？通常，您可以使用像Packer这样的工具来创建安装了Web服务器的自定义AMI ，而不是使用空的Ubuntu AMI 。但同样，为了保持这个例子的简单，我们将上面的脚本作为EC2 Instance的用户数据的一部分运行，AWS将在实例启动时执行： 12345678910111213资源“aws_instance”“example”&#123; ami =“ami-2d39803a” instance_type =“t2.micro” user_data = &lt;&lt; - EOF ＃！/ bin / bash echo“Hello，World”&gt; index.html nohup busybox httpd -f - p 8080＆ EOF 标签&#123; Name =“terraform-example” &#125; &#125; “&lt;&lt; - EOF”和“EOF”是Terraform的heredoc语法，它允许您创建多行字符串而无需将“\\ n”放在所有位置（在此处了解有关Terraform语法的更多信息）。 在此Web服务器工作之前，您需要再做一件事。默认情况下，AWS不允许来自EC2实例的任何传入或传出流量。要允许EC2实例在端口8080上接收流量，您需要创建一个安全组： 123456789资源“aws_security_group”“instance”&#123; name =“terraform-example-instance” ingress &#123; from_port = 8080 to_port = 8080 protocol =“tcp” cidr_blocks = [“0.0.0.0/0”] &#125; &#125; 上面的代码创建了一个名为aws_security_group的新资源（注意AWS提供程序的所有资源如何以“aws_”开头）并指定该组允许来自CIDR块0.0.0.0/0的端口8080上的传入TCP请求。CIDR块是指定IP地址范围的简明方法。例如，10.0.0.0/24的CIDR块表示10.0.0.0和10.0.0.255之间的所有IP地址。CIDR块0.0.0.0/0是包含所有可能IP地址的IP地址范围，因此上面的安全组允许来自任何IP的端口8080上的传入请求。 请注意，在上面的安全组中，我们复制并粘贴了端口8080.为了使代码保持干燥并使配置代码变得容易，Terraform允许您定义输入变量： 123变量“server_port”&#123; description =“服务器将用于HTTP请求的端口” &#125; 您可以通过Terraform的插值语法在安全组中使用此变量： 12from_port =“$ &#123;var.server_port&#125;” to_port =“$ &#123;var.server_port&#125;” 您还可以在EC2实例的user_data中使用相同的语法： 1nohup busybox httpd -f -p“$ &#123;var.server_port&#125;”＆ 如果您现在运行计划或应用命令，Terraform将提示您输入server_port变量的值： 1234&gt; terraform plan var.server_port 服务器将用于HTTP请求的端口输入值：8080 为变量提供值的另一种方法是使用“-var”命令行选项： 1&gt; terraform plan -var server_port =“8080” 如果您不希望每次都手动输入端口，则可以将默认值指定为变量声明的一部分（请注意，仍可通过“-var”命令行选项覆盖此默认值）： 1234变量“server_port”&#123; description =“服务器将用于HTTP请求的端口” default = 8080 &#125; 最后要做的事情是：您需要告诉EC2实例实际使用新的安全组。为此，您需要将安全组的ID传递到aws_instance资源的vpc_security_group_ids参数中。你怎么得到这个ID？ 在Terraform中，每个资源都具有可以使用与插值相同的语法引用的属性。您可以在每个资源的文档中找到属性列表。例如，aws_security_group属性包括安全组的ID，您可以在EC2实例中引用该ID，如下所示： 1vpc_security_group_ids = [“$ &#123;aws_security_group.instance.id&#125;”] 语法为“$ {TYPE.NAME.ATTRIBUTE}”。当一个资源引用另一个资源时，您将创建一个隐式依赖项。Terraform解析这些依赖关系，从它们构建依赖关系图，并使用它来自动确定它应该以什么顺序创建资源（例如Terraform知道它需要在将其与EC2实例一起使用之前创建安全组）。实际上，Terraform将尽可能并行地创建尽可能多的资源，这意味着它可以非常快速地应用您的更改。这就是声明性语言的美妙之处：你只需指定你想要的东西，Terraform就会找出实现它的最有效方法。 如果运行计划命令，您将看到Terraform想要用具有新用户数据的新EC2实例（“ - / +”表示“替换”）替换原始EC2实例并添加安全组： 1234567891011121314151617181920212223&gt; terraform计划（......）- / + aws_instance.example ami：“ami-2d39803a”=&gt;“ami-2d39803a” instance_state：“running”=&gt;“&lt;computed&gt;” instance_type：“t2.micro”=&gt;“t2.micro” security_groups。＃： “0”=&gt;“&lt;计算&gt;” vpc_security_group_ids。＃：“1”=&gt;“&lt;计算&gt;”（......）+ aws_security_group.instance 描述：“由Terraform管理” 出口。＃：“&lt;计算&gt;” 入口。＃：“1” ingress.516175195.cidr_blocks。＃：“1” ingress.516175195.cidr_blocks.0：“0.0.0.0 / 0“ ingress.516175195.from_port：”8080“ ingress.516175195.protocol：”tcp“ ingress.516175195.security_groups。＃：”0“ ingress.516175195.self：”false“ ingress.516175195.to_port：”8080“ owner_id：“&lt;计算&gt;” vpc_id：“&lt;计算&gt;”计划：2添加，0改变，1破坏。 这正是我们想要的，所以再次运行apply命令，您将看到新的EC2实例部署： 在屏幕底部的描述面板中，您还将看到此EC2实例的公共IP地址。给它一两分钟启动，然后尝试在端口8080处卷曲此IP： 12&gt; curl http：// &lt;EC2_INSTANCE_PUBLIC_IP&gt;：8080 Hello，World 耶，一个工作的网络服务器！但是，必须手动在EC2控制台周围找到这个IP地址并不好玩。幸运的是，您可以通过指定输出变量来做得更好： 123输出“public_ip”&#123; value =“ $ &#123;aws_instance.example.public_ip &#125;” &#125; 我们再次使用插值语法来引用aws_instance资源的public_ip属性。如果再次运行apply命令，Terraform将不会应用任何更改（因为您没有更改任何资源），但它会显示新输出： 123456&gt; terraform apply aws_security_group.instance：刷新状态...（ID：sg-db91dba1）aws_instance.example：刷新状态...（ID：i-61744350）申请完成！资源：0添加，0更改，0销毁。输出：public_ip = 54.174.13.5 输入和输出变量是Terraform强大功能的重要组成部分，特别是与模块结合使用时，我们将在第4部分中讨论的主题，如何使用Terraform模块创建可重用的基础架构。 部署Web服务器集群运行单个服务器是一个良好的开端，但在现实世界中，单个服务器是单点故障。如果该服务器崩溃，或者由于流量太大而导致服务器不堪重负，则用户将无法再访问您的站点。解决方案是运行服务器群集，绕过服务器路由，并根据流量调整群集大小（有关详细信息，请查看在Amazon Web Services上构建可扩展Web应用程序的综合指南）。 手动管理这样的集群是很多工作。幸运的是，您可以让AWS使用Auto Scaling Group（ASG）来处理它。ASG可以自动启动EC2实例集群，监控其运行状况，自动重启故障节点，并根据需求调整集群大小。 创建ASG的第一步是创建启动配置，该配置指定如何在ASG中配置每个EC2实例。从早期部署单个EC2实例开始，您已经确切地知道如何配置它，并且您可以在aws_launch_configuration资源中重用几乎完全相同的参数： 12345678910111213资源“aws_launch_configuration”“example”&#123; image_id =“ami-2d39803a” instance_type =“t2.micro” security_groups = [“$ &#123;aws_security_group.instance.id&#125;”] user_data = &lt;&lt; - EOF ＃！/ bin / bash echo“Hello，World”&gt; index.html nohup busybox httpd -f -p“$ &#123;var.server_port&#125;”＆ EOF 生命周期&#123; create_before_destroy = true &#125; &#125; 唯一新添加的是生命周期块，这是使用ASG启动配置所必需的。您可以向任何Terraform资源添加生命周期块以自定义其生命周期行为。其中一个可用的生命周期设置是create_before_destroy，它告诉Terraform在销毁原始文件之前始终创建替换资源（例如，在替换EC2实例时，始终在删除旧实例之前创建新实例）。 create_before_destroy参数的捕获是，如果在资源X上将其设置为true，则还必须在X依赖的每个资源上将其设置为true。对于启动配置，这意味着您需要在安全组上将create_before_destroy设置为true： 123456789101112资源“aws_security_group”“instance”&#123; name =“terraform-example-instance” ingress &#123; from_port =“$ &#123;var.server_port&#125;” to_port =“$ &#123;var.server_port&#125;” protocol =“tcp” cidr_blocks = [“0.0.0.0/0”] &#125; 生命周期&#123; create_before_destroy = true &#125; &#125; 现在，您可以使用aws_autoscaling_group资源创建ASG ： 12345678910资源“aws_autoscaling_group”“example”&#123; launch_configuration =“$ &#123;aws_launch_configuration.example.id&#125;” min_size = 2 max_size = 10 tag &#123; key =“Name” value =“terraform-asg-example” propagate_at_launch = true &#125; &#125; 此ASG将运行2到10个EC2实例（初始启动默认为2），每个实例都标记为“terraform-example”。每个EC2实例的配置由您之前创建的启动配置决定，我们使用Terraform的插值语法进行参考。 要使此ASG正常工作，您需要再指定一个参数：availability_zones。此参数指定应部署EC2实例的可用区（AZ）。每个AZ代表一个独立的AWS数据中心，因此通过跨多个AZ部署实例，即使某些AZ发生故障，也可确保您的服务可以继续运行。您可以对AZ列表进行硬编码（例如将其设置为[“us-east-1a”，“us-east-1b”]），但每个AWS账户都可以访问一组略有不同的AZ，因此您可以使用aws_availability_zones数据源获取您帐户的确切列表： 1数据“aws_availability_zones”“全部”&#123;&#125; 甲数据源表示一块的只读信息被取出从提供者（在此情况下，AWS）每次运行Terraform时间。除可用区域外，还有数据源可查找AMI ID，IP地址范围和当前用户的身份。将数据源添加到Terraform模板不会创建任何新内容; 它只是一种检索动态数据的方法。 要使用数据源，请使用标准插值语法引用它： 1234567891011资源“aws_autoscaling_group”“example”&#123; launch_configuration =“$ &#123;aws_launch_configuration.example.id&#125;” availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”] min_size = 2 max_size = 10 tag &#123; key =“Name” value =“terraform-asg-example” propagate_at_launch = true &#125; &#125; 部署负载均衡器在启动ASG之前，还有一个问题需要解决：现在您有许多实例，您需要一个负载均衡器来分配所有实例的流量。创建高可用性和可伸缩性的负载均衡器需要大量工作。您可以再次使用Elastic Load Balancer（ELB）让AWS为您处理。要使用Terraform创建ELB，请使用aws_elb资源： 1234资源“aws_elb”“example”&#123; name =“terraform-asg-example” availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”] &#125; 这会创建一个ELB，可以在您帐户中的所有AZ中使用。当然，在你告诉ELB如何路由请求之前，上面的定义并不多。为此，您添加一个或多个“侦听器”，指定ELB应侦听的端口以及应将请求路由到的端口： 12345678910资源“aws_elb”“example”&#123; name =“terraform-asg-example” availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”] listener &#123; lb_port = 80 lb_protocol =“http” instance_port =“$ &#123;var.server_port&#125;” instance_protocol =“http” &#125; &#125; 在上面的代码中，我们告诉ELB在端口80（HTTP的默认端口）上接收HTTP请求，并将它们路由到ASG中Instances使用的端口。请注意，默认情况下，ELB不允许任何传入或传出流量（就像EC2实例一样），因此您需要添加一个安全组以明确允许端口80上的传入请求： 123456789资源“aws_security_group”“elb”&#123; name =“terraform-example-elb” ingress &#123; from_port = 80 to_port = 80 protocol =“tcp” cidr_blocks = [“0.0.0.0/0”] &#125; &#125; 现在，您需要通过添加security_groups参数告诉ELB使用此安全组： 1234567891011资源“aws_elb”“example”&#123; name =“terraform-asg-example” security_groups = [“$ &#123;aws_security_group.elb.id&#125;”] availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”] listener &#123; lb_port = 80 lb_protocol =“http” instance_port =“$ &#123;var.server_port&#125;” instance_protocol =“http” &#125; &#125; ELB还有另外一个漂亮的技巧：它可以定期检查你的EC2实例的运行状况，如果一个实例不健康，它会自动停止将流量路由到它。让我们添加一个HTTP运行状况检查，其中ELB将每隔30秒向每个EC2实例的“/”URL发送一个HTTP请求，并且只有在实例响应200 OK时才将其标记为正常： 123456789101112131415161718资源“aws_elb”“example”&#123; name =“terraform-asg-example” security_groups = [“$ &#123;aws_security_group.elb.id&#125;”] availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”] health_check &#123; healthy_threshold = 2 unhealthy_threshold = 2 timeout = 3 interval = 30 target =“HTTP：$ &#123;var.server_port&#125; /” &#125; listener &#123; lb_port = 80 lb_protocol =“http” instance_port =“$ &#123;var.server_port&#125;” instance_protocol =“http” &#125; &#125; 要允许这些运行状况检查请求，您需要修改ELB的安全组以允许出站请求： 123456789101112131415资源“aws_security_group”“elb”&#123; name =“terraform-example-elb” 出口&#123; from_port = 0 to_port = 0 protocol =“ - 1” cidr_blocks = [“0.0.0.0/0”] &#125; ingress &#123; from_port = 80 to_port = 80 protocol =“tcp” cidr_blocks = [“0.0.0.0/0”] &#125; &#125; ELB如何知道向哪些EC2实例发送请求？您可以使用ELB的实例参数将EC2实例的静态列表附加到ELB，但是使用ASG，实例将一直动态启动和终止，因此无法工作。相反，您可以使用aws_autoscaling_group资源的load_balancers参数告诉ASG在该实例启动时注册ELB中的每个实例： 12345678910111213资源“aws_autoscaling_group”“example”&#123; launch_configuration =“$ &#123;aws_launch_configuration.example.id&#125;” availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”] min_size = 2 max_size = 10 load_balancers = [“$ &#123;aws_elb.example.name&#125;”] health_check_type =“ELB” tag &#123; key =“Name” value =“terraform-asg-example” propagate_at_launch = true &#125; &#125; 请注意，我们还将ASG的health_check_type配置为“ELB”。这告诉ASG使用ELB的运行状况检查来确定实例是否健康，并在ELB将其报告为不健康时自动重启实例。 在部署负载均衡器之前要做的最后一件事：让我们将其DNS名称添加为输出，以便更容易测试事情是否正常： 123输出“elb_dns_name”&#123; value =“$ &#123;aws_elb.example.dns_name&#125;” &#125; 运行plan命令以验证您的更改，如果一切正常，请运行apply。应用完成后，您应该看到elb_dns_name输出： 12输出：elb_dns_name = terraform-asg-example-123.us-east-1.elb.amazonaws.com 复制此URL。实例启动并在ELB中显示为健康状态需要几分钟。在此期间，您可以检查已部署的内容。打开EC2控制台的ASG部分，您应该看到已创建ASG： 如果切换到Instances选项卡，您将在启动过程中看到两个实例： 最后，如果切换到Load Balancers选项卡，您将看到您的ELB： 等待“状态”指示符说“服务中有2个实例中的2个”。这通常需要1-2分钟。看到之后，测试先前复制的elb_dns_name输出： 12&gt; curl http：// &lt;elb_dns_name&gt; Hello，World 成功！ELB将流量路由到您的EC2实例。每次点击URL时，它都会选择不同的实例来处理请求。您现在拥有一个完全可用的Web服务器集群！提醒一下，上面示例的完整示例代码位于：https：//github.com/gruntwork-io/intro-to-terraform。 此时，您可以看到群集如何响应启动新实例或关闭旧实例。例如，转到Instances选项卡，通过选中其复选框，选择顶部的“Actions”按钮，然后将“Instance State”设置为“Terminate”来终止其中一个Instances。继续测试ELB URL和你即使在终止实例时，也应该为每个请求获得“200 OK”，因为ELB将自动检测到Instance已关闭并停止路由到它。更有趣的是，在实例关闭后的短时间内，ASG将检测到正在运行的实例少于2个，并自动启动一个新实例来替换它（自我修复！）。您还可以通过更改min_size和max_size参数或向Terraform代码添加desired_size参数来查看ASG如何调整自身大小。 当然，ASG还有许多其他方面，我们在这里没有涉及。对于实际部署，您需要将IAM角色附加到EC2实例，设置机制以使用零停机时间更新ASG中的EC2实例，并配置自动扩展策略以调整ASG的大小以响应负载。对于完全预组装，经过实战考验，文档化，生产就绪的ASG版本，以及其他类型的基础架构（如Docker集群，关系数据库，VPC等），您可能需要查看Gruntwork基础架构包裹。 清理当您尝试使用Terraform时，最好删除您创建的所有资源，以便AWS不会向您收取费用。由于Terraform会跟踪您创建的资源，因此清理工作变得轻而易举。您需要做的就是运行destroy命令： 12345terraform destroy 你真的想破坏吗？ Terraform将删除您的所有托管基础架构。 没有撤消。只接受&apos;是&apos;确认。输入一个值： 输入“yes”并按Enter键后，Terraform将使用尽可能多的并行性构建依赖关系图并按正确的顺序删除所有资源。大约一分钟后，您的AWS账户应该再次清理。 结论您现在已经掌握了如何使用Terraform的基本知识。声明性语言可以很容易地准确描述您要创建的基础结构。plan命令允许您在部署之前验证更改并捕获错误。变量，插值和依赖性允许您保持代码干燥和高效。 但是，我们只是触及了表面。在本系列的第3部分“ 如何管理Terraform状态”中，我们将展示Terraform如何跟踪它已经创建的基础架构，以及对如何构建Terraform代码所产生的深远影响。在本系列的第4部分中，我们将展示如何使用Terraform模块创建可重用的基础架构。","categories":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/categories/Terraform/"}],"tags":[],"keywords":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/categories/Terraform/"}]},{"title":"Docker Swarm架构、特性与基本实践","slug":"Docker-Swarm架构、特性与基本实践","date":"2019-03-30T04:57:09.000Z","updated":"2019-03-30T05:02:08.209Z","comments":true,"path":"Docker/Docker-Swarm架构、特性与基本实践/","link":"","permalink":"http://blog.ozairs.com/Docker/Docker-Swarm架构、特性与基本实践/","excerpt":"","text":"Docker集群管理和编排的特性是通过SwarmKit进行构建的， 其中Swarm mode是Docker Engine内置支持的一种默认实现。Docker 1.12以及更新的版本，都支持Swarm mode，我们可以基于Docker Engine来构建Swarm集群，然后就可以将我们的应用服务（Application Service）部署到Swarm集群中。创建Swarm集群的方式很简单，先初始化一个Swarm集群，然后将其他的Node加入到该集群即可。本文主要基于Docker Swarm官网文档，学习总结。 基本特性 Docker Swarm具有如下基本特性： 集群管理集成进Docker Engine 使用内置的集群管理功能，我们可以直接通过Docker CLI命令来创建Swarm集群，然后去部署应用服务，而不再需要其它外部的软件来创建和管理一个Swarm集群。 去中心化设计 Swarm集群中包含Manager和Worker两类Node，我们可以直接基于Docker Engine来部署任何类型的Node。而且，在Swarm集群运行期间，我们既可以对其作出任何改变，实现对集群的扩容和缩容等，如添加Manager Node，如删除Worker Node，而做这些操作不需要暂停或重启当前的Swarm集群服务。 声明式服务模型（Declarative Service Model） 在我们实现的应用栈中，Docker Engine使用了一种声明的方式，让我们可以定义我们所期望的各种服务的状态，例如，我们创建了一个应用服务栈：一个Web前端服务、一个后端数据库服务、Web前端服务又依赖于一个消息队列服务。 服务扩容缩容 对于我们部署的每一个应用服务，我们可以通过命令行的方式，设置启动多少个Docker容器去运行它。已经部署完成的应用，如果有扩容或缩容的需求，只需要通过命令行指定需要几个Docker容器即可，Swarm集群运行时便能自动地、灵活地进行调整。 协调预期状态与实际状态的一致性 Swarm集群Manager Node会不断地监控集群的状态，协调集群状态使得我们预期状态和实际状态保持一致。例如我们启动了一个应用服务，指定服务副本为10，则会启动10个Docker容器去运行，如果某个Worker Node上面运行的2个Docker容器挂掉了，则Swarm Manager会选择集群中其它可用的Worker Node，并创建2个服务副本，使实际运行的Docker容器数仍然保持与预期的10个一致。 多主机网络 我们可以为待部署应用服务指定一个Overlay网络，当应用服务初始化或者进行更新时，Swarm Manager在给定的Overlay网络中为Docker容器自动地分配IP地址，实际是一个虚拟IP地址（VIP）。 服务发现 Swarm Manager会给集群中每一个服务分配一个唯一的DNS名称，对运行中的Docker容器进行负载均衡。我们可以通过Swarm内置的DNS Server，查询Swarm集群中运行的Docker容器状态。 负载均衡 在Swarm内部，可以指定如何在各个Node之间分发服务容器（Service Container），实现负载均衡。如果想要使用Swarm集群外部的负载均衡器，可以将服务容器的端口暴露到外部。 安全策略 在Swarm集群内部的Node，强制使用基于TLS的双向认证，并且在单个Node上以及在集群中的Node之间，都进行安全的加密通信。我们可以选择使用自签名的根证书，或者使用自定义的根CA（Root CA）证书。 滚动更新（Rolling Update） 对于服务需要更新的场景，我们可以在多个Node上进行增量部署更新，Swarm Manager支持通过使用Docker CLI设置一个delay时间间隔，实现多个服务在多个Node上依次进行部署。这样可以非常灵活地控制，如果有一个服务更新失败，则暂停后面的更新操作，重新回滚到更新之前的版本。 基本架构 Docker Swarm提供了基本的集群能力，能够使多个Docker Engine组合成一个group，提供多容器服务。Swarm使用标准的Docker API，启动容器可以直接使用docker run命令。Swarm更核心的则是关注如何选择一个主机并在其上启动容器，最终运行服务。Docker Swarm基本架构，如下图所示 如上图所示，Swarm Node表示加入Swarm集群中的一个Docker Engine实例，基于该Docker Engine可以创建并管理多个Docker容器。其中，最开始创建Swarm集群的时候，Swarm Manager便是集群中的第一个Swarm Node。在所有的Node中，又根据其职能划分为Manager Node和Worker Node，具体分别如下所示： Manager Node Manager Node负责调度Task，一个Task表示要在Swarm集群中的某个Node上启动Docker容器，一个或多个Docker容器运行在Swarm集群中的某个Worker Node上。同时，Manager Node还负责编排容器和集群管理功能（或者更准确地说，是具有Manager管理职能的Node），维护集群的状态。需要注意的是，默认情况下，Manager Node也作为一个Worker Node来执行Task。Swarm支持配置Manager只作为一个专用的管理Node，后面我们会详细说明。 Worker Node Worker Node接收由Manager Node调度并指派的Task，启动一个Docker容器来运行指定的服务，并且Worker Node需要向Manager Node汇报被指派的Task的执行状态。 构建Swarm集群 我们实践Swarm集群，包括三个Node，对应的主机名和IP地址分别如下所示： 1`manager 192.168.1.107``worker1 192.168.1.108``worker2 192.168.1.109` 首先，需要保证各个Node上，docker daemon进程已经正常启动，如果没有则执行如下命令启动： 1`systemctl start docker` 接下来就可以创建Swarm集群，创建Swarm的命令，格式如下所示： 1`docker swarm init --advertise-addr &lt;MANAGER-IP&gt;` 我们在准备好的manager Node上，登录到该Node，创建一个Swarm，执行如下命令： 1`docker swarm init --advertise-addr 192.168.1.107` 上面--advertise-addr选项指定Manager Node会publish它的地址为192.168.1.107，后续Worker Node加入到该Swarm集群，必须要能够访问到Manager的该IP地址。可以看到，上述命令执行结果，如下所示： 1`Swarm initialized: current node (5pe2p4dlxku6z2a6jnvxc4ve6) is now a manager.` `To add a worker to this swarm, run the following command:` ` ``docker swarm join \\`` ``--token SWMTKN-1-4dm09nzp3xic15uebqja69o2552b75pcg7or0g9t2eld9ehqt3-1kb79trnv6fbydvl9vif3fsch \\`` ``192.168.1.107:2377` `To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions.` 该结果中给出了后续操作引导信息，告诉我们如何将一个Worker Node加入到Swarm集群中。也可以通过如下命令，来获取该提示信息： 1`docker swarm ``join``-token worker` 在任何时候，如果我们需要向已经创建的Swarm集群中增加Worker Node，只要新增一个主机（物理机、云主机等都可以），并在其上安装好Docker Engine并启动，然后执行上述docker swarm join命令，就可以加入到Swarm集群中。这时，我们也可以查看当前Manager Node的基本信息，执行docker info命令，输出信息中可以看到，包含如下关于Swarm的状态信息： 1`Swarm: active`` ``NodeID: qc42f6myqfpoevfkrzmx08n0r`` ``Is Manager: true`` ``ClusterID: qi4i0vh7lgb60qxy3mdygb27f`` ``Managers: 1`` ``Nodes: 1` 可以看出，目前Swarm集群只有Manager一个Node，而且状态是active。也可以在Manager Node上执行docker node ls命令查看Node状态，如下所示： 1`ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS``qc42f6myqfpoevfkrzmx08n0r * manager Ready Active Leader` 接下来，我们可以根据上面提示信息，我们分别在worker1、worker2两个Worker Node 上，执行命令将Worker Node加入到Swarm集群中，命令如下所示： 1`docker swarm ``join` `\\`` ``--token SWMTKN-1-4dm09nzp3xic15uebqja69o2552b75pcg7or0g9t2eld9ehqt3-1kb79trnv6fbydvl9vif3fsch \\`` ``192.168.1.107:2377` 如果成功，可以看到成功加入Swarm集群的信息。这时，也可以在Manager Node上，查看Swarm集群的信息，示例如下所示： 1`Swarm: active`` ``NodeID: qc42f6myqfpoevfkrzmx08n0r`` ``Is Manager: true`` ``ClusterID: qi4i0vh7lgb60qxy3mdygb27f`` ``Managers: 1`` ``Nodes: 3` 想要查看Swarm集群中全部Node的详细状态信息，可以执行如下所示命令： 1`docker node ``ls` Swarm集群Node的状态信息，如下所示： 1`ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS``oibbiiwrgwjkw0ni38ydrfsre worker1 Ready Active ``oocli2uzdt2hy6o50g5z6j7dq worker2 Ready Active ``qc42f6myqfpoevfkrzmx08n0r * manager Ready Active Leader` 上面信息中，AVAILABILITY表示Swarm Scheduler是否可以向集群中的某个Node指派Task，对应有如下三种状态： Active：集群中该Node可以被指派Task Pause：集群中该Node不可以被指派新的Task，但是其他已经存在的Task保持运行 Drain：集群中该Node不可以被指派新的Task，Swarm Scheduler停掉已经存在的Task，并将它们调度到可用的Node上 查看某一个Node的状态信息，可以在该Node上执行如下命令： 1`docker node inspect self` 我们在Manager Node上执行上述命令，查看的状态信息如下所示： 1`[`` ``&#123;`` ``&quot;ID&quot;: &quot;qc42f6myqfpoevfkrzmx08n0r&quot;,`` ``&quot;Version&quot;: &#123;`` ``&quot;Index&quot;: 9`` ``&#125;,`` ``&quot;CreatedAt&quot;: &quot;2017-03-12T15:25:51.725341879Z&quot;,`` ``&quot;UpdatedAt&quot;: &quot;2017-03-12T15:25:51.84308356Z&quot;,`` ``&quot;Spec&quot;: &#123;`` ``&quot;Role&quot;: &quot;manager&quot;,`` ``&quot;Availability&quot;: &quot;active&quot;`` ``&#125;,`` ``&quot;Description&quot;: &#123;`` ``&quot;Hostname&quot;: &quot;manager&quot;,`` ``&quot;Platform&quot;: &#123;`` ``&quot;Architecture&quot;: &quot;x86_64&quot;,`` ``&quot;OS&quot;: &quot;linux&quot;`` ``&#125;,`` ``&quot;Resources&quot;: &#123;`` ``&quot;NanoCPUs&quot;: 1000000000,`` ``&quot;MemoryBytes&quot;: 1912082432`` ``&#125;,`` ``&quot;Engine&quot;: &#123;`` ``&quot;EngineVersion&quot;: &quot;17.03.0-ce&quot;,`` ``&quot;Plugins&quot;: [`` ``&#123;`` ``&quot;Type&quot;: &quot;Network&quot;,`` ``&quot;Name&quot;: &quot;bridge&quot;`` ``&#125;,`` ``&#123;`` ``&quot;Type&quot;: &quot;Network&quot;,`` ``&quot;Name&quot;: &quot;host&quot;`` ``&#125;,`` ``&#123;`` ``&quot;Type&quot;: &quot;Network&quot;,`` ``&quot;Name&quot;: &quot;macvlan&quot;`` ``&#125;,`` ``&#123;`` ``&quot;Type&quot;: &quot;Network&quot;,`` ``&quot;Name&quot;: &quot;null&quot;`` ``&#125;,`` ``&#123;`` ``&quot;Type&quot;: &quot;Network&quot;,`` ``&quot;Name&quot;: &quot;overlay&quot;`` ``&#125;,`` ``&#123;`` ``&quot;Type&quot;: &quot;Volume&quot;,`` ``&quot;Name&quot;: &quot;local&quot;`` ``&#125;`` ``]`` ``&#125;`` ``&#125;,`` ``&quot;Status&quot;: &#123;`` ``&quot;State&quot;: &quot;ready&quot;,`` ``&quot;Addr&quot;: &quot;127.0.0.1&quot;`` ``&#125;,`` ``&quot;ManagerStatus&quot;: &#123;`` ``&quot;Leader&quot;: true,`` ``&quot;Reachability&quot;: &quot;reachable&quot;,`` ``&quot;Addr&quot;: &quot;192.168.1.107:2377&quot;`` ``&#125;`` ``&#125;``]` 管理Swarm Node Swarm支持设置一组Manager Node，通过支持多Manager Node实现HA。那么这些Manager Node之间的状态的一致性就非常重要了，多Manager Node的Warm集群架构，如下图所示： 通过上图可以看到，Swarm使用了Raft协议来保证多个Manager之间状态的一致性。基于Raft协议，Manager Node具有一定的容错功能，假设Swarm集群中有个N个Manager Node，那么整个集群可以容忍最多有(N-1)/2个节点失效。如果是一个三Manager Node的Swarm集群，则最多只能容忍一个Manager Node挂掉。下面，我们按照对Node的不同操作，通过命令的方式来详细说明： （1）Node状态变更管理 前面我们已经提到过，Node的AVAILABILITY有三种状态：Active、Pause、Drain，对某个Node进行变更，可以将其AVAILABILITY值通过Docker CLI修改为对应的状态即可，下面是常见的变更操作： 设置Manager Node只具有管理功能 对服务进行停机维护，可以修改AVAILABILITY为Drain状态 暂停一个Node，然后该Node就不再接收新的Task 恢复一个不可用或者暂停的Node 例如，将Manager Node的AVAILABILITY值修改为Drain状态，使其只具备管理功能，执行如下命令： 1`docker node update --availability drain manager` 这样，Manager Node不能被指派Task，也就是不能部署实际的Docker容器来运行服务，而只是作为管理Node的角色。 （2）给Node添加标签元数据 每个Node的主机配置情况可能不同，比如有的适合运行CPU密集型应用，有的适合运行IO密集型应用，Swarm支持给每个Node添加标签元数据，这样可以根据Node的标签，来选择性地调度某个服务部署到期望的一组Node上。给SWarm集群中的某个Worker Node添加标签，执行如下命令格式如下： 1`docker node update --label-add 键名称=值` 例如，worker1主机在名称为bjidc这个数据中心，执行如下命令添加标签： 1`docker node update --label-add datacenter=bjidc` （3）Node提权/降权 改变Node的角色，Worker Node可以变为Manager Node，这样实际Worker Node有工作Node变成了管理Node，对应提权操作，例如将worker1和worker2都升级为Manager Node，执行如下命令： 1`docker node promote worker1 worker2` 对上面已提权的worker1和worker2执行降权，需要执行如下命令： 1`docker node demote worker1 worker2` （4）退出Swarm集群 如果Manager想要退出Swarm集群， 在Manager Node上执行如下命令： 1`docker swarm node leave` 就可以退出集群，如果集群中还存在其它的Worker Node，还希望Manager退出集群，则加上一个强制选项，命令行如下所示： 1`docker swarm node leave --force` 同样，如果Worker想要退出Swarm集群，在Worker Node上，执行如下命令： 1`docker swarm node leave` 即使Manager已经退出SWarm集群，执行上述命令也可以使得Worker Node退出集群，然后又可以加入到其它新建的Swarm集群中。 管理服务 在Swarm集群上部署服务，必须在Manager Node上进行操作。先说明一下Service、Task、Container（容器）这个三个概念的关系，如下图（出自Docker官网）非常清晰地描述了这个三个概念的含义：在Swarm mode下使用Docker，可以实现部署运行服务、服务扩容缩容、删除服务、滚动更新等功能，下面我们详细说明。 （1）创建服务 创建Docker服务，可以使用docker service create命令实现，例如，我们要创建如下两个服务，执行如下命令： 1`docker service create --replicas 1 --name myapp alpine ``ping` `shiyanjun.cn``docker service create --replicas 2 --name myredis redis` 第一个命令行，从Docker镜像alpine创建了一个名称为myapp的服务，其中指定服务副本数为1，也就是启动一个Docker容器来运行该服务。第二个命令行， 创建一个Redis服务，服务副本数为2，那么会启动两个Docker容器来运行myredis服务。查看当前，已经部署启动的全部应用服务，执行如下命令： 1`docker service ``ls` 执行结果，如下所示： 1`ID NAME MODE REPLICAS IMAGE``kilpacb9uy4q myapp replicated 1/1 alpine:latest``vf1kcgtd5byc myredis replicated 2/2 redis` 也可以查询指定服务的详细信息，执行如下命令： 1`docker service ``ps` `myredis` 查看结果信息，如下所示： 1`ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS``0p3r9zm2uxpl myredis.1 redis manager Running Running 48 seconds ago ``ty3undmoielo myredis.2 redis worker1 Running Running 44 seconds ago` 上面信息中，在manager和worker1这两个Node上部署了myredis这个应用服务，也包含了它们对应的当前状态信息。此时，也可以通过执行docker ps命令，在Manager Node上查看当前启动的Docker容器： 1`CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES``07f93f82a407 redis:latest &quot;docker-entrypoint...&quot; 7 minutes ago Up 7 minutes 6379/tcp myredis.1.0p3r9zm2uxple5i1e2mqgnl3r` 在Worker1上查看当前启动的Docker容器，也就是我们的另一个myredis实例在该Node上： 1`CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES``41c31e96cccb redis:latest &quot;docker-entrypoint...&quot; 8 minutes ago Up 8 minutes 6379/tcp myredis.2.ty3undmoielo18g7pnvh0nutz` 创建服务时，我们可以对运行时服务容器进行配置，例如如下命令： 1`docker service create --name helloworld \\`` ``--``env` `MYVAR=myvalue \\`` ``--workdir ``/tmp` `\\`` ``--user my_user \\`` ``alpine ``ping` `docker.com` 上面，通过--env选项来设置环境变量，通过--workdir选项来设置工作目录，通过--user选项来设置用户信息。 （2）扩容缩容服务 Docker Swarm支持服务的扩容缩容，Swarm通过--mode选项设置服务类型，提供了两种模式：一种是replicated，我们可以指定服务Task的个数（也就是需要创建几个冗余副本），这也是Swarm默认使用的服务类型；另一种是global，这样会在Swarm集群的每个Node上都创建一个服务。如下图所示（出自Docker官网），是一个包含replicated和global模式的Swarm集群： 上图中，黄色表示的replicated模式下的Service Replicas，灰色表示global模式下Service的分布。服务扩容缩容，在Manager Node上执行命令的格式，如下所示： 1`docker service scale 服务ID=服务Task总数` 例如，将前面我们部署的2个副本的myredis服务，扩容到3个副本，执行如下命令： 1`docker service scale myredis=3` 通过命令docker service ls 查看，扩容操作结果如下所示： 1`ID NAME MODE REPLICAS IMAGE``kilpacb9uy4q myapp replicated 1/1 alpine:latest``vf1kcgtd5byc myredis replicated 3/3 redis` 进一步通过docker service ps myredis查看一下myredis的各个副本的状态信息，如下所示： 1`ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS``0p3r9zm2uxpl myredis.1 redis manager Running Running 14 minutes ago ``ty3undmoielo myredis.2 redis worker1 Running Running 14 minutes ago ``zxsvynsgqmpk myredis.3 redis worker2 Running Running less than a second ago` 可以看到，我们目前3个Node的Swarm集群，每个Node上都有一个myredis应用服务的副本，可见也实现了很好的负载均衡。缩容服务，只需要将副本数小于当前应用服务拥有的副本数即可实现，大于指定缩容副本数的副本会被删除。 （3）删除服务 删除服务，只需要在Manager Node上执行如下命令即可： 1`docker service ``rm` `服务ID` 例如，删除myredis应用服务，执行docker service rm myredis，则应用服务myredis的全部副本都会被删除。 （4）滚动更新 服务的滚动更新，这里我参考官网文档的例子说明。在Manager Node上执行如下命令： 1`docker service create \\`` ``--replicas 3 \\`` ``--name redis \\`` ``--update-delay 10s \\`` ``redis:3.0.6` 上面通过指定--update-delay选项，表示需要进行更新的服务，每次成功部署一个，延迟10秒钟，然后再更新下一个服务。如果某个服务更新失败，则Swarm的调度器就会暂停本次服务的部署更新。另外，也可以更新已经部署的服务所在容器中使用的Image的版本，例如执行如下命令： 1`docker service update --image redis:3.0.7 redis` 将Redis服务对应的Image版本有3.0.6更新为3.0.7，同样，如果更新失败，则暂停本次更新。 （5）添加Overlay网络 在Swarm集群中可以使用Overlay网络来连接到一个或多个服务。具体添加Overlay网络，首先，我们需要创建在Manager Node上创建一个Overlay网络，执行如下命令： 1`docker network create --driver overlay my-network` 创建完Overlay网络my-network以后，Swarm集群中所有的Manager Node都可以访问该网络。然后，我们在创建服务的时候，只需要指定使用的网络为已存在的Overlay网络即可，如下命令所示： 1`docker service create \\`` ``--replicas 3 \\`` ``--network my-network \\`` ``--name myweb \\`` ``nginx` 这样，如果Swarm集群中其他Node上的Docker容器也使用my-network这个网络，那么处于该Overlay网络中的所有容器之间，通过网络可以连通。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"docker swarm","slug":"docker-swarm","permalink":"http://blog.ozairs.com/tags/docker-swarm/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation","slug":"为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation","date":"2019-03-29T21:59:47.000Z","updated":"2019-03-29T22:04:21.895Z","comments":true,"path":"Terraform/为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation/","link":"","permalink":"http://blog.ozairs.com/Terraform/为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation/","excerpt":"","text":"这是Terraform系列综合指南的第1部分。在本系列的介绍中，我们讨论了为什么每家公司都应该使用基础架构代码（IAC）。在这篇文章中，我们将讨论为什么我们选择Terraform作为我们选择的IAC工具。 如果您在互联网上搜索“基础架构即代码”，那么很容易想出一个最受欢迎的工具列表： Chef Puppet Ansible SaltStack CloudFormation Terraform 什么不容易找出你应该使用哪一个。所有这些工具都可用于将基础架构作为代码进行管理。所有这些都是开源的，由大型贡献者社区支持，并与许多不同的云提供商合作（除了CloudFormation，它是闭源和仅AWS）。所有这些都提供企业支持。所有这些都有很好的文档记录，包括官方文档和社区资源，如博客文章和StackOverflow问题。那你怎么决定？ 更难以理解的是，您在这些工具之间在线找到的大多数比较只是列出每个工具的一般属性，并使其听起来像您可以同样成功地使用它们。虽然这在技术上是正确的，但它没有帮助。这有点像告诉编程新手，你可以用PHP，C或汇编建立一个网站同样成功 - 这个声明在技术上是正确的，但是省略了大量的信息，这些信息在做出正确的决定时非常有用。 在这篇文章中，我们将深入探讨为什么我们选择Terraform而不是其他IAC工具的一些非常具体的原因。与所有技术决策一样，这是一个权衡和优先级的问题，虽然您的特定优先级可能与我们的不同，但我们希望分享我们的思维过程将帮助您做出自己的决定。以下是我们考虑的主要权衡因素： 配置管理与业务流程 可变基础设施与不可变基础设施 程序性与陈述性 客户端/服务器架构与仅客户端架构 配置管理与业务流程Chef，Puppet，Ansible和SaltStack都是“配置管理”工具，这意味着它们旨在安装和管理现有服务器上的软件。CloudFormation和Terraform是“业务流程工具”，这意味着它们旨在自行配置服务器，将这些服务器配置为其他工具。这两个类别并不相互排斥，因为大多数配置管理工具都可以进行一定程度的配置，大多数编排工具可以进行某种程度的配置管理。但是，对配置管理或编排的关注意味着某些工具将更适合某些类型的任务。 特别是，我们发现如果您使用Docker或Packer，您的绝大多数配置管理需求已经得到了解决。使用Docker和Packer，您可以创建已安装和配置服务器所需的所有软件的映像（例如容器或虚拟机映像）（有关Docker的优缺点的详细信息，请参阅此处）。拥有这样的图像后，您只需要一台服务器即可运行它。如果您需要做的就是配置一堆服务器，那么像Terraform这样的编排工具通常比配置管理工具更合适（这里是一个如何使用Terraform在AWS上部署Docker的示例）。 可变基础设施与不可变基础设施Chef，Puppet，Ansible和SaltStack等配置管理工具通常默认为可变基础架构范例。例如，如果您告诉Chef安装新版本的OpenSSL，它将在现有服务器上运行软件更新，并且更改将在原地进行。随着时间的推移，当您应用越来越多的更新时，每个服务器都会构建一个独特的更改历史记录。这通常会导致称为配置漂移的现象，其中每个服务器与所有其他服务器略有不同，导致难以诊断且几乎不可能再现的细微配置错误。 如果您正在使用Terraform等编排工具来部署Docker或Packer创建的机器映像，那么每个“更改”实际上都是新服务器的部署（就像函数式编程中变量的每次“更改”实际返回一样）新变量）。例如，要部署新版本的OpenSSL，您可以使用Packer或Docker创建新映像，并安装新版本的OpenSSL，将该映像部署到一组全新的服务器上，然后取消部署旧服务器。这种方法降低了配置偏移错误的可能性，使您更容易确切知道服务器上运行的软件，并允许您随时轻松部署任何以前版本的软件。当然，也可以强制配置管理工具进行不可变部署， 程序性与陈述性Chef和Ansible鼓励一种程序风格，您可以编写代码，逐步指定如何实现某些所需的最终状态。Terraform，CloudFormation，SaltStack和Puppet都鼓励更具说明性的风格，您可以编写指定所需最终状态的代码，IAC工具本身负责确定如何实现该状态。 例如，假设您要部署10台服务器（AWS术语中的“EC2 Instances”）来运行应用程序的v1。以下是使用过程方法执行此操作的Ansible模板的简化示例： 1234- ec2： count：10 image：ami-v1 instance_type：t2.micro 以下是使用声明方法执行相同操作的Terraform模板的简化示例： 12345资源“aws_instance”“example”&#123; count = 10 ami =“ami-v1” instance_type =“t2.micro” &#125; 现在在表面上，这两种方法可能看起来相似，当您最初使用Ansible或Terraform执行它们时，它们将产生类似的结果。有趣的是，当您想要进行更改时会发生什么。 例如，假设流量已经增加，并且您希望将服务器数量增加到15.使用Ansible，您之前编写的过程代码不再有用; 如果您刚刚将服务器数量更新为15并重新启动该代码，那么它将部署15台新服务器，总共提供25台服务器！因此，您必须了解已部署的内容并编写一个全新的过程脚本来添加5个新服务器： 1234- ec2： count：5 image：ami-v1 instance_type：t2.micro 使用声明性代码，因为你所做的就是声明你想要的结束状态，而Terraform计算出如何到达那个结束状态，Terraform也会知道它过去创建的任何状态。因此，要部署另外5台服务器，您只需返回相同的Terraform模板并将计数从10更新为15： 12345Resource “aws_instance”“example”&#123; count = 15 ami =“ami-v1” instance_type =“t2.micro” &#125; 如果你执行了这个模板，Terraform会意识到它已经创建了10个服务器，因此它需要做的只是创建5个新服务器。实际上，在运行此模板之前，您可以使用Terraform的“计划”命令来预览它将进行的更改： 1234567891011121314151617&gt; terraform计划+ aws_instance.example.11 ami：“ami-v1” instance_type：“t2.micro”+ aws_instance.example.12 ami：“ami-v1” instance_type：“t2.micro”+ aws_instance.example.13 ami：“ami-v1” instance_type：“t2.micro”+ aws_instance.example.14 ami：“ami-v1” instance_type：“t2.micro”+ aws_instance.example.15 ami：“ami-v1” instance_type：“t2.micro”计划：5添加，0改变，0破坏。 现在，当您想要部署v2服务时会发生什么？使用过程方法，您之前的两个Ansible模板都没有用，所以您必须编写另一个模板来跟踪之前部署的10个服务器（或者现在是15个？）并仔细更新每个模板到新版本。使用Terraform的声明式方法，您可以再次返回完全相同的模板，只需将ami版本号更改为v2： 12345Resource “aws_instance”“example”&#123; count = 15 ami =“ami-v2” instance_type =“t2.micro” &#125; 显然，上述例子是简化的。Ansible允许您在部署新的EC2实例之前使用标签来搜索现有的EC2实例（例如，使用instance_tags和count_tag参数），但是必须根据每个资源的情况为Ansible管理的每个资源手动找出这种逻辑。过去的历史，可能会令人惊讶地复杂化（例如，不仅通过标签，还可以通过图像版本，可用区域等查找现有实例）。这突出了程序IAC工具的两个主要问题： 处理过程代码时，代码中未完全捕获基础结构的状态。阅读我们上面创建的三个Ansible模板并不足以了解已部署的内容。您还必须知道我们应用这些模板的顺序。如果我们以不同的顺序应用它们，我们最终可能会使用不同的基础结构，而这不是您在代码库本身中可以看到的。换句话说，要推理Ansible或Chef代码库，您必须知道所发生的每个更改的完整历史记录。 过程代码的可重用性本质上是有限的，因为您必须手动考虑代码库的当前状态。由于该状态不断变化，因此一周前使用的代码可能不再可用，因为它旨在修改不再存在的基础架构状态。结果，程序代码库随着时间的推移趋于变大和变得复杂。 另一方面，使用Terraform中使用的声明式方法，代码始终代表基础架构的最新状态。一目了然，您可以分辨当前部署的内容及其配置方式，而无需担心历史记录或时间安排。这也使得创建可重用代码变得容易，因为您不必手动考虑当前的世界状态。相反，您只需专注于描述您想要的状态，Terraform会自动确定如何从一个状态到另一个状态。因此，Terraform代码库往往保持小巧且易于理解。 当然，声明性语言也有缺点。如果无法使用完整的编程语言，您的表达能力就会受到限制。例如，某些类型的基础架构更改（例如滚动，零停机部署）很难用纯粹的声明性术语表达。同样，如果没有“逻辑”（例如if语句，循环）的能力，创建通用的，可重用的代码可能会很棘手（特别是在CloudFormation中）。幸运的是，Terraform提供了许多强大的原语 - 例如输入变量，输出变量，模块，create_before_destroy，count和插值函数 - 即使在声明性语言中，也可以创建干净，可配置的模块化代码。我们将在第4部分，如何使用Terraform模块创建可重用的基础架构和第5部分，Terraform提示和技巧：循环，if语句和陷阱中更多地讨论这些工具。 客户端/服务器架构与仅客户端架构Chef，Puppet和SaltStack默认都使用客户端/服务器架构。客户端可以是Web UI或CLI工具，用于发出命令（例如“部署X”）。这些命令转到服务器，服务器负责执行命令并存储系统状态。要执行这些命令，服务器会与代理进行通信，代理必须在您要配置的每台服务器上运行。这有许多缺点： 您必须在每台服务器上安装和运行额外的软件。 您必须部署额外的服务器（甚至是服务器集群以实现高可用性），仅用于配置管理。 您不仅需要安装这些额外的软件和硬件，而且还必须对其进行维护，升级，备份，监控以及在发生中断时进行恢复。 由于客户端，服务器和代理都需要通过网络进行通信，因此必须为它们打开额外的端口，并配置它们相互进行身份验证的方式，所有这些都会增加攻击者的表面积。 所有这些额外的移动部件都会在您的基础架构中引入大量新的故障模式。当您在凌晨3点收到错误报告时，您必须弄清楚它是否是您的应用程序代码，IAC代码，配置管理客户端软件，配置管理代理软件或配置管理服务器软件中的错误，或所有这些配置管理部件用于通信的端口，或者它们彼此进行身份验证的方式，或者…… CloudFormation，Ansible和Terraform使用仅客户端架构。实际上，CloudFormation也是客户端/服务器，但AWS透明地处理所有服务器细节，作为最终用户，您只需要考虑客户端代码。Ansible客户端通过SSH直接连接到您的服务器。Terraform使用云提供商API来配置基础架构，因此除了您已经使用云提供商之外，没有新的身份验证机制，也不需要直接访问您的服务器。我们发现这是易用性，安全性和可维护性方面的最佳选择。 结论总而言之，下面的表格显示了最流行的IAC工具如何叠加： 比较流行的基础架构作为代码工具。点击图像查看大图。请注意，此表显示了使用每个工具的“惯用”方式。 在Gruntwork，我们想要的是一个开源的，与云无关的编排工具，它支持不可变基础架构，声明性语言和仅客户端架构。从上表中可以看出，Terraform是唯一符合我们所有标准的工具。 当然，Terraform并不完美。它比名单上的所有其他工具更年轻，更不成熟：虽然Puppet于2005年推出，2009年是Chef，2011年是SaltStack和CloudFormation，2012年是Ansible，Terraform仅在2年前推出，2014年.Terraform仍然是pre 1.0.0（最新版本为0.7.4），因此无法保证稳定或向后兼容的API。错误相对常见（例如，标签“bug” 存在超过800个未解决的问题），尽管绝大多数都是无害的最终一致性问题，当您重新运行Terraform时这些问题就会消失。Terraform如何存储状态也存在一些问题，尽管我们将在第3部分：如何管理Terraform状态中讨论这些问题的有效解决方案。 尽管有它的缺点，我们发现Terraform的优势远远超过它的弱点，并且没有其他IAC工具几乎符合我们的标准。如果Terraform听起来像是符合您标准的东西，请转到第2部分：Terraform简介，了解更多信息。","categories":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/categories/Terraform/"}],"tags":[{"name":"Iac","slug":"Iac","permalink":"http://blog.ozairs.com/tags/Iac/"}],"keywords":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/categories/Terraform/"}]},{"title":"使用Jenkins Pipeline进行持续集成","slug":"使用Jenkins-Pipeline进行持续集成","date":"2019-03-29T06:16:10.000Z","updated":"2019-03-29T06:18:18.570Z","comments":true,"path":"Jenkins/使用Jenkins-Pipeline进行持续集成/","link":"","permalink":"http://blog.ozairs.com/Jenkins/使用Jenkins-Pipeline进行持续集成/","excerpt":"","text":"本文与Github，Gitflow和Jenkins持续集成和交付的内容有关。但这次我将扩展与Jenkins持续集成的主题，并深入探讨Jenkins Pipelines的细节。在这里，您将找到有关与Jenkins Pipeline持续集成的所有信息！ 好的，确定你知道这一切，但基本条款永远不会让情况更糟。我们将从他们开始。 主要内容Jenkins是一个开源的持续集成（CI）工具，可以通过自动化帮助协调开发过程（构建，测试和部署）。换句话说，Jenkins是帮助开发团队实现其流程工业化的领先工具之一。这是开发人员的队友，当您在特定分支（主控和开发）上推送代码时，您可以要求将代码投入生产（或升级）。 正如您所知，CI（持续集成）是将所有开发人员工作副本每天多次合并到共享主线的做法。 Jenkins很有用，因为它将自由式作业编排成CI管道。 Pipeline（Jenkins Pipeline）是一套插件，支持在Jenkins中实现和集成连续交付管道。持续交付管道是您将软件从版本控制直至用户和客户的过程的自动表达。 Pipeline为Jenkins添加了一套功能强大的自动化工具。设置管道项目意味着编写一个脚本，该脚本将按顺序应用我们想要完成的流程的一些步骤。 Jenkinsfile是一个文本文件，包含Jenkins管道的定义，并被检入源代码管理。 构建作业是由Jenkins控制和监视的可运行任务。作业示例包括编译源代码，运行测试，配置测试环境，部署，归档，发布构建作业（如报告）以及执行任意脚本。 管道Jenkins管道功能 代码：管道在代码中实现，通常检查到源代码控制中，使团队能够编辑，审查和迭代其交付管道。 持久：管道可以在Jenkins主计划的计划内和计划外重启中存活。 Pausable：在继续管道运行之前，管道可以选择停止并等待人工输入或批准。 功能多样：管道支持复杂的实际连续交付要求，包括并行分叉/连接，循环和执行工作的能力。 可扩展：Pipeline插件支持其DSL（特定于域的语言）的自定义扩展以及与其他插件集成的多个选项。 Jenkins管道条款步骤 - 单个任务; 从根本上说步Jenkins是什么做的。 节点。Pipeline执行的大多数工作是在一个或多个声明的节点步骤的上下文中完成的。节点选择管道将在何处执行。限制节点步骤内的工作有两个作用： 通过向Jenkins队列添加项来计划要运行的块中包含的步骤。只要执行程序在节点上空闲，步骤就会运行。 创建工作空间（特定于该特定管道的目录），可以对从源控件检出的文件进行工作。 阶段是定义整个管道的概念上不同的子集的步骤，例如：“构建”，“测试”和“部署”，许多插件使用它来可视化或呈现Jenkins管道状态/进度。 声明性和脚本化管道 Jenkins Pipeline正在使用具有两种不同语法的域特定语言（DSL）： Declarative Pipeline在Pipeline子系统之上提供了更简化和固定的语法。 Scripted Pipeline遵循使用Groovy构建的更强制的编程模型。 JenkinsfileJenkinsfile用于替换当前使用的三个Jenkins构建作业： 主要集成分支的多分支：开发，发布，修补程序和主服务器。 合并自动测试GitLab合并请求的请求。 参数化为按需测试。 使用Jenkinsfile可以解决的问题 将CI / CD管道定义为代码，使其自我记录，可重现和版本化。 对任何类型的构建作业都有单一的构建步骤定义，无论是多分支，合并请求还是参数化。 远离构建步骤的手动配置。 使管道易于扩展。例如，将新的静态分析工具报告添加到所有已配置的构建作业中应该不复杂。 将您的代码投入生产定义管道 设置/配置构建环境。 看看你的代码。 构建代码。确保您不使用任何特定于环境的构建过程设置可以独立于环境。 执行质量控制。此步骤包含两个主要任务：运行测试和执行代码质量检查。 在Continuous Integration环境中部署代码。 运行功能测试。 在测试环境中部署代码。 在用户接受环境中部署代码。 在生产环境中部署代码。 触发作业的一种常见方法是将更改提交到存储库。这意味着当开发人员完成开发任务并将其更改推送到项目的存储库时（例如，如果您使用Git，则执行Git push命令），该作业将自动触发。一个简单的方法是通过GitHub Jenkins插件。 Jenkins部署的最佳实践 Jenkins不会将默认配置作为其默认配置的一部分执行任何安全检查，因此请始终确保对Jenkins服务器上的用户进行身份验证并强制实施访问控制。保护您的Jenkins服务器。 在包含多个配置作业的用户的大型复杂集成环境中，应确保它们不在主服务器上运行构建，并且可以无限制地访问JENKINS_HOME目录。小心的主机。 为确保在需要时可以使用所有配置和活动日志，请使用备份配置。 Jenkins需要磁盘空间来执行构建，存储数据日志和保存存档。要保持Jenkins的正常运行，请确保为Jenkins保留10％或更多的磁盘空间，以防止出现碎片。 Jenkins 2.0版本提供了代码管道，新的安装体验和一些UI改进。用它。（您可以在文章末尾添加“管道作为代码”链接找到更多相关信息）。 Jenkins Pipeline插件的最佳实践： 不要使用像Build Pipeline插件或Buildflow插件这样的旧插件。相反，使用真正的Jenkins Pipeline插件套件。 将您的管道开发为代码。使用该功能将Jenkins文件存储在SCM中然后版本中，并像测试其他软件一样进行测试。 管道中的任何非设置工作都应在阶段块中进行。 Pipeline提供了一种简单的语法，用于将管道分支为并行步骤。用它！ Pipeline有一个简单的机制来超时管道的任何给定步骤。作为最佳实践，您应该始终计划输入周围的超时。 使用env全局变量设置环境变量。 有用的资源 Jenkins官方网站 包含片段，提示和技巧的存储库以及Jenkins管道插件的脚本示例 Jenkins Pipeline 入门 管道语法 Jenkins简介2 管道作为代码 处理Jenkins管道中的合并请求 Jenkins的声明性管道 实用的持续部署","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}],"tags":[{"name":"Pipeline","slug":"Pipeline","permalink":"http://blog.ozairs.com/tags/Pipeline/"}],"keywords":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}]},{"title":"使用凭据文件向AWS进行身份验证","slug":"使用凭据文件向AWS进行身份验证","date":"2019-03-29T03:44:36.000Z","updated":"2019-03-29T03:45:28.772Z","comments":true,"path":"AWS/使用凭据文件向AWS进行身份验证/","link":"","permalink":"http://blog.ozairs.com/AWS/使用凭据文件向AWS进行身份验证/","excerpt":"","text":"这是在命令行上对AWS进行身份验证的综合指南的第1部分。在本系列的介绍中，我们介绍了AWS身份验证的基础知识，包括IAM用户，IAM角色和访问密钥。在这篇文章中，我们将介绍在命令行上对AWS进行身份验证的第一个选项：凭据文件。 基本用法您可以将AWS Access密钥存储在（或在Windows上）的凭据文件中。通常，您创建此文件的方式是安装AWS CLI并运行命令：~/.aws/credentials`%UserProfile%.aws\\credentialsaws configure` 12345$ aws configure AWS Access密钥ID：AKIAIOSFODNN7EXAMPLE AWS秘密访问密钥：wJalrXUtnFEMI / K7MDENG / bPxRfiCYEXAMPLEKEY 默认区域名称[无]：us-west-2 默认输出格式[无]：json AWS会提示您输入您的访问密钥ID和秘密访问密钥，并将其存储在~/.aws/credentials： 123[默认] aws_access_key_id = AKIAIOSFODNN7EXAMPLE aws_secret_access_key = wJalrXUtnFEMI / K7MDENG / bPxRfiCYEXAMPLEKEY 它还存储您输入的其他设置~/.aws/config： 123[default] region = us-west-2 output = json 存在这些文件后，您可以运行与AWS通信的任何CLI或SDK工具，它将自动查找并使用此凭据文件和设置。 使用多组访问密钥如果您有多组访问密钥（例如，对于不同AWS账户中的多个IAM用户），您可以在凭证文件中为每个用户创建单独的命名配置 文件~/.aws/credentials： 123456[默认] aws_access_key_id = AKIAIOSFODNN7EXAMPLE aws_secret_access_key = wJalrXUtnFEMI / K7MDENG / bPxRfiCYEXAMPLEKEY[user2] aws_access_key_id = AKIAI44QH8DHBEXAMPLE aws_secret_access_key = je7MtGbClwBF / 2Zp9Utk / h3yCo8nvbEXAMPLEKEY 同样，您可以在配置文件中拥有多个命名配置文件~/.aws/config： 123456[default] region = us-west-2 output = json[profile user2] region = us-east-1 output = text 请注意，default默认情况下，您可能会使用所调用的命名配置文件。要告诉CLI工具使用除default配置文件之外的其他内容，您必须执行以下操作之一： 设置AWS_PROFILE环境变量。例如，在Linux中，你会运行export AWS_PROFILE=user2。之后，您可以运行任何AWS CLI工具（例如terraform apply），它应该使用您的命名配置文件。 某些工具允许您将配置文件指定为命令行参数或代码中的参数。例如，awsCLI允许您指定--profile：aws ec2 describe-instances --profile user2。在Terraform中，您可以profile在provider块中设置参数： 123提供者“aws”&#123; profile =“user2” &#125; 使用IAM角色如果您想假设IAM角色 - 例如，您在security帐户中有一个IAM用户并想在您的dev帐户中承担IAM角色- 您有两个选择。第一个选项取决于您正在使用的CLI工具。某些CLI工具允许您通过命令行参数或代码指定要承担的IAM角色。例如，使用Terraform，您可以assume_role在provider配置中指定设置： 12345provider“aws”&#123; assume_role &#123; role_arn =“arn：aws：iam :: 123456789012：role / dev-full-access” &#125; &#125; 第二个选项是role_arn在Config File中指定参数~/.aws/config： 12[profile dev-full-access] role_arn = arn：aws：iam :: 123456789012：role / dev-full-access 使用任一选项，您指定的值role_arn是开发帐户中IAM角色的Amazon资源名称（ARN），其格式为： 1ARN：AWS：IAM :: &lt;ACCOUNT_ID&gt;：角色/ &lt;ROLE_NAME&gt; 下次运行使用dev-full-access命名配置文件的任何CLI命令时，AWS SDK将自动采用指定的IAM角色role_arn。 与MFA合作如果您正在使用awsCLI，则使用带有凭据配置文件的MFA非常简单。您只需将其添加mfa_serial到您的配置文件中~/.aws/config： 12[profile with-mfa] mfa_serial = arn：aws：iam :: 123456789012：mfa / jon-doe 该mfa_serial参数应设置为MFA设备的ARN，您可以从AWS Web Console 的IAM用户页面获取该ARN 。它应该是这样的格式： 1ARN：AWS：IAM :: &lt;ACCOUNT_ID&gt;：MFA / &lt;USERNAME&gt; 添加mfa_serial参数后，下次aws使用该命名配置文件运行CLI时，它将提示您输入MFA令牌： 12$ aws s3 ls --profile with-mfa输入MFA代码： 但是如果你运行的东西不是aws，比如terraform或者packer怎么办？在这种情况下，事情变得有点毛茸茸，因为大多数其他工具不会自动提示您输入MFA令牌。相反，您必须在该工具之外执行MFA身份验证过程，这是一个单调乏味的过程。 首先，使用普通（永久）AWS Access Keys配置凭证文件（例如，通过运行aws configure）。接下来，您运行该aws sts get-session-token命令，将其传递给您的MFA设备的ARN以及来自Google身份验证器应用程序或您的密钥卡的MFA令牌： 1234aws sts get-session-token \\ --serial-number arn：aws：iam :: 123456789012：mfa / jon-doe \\ --token-code 123456 \\ --duration-seconds 43200 这将返回一个包含临时访问密钥的JSON blob （请注意--duration-seconds前面命令中的参数，该参数指定这些临时访问密钥何时到期）： 12345678&#123; “Credentials”：&#123; “SecretAccessKey”：“secret-access-key”， “SessionToken”：“temporary-session-token”， “Expiration”：“expiration-date-time”， “AccessKeyId”：“access-key -id“ &#125; &#125; 您需要获取这些临时访问密钥并将其复制到凭证文件中的命名配置文件中~/.aws/credentials： 1234[with-mfa] aws_access_key_id = &lt;Access-key-as-in-returned-output&gt; aws_secret_access_key = &lt;Secret-access-key-as-in-returned-output&gt; aws_session_token = &lt;Session-Token-as-in-returned-输出&gt; 需要注意的是临时接入键，可以设置不仅aws_access_key_id和aws_secret_access_key你的证书文件，同时也aws_session_token。 现在，您可以使用此命名配置文件运行其他CLI工具： 12导出AWS_PROFILE = with-mfa terraform apply 请注意，临时访问密钥在一段时间（通常为12小时）后过期，因此您必须反复执行此操作。不好玩。 优点和缺点优点 基本身份验证很容易。 使用IAM角色很容易。 命名配置文件可以轻松管理多组凭据和设置。 缺点 您的访问密钥以明文形式存储在磁盘上。这不安全。 您始终使用永久访问密钥进行身份验证，而不是使用已轮换的临时访问密钥。 使用MFA很复杂且容易出错。 您的凭据永远位于磁盘上，如果您忘记指定其他命令，则默认的命名配置文件将用于所有命令，这很容易出错。 在您的代码中指定命名配置文件（例如，在您的Terraform代码中）很有诱惑力，以确保使用正确的凭据，但这需要您的所有团队成员为您的命名配置文件使用相同的名称，这可能很难强制执行。 结论尽管许多AWS教程都使用凭证文件，但我们通常建议不要使用凭证文件，因为以明文形式将永久AWS凭证存储在磁盘上并不安全。更糟糕的是，使用凭据文件时，MFA的使用非常复杂，大多数用户都不会为此烦恼。","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"Credential","slug":"Credential","permalink":"http://blog.ozairs.com/tags/Credential/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"【DevOps进阶之路Day1】精通Jenkins Pipeline PartI","slug":"精通Jenkins-Pipeline-PartI","date":"2019-03-28T11:48:43.000Z","updated":"2019-03-28T12:00:08.126Z","comments":true,"path":"Jenkins/精通Jenkins-Pipeline-PartI/","link":"","permalink":"http://blog.ozairs.com/Jenkins/精通Jenkins-Pipeline-PartI/","excerpt":"","text":"前言 詹金斯 使用过水电工Travis-CI的朋友们，应该很多都试过翘胡子Jenkins。不过笔者猜应该大多数的朋友都是使用Jenkins的自由风格项目。 虽然Free Style项目可以让你客制化任何的Shell Script来执行你想要的脚本进行测试，但其脚本会依赖Jenkins节点上的环境来执行，Jenkins节点上的任何环境改变都可能影响到你的build job的状况，譬如说，系统套件的升级，工具路径的修改，不同的Job间互相的影响…等等。 此时，最好的做法是将每个Build Job都用VM或Container做隔离，确保每次执行建置的工作环境都是一样的。 Travis CI的做法是，为了避免给个建筑互相影响，会为每一个建置都开一台全新的GCE Instance，即使你的测试是在Container mode下执行，都会是全新的VM环境。 然而Travis CI采用YAML格式的设定档格式，这种做法虽然容易使用，但伴随而来的缺点就是动态性不足，你无法轻易的将某个Step产生出来的结果，做出一些逻辑判断，然后再把不同的操作逻辑丢到另外一台机器上平行执行。 在Jenkins上的选择相对得多，为了解决日渐庞大复杂的Build Flow，2016年四月Jenkins释出了Pipeline plugin，提供所谓的流水线建设功能来让建设工作变得容易扩大。而这个Pipeline Plugin是基于一种语言 - Apache Groovy开发的。 这系列文章不是要教读者一步一步如何使用Jenkins Pipeline，而是跟读者们解释Jenkins Pipeline的底层机制，在开发时，可以避免去踩到这些相关（你以为可以，但却不行）的陷阱。 Apache Groovy可能很多人对Apache Groovy很陌生，Apache Groovy是一位名叫James Strachan的Java开发者于2003年开发出的一套Java语法相容的新语言，在当时纳入了如Ruby，Perl，Python，Smalltalk ，功能语言等语言的特性，可以被静态编译，也可以被动态执行.Groovy可被编译为JVM字节码在JVM上执行，除此之外，Groovy也可使用Java原生套件，你可以一部分用Java写，一部分使用Groovy去调用Java的类。 在Groovy里的Closure也可以像函数式语言一样，使用Curry（部分申请）。 2007年约为Rails火红的年代，Groovy的设计在JAX 2007得到创新奖，2008年时的Grails（Groovy web framework）也在JAX 2008年得到创新奖。 后来设计Groovy和Grails的这家公司G2One被SpringSource收购，而2009年时VMware又收购了SpringSource。 一直谈Groovy的背景，可能很多人还是很难想像Groovy的程式码长什么样子，我们就来看几个范例： 很像Java的范例： 123456class AGroovyBean &#123; String color &#125; def bean = new AGroovyBean（）; bean.color =“baby blue” bean.setColor（“baby blue”） 很像Ruby + Perl的范例： 1//相当于：取（2.pills）.of（氯喹）。之后（6.hours）6小时后服用2.pill的氯喹 同Perl与Ruby，在Groovy里面的函数调用的圆括号是可以省略的，Closure也有多种写法： 123def run = &#123;println it&#125; def run = &#123; - &gt; println it&#125; def run = &#123;a - &gt; println a&#125; 上面三种写法都是一样的。 此外Groovy本身针对DSL提供一些特别的语言功能，让你可以写出： 123withDocker（“mysql：5.7”）&#123; sh“....” &#125; 像上面这样的程式码，他在Pipeline里实际上的语意与下列程式码相同： 123this.withDocker（“mysql：5.7”，&#123; - &gt; this.sh（“...”）&#125;） 管道DSL回到Jenkins Pipeline，为什么Jenkins管道使用Groovy设计呢？主要是因为整个Jenkins生态系都是使用Java开发而成，而Java却不适合拿来设计Build Job的DSL（Domain Specific Language），Groovy既相容Java ，JVM就被Jenkins作者拿来设计Pipeline Plugin了。 编程语言有了DSL的强大功能，你就可以使用这样简化的语法，针对你的Build Pipeline写出一个以程序语言为基础的设定档案。 譬如： 123节点（“ec2”）&#123; sh“echo Hello World” &#125; 上面的范例就是一个最简单的Scripted Pipeline，纯Groovy的写法，意思是找到一台label为ec2的机器，然后在这台机器上面执行shell命令：“echo Hello World”。 这边要稍微说明一下，Jenkins Pipeline的语法分为两种，Scripted Pipeline与Declarative Pipeline。 这两种语法官方网站上并没有详细解释底层机制的不同，由笔者解释的话，Scripted Pipeline就是原生的Groovy Script，会在Jenkins里面的Groovy Shell执行。 而Declarative Pipeline相对复杂一些，pipeline这个关键字在Jenkinsfile里面是一个步骤（实际上是方法），这个步骤（方法）会将后面整个封闭的代码，对…就是程式码，带入到Pipeline Model Plugin的核心，用一套Groovy写成的Pipeline Model Parser来重新剖析程式码，转为AST后，再经过Groovy的AST Transformer来重新建构整个Pipeline的逻辑。 也因此你常用的Declarative Pipeline里面，pipeline { }所包起来的部分并不是纯Groovy Syntax，他利用客制化的剖析器（Parser）来达成一些语意上的限制。 Jenkinsfile在Groovy里面，万物皆为类，既使是脚本文件，也都被无形的类包装起来。 举例来说，你开一个纯文字档案叫test.groovy，然后在里面写入一段代码： 1println this.getClass（） 结果会印出： 1班级考试 发现什么了吗？也就是说，当Jenkins在执行你的Jenkinsfile的时候，你在Jenkinsfile里就是在类的某个方法里面执行，而你的档案名称就变成你的类名。怎么证明呢？ 如果你尝试把Call Stack dump出来会看到什么呢？ 12StackTraceElement [] cause = Thread.currentThread（）。getStackTrace（）; 打印原因 结果是： 注意到上面，，test.run其实意味着我们脚本里面写的程式码，是被包装在一个叫做run的方法里面执行的。 Groovy会编译你的程式码，转换为一个继承groovy.lang.Script的类别，这个类别包含了一个抽象化的方法（方法）叫做run。 当这个脚本被编译时，脚本体会变成这个运行方法的一部分，而其他的方法定义会转为这个类实现的一部分。 这个Stack Call往上追，你会看到GroovyShell.run，这是什么东西呢？ GroovyShell 提供了一个介面，让你可以在Groovy里面动态建立一个执行环境，然后在这个沙盒里面执行程式。 123456def binding = new Binding（） def shell = new GroovyShell（binding）binding.setVariable（ &apos;x&apos;，1） binding.setVariable（&apos;y&apos;，3）shell.evaluate&apos;z = 2 * x + y&apos;assert binding。 getVariable（&apos;z&apos;）== 5 Binding就是用来连结目前的执行环境与沙盒执行环境的类别，而Jenkins就是利用Binding来将Jenkins的环境资讯注入到Jenkinsfile执行的。 而这个脚本基类可以被客制化，DSL的设计师可以将这个基类改为自己特制的类来提供一些特别功能。 举例来说： 1234DEF配置=新CompilerConfiguration（）config.scriptBaseClass = &apos;MyBaseClass&apos;高清壳=新GroovyShell（this.class.classLoader，配置）shell.evaluate “” “ 的setName &apos;朱迪思&apos; 迎接（） ”“” 而你可以实作一个类叫做MyBaseClass来来提供setName与greet方法： 123456抽象类MyBaseClass扩展Script &#123; String name public void greet（）&#123; println“Hello，$ name！” &#125; &#125; 到这边我想读者已经很清楚了，为什么Jenkinsfile里面会有sh，pipeline，echo这些特有的函数可以用？ 其实，你当使用pipeline {}的时候，他实际上就是等于： 12this.pipeline（&#123; - &gt; &#125;） 今天的Jenkins实作细节就先到这边，下集待续。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}],"tags":[{"name":"Pipeline","slug":"Pipeline","permalink":"http://blog.ozairs.com/tags/Pipeline/"}],"keywords":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}]},{"title":"如何遵循尽职调查法，做更多有效的工作","slug":"如何遵循尽职调查法，做更多有效的工作","date":"2019-03-26T02:56:31.000Z","updated":"2019-03-26T03:09:34.360Z","comments":true,"path":"评论/如何遵循尽职调查法，做更多有效的工作/","link":"","permalink":"http://blog.ozairs.com/评论/如何遵循尽职调查法，做更多有效的工作/","excerpt":"","text":"【译文】 ç什么容易谈到apitalizing是人们如何成功往往会获得成功。它也是成功故事的一部分，经常被遗漏，因为如果没有被误解，几乎不可能谈论它。 成功的人不努力工作（这个词，“难”，有错误的含义）。成功人士不会继续向死胡同努力。他们也不会强迫什么是不可行的，无效的，或者根本就是不锻炼。他们在看到最多结果的地方一直工作，他们能够经常工作的原因 - 通常比同龄人更多 - 是因为工作对他们来说有点自然。如果没有，他们就会筋疲力尽，被烧毁，而且结果很少。 传统智慧告诉你不要放弃，无论如何。但人们总是告诉你，当你停止努力让事情发生时，好事往往会发生。最受欢迎的关系建议是，当我们停止寻找他们时，我们的合作伙伴会出现。对于许多夫妻来说，他们想要怀孕的那一刻就是他们怀孕的那一刻。 当你试图强迫幸福时，它就会让你失望。如果不这样做，它往往会自行发生。你最终在生活中所做的工作几乎从来都不是A计划; 这是计划B，当你放弃那些不自然的事情时，你就开始做了。当你试着不去思考像白象这样的东西时 - 你可以专注于它。你试图避免的东西越多，你到处都看得越多。你试图抓住充满干燥沙子的拳头越多，它越快滑过你的手指。 有些事情是我们无法控制的，它们会将我们重新定向到比我们最初为自己选择的结果更大的结果。 人们通常不希望将他们在生活中的成功归因于机会，命运或预先存在的条件，因为当然，这些并不是唯一的因素。但是，根本不承认它们是剥夺他人的重要见解。成功不仅仅是因为很多人努力工作而使某人“努力”。你可以说服务行业的人比拥有他们工作的机构的人工作更加困难。他们看到不同的结果，因为他们的能量是针对不同的事情。当我们不得不强迫自己去做时，工作变得艰难，当它本身无趣或没有吸引力时，我们必须强迫自己。 当我们承诺做一些我们倾向于擅长或有自然兴趣的事情时，我们会立即开始一个快速加强的反馈循环。当我们付出努力并立即获得积极成果时，我们的能量得到加强。当我们看到结果并且相信那些结果时，我们会变得纪律严明。出于这个原因，有些人认为我们最喜欢的东西往往只是我们擅长的东西。 当您忘记时间并完全沉浸在任务中时，“ 心流”就是最佳性能状态。这通常是我们生产出我们生活中最好的作品，而那些每天都能做到的人往往会为自己的长期成功做出令人难以置信的成功。但自然实现心流状态几乎是不可能的，你必须强迫自己去做。 任何成功的人都会告诉你 - 尽管他们确实做了很多工作 - 但几乎总是有一些无助的元素在起作用。这项工作是学习如何出现，脱离自己的头脑，让它发生，而不会让你产生怀疑和焦虑。 牛逼最省力的他律是比生产力黑客更多。这不是一个快速，简单的成功计划。这是我们生活中不变的，经常令人沮丧的一部分。这是我们的自然法则如何治理的一个要素，它在某种程度上是一种比我们更大的力量，一种我们想要理解并对我们有利的工作。 大自然遵循蓝图。当我们不干扰治疗时，我们的身体会自愈。我们的生活往往以同样的方式运作。当我们谈论生活中“无法控制”的东西时，它几乎总是消极的，如票据或损失或疾病。但它也是相反的。有些事情是我们无法控制的，它们会将我们重新定向到比我们最初为自己选择的结果更大的结果。 我们每个人都有一套完全独特的优点和缺点，好奇心，激情，沮丧和伤口。这些交叉往往是我们生活中最肥沃的繁殖地。我们经常回顾并且可以看到这些看似随机的因素中的每一个都在我们最终结束的地方发挥了作用。它们不是随机的; 他们绘制了我们根本上是谁的蓝图。 您需要清楚地了解最终目标，然后将其分解为更小的步骤。这不是魔术。这就是我们取得进步的方式。 我们的选择是我们是否激活了潜在的潜力。我们的身体和生活就像能量系统。当我们用压力阻塞他们时，他们开始出现故障。这就像我们心灵河底的一个错误 - 水仍然在顶部涟漪。我们需要清楚地了解我们的最终目标，然后将其分解为更小的步骤。这不是魔术。这就是我们取得进步的方式。 但是，以一种破坏和窘迫的方式强迫事情会让他们失望。想要的东西让你处于没有它的能量之中。过度依赖于结果会使你如此着迷于完美和你自己的时间，最终破坏真正重要的东西，这是最终的结果。我们怀念成功不是世界给予我们的事实; 这是我们为世界提供的东西，然后从中获益。 成功始于我们。我们的兴趣，技能和激情; 我们的创伤和不满; 我们肩膀上的筹码和心中的梦想都不是随意的。它们交叉的地方是我们的呼唤，它对我们每个人来说都是完全独特的。我们不必强迫它。我们没有必要竞争它。我们只需要回应它，开始向它展示，然后，像我们手掌中的沙子，学会放松我们的抓地力，并让它成为现实。 【原文】 Capitalizing on what comes easily is how successful people tend to get ahead. It’s also part of the success story that’s often left out because it’s almost impossible to talk about without it becoming misconstrued. Successful people don’t work hard (that word, “hard,” has the wrong connotation). Successful people don’t keep throwing effort at dead ends. They also don’t force what’s nonviable, ineffective, or just simply not working out. They work consistently where they see the most results, and the reason they are able to work so often—usually much more than their peers—is because the work comes somewhat naturally to them. If it didn’t, they’d be exhausted, burned out, and left with minimal results. Conventional wisdom tells you not to give up—ever, no matter what. But people tell you all the time that good things tend to happen when you stop trying so hard to make them happen. The most popular relationship advice is that our partners will show up when we stop looking for them. For many couples, the moment they stop trying to get pregnant is the moment they conceive. When you try to force happiness, it eludes you. If you don’t, it tends to happen on its own. The work you end up doing in your life is almost never Plan A; it’s Plan B, which is what you started doing when you gave up on what didn’t come naturally. When you try not to think about something—like a white elephant—it’s all you can focus on. The more you try to avoid something, the more you see it everywhere. The more you try to grip a fist full of dry sand, the faster it slips through your fingers. There are things out of our control that sort of redirect us to outcomes greater than we would have initially chosen for ourselves. People generally don’t want to misattribute their successes in life to chance, fate, or pre-existing conditions because, of course, those aren’t the only factors at play. But to not acknowledge them at all is to deprive others of vital insight. Success is more than just how “hard” someone works because a lot of people work hard. You could argue that people in the service industry work a whole lot harder than the people who own the establishment they’re working in. They see different results because their energy is directed toward different things. Work becomes hard when we have to force ourselves to do it, and we have to force ourselves when it’s inherently uninteresting or unappealing. When we commit to doing something we are inclined to be good at or have a natural interest in, we start an immediate feedback loop that strengthens quickly. When we put effort toward something and immediately receive positive results, our energy is reinforced. We become disciplined when we see results and when we trust those results. For this very reason, some people suggest that the things we enjoy most are often just the things we are good at. “Flow” is that peak performance state when you lose track of time and become fully immersed in your task. This is often when we produce the best work of our lives, and those who can do it every day often position themselves for incredible long-term success. But it’s almost impossible to achieve a flow state doing something you have to force yourself to do. Any successful person will tell you that—although they have certainly worked a lot—there is almost always an element of effortlessness at play. The work is learning how to show up, get out of your own head, and allow it to happen without your doubts and anxieties stopping you. The law of least effort is more than a productivity hack. It’s not a quick, easy success scheme. It’s a constant, often frustrating, part of our lives. It’s an element of how our natural laws are governed, and it’s in some ways a force greater than we are, one that we want to understand and have work in our favor. Nature follows a blueprint. Our bodies heal themselves when we don’t interfere with the healing. Our lives tend to function the same way. When we talk about what we “can’t control” in life, it’s almost always negative—like bills or loss or illness. But it works the opposite way too. There are things out of our control that sort of redirect us to outcomes greater than we would have initially chosen for ourselves. Within each of us is a completely unique set of strengths and weaknesses, curiosities, passions, distastes, and wounds. Where these intersect tends to be the most fertile breeding ground of our lives. We often look back and can see that each of these seemingly random factors played a role in where we ultimately ended up. They weren’t random; they mapped a blueprint of who we fundamentally are. You need to clearly understand the end goal and then break it down into smaller steps. This isn’t magic. This is how we make progress. Our choice is whether we activate the latent potential. Our bodies and our lives are like energy systems. When we clog them with stress, they start to malfunction. It’s like a fault at the bottom of the river of our psyches—the water still ripples at the top. We need to clearly understand our end goals and then break them down into smaller steps. This isn’t magic. This is how we make progress. But forcing things in a way that wreaks havoc and distress holds them back. Wanting something puts you in the energy of not having it. Being overly attached to an outcome makes you so obsessed with perfection and your own timing that you end up sabotaging what really matters, which is the end result. We miss the fact that success is not something the world gives us; it’s something we offer the world and then reap the benefits of doing so. Success starts with us. Our interests, skills, and passions; our trauma and our grievances; the chips on our shoulders and the dreams in our hearts are not random. The place where they intersect is our calling, and it is wholly and completely unique to each of us. We don’t have to force it. We don’t have to compete for it. We simply have to respond to it, start showing up to it, and then, like the sand in our palms, learn to loosen our grip, and allow it to be.","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"励志","slug":"励志","permalink":"http://blog.ozairs.com/tags/励志/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"Jenkins自动化部署","slug":"Jenkins自动化部署","date":"2019-03-25T10:13:57.000Z","updated":"2019-03-25T11:48:37.525Z","comments":true,"path":"Jenkins/Jenkins自动化部署/","link":"","permalink":"http://blog.ozairs.com/Jenkins/Jenkins自动化部署/","excerpt":"","text":"一、 Pipeline平台部署 jenkins + pipeline构建自动化部署 https://www.cnblogs.com/shenh/p/8963688.html Jenkins pipeline脚本编写实践分享（一）上篇 Jenkins pipeline脚本编写实践分享（二） jenkins学习之pipeline Jenkins持续集成 - 管道详解","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/tags/Jenkins/"}],"keywords":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}]},{"title":"Chef入门与实战","slug":"Chef入门与实战","date":"2019-03-24T06:51:16.000Z","updated":"2019-03-24T07:21:08.792Z","comments":true,"path":"DevOps/Chef入门与实战/","link":"","permalink":"http://blog.ozairs.com/DevOps/Chef入门与实战/","excerpt":"","text":"一、Chef 专用名词1. package 2. service 3. file ​ 二、Chef命令汇总 执行Recipe： chef-client –local-mode hello.rb 创建Cookbook： chef generate cookbook cookbookname 创建Recipe： chef generate recipe cookbook/apacher server","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Chef","slug":"Chef","permalink":"http://blog.ozairs.com/tags/Chef/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"Docker 实战应用","slug":"Docker-实战应用","date":"2019-03-23T08:39:20.000Z","updated":"2019-03-25T11:49:30.368Z","comments":true,"path":"Docker/Docker-实战应用/","link":"","permalink":"http://blog.ozairs.com/Docker/Docker-实战应用/","excerpt":"","text":"一、Docker平台部署Amazon ECS 的 Docker 基本知识 https://docs.aws.amazon.com/zh_cn/AmazonECS/latest/developerguide/docker-basics.html#install_docker 二、ECS中Dokcer的配置 Environment设置Entry Point sh, -c, while true; do echo $(date)&gt; /shared-data/index_html; sleep 5; done 使用 Amazon ECS CLI 创建包含 Fargate 任务的集群 教程：CodePipeline 持续部署 三、使用Jenkins配合Github hook持续集成 使用Jenkins配合Github hook持续集成 使用Jenkins和Amazon ECS设置构建管道 如何使用AWS CodePipeline，AWS CodeBuild与AWS CloudFormation实现Amazon ECS上的持续集成持续部署解决方案 Docker使用jenkins部署java项目到远程linux jenkins+docker+git构建java自动化部署","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"AWS 实战部署","slug":"AWS-实战部署","date":"2019-03-22T11:30:34.000Z","updated":"2019-03-22T11:33:28.244Z","comments":true,"path":"AWS/AWS-实战部署/","link":"","permalink":"http://blog.ozairs.com/AWS/AWS-实战部署/","excerpt":"","text":"如果您已注册 Amazon Web Services (AWS) 并已在使用 Amazon Elastic Compute Cloud (Amazon EC2)，您与使用 Amazon ECS 已近在咫尺。这两个服务的设置过程相似。以下指南将帮助您做好使用 Amazon ECS 首次运行向导或 Amazon ECS 命令行界面 (CLI) 启动首个集群的准备。 注意 因为 Amazon ECS 使用 Amazon EC2 的许多组件，所以，您可以将 Amazon EC2 控制台用于这些步骤中的许多步骤。 要开始设置 Amazon ECS，请完成以下任务。如果您已完成以下任何步骤，可以将其跳过并继续安装自定义 AWS CLI。 注册 AWS 创建 IAM 用户 创建 IAM 角色 创建密钥对 创建 Virtual Private Cloud 创建安全组 安装 AWS CLI 注册 AWS当您注册 AWS 时，您的 AWS 账户会自动注册所有服务，包括 Amazon EC2 和 Amazon ECS。您只需为使用的服务付费。 如果您已有 AWS 账户，请跳到下一个任务。如果您还没有 AWS 账户，请使用以下步骤创建。 创建 AWS 账户 打开 https://aws.amazon.com/，然后选择 Create an AWS Account (创建 AWS 账户)。 注意 如果您之前曾使用 AWS 账户根用户 凭证登录 AWS 管理控制台，请选择 Sign in to a different account (登录其他账户)。如果您之前曾使用 IAM 凭证登录控制台，请选择 Sign-in using root account credentials (使用根账户凭证登录)。然后选择 Create a new AWS account (创建新的 AWS 账户)。 按照联机说明操作。 在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。 请记下您的 AWS 账号，因为在下一个任务中您会用到它。 创建 IAM 用户AWS 中的服务（如 Amazon EC2 和 Amazon ECS）要求您在访问时提供凭证，以便服务可以确定您是否有权限访问其资源。控制台要求您的密码。您可以为您的 AWS 账户创建访问密钥以访问命令行界面或 API。但是，我们不建议您使用 AWS 账户的凭证访问 AWS，而建议您改用 AWS Identity and Access Management (IAM)。创建 IAM 用户，然后将该用户添加到具有管理权限的 IAM 组或授予此用户管理权限。然后，您就可以使用专门的 URL 和该 IAM 用户的凭证来访问 AWS。 如果您已注册 AWS 但尚未为自己创建一个 IAM 用户，则可以使用 IAM 控制台自行创建。 为您自己创建一个 IAM 用户并将该用户添加到管理员组 使用 AWS 账户电子邮件地址和密码，以 AWS 账户根用户 身份登录到 IAM 控制台 (https://console.aws.amazon.com/iam/)。 注意 强烈建议您遵守以下使用 Administrator IAM 用户的最佳实践，妥善保存根用户凭证。只在执行少数账户和服务管理任务时才作为根用户登录。 在控制台的导航窗格中，选择 Users (用户)，然后选择 Add user (添加用户)。 对于 User name (用户名)，键入 Administrator。 选中 AWS 管理控制台 access (AWS 管理控制台访问) 旁边的复选框，选择 Custom password (自定义密码)，然后在文本框中键入新用户的密码。您可以选择 Require password reset (需要重置密码) 以强制用户在下次登录时创建新密码。 选择下一步: 权限。 在设置权限页面上，选择将用户添加到组。 选择 Create group。 在 Create group (创建组) 对话框中，对于 Group name (组名称)，键入 Administrators。 对于 Filter policies (筛选策略)，选中 AWS managed - job function (AWS 托管 - 工作职能) 的复选框。 在策略列表中，选中 AdministratorAccess 的复选框。然后选择 Create group。 返回到组列表中，选中您的新组所对应的复选框。如有必要，选择 Refresh 以在列表中查看该组。 选择 Next: Tags (下一步: 标签) 通过以键值对的形式附加标签来向用户添加元数据。 选择 Next: Review 以查看要添加到新用户的组成员资格的列表。如果您已准备好继续，请选择 Create user。 您可使用此相同的流程创建更多的组和用户，并允许您的用户访问 AWS 账户资源。要了解有关使用策略限制用户对特定 AWS 资源的权限的信息，请参阅访问管理和示例策略。 要以该新 IAM 用户的身份登录，请从 AWS 控制台注销，然后使用以下 URL，其中 your_aws_account_id 是您不带连字符的 AWS 账号（例如，如果您的 AWS 账号是 1234-5678-9012，则您的 AWS 账户 ID 是 123456789012）： 1https://your_aws_account_id.signin.aws.amazon.com/console/ 输入您刚创建的 IAM 用户名和密码。登录后，导航栏显示 your_user_name @ your_aws_account_id。 如果您不希望您的登录页面 URL 包含 AWS 账户 ID，可以创建账户别名。从 IAM 控制面板中，选择 Create Account Alias (创建账户别名)，然后输入一个别名，例如您的公司名称。要在创建账户别名后登录，请使用以下 URL： 1https://your_account_alias.signin.aws.amazon.com/console/ 要为您的账户验证 IAM 用户的登录链接，请打开 IAM 控制台并在控制面板的 IAM users sign-in link (IAM 用户登录链接) 下进行检查。 有关 IAM 的更多信息，请参阅 AWS Identity and Access Management 用户指南。 创建 IAM 角色在 Amazon ECS 容器代理可以代表您调用 Amazon ECS API 操作之前，它需要服务的 IAM 策略和角色，以便了解属于您的代理。 对于使用 EC2 启动类型的任务，您可以创建一个 IAM 角色，该角色可让代理知道应向哪个账户注册容器实例。当您使用 Amazon 通过此角色提供的经 Amazon ECS 优化的 AMI 启动容器实例时，代理会自动将容器实例注册到 default 集群中。此角色称为 Amazon ECS 容器实例 IAM 角色。有关更多信息，请参阅Amazon ECS 容器实例 IAM 角色。 Amazon ECS 容器代理还会代表您调用 Amazon EC2 和 Elastic Load Balancing API，以便在负载均衡器中注册和取消注册容器实例。您必须在启动服务前为其创建一个 IAM 角色，然后才能将负载均衡器附加到 Amazon ECS 服务。此要求适用于您计划用于负载均衡器的任意 Amazon ECS 服务。此角色称为 Amazon ECS 服务计划程序 IAM 角色。有关更多信息，请参阅 Amazon ECS 服务计划程序 IAM 角色。 对于使用 Fargate 启动类型的任务，您可以创建一个 IAM 角色，该角色允许代理从 Amazon ECR 中提取容器映像或者使用 awslogs 日志驱动程序，该驱动程序是当前唯一受支持的此启动类型的日志记录选项。此角色称为 Amazon ECS 任务执行 IAM 角色。有关更多信息，请参阅 Amazon ECS 任务执行 IAM 角色。 注意 在 Amazon ECS 控制台首次运行体验中，将自动为您创建这些 IAM 角色，因此，如果您打算使用控制台，则可以继续下一个部分。如果您不打算使用控制台，而是计划使用 AWS CLI，则需要手动创建这些 IAM 角色。 创建密钥对对于 Amazon ECS，密钥对只有在您打算使用 EC2 启动类型时才需要。 AWS 使用公有密钥密码术来保护实例的登录信息。 Linux 实例（例如 Amazon ECS 容器实例）没有用于 SSH 访问的密码。您使用密钥对安全地登录到实例。您可以在启动容器实例时指定密钥对的名称，然后提供私有密钥（使用 SSH 登录时）。 如果您尚未创建密钥对，则可以通过 Amazon EC2 控制台自行创建。如果您计划在多个区域启动实例，则需要在每个区域中创建密钥对。有关区域的更多信息，请参阅 Amazon EC2 用户指南（适用于 Linux 实例） 中的区域和可用区。 创建密钥对 打开 Amazon EC2 控制台 https://console.aws.amazon.com/ec2/。 从导航栏中，选择密钥对所在的区域。您可以选择向您提供的任何区域，无需理会您身处的位置。但是，密钥对特定于区域。例如，如果您计划在美国东部（俄亥俄）区域中启动容器实例，则必须在美国东部（俄亥俄）区域中为实例创建密钥对。 在导航窗格中的 NETWORK &amp; SECURITY 下，选择 Key Pairs。 提示 导航窗格位于控制台的左侧。如果您看不到窗格，它可能被最小化了；请选择箭头展开该窗格。您可能必须向下滚动才能看到 Key Pairs 链接。 选择 Create Key Pair。 在 Create Key Pair 对话框的 Key pair name 字段中输入新密钥对的名称，然后选择 Create。使用一个容易记住的名称 (如您的 IAM 用户名) 后跟 -key-pair 加区域名称。例如，me-key-pair-useast2。 您的浏览器会自动下载私有密钥文件。基本文件名是您为密钥对指定的名称，文件扩展名为 .pem。将私有密钥文件保存在安全位置。 重要 这是您保存私有密钥文件的唯一机会。启动实例时，提供密钥对的名称；每次连接到实例时，提供相应的私有密钥。 如果您在 macOS 或 Linux 计算机上使用 SSH 客户端连接到您的 Linux 实例，请使用以下命令设置您私有密钥文件的权限，以确保只有您可以读取它。 1chmod 400 your_user_name-key-pair-region_name.pem 有关更多信息，请参阅 Amazon EC2 用户指南（适用于 Linux 实例） 中的 Amazon EC2 密钥对。 使用密钥对连接到实例 要从运行 macOS 或 Linux 的计算机连接到 Linux 实例，需要使用 -i 选项对 SSH 客户端指定 .pem 文件和私有密钥的路径。若要从运行 Windows 的计算机连接到 Linux 实例，可以使用 MindTerm 或 PuTTY。如果您计划使用 PuTTY，则需要安装它并遵循以下过程将 .pem 文件转换为 .ppk 文件。 （可选）准备使用 PuTTY 从 Windows 连接到 Linux 实例 从 http://www.chiark.greenend.org.uk/~sgtatham/putty/ 下载并安装 PuTTY。请务必安装整个套件。 启动 PuTTYgen（例如，在开始菜单中，依次单击所有程序 &gt; PuTTY &gt; PuTTYgen ）。 在 Type of key to generate 下，选择 RSA。 选择 Load。默认情况下，PuTTYgen 仅显示扩展名为 .ppk 的文件。要找到您的 .pem 文件，请选择显示所有类型的文件的选项。 选择您在上一个过程中创建的私有密钥文件，然后选择 Open。选择 OK 关闭确认对话框。 选择 Save private key (保存私有密钥)。PuTTYgen 会显示一条警告，提示将在未提供口令的情况下保存密钥。选择是。 为密钥指定密钥对所用的相同名称。PuTTY 会自动添加 .ppk 文件扩展名。 创建 Virtual Private CloudAmazon Virtual Private Cloud (Amazon VPC) 允许您在已定义的虚拟网络内启动 AWS 资源。强烈建议您在 VPC 中启动您的容器实例。 注意 Amazon ECS 控制台首次运行体验会为您的集群创建 VPC，因此，如果您打算使用 Amazon ECS 控制台，则可以跳到下一个部分。 如果您有默认 VPC，也可以跳过此部分并进入下一个任务，即 创建安全组。要确定您是否具有默认 VPC，请参阅 Amazon EC2 用户指南（适用于 Linux 实例） 中的 Amazon EC2 控制台中支持的平台。否则，您可以使用以下步骤在账户中创建非默认 VPC。 重要 如果您的账户在某个区域中支持 Amazon EC2 Classic，则您在该区域没有默认 VPC。 创建非默认 VPC 打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/。 从导航栏中，为 VPC 选择区域。VPC 特定于某一区域，因此您应选择已创建密钥对的区域。 在 VPC 控制面板上，选择 Launch VPC Wizard (启动 VPC 向导)。 在 Step 1: Select a VPC Configuration 页面上，确保选中 VPC with a Single Public Subnet，然后选择 Select。 在 Step 2: VPC with a Single Public Subnet (步骤 2: 带有单个公有子网的 VPC) 页面上，在 VPC name (VPC 名称) 字段中为您的 VPC 输入友好名称。保留其他默认配置设置，然后选择 Create VPC。在确认页面上，请选择 OK。 有关 Amazon VPC 的更多信息，请参阅 Amazon VPC 用户指南 中的 Amazon VPC 是什么？。 创建安全组安全组用作相关容器实例的防火墙，可在容器实例级别控制入站和出站流量。您可以向安全组添加规则，以便使用 SSH 从您的 IP 地址连接到容器实例。您还可以添加允许来自任意位置的入站和出站 HTTP 和 HTTPS 访问的规则。向任务所需的开放端口添加任意规则。容器实例需要外部网络访问来与 Amazon ECS 服务终端节点通信。 注意 Amazon ECS 控制台首次运行时会为您的实例创建安全组并根据您使用的任务定义创建负载均衡器，因此，如果要使用 Amazon ECS 控制台，则可以跳到下一个部分。 如果您计划在多个区域中启动容器实例，则需要在每个区域中创建安全组。有关更多信息，请参阅 Amazon EC2 用户指南（适用于 Linux 实例） 中的区域和可用区。 提示 您需要本地计算机的公有 IP 地址，可以使用服务获得该地址。例如，我们提供以下服务：http://checkip.amazonaws.com/ 或 https://checkip.amazonaws.com/。要查找另一项可提供您的 IP 地址的服务，请使用搜索短语“what is my IP address”。 如果您通过 Internet 服务提供商 (ISP) 连接或者在不使用静态 IP 地址的情况下从防火墙后面连接，则必须找出客户端计算机使用的 IP 地址范围。 为您的 VPC 创建具有最小特权的 打开 Amazon EC2 控制台 https://console.aws.amazon.com/ec2/。 从导航栏中选择安全组的区域。安全组特定于某一区域，因此您应选择已创建密钥对的区域。 在导航窗格中，选择 Security Groups，然后选择 Create Security Group。 输入新安全组的名称和描述。选择一个您容易记住的名称，例如 ecs-instances-default-cluster。 在 VPC 列表中，确保选择了您的默认 VPC。它标有星号 (*)。 注意 如果您的账户支持 Amazon EC2 Classic，请选择您在上一个任务中创建的 VPC。 Amazon ECS 容器实例不需要打开任何入站端口。但您可能需要添加 SSH 规则，以便登录容器实例并使用 Docker 命令检查任务。如果您希望容器实例托管运行 Web 服务器的任务，也可以添加适用于 HTTP 和 HTTPS 的规则。容器实例需要外部网络访问来与 Amazon ECS 服务终端节点通信。完成以下步骤可添加这些可选的安全组规则。 在 Inbound 选项卡上，创建以下规则 (为每个新规则选择 Add Rule)，然后选择 Create： 从 Type 列表中选择 HTTP，确保 Source 设置为 Anywhere (0.0.0.0/0)。 从 Type 列表中选择 HTTPS，确保 Source 设置为 Anywhere (0.0.0.0/0)。 从 Type 列表中选择 SSH。在 Source 字段中，确保选中 Custom IP，然后采用 CIDR 表示法指定您计算机或网络的公有 IP 地址。要采用 CIDR 表示法指定单个 IP 地址，请添加路由前缀 /32。例如，如果您的 IP 地址是 203.0.113.25，请指定 203.0.113.25/32。如果您的公司要分配同一范围内的地址，请指定整个范围，例如 203.0.113.0/24。 重要 出于安全原因，我们不建议您允许从所有 IP 地址 (0.0.0.0/0) 对您的实例进行 SSH 访问（以测试为目的的短暂访问除外）。 安装 AWS CLI可以在 AWS 管理控制台中手动管理 Amazon ECS 的所有操作。但是，您可以在本地桌面上安装 AWS CLI 或开发人员工具包并生成脚本，以便在 Amazon ECS 中自动执行常见管理任务。 要对 Amazon ECS 使用 AWS CLI，请安装最新版本的 AWS CLI。有关安装 AWS CLI 或升级到最新版本的信息，请参阅 AWS Command Line Interface 用户指南 中的安装 AWS 命令行界面。","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"ECS","slug":"ECS","permalink":"http://blog.ozairs.com/tags/ECS/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"Splunk入门手册","slug":"Splunk入门手册","date":"2019-03-22T04:07:41.000Z","updated":"2019-03-22T04:20:08.795Z","comments":true,"path":"Big-Data/Splunk入门手册/","link":"","permalink":"http://blog.ozairs.com/Big-Data/Splunk入门手册/","excerpt":"","text":"一、关于搜索不同时间段的记录 *earliest=-24h@h latest=-12h@h 二、关于搜索不同目录的记录 *source=”/var/log/ansible.log”","categories":[{"name":"Big Data","slug":"Big-Data","permalink":"http://blog.ozairs.com/categories/Big-Data/"}],"tags":[{"name":"Splunk","slug":"Splunk","permalink":"http://blog.ozairs.com/tags/Splunk/"}],"keywords":[{"name":"Big Data","slug":"Big-Data","permalink":"http://blog.ozairs.com/categories/Big-Data/"}]},{"title":"Kubernetes实战应用","slug":"Kubernetes实战应用","date":"2019-03-20T22:35:07.000Z","updated":"2019-04-01T11:24:23.034Z","comments":true,"path":"Kubernetes/Kubernetes实战应用/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/Kubernetes实战应用/","excerpt":"","text":"一、平台构建1、使用Vagrant和VirtualBox在本地搭建分布式的Kubernetes集群和Istio Service Mesh https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster/blob/master/README-cn.md 二、集群部署命令 启动kubenetes minikube start 运行应用：kubectl run helloworld –image=karthequian/helloworld –port=80 查看部署，资源，pods kubectl get deployments kubectl get rs kuebectl get pods 部署应用服务 kubectl expose deployment helloworld –type=NodePort 通过文件方式同时部署服务和Deployment kubectl create -f deploy-all.yml 查看服务 kubectl get services 扩展集群服务器 kubectl scale –replicas=3 deploy/helloworld 启动应用 minikube service helloworld （可以通过Web浏览器进行查看） 查看所有部署服务 minikube get all 将部署服务导出到YAML文件 kubectl get deploy/helloworld -o yaml 查看服务器集群状态： kubectl cluster-info 定位故障 kubectl describe deploy/depolyname kubectl describe po/podname kubectl log podname 登陆到服务节点：kubectl exec -it podname /bin/bash 如果单节点存在多个Container，登陆到某个服务节点：kubectl exec -it -c containername podname /bin/bash 查看所有服务进程：ps -ef 三、图形化管理工具 查看minikube 插件 minikube addons list minikube addon enable heapester 四、如何配置数据 To create a configmap for this literal type kubectl create configmap logger --from-literal=log_level=debug To see all your configmaps: kubectl get configmaps To read the value in the logger configmap: kubectl get configmap/logger -o yaml To edit the value, we can run kubectl edit configmap/logger ` 五、如何配置应用密钥 To create a secret: kubectl create secret generic apikey --from-literal=api_key=123456789 Notice that we can’t read the value of the secret directly:kubectl get secret apikey -o yaml Understand how to add a secret to a deployment ​ Adding a secret to a deployment is similar to what we did for configmaps. You can add a secret to the env portion, and start up the deployment with:kubectl create -f secretreader-deployment.yaml 六、如何创建任务How to run jobsJobs are a construct that run a pod once, and then stop. However, unlike pods in deployments, the output of the job is kept around until you decide to remove it. Running a job is similar to running a deployment, and we can create this by kubectl create -f simplejob.yaml To see the output of the job: kubectl get jobs You can find the pod that ran by doing a kubectl get pods --all-pods, and then get the logs from it as well. How to run cron jobsCron jobs are like jobs, but they run periodically. Start your cron by running kubectl create -f cronjob.yaml We can use the cronjob api to view your cronjobs: kubectl get cronjobs. It adds the last schedule date 七、如何创建DaemonSet","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Istio","slug":"Istio","permalink":"http://blog.ozairs.com/tags/Istio/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"Istio - Kubernetes和云原生系统的服务网格","slug":"Istio-Kubernetes和云原生系统的服务网格","date":"2019-03-20T21:17:38.000Z","updated":"2019-03-20T21:19:23.004Z","comments":true,"path":"Kubernetes/Istio-Kubernetes和云原生系统的服务网格/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/Istio-Kubernetes和云原生系统的服务网格/","excerpt":"","text":"微服务，尤其是基于云原生的基于容器的微服务，彻底改变了应用程序的构建和部署方式。这种转变受到基于容器的微服务提供的许多积极因素的驱动（例如速度，可移植性……）。但是，传统的监控工具并不适用于这些新系统。服务网格概念（特别是服务网格的Isto实现）带来了重新获得系统可见性，改进授权和安全性，管理路由，收集指标等的能力。点击上面的视频观看剧集并获取所有详细信息。 编辑成绩单对于那些喜欢阅读的人，我们已经通过我们的编辑运行成绩单，以获得更顺畅的阅读体验。 如果您在过去几年中一直在微服务领域工作，那么服务网格的概念对您来说可能并不陌生。对于我们其他人来说，它有点诞生于微服务空间带来的一些需求，特别是对可见性，流量路由，身份验证，安全性和指标收集的一些需求。问题源于这样一个事实，即在云空间内，特别是微服务空间，当我们将服务转移到容器中时，这是一种非常常见的模型，我们失去了一些我们能够用来获得经典可见性的仪器单片应用。 例如，在单一应用程序中，应用程序内的内部服务将通过内部消息传递进行通信，并且这些消息通信范例通常通过应用程序本身内的交互来管理。您基本上可以监视在不同资源之间传递的消息的内存空间。当我们突然去微服务时，不再容易完成。当我们去容器时，我们突然失去了将一些额外服务添加到我们的基础虚拟机中以收集该信息的能力。 嗯，这就是服务网格概念发挥作用的地方。让我们在所有微服务之间放置一些东西，然后捕获它们之间的所有流量。这会产生一些问题。特别是在分布式系统中，我突然想知道如何管理实际监控和计量我的服务的所有那些交互式小组件。 随之而来的是Kubernetes，突然之间游戏发生了巨大的变化。并不是我们无法实现这些服务功能，而是现在我们可以直接在各个服务容器本身旁边注入该功能。这通过一种称为服务注入的技术或有效地将另一个容器添加到我们的环境中来完成 然后最重要的是，由于我们通常关注网络流量，我们再次谈到微服务是这种通信的主要模型，我们实际上可以开始在pod中绑定服务，我们实际上是重定向本地流量现在。 通过这样做，我们解决了微服务所带来的一些问题。特别是监视资源之间通信的能力。这是Google实际带入Istio领域的事情之一，能够有效地捕获这些数据，有效地扩展了容器引擎（cAdvisor引擎）的概念，用于人们在应用程序空间中使用的容器运行时。基本上，然后能够查看应用程序数据流，然后集中该度量数据并可能监视通信。 一旦我完成了这一切 - 一旦我在那个级别注入了自己 - 我正在看着来回流动的数据包我可以做一些非常有趣的事情。我可以添加身份验证，因此这是IBM为这一组合做出的贡献之一。在路由之上是能够对这些不同服务之间的连接进行排序。路由是我可以控制的另一件事; 任何帧被发送而不是只是说好我将永远转发到负载均衡器，它将分配给n个资源，负载均衡器成为我沟通的一部分。现在我可以确定我实际上要将这些帧发送到哪个目标非常强大。 由于我有这种控制水平，我甚至可以做一些有趣的事情，比如注入错误。因此，当我开始将我的应用程序分发给这些微服务时，如果出现问题，我很难弄清楚我的应用程序将如何表现。我如何在任何一个特定的微服务中实际强制失败，以检查我的应用程序在遇到这种故障时如何保持弹性？好吧，我现在可以开始注入它作为我的QA或开发过程的一部分，甚至包括生产级别的注入。我可以继续创建故障以确保我的系统继续正常运行，如果不是，我实际上可以提醒它。 所以这些是微服务网格的一些交互 - 服务网格 - 空间实际提供，而Istio通过可注入代理提供这一点。基本上，我将采用代理引擎，在这种情况下，Istio空间正在使用Envoy代理。Envoy最初由Lyft开发，现在是CNCF的一个开源项目。实际上，Isto也是CNCF的一部分，对于那些没有听说过的人来说，它是Cloud Native Computing Foundation，它是Linux Foundation空间中的一个子基础。 所以这个服务功能真的是Istio提供的。Istio提供此Envoy代理功能，可以在Kubernetes空间中注入每个容器，或者如果要使用非Kubernetes模型，则将其插入转发路径。使用像Docker这样的容器甚至是虚拟机; 您实际上可以将此代理添加为虚拟机中的进程，并通过该方式注入流量。所以我们可以使用微服务…我们也可以使用大型服务，单片服务，我们可以使用这个服务网格将它们连接在一起。 但是有了Istio，我们就会获得身份验证，所以因为所有流量都通过这些Envoy代理，我实际上可以验证和结束通信。我可以监控和计量流量，以了解延迟发生的情况; 看看我在路径基础上获得了什么样的吞吐量。我可以将它发送到中央跟踪服务开放跟踪，例如，Jaeger项目是在那里使用的相当常见的项目之一。我也可以像我说的那样开始研究路由。我可以重定向流量并在Kubernetes空间内，例如，我可以使用标签来实际定义我的端点在哪里以及应该在哪里提供服务。 这一切都非常强大，但现在我也有中央控制权。这是这个Istio带来的最后一件事 - 中央证书控制。这对TLS身份验证很重要。使用名为Mixer的工具收集中心指标，实际上将所有指标数据收集在一起，然后集中配置控制，这实际上是为什么Envoy被选为代理。因为使用Envoy，我现在有一个中央控制器，可以将配置分发到该网格内的所有分布式代理。Envoy以非常有效的方式实现这一点，因为它实际上不需要重新配置重启; 它可以进行热重新配置 - 一个非常强大的功能！ 因此，服务网格是微服务空间的重要组成部分。它真正改变了微服务如何拼接在一起，如何对它们进行计量/监控，甚至通过从具有安全性的集中控制平面注入故障来改善这些服务的性能和弹性。所以在这一大捆绑中有很多东西，但那真的是Istio的能力。更一般地说，它是云本机引擎中更大的服务网格空间的一部分，它真正接管了当今应用程序的构建方式。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Istio","slug":"Istio","permalink":"http://blog.ozairs.com/tags/Istio/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"Maven和Ant简介以及两者的区别","slug":"Maven和Ant简介以及两者的区别","date":"2019-03-20T20:59:39.000Z","updated":"2019-03-20T21:02:59.763Z","comments":true,"path":"DevOps/Maven和Ant简介以及两者的区别/","link":"","permalink":"http://blog.ozairs.com/DevOps/Maven和Ant简介以及两者的区别/","excerpt":"","text":"一．Maven简介Maven是基于项目对象模型(POM)，可以通过一小段描述信息来管理项目的构建，报告和文档的软件项目管理工具。目前，绝大多数开发人员都把 Ant 当作 Java 编程项目的标准构建工具。遗憾的是，Ant 的项目管理工具（作为 make的替代工具）不能满足绝大多数开发人员的需要。通过检查 Ant 构建文件，很难发现项目的相关性信息和其它信息（如开发人员/拥有者、版本或站点主页）。Maven 除了以程序构建能力为特色之外，还提供 Ant 所缺少的高级项目管理工具。由于 Maven 的缺省构建规则有较高的可重用性，所以常常用两三行 Maven 构建脚本就可以构建简单的项目，而使用 Ant 则需要十几行。事实上，由于 Maven 的面向项目的方法，许多 Apache Jakarta 项目现在使用 Maven，而且公司项目采用 Maven 的比例在持续增长。Maven这个单词来自于意第绪语，意为知识的积累，最早在Jakata Turbine项目中它开始被用来试图简化构建过程。当时有很多项目，它们的Ant build文件仅有细微的差别，而JAR文件都由CVS来维护。于是Maven创始者开始了Maven这个项目，该项目的清晰定义包括，一种很方便的发布项目信息的方式，以及一种在多个项目中共享JAR的方式.二．Maven常用命令mvn archetype：create 创建Maven项目mvn compile 编译源代码mvn deploy 发布项目mvn test-compile 编译测试源代码mvn test 运行应用程序中的单元测试mvn site 生成项目相关信息的网站mvn clean 清除项目目录中的生成结果mvn package 根据项目生成的jarmvn install 在本地Repository中安装jarmvn eclipse:eclipse 生成eclipse项目文件mvnjetty:run 启动jetty服务mvntomcat:run 启动tomcat服务 Ant Ant简介Ant是一种基于Java的build工具。理论上来说，它有些类似于（Unix）C中的make ，但没有make的缺陷。目前的最新版本为：Ant 1.9.1既然我们已经有了make, gnumake, nmake, jam以及其他的build工具为什么还要要一种新的build工具呢？因为Ant的原作者在多种(硬件)平台上开发软件时，无法忍受这些工具的限制和不便。类似于make的工具本质上是基于shell（语言）的：他们计算依赖关系，然后执行命令（这些命令与你在命令行敲的命令没太大区别）。这就意味着你可以很容易地通过使用OS特有的或编写新的（命令）程序扩展该工具；然而，这也意味着你将自己限制在了特定的OS，或特定的OS类型上，如Unix。Ant就不同了。与基于shell命令的扩展模式不同，Ant用Java的类来扩展。（用户）不必编写shell命令，配置文件是基于XML的，通过调用target树，就可执行各种task。每个task由实现了一个特定Task接口的对象来运行。当一个代码项目大了以后，每次重新编译，打包，测试等都会变得非常复杂而且重复，因此c语言中有make脚本来帮助这些工作的批量完成。在Java 中应用是平台无关性的，当然不会用平台相关的make脚本来完成这些批处理任务了，ANT本身就是这样一个流程脚本引擎，用于自动化调用程序完成项目的编译，打包，测试等。除了基于JAVA是平台无关的外，脚本的格式是基于XML的，比make脚本来说还要好维护一些。每个ant脚本（缺省叫build.xml）中设置了一系列任务(target)：比如对于一个一般的项目可能需要有以下任务。 任务1：usage 打印本脚本的帮助信息（缺省） 任务2：clean &lt;– init 清空初始化环境 任务3：javadoc &lt;– build &lt;– init 生成JAVADOC 任务4：jar &lt;– build &lt;– init 生成JAR 任务5：all &lt;– jar + javadoc &lt;– build &lt;– init 完成以上所有任务：jar javadoc注：我看到很多项目的ant脚本中的命名基本上都是一致的，比如：编译一般叫build或者compile；打包一般叫jar或war；生成文档一般命名为 javadoc或javadocs；执行全部任务all。在每个任务的中，ANT会根据配置调用一些外部应用并配以相应参数执行。虽然ANT可调用的外部应用种类非常丰富，但其实最常用的就2，3个：比如javac javadoc jar等。二．Ant的优点Ant是Apache软件基金会JAKARTA目录中的一个子项目，它有以下的优点。跨平台性。Ant是纯Java语言编写的，因此具有很好的跨平台性。操作简单。Ant是由一个内置任务和可选任务组成的。Ant运行时需要一个XML文件(构建文件)。Ant通过调用target树，就可以执行各种task。每个task实现了特定接口对象。由于Ant构建文件时XML格式的文件，所以很容易维护和书写，而且结构很清晰。Ant可以集成到开发环境中。由于Ant的跨平台性和操作简单的特点，它很容易集成到一些开发环境中去。三．Ant 开发Ant的构建文件当开始一个新的项目时，首先应该编写Ant构建文件。构建文件定义了构建过程，并被团队开发中每个人使用。Ant构建文件默认命名为build.xml，也可以取其他的名字。只不过在运行的时候把这个命名当作参数传给Ant。构建文件可以放在任何的位置。一般做法是放在项目顶层目录中，这样可以保持项目的简洁和清晰。下面是一个典型的项目层次结构。(1) src存放文件。(2) class存放编译后的文件。(3) lib存放第三方JAR包。(4) dist存放打包，发布以后的代码。Ant构建文件是XML文件。每个构建文件定义一个唯一的项目(Project元素)。每个项目下可以定义很多目标(target元素)，这些目标之间可以有依赖关系。当执行这类目标时，需要执行他们所依赖的目标。每个目标中可以定义多个任务，目标中还定义了所要执行的任务序列。Ant在构建目标时必须调用所定义的任务。任务定义了Ant实际执行的命令。Ant中的任务可以为3类。（1） 核心任务。核心任务是Ant自带的任务。（2） 可选任务。可选任务实来自第三方的任务，因此需要一个附加的JAR文件。（3） 用户自定义的任务。用户自定义的任务是用户自己开发的任务。1.标签每个构建文件对应一个项目。标签时构建文件的根标签。它可以有多个内在属性，就如代码中所示，其各个属性的含义分别如下。(1) default表示默认的运行目标，这个属性是必须的。(2) basedir表示项目的基准目录。(3) name表示项目名。(4) description表示项目的描述。每个构建文件都对应于一个项目，但是大型项目经常包含大量的子项目，每一个子项目都可以有自己的构建文件。2.标签一个项目标签下可以有一个或多个target标签。一个target标签可以依赖其他的target标签。例如，有一个target用于编译程序，另一个target用于生成可执行文件。在生成可执行文件之前必须先编译该文件，因此可执行文件的target依赖于编译程序的target。Target的所有属性如下。(1).name表示标明，这个属性是必须的。(2).depends表示依赖的目标。(3)if表示仅当属性设置时才执行。(4)unless表示当属性没有设置时才执行。(5)description表示项目的描述。Ant的depends属性指定了target的执行顺序。Ant会依照depends属性中target出现顺序依次执行每个target。在执行之前，首先需要执行它所依赖的target。程序中的名为run的target的depends属性compile，而名为compile的target的depends属性是prepare，所以这几个target执行的顺序是prepare-&gt;compile-&gt;run。一个target只能被执行一次，即使有多个target依赖于它。如果没有if或unless属性，target总会被执行。3.标签该标签用于创建一个目录，它有一个属性dir用来指定所创建的目录名，其代码如下：通过以上代码就创建了一个目录，这个目录已经被前面的property标签所指定。4标签该标签用来生成一个JAR文件，其属性如下。(1) destfile表示JAR文件名。(2) basedir表示被归档的文件名。(3) includes表示被归档的文件模式。(4) exchudes表示被排除的文件模式。5．&lt;javac标签&gt;该标签用于编译一个或一组java文件，其属性如下。(1).srcdir表示源程序的目录。(2).destdir表示class文件的输出目录。(3).include表示被编译的文件的模式。(4).excludes表示被排除的文件的模式。(5).classpath表示所使用的类路径。(6).debug表示包含的调试信息。(7).optimize表示是否使用优化。(8).verbose 表示提供详细的输出信息。(9).fileonerror表示当碰到错误就自动停止。6．标签该标签用来执行编译生成的.class文件，其属性如下。(1).classname 表示将执行的类名。(2).jar表示包含该类的JAR文件名。(3).classpath所表示用到的类路径。(4).fork表示在一个新的虚拟机中运行该类。(5).failonerror表示当出现错误时自动停止。(6).output 表示输出文件。(7).append表示追加或者覆盖默认文件。7.标签该标签用于删除一个文件或一组文件，其属性如下。(1)/file表示要删除的文件。(2).dir表示要删除的目录。(3).includeEmptyDirs 表示指定是否要删除空目录，默认值是删除。(4).failonerror 表示指定当碰到错误是否停止，默认值是自动停止。(5).verbose表示指定是否列出所删除的文件，默认值为不列出。8.标签该标签用于文件或文件集的拷贝，其属性如下。(1).file 表示源文件。(2).tofile 表示目标文件。(3).todir 表示目标目录。(4).overwrite 表示指定是否覆盖目标文件，默认值是不覆盖。(5).includeEmptyDirs 表示制定是否拷贝空目录，默认值为拷贝。(6).failonerror 表示指定如目标没有发现是否自动停止，默认值是停止。(7).verbose 表示制定是否显示详细信息，默认值不显示。四．Ant的数据类型在构建文件中为了标识文件或文件组，经常需要使用数据类型。数据类型包含在org.apache.tool.ant.types包中。下面镜简单介绍构建文件中一些常用的数据类型。 argument 类型由Ant构建文件调用的程序，可以通过元素向其传递命令行参数，如apply,exec和java任务均可接受嵌套元素，可以为各自的过程调用指定参数。以下是的所有属性。(1).values 是一个命令参数。如果参数中有空格，但又想将它作为单独一个值，则使用此属性。(2).file表示一个参数的文件名。在构建文件中，此文件名相对于当前的工作目录。(3).line表示用空格分隔的多个参数列表。(4).path表示路径。2.ervironment 类型由Ant构建文件调用的外部命令或程序，元素制定了哪些环境变量要传递给正在执行的系统命令，元素可以接受以下属性。(1).file表示环境变量值的文件名。此文件名要被转换位一个绝对路径。(2).path表示环境变量的路径。Ant会将它转换为一个本地约定。(3).value 表示环境变量的一个直接变量。(4).key 表示环境变量名。注意 file path 或 value只能取一个。3.filelist类型Filelist 是一个支持命名的文件列表的数据类型，包含在一个filelist类型中的文件不一定是存在的文件。以下是其所有的属性。(1).dir是用于计算绝对文件名的目录。(2).files 是用逗号分隔的文件名列表。(3).refid 是对某处定义的一个的引用。注意 dir 和 files 都是必要的，除非指定了refid(这种情况下，dir和files都不允许使用)。4.fileset类型Fileset 数据类型定义了一组文件，并通常表示为元素。不过，许多ant任务构建成了隐式的fileset,这说明他们支持所有的fileset属性和嵌套元素。以下为fileset 的属性列表。(1).dir表示fileset 的基目录。(2).casesensitive的值如果为false，那么匹配文件名时，fileset不是区分大小写的，其默认值为true.(3).defaultexcludes 用来确定是否使用默认的排除模式，默认为true。(4).excludes 是用逗号分隔的需要派出的文件模式列表。(5).excludesfile 表示每行包含一个排除模式的文件的文件名。(6).includes 是用逗号分隔的，需要包含的文件模式列表。(7).includesfile 表示每行包括一个包含模式的文件名。5.patternset 类型Fileset 是对文件的分组，而patternset是对模式的分组，他们是紧密相关的概念。支持4个属性：includes excludex includexfile 和 excludesfile,与fileset相同。Patternset 还允许以下嵌套元素：include,exclude,includefile 和 excludesfile.6.filterset 类型Filterset定义了一组过滤器，这些过滤器将在文件移动或复制时完成文件的文本替换。主要属性如下：(1).begintoken 表示嵌套过滤器所搜索的记号，这是标识其开始的字符串。(2).endtoken表示嵌套过滤器所搜索的记号这是标识其结束的字符串。(3).id是过滤器的唯一标志符。(4).refid是对构建文件中某处定义一个过滤器的引用。7.Path类型Path元素用来表示一个类路径，不过它还可以用于表示其他的路径。在用作几个属性时，路经中的各项用分号或冒号隔开。在构建的时候，此分隔符将代替当前平台中所有的路径分隔符，其拥有的属性如下。(1).location 表示一个文件或目录。Ant在内部将此扩展为一个绝对路径。(2).refid 是对当前构建文件中某处定义的一个path的引用。(3).path表示一个文件或路径名列表。8.mapper类型Mapper类型定义了一组输入文件和一组输出文件间的关系，其属性如下。(1).classname 表示实现mapper类的类名。当内置mapper不满足要求时，用于创建定制mapper.(2).classpath表示查找一个定制mapper时所用的类型路径。(3).classpathref是对某处定义的一个类路径的引用。(4).from属性的含义取决于所用的mapper.(5).to属性的含义取决于所用的mapper.(6).type属性的取值为identity，flatten glob merge regexp 其中之一，它定义了要是用的内置mapper的类型。五．Ant的安装解包后在系统可执行路径中加入指向ant的bin的路径就可以了，比如可以在GNU/Linux上把以下配置加入/etc/profile中：export ANT_HOME=/home/antexport JAVA_HOME=/usr/java/j2sdk1.4.1export PATH=$PATH:$JAVA_HOME/bin:$ANT_HOME/binWindows 下的安装：下载后解压到某个目录我这里以D:\\apache-ant-1.7.1为例子：添加path全局环境变量:D:\\apache-ant-1.7.1\\bin这样在command line就可以运行ant命令了测试：运行-&gt;cmd/command-&gt;ant 如果没有安装成功则回报找不到这个命令，安装成功会有相关的提示信息显示。这样执行ant 后，如果不指定配置文件ant会缺省找build.xml这个配置文件，并根据配置文件执行任务，缺省的任务设置可以指向最常用的任务，比如： build，或指向打印帮助信息：usage，告诉用户有那些脚本选项可以使用。六．Ant的运行安装好Ant并且配置好路径之后，在命令行中切换到构建文件的目录，输入Ant命令就可以运行Ant.若没有指定任何参数，Ant会在当前目录下查询build.xml文件。如果找到了就用该文件作为构建文件。如果使用了 –find 选项，Ant 就会在上级目录中找构建文件，直至到达文件系统的根目录。如果构建文件的名字不是build.xml ，则Ant运行的时候就可以使用 –buildfile file,这里file 指定了要使用的构建文件的名称，示例如下：Ant如下说明了表示当前目录的构建文件为build.xml 运行 ant 执行默认的目标。Ant –buildfile test.xml使用当前目录下的test.xml 文件运行Ant ,执行默认的目标 Moven与Ant的区别 Maven 和 Ant 针对构建问题的两个不同方面。Ant 为 Java 技术开发项目提供跨平台构建任务。Maven 本身描述项目的高级方面，它从 Ant 借用了绝大多数构建任务。因此，由于 Maven 和 Ant 代表两个差异很大的工具，所以接下来只说明这两个工具的等同组件之间的区别。 Maven Ant标准构建文件 project.xml 和 maven.xml build.xml特性处理顺序 ${maven.home}/bin/driver.properties${project.home}/project.properties${project.home}/build.properties${user.home}/build.properties通过 -D 命令行选项定义的系统特性最后一个定义起决定作用。 通过 -D 命令行选项定义的系统特性由 任务装入的特性第一个定义最先被处理。构建规则 构建规则更为动态（类似于编程语言）；它们是基于 Jelly 的可执行 XML。 构建规则或多或少是静态的，除非使用 任务。（请参阅 参考资料以获得相关教程。）扩展语言 插件是用 Jelly（XML）编写的。 插件是用 Java 语言编写的。构建规则可扩展性 通过定义 和 使构建 goal 可扩展。 构建规则不易扩展；可通过使用 任务模拟 和 所起的作用。Maven是一个项目管理工具，它包含了一个项目对象模型 (Project Object Model)，一组标准集合，一个项目生命周期(Project Lifecycle)，一个依赖管理系统(Dependency Management System)，和用来运行定义在生命周期阶段(phase)中插件(plugin)目标(goal)的逻辑。当你使用Maven的时候，你用一个明确定义的项目对象模型来描述你的项目，然后Maven可以应用横切的逻辑，这些逻辑来自一组共享的（或者自定义的）插件。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://blog.ozairs.com/tags/Maven/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"CloudFormation经验贴汇总","slug":"CloudFormation经验贴汇总","date":"2019-03-19T12:30:11.000Z","updated":"2019-03-19T13:02:08.841Z","comments":true,"path":"AWS/CloudFormation经验贴汇总/","link":"","permalink":"http://blog.ozairs.com/AWS/CloudFormation经验贴汇总/","excerpt":"","text":"1. CloudFormation两年：经验教训https://www.colabug.com/4023693.html 2.您的基础架构代码CloudFormation与Terraform？https://www.colabug.com/3313548.html","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"CloudFormation","slug":"CloudFormation","permalink":"http://blog.ozairs.com/tags/CloudFormation/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"使用Cloud Formation为AWS上的私有实例设置绝对可靠的Bastion节点","slug":"使用Cloud-Formation为AWS上的私有实例设置绝对可靠的Bastion节点","date":"2019-03-19T10:43:25.000Z","updated":"2019-03-19T10:47:22.853Z","comments":true,"path":"AWS/使用Cloud-Formation为AWS上的私有实例设置绝对可靠的Bastion节点/","link":"","permalink":"http://blog.ozairs.com/AWS/使用Cloud-Formation为AWS上的私有实例设置绝对可靠的Bastion节点/","excerpt":"","text":"在AWS上设置基础架构时，您需要为管理目的提供SSH / RDP访问私有实例的方法。实现此目的的一种简单方法是在实例的安全组的入站规则中简单地允许端口22上的SSH流量，然后通过弹性IP和Internet网关将实例暴露给公共Internet。然而，由于攻击者可能很容易访问您的安全密钥对，并且如果这样的密钥对也可用于其他私有实例，则这会变得有缺陷，那么此类攻击者可以完全访问和控制您的基础结构。 为了避免这种情况，公司现在使用遍布所有可用区域（AZ）的堡垒实例，其中已经设置了基础架构。Bastion节点是一个专门的实例，故意暴露在互联网上，其设计和配置仅限于遭受攻击的唯一原因。看到堡垒节点暴露在非军事区（DMZ）的公共互联网中，面临潜在攻击的大量风险，因此有必要确保堡垒节点完全万无一失。本文提供了如何设置可靠的堡垒节点的实用见解。使用CloudFormation是因为它通过简单地调整云形成模板中的一些参数，简化了为每个AZ设置堡垒实例的整个瓶颈。 先修知识： 基本了解以下Amazon Web服务/概念：EC2，VPC，子网，NAT，安全组和访问控制列表（ACL） 对云形成的基本认识。 我们将在10.6.0.0/16 VPC中考虑在10.6.0.0/24子网上具有私有实例的假设网络。此外，我们的堡垒实例应存在于10.5.0.0/24子网中的10.5.0.0/16 VPC中，如下图所示： 从上图可以看出，NAT网关也已添加到架构中。这为我们的私有实例提供了额外的安全层，只要他们需要访问公共互联网进行软件更新。NAT网关允许来自私有实例的所有出站流量，但阻止从Internet到私有实例的所有始发流量。使用NAT网关，因为我们只想允许来自堡垒节点的SSH流量并阻止来自互联网的所有其他流量。出于简化/清晰的目的，有意地从上面的图中省略了每个实例的安全组信息，但是应该在云形成模板中进行研究。该图还包含10.6.0的访问控制列表（ACL）信息。有状态的。我们将在以下部分中探索Bastion节点，私有实例和NAT网关的配置细节： 堡垒节点 它存在于自己的VPC中，该VPC暴露于Internet网关并使用VPC对等连接与VPC2（我们的私有实例的VPC）进行通信。互联网网关已与VPC相关联，并且已将弹性IP（EIP）分配给堡垒节点以允许来自互联网的流量。 路由表清楚地表明，除了10.5.0.0/16和10.6.0.0/16网络之外，所有来自堡垒节点的出站流量都应通过互联网网关转发。发往10.6.0.0/16的流量应使用VPC对等连接作为网关，这样，SSH流量就可以到达我们的私有实例。 对于安全组，我们只允许来自/到公共互联网的所有SSH流量并阻止所有其他流量。以下是使用云形成实现这一目标的方法： 私有集群中的实例 我们决定将我们的假设私有集群放在10.6.0.0/24子网上。路由表描述了发往10.5.0.0/16网络的所有流量都应使用对等连接作为网关。特定于Internet的出站流量使用NAT实例作为网关。 对于安全组，我们仅允许来自10.5.0.0/24子网的SSH流量和来自Internet上的Internet（0.0.0.0/0）的HTTP / HTTPS流量，并拒绝所有其他协议。 要添加额外的安全层，我们使用ACL，仅允许SSH，HTTP和HTTPS流量，如上图所示，同时显示入口和出口。由于NAT网关请求此端口以便与私有实例通信，因此端口1024-65535已保持打开以进行短暂连接。下面使用此云形成模板显示： NAT网关 NAT网关也已放置在自己的10.6.1.0/24子网中。路由表描述了互联网的所有出站流量应使用Internet网关正确分段网络，因为NAT不需要访问对等连接。 NAT网关的安全组仅允许来自Internet的HTTP和HTTPs流量。以下是云形成如何实现： 现在我们有了堡垒架构的完整设置。还剩下最后一件事就是SSH Agent Forwarding SSH代理转发 为什么需要这个？我们可以简单地进入堡垒，然后跳转到我们的任何私有实例中。为什么这是真的，这是一个巨大的安全风险。有权访问堡垒主机的任何人都可以访问其他所有用户的私钥，并可以模拟该用户。因此，凭证不应存储在堡垒主机上，而应通过SSH代理转发从本地计算机转发到堡垒。 -A使用SSH命令添加一段时间应该将您的本地凭据转发到下一台机器上，但是，我们将通过〜/ .ssh / config文件进行此配置以简化我们的生活并避免尝试在每次ssh尝试时转发代理。 将以下行添加到ssh配置文件中： 12345Host bastion HostName [Bastion Public Ip address] User ec2-user #For example IdentityFile [Path to Identity file] ForwardAgent Yes 注意：如果该文件不存在，您可以直接触摸该文件touch ~/.ssh/config 现在，我们可以简单地说ssh bastion，我们可以进入我们的堡垒实例，我们可以从中跳转到所有其他实例。 为了进一步简化，我们可以将以下行添加到文件~/.bashrc或~/.zshrc文件中： 123456function ssh-instance（）&#123; BASTION_USER =＃你的堡垒用户名 BASTION_IP =＃你的堡垒IP SSH_OPTIONS =“ProxyCommand ssh -q -A -W％h：％p $ BASTION_USER @ $ BASTION_IP” ssh $ 1 @ $ 2 -o $ SSH_OPTIONS &#125; 保存文件，通过它来源source ~/.bashrc，现在你可以简单地说ssh-instance ec2-user [my instance ip]，瞧，你直接进入你的私人实例，而不必首先通过堡垒。 其他提示 建议对堡垒节点和私有实例使用不同的ssh密钥，并经常轮换这些密钥以减少攻击者获取访问权限的可能性。 此外，专用的SysAdmin或DevOps工程师还可以在每个堡垒节点中设置用户组，并创建分配给具有各种管理权限的这些不同用户组的用户。应将每个用户的公共ssh密钥复制到~/.ssh/authorized_keys文件中。 结论 本文探讨了如何在AWS上为我们的私有实例设置一个万无一失的堡垒节点，而不会在需要系统/软件更新时损害这些实例的Internet可访问性。 本文的云形成模板可以在这里找到：https：//github.com/nwochaadim/BastionNode-with-CloudFormation","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"CloudFormation","slug":"CloudFormation","permalink":"http://blog.ozairs.com/tags/CloudFormation/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"玩转Jenkins Pipeline","slug":"玩转Jenkins-Pipeline","date":"2019-03-18T08:47:54.000Z","updated":"2019-03-18T08:51:11.320Z","comments":true,"path":"Jenkins/玩转Jenkins-Pipeline/","link":"","permalink":"http://blog.ozairs.com/Jenkins/玩转Jenkins-Pipeline/","excerpt":"","text":"Jenkins Pipeline的总体介绍1.Jenkins Pipeline 的核心概念 Pipeline，简而言之，就是一套运行于Jenkins上的工作流框架，将原本独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排与可视化。 Pipeline是Jenkins2.X的最核心的特性，帮助Jenkins实现从CI到CD与DevOps的转变 Pipeline是一组插件，让Jenkins可以实现持续交付管道的落地和实施。 持续交付管道（CD Pipeline）是将软件从版本控制阶段到交付给用户或客户的完整过程的自动化表现。软件的每一次更改（提交到源代码管理系统）都要经过一个复杂的过程才能被发布。 Pipeline提供了一组可扩展的工具，通过Pipeline Domain Specific Language（DSL）syntax可以达到Pipeline as Code（Jenkinsfile存储在项目的源代码库）的目的。 Stage：阶段，一个Pipeline可以划分成若干个Stage，每个Stage代表一组操作，例如：“Build”，“Test”，“Deploy”。 注意，Stage是一个逻辑分组的概念，可以跨多个Node Node：节点，一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行环境。 Step：步骤，Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenklins Plugin提供，例如：sh ‘make’ Pipeline五大特性 1、代码:Pipeline以代码的形式实现，通常被检入源代码控制，使团队能够编辑、审查和迭代其CD流程。2、可持续性：Jenklins重启或者中断后都不会影响Pipeline Job。3、停顿：Pipeline可以选择停止并等待任工输入或批准，然后再继续Pipeline运行。4、多功能：Pipeline支持现实世界的复杂CD要求，包括fork/join子进程，循环和并行执行工作的能力5、可扩展：Pipeline插件支持其DSL的自定义扩展以及与其他插件集成的多个选项。 Pipeline和Freestyle的区别 Freestyle：上游/下游Job调度，如BuildJob —&gt; TestJob —&gt; DeployJob在DSL Job里面调度多个子Job（利用Build Flow Plugin） Pipeline：单个Job中完成所有的任务编排全局视图 Multibranch Pipeline根据你的代码中Jenlinsfile自动创建Job Jenlins Pipeline的基础语法Pipeline脚本是由Groovy语言实现（无需专门学习） 支持两种语法Declarative 声明式（在Pipeline plugin 2.5中引入）Scripted Pipeline 脚本式 如何创建最基本的PIpeline直接在Jenkins Web UI 网页界面中输入脚本通过创建一个jenkinsfile可以检入项目的源代码管理库 通常推荐在Jenkins中直接从源代码控制（SCM）中载入Jenklinsfile Pipeline 声明式Pipeline 声明式Pipeline的基本语法和表达式遵循与Groovy语法相同的规则，但有以下例外： 声明式pipeline必须包含在固定格式pipeline{}快内每个声明语句必须独立一行，行尾无需使用分号块（blocks{}）只能包含章节（Sections），指令（Directives），步骤（Steps）或赋值语句属性引用语句被视为无参数方法调用。例：输入被视为 input()块（blocks{}）由大括号括起来的语句，如pipeline{},Section{},parameters{},script{}章节（Sections）通常包含一个或多个指令或步骤。如 agent 、post、stages、steps指令（Directives）environment、options、parameters、triggers（触发）、stage、tools、when步骤（Steps）Pipeline steps reference执行脚本式pipeline：使用script{} agent必须存在，agent必须在pipeline块内的顶层定义，但stage内是否使用使可选的参数：any/none/label/node/docker/dockerfile常用选项 label/cuetomWorkspace/reuseNode 示例 agent { label ‘my-label’ } agent { node { label ‘my-label’ customWorkspace ‘/some/other/path’ }} agent { docker { image ‘nginx:1.12.2’ label ‘my-label’ args ‘-v /tmp:/tmp’ }} post 不是必须的，用于pipeline的最外层或者stage{}中 pipeline { agent any stages { stage(‘Example’){ steps { echo ‘Hello world’ } } } post { always { echo ‘say goodbay’ } }} stages 必须，包括顺序执行的一个或多个stage命令，在pipeline内仅能使用一次，通常位于agent/options后面，例子如上 steps 必须，steps位于stage指令块内部，包括一个或多个step。仅有一个step的情况下可以忽略关键字step及其{},例子如上 environment 不是必须的，environment定义了一组全局的环境变量键值对，存在于pipeline{}或者stage指令内。执行特殊方法credentials()可以获取jenkins中预定义的凭证明文内容 environment {CC=’clang’}environment {AN_ACCESS_KEY = credentials(‘my-prefined-secret-text’)}steps {sh ‘printenv’} options 不是必须的 预定义pipeline专有的配置信息，仅可定义一次 pipeline { agent any options{ timeout(time:1,unit: ‘HOURS’) } …} parameters 不是必须的 定义参数化构建的参数可选参数 booleanParam,choice,file,text,password,run,string paramenters { choice(name:’PerformMavenRelease’,choices:’False\\nTrue’,description:’desc’) password(name:’CredsToUse’,description:’Apassword to build with’,defaultValue:’’)}environment { BUILD_USR_CHOICE=”${params.PerformMavenRelease}” BUILD_USR_CREDS=”${params.CredsToUse}”} triggers 不是必须的 定义pipeline被自动触发的方式选项 cron、pollSCM、upstream triggers {cron(‘H 4/ 0 0 1-5’)}triggers {pollSCM(‘H 4/ 0 0 1-5’)}triggers {upstream(upstreamProjects:’job1,job2’,threshold:hudson.model.Result.SUCCESS)} 快速创建一个pipeline新建 选择pipeline 填写Job 的名字 填写相应的pipeline script pipeline{ agent any stages { stage(‘Build’) { steps{ echo ‘This is a build step’ } } stage(‘Test’) { steps{ echo ‘This is a test step’ } } stage(‘Deploy’) { steps{ echo ‘This is a deploy step’ } } }}1 保存之后，立即构建 常用的辅助工具 Snipper Generator（代码片段生成器，语法检查器）Replay Pipeline（重放pipeline，可以修改script，修改后的不存入config.xml）DSL Reference 语法参考手册全局变量引用Stage ViewBlueOcean(可视化)Pipeline神器：可视化编辑器命令行Pipeline调试工具变量的传递 自定义变量（局部）def username = ‘Jenkins’echo “Hello Mr.${username}” #注意一定要用双引号，单引号识别为字符串 环境变量（局部）withEnv([‘MYTOOL_HOME=/usr/local/mytool’]){ sh ‘$MYTOOL_HOME/bin/start’}123环境变量（全局）environment {CC=’clang’}echo “Compiler is ${env.CC}” 参数化构建（全局）parameters {string(name:’Jenkins’,defaultValue:’Hello’,description:’How should I greet the world’)}ehco “${params.Greeting} World!” 判断when仅用于stage内部when的内置条件为： when {branch ‘master’} when {environment name:’DEPLOY_TO’,value:’production’}#当有环境变量 name 为 DEPLOY_TO 值是 production 条件成立 when {expression {return params.DEBUG_BUILD}}#表达式返回值为真时 when {not {branch ‘master’}} when {allOf {branch ‘master’; environment name:’DEBUG_TO’,value:’production’}}#allOf 所有条件都满足时 when {anyOf {branch ‘master’ ; branch ‘staging’}}#anyOf有一个条件满足时即可 判断和异常处理流程控制if/else条件 node { stage(‘Example’){ if(env.BRANCH_NAME == ‘master’){ echo ‘I only execute on the master branch’ }else { echo ‘Iexecute elsewhere’ } }} 异常处理try/catch/finally node{ stage(‘Example’){ try{ sh ‘exit 1’ } catch (exc) { echo ‘something failed,I should sound the klaxons!’ throw } }} for循环仅存在域脚本式pipeline中，但是可以通过在声明式pipeline中调用script step来执行 pipeline { agent any stages { stage(‘Example’){ steps{ echo ‘Hello world!’ script { def browsers = [‘chrome’,’firefox’] for (int i = 0;i &lt; browers.size();++i){ echo “Testing the ${browsers[i]} browser” } } } } }} 并发需要放在stages中，stages可以嵌套使用stage下的steps和parallel不能共存，只能二选一使用了并发的stage不能再有agent/tools","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}],"tags":[{"name":"Pipeline","slug":"Pipeline","permalink":"http://blog.ozairs.com/tags/Pipeline/"}],"keywords":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}]},{"title":"使用jenkins+ant 构建非maven项目","slug":"使用jenkins-ant-构建非maven项目","date":"2019-03-18T05:06:47.000Z","updated":"2019-03-18T05:14:51.282Z","comments":true,"path":"Jenkins/使用jenkins-ant-构建非maven项目/","link":"","permalink":"http://blog.ozairs.com/Jenkins/使用jenkins-ant-构建非maven项目/","excerpt":"","text":"使用ant构建是因为在许多公司仍有许多项目没有使用maven,所以自己学习并研究了了一下 1. 安装构建环境除普通必要的环境外，需要额外安装ANT 到官方主页http://ant.apache.org下载新版的ant， 得到的是一个apache-ant-1.10.1-bin.zip的压缩包。将其解压到你的硬盘上 接下来配置环境变量即可，配置和java类似 ANT_HOME : D:\\MyWorkApps\\apache-ant-1.10.1 CLASSPATH : D:\\MyWorkApps\\apache-ant-1.10.1\\lib PATH: D:\\MyWorkApps\\apache-ant-1.10.1\\bin 注意：配置没有使用%ANT_HOME%bin 原因:经测试部分系统path不识别%ANT_HOME% 解决方法：换成解压目录路径，如上即可 测试一下是否安装成功 build failed 即成功，只是没有build.xml而已 2. jenkins安装ant插件并进行环境配置进入系统设置，插件管理，安装ant插件 我这里已经安装好了 然后进入 系统管理 =》 Global Tool Configuration 配置JDK也是必须的，若果使用ANT构建就需配置ANT,使用MAVEN构建即要配置MAVEN 配置也很简单 如下 Name 可以随意取 ,HOME即为安装目录 3. 进入jenkins构建项目点击新建 如上填写选择，点击ok 继续，到源码管理，选择svn,输入地址和账号密码 继续 可以看到这里实用最简单的配置，构建触发器，和构建环境都没有选， 构建里选择一下我们刚刚安装配置的ANT 点击保存即可 \\4. build.xml文件配置 使用ANT进行构建，最主要的就是build.xml文件的编写 这里只需要修改property的几个属性即可 由于我们在构建中指定了ANT，所以下面的这个可以去除掉 project name 这个name即是打包之后的包名，也是我们进入工程的工程名称 如：http://localhost:8099/myweb/hello/world.do 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project name=\"hellojk\" default=\"deploy\" basedir=\".\"&gt; &lt;property environment=\"env\" /&gt; &lt;property name=\"webapp.name\" value=\"hellojk\" /&gt; &lt;property name=\"catalina.home\" value=\"D:\\Program Files\\Apache Software Foundation\\Tomcat 8.5\" /&gt; &lt;property name=\"dist.dir\" value=\"$&#123;basedir&#125;/dist\" /&gt; &lt;property name=\"webRoot.dir\" value=\"$&#123;basedir&#125;/WebRoot\" /&gt; &lt;property name=\"src.dir\" value=\"$&#123;basedir&#125;/src\" /&gt; &lt;property name=\"config.dir\" value=\"$&#123;basedir&#125;/config\" /&gt; &lt;property name=\"lib.dir\" value=\"$&#123;webRoot.dir&#125;/WEB-INF/lib\" /&gt; &lt;property name=\"build.dir\" value=\"$&#123;basedir&#125;/build\" /&gt; &lt;!-- 使用eclipse jdt进行编译，而不使用JDK编译 --&gt; &lt;!-- &lt;property name=\"build.compiler\" value=\"org.eclipse.jdt.core.JDTCompilerAdapter\" /&gt; --&gt; &lt;!-- &lt;property name=\"build.compiler\" value=\"D:\\MyWorkApps\\Java\\jdk1.8.0_51\" /&gt; --&gt; &lt;!-- 初始化classpath --&gt; &lt;path id=\"project.classpath\"&gt; &lt;fileset dir=\"$&#123;lib.dir&#125;\"&gt; &lt;include name=\"**/*.jar\" /&gt; &lt;/fileset&gt; &lt;!-- 添加tomcat类路径 --&gt; &lt;fileset dir=\"$&#123;catalina.home&#125;/lib\"&gt; &lt;include name=\"*.jar\" /&gt; &lt;/fileset&gt; &lt;!-- ant lib包 --&gt; &lt;!--&lt;fileset dir=\"$&#123;ant.dir&#125;\"&gt; &lt;include name=\"**/*.jar\" /&gt; &lt;/fileset&gt; --&gt; &lt;/path&gt; &lt;!-- get the source compile classpath in a printable form --&gt; &lt;pathconvert pathsep=\"$&#123;line.separator&#125;| |-- \" property=\"echo.path.compile\" refid=\"project.classpath\"&gt; &lt;/pathconvert&gt; &lt;!-- show classpath jars --&gt; &lt;target name=\"print_classpath\"&gt; &lt;echo message=\"|-- compile classpath\"/&gt; &lt;echo message=\"| |\"/&gt; &lt;echo message=\"| |-- $&#123;echo.path.compile&#125;\"/&gt; &lt;/target&gt; &lt;!-- 删除之前的目录结构 --&gt; &lt;target name=\"clear\" description=\"清理旧文件\"&gt; &lt;delete dir=\"$&#123;build.dir&#125;\" /&gt; &lt;delete dir=\"$&#123;dist.dir&#125;\" /&gt; &lt;delete file=\"$&#123;catalina.home&#125;/webapps/$&#123;webapp.name&#125;.war\" /&gt; &lt;delete dir=\"$&#123;catalina.home&#125;/webapps/$&#123;webapp.name&#125;\" /&gt; &lt;/target&gt; &lt;!-- 创建目录结构 --&gt; &lt;target name=\"init\" depends=\"clear\" description=\"创建初始化目录结构\"&gt; &lt;mkdir dir=\"$&#123;build.dir&#125;/classes\" /&gt; &lt;mkdir dir=\"$&#123;dist.dir&#125;\" /&gt; &lt;/target&gt; &lt;!-- 编译java --&gt; &lt;target name=\"compile\" depends=\"init\" description=\"编译java文件\"&gt; &lt;echo message=\"begin compile...\" /&gt; &lt;javac srcdir=\"$&#123;src.dir&#125;\" destdir=\"$&#123;build.dir&#125;/classes\" includeantruntime=\"false\" nowarn=\"on\" source=\"1.8\" target=\"1.8\" deprecation=\"true\" debug=\"true\" encoding=\"UTF-8\" classpathref=\"project.classpath\" &gt; &lt;compilerarg line=\"-Xlint:unchecked\" /&gt; &lt;!-- &lt;classpath refid=\"project.classpath\" /&gt; --&gt; &lt;/javac&gt; &lt;copy todir=\"$&#123;build.dir&#125;\"&gt; &lt;fileset dir=\"$&#123;src.dir&#125;\"&gt; &lt;include name=\"**/*.xml\" /&gt; &lt;include name=\"**/*.properties\" /&gt; &lt;include name=\"**/*.sql\" /&gt; &lt;/fileset&gt; &lt;fileset dir=\"$&#123;config.dir&#125;\"&gt; &lt;include name=\"**/*.xml\" /&gt; &lt;include name=\"**/*.properties\" /&gt; &lt;include name=\"**/*.sql\" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;echo message=\"end compile...\" /&gt; &lt;/target&gt; &lt;!-- 将class文件打成 jar包 --&gt; &lt;!-- &lt;target name=\"pack\" depends=\"compile\"&gt; &lt;jar jarfile=\"$&#123;build.dir&#125;/$&#123;webapp.name&#125;.jar\"&gt; &lt;fileset dir=\"$&#123;build.dir&#125;/classes\"&gt; &lt;include name=\"**/*.class\"/&gt; &lt;/fileset&gt; &lt;/jar&gt; &lt;/target&gt; --&gt; &lt;!-- 打成war包, 名称默认为 项目名 --&gt; &lt;target name=\"war\" depends=\"compile\" description=\"将工程打成war包\"&gt; &lt;echo message=\"begin war...\" /&gt; &lt;war destfile=\"$&#123;dist.dir&#125;/$&#123;webapp.name&#125;.war\" basedir=\"$&#123;webRoot.dir&#125;\" webxml=\"$&#123;webRoot.dir&#125;/WEB-INF/web.xml\"&gt; &lt;lib dir=\"$&#123;lib.dir&#125;\" /&gt; &lt;classes dir=\"$&#123;build.dir&#125;/classes\" /&gt; &lt;fileset dir=\"$&#123;webRoot.dir&#125;\"&gt; &lt;include name=\"***.*\" /&gt; &lt;/fileset&gt; &lt;/war&gt; &lt;echo message=\"end war...\" /&gt; &lt;/target&gt; &lt;!-- copy war包 tomcat的deploy目录 --&gt; &lt;target name=\"deploy\" depends=\"war\" description=\"部署项目\"&gt; &lt;echo message=\"begin deploy...\" /&gt; &lt;copy file=\"$&#123;dist.dir&#125;/$&#123;webapp.name&#125;.war\" todir=\"$&#123;catalina.home&#125;/webapps\" /&gt; &lt;echo message=\"end deploy...\" /&gt; &lt;/target&gt; &lt;/project&gt; 如构建出现这样的错误（之前使用别的build.xml构建时错误） 大多是工程里缺少文件夹，手动创建即可 走了很多弯路，不过最后成功了","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/tags/Jenkins/"}],"keywords":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/categories/Jenkins/"}]},{"title":"从Docker到Jenkins再到Ansible的部署经验","slug":"从Docker到Jenkins再到Ansible的部署经验","date":"2019-03-17T10:53:04.000Z","updated":"2019-03-17T10:56:53.775Z","comments":true,"path":"Ansible/从Docker到Jenkins再到Ansible的部署经验/","link":"","permalink":"http://blog.ozairs.com/Ansible/从Docker到Jenkins再到Ansible的部署经验/","excerpt":"","text":"从Docker 到Jenkins 到Ansible的部署经验工作中，除了开发功能，还负责系统的部署工作。我从频繁的部署工作中，逐渐找到了一些偷懒的方法。从传统的Java -jar命令启动服务，到通过Docker 容器构建部署服务，再后来通过自动化部署工具Jenkins来完成部署，最后再结合Ansible完成远程部署。一步步的进步极大的减少部署工作，提高了工作效率（增加了许多划水时间）。 Docker简介 Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux机器上，也可以实现虚拟化，容器是完全使用沙箱机制，相互之间不会有任何接口。 Docker给我的印象很深，没有什么环境是docker pull 解决不了的， 常用命令123456789101112131415161718192021222324252627docker ps ， docker ps 默认显示运行中的容器，-a 显示所有，-l显示近期创建的容器docker start xxx ， 启动xxx容器docker restart xxx ， 重启xxx容器docker run xxx ， 创建并运行xxx容器docker build -t xxx . ，使用 Dockerfile 创建镜像docker stop xxx ， 关闭容器docker rm xxx ， 删除容器docker images ， 查看所有镜像docker rmi xxx ， 删除xxx镜像docker exec -it xxx sh ， 进入xxx容器中，用quit退出docker logs -f xxx --tail 500 ， 查看xxx容器的日志，显示最后500行，常用命令docker inspect xxxx ， 查看容器配置信息docker-compose -f app.yml up -d ， 按照app.yml文件配置以debug形式启动docker-compose -f app.yml down ， 按照app.yml文件配置形式关闭 使用场景第一步：在gradle项目加入docker插件，即在gradle.build 文件中加入以下代码。需要注意的有插件的版本，项目打包后的名称，Dockerfile文件目录 1234567891011121314151617dependencies &#123; classpath(&quot;se.transmode.gradle:gradle-docker:1.2&quot;)&#125;apply plugin: &apos;docker&apos;task buildDocker(type: Docker, dependsOn: build) &#123; push = false applicationName = &quot;项目名&quot; dockerfile = file(&apos;src/main/docker/Dockerfile文件目录&apos;) doFirst &#123; copy &#123; from jar into stageDir &#125; &#125;&#125; 第二步：创建Dockerfile文件，文件目录要和第一步中设置的保持一致。需要配置jdk镜像和基本的启动参数 12345678910FROM frolvlad/alpine-oraclejdk8:slimVOLUME /tmpADD 项目jar名称.jar app.jarRUN sh -c &apos;touch /app.jar&apos;ENV JAVA_OPTS=&quot;&quot;ENV PORT=&quot;6666&quot;ENV DB_CONNECTION=&quot;jdbc:mysql://ip:port/database&quot;ENV DB_USER=&quot;user&quot;ENV DB_PASSWORD=&quot;password&quot;ENTRYPOINT [ &quot;sh&quot;, &quot;-c&quot;, &quot;java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar --spring.datasource.url=$DB_CONNECTION --spring.datasource.usernam=$DB_USER --spring.datasource.password=$DB_PASSWORD --port=$PORT&quot;] 第三步：将jar拷贝到服务器上，然后执行编译，运行的docker命令 一）、通过gradle的bootJar，将项目打包。同时需要把引入的第三方jar也要一起打入到项目jar中。 二）、Windows系统中可以通过Xftp将jar和Dockerfile文件拷贝同一个目录下。Linux系统可以通过scp命令上传文件。 三）、执行docker ps，查看当前运行的容器，执行docker stop和docker rm 关闭和删除之前旧版本的容器 四）、找到jar的目录，并在当前目录下，执行 docker build -t 镜像名称 . 的命令编译项目，注意后面的点不要漏了。 五）、编译成功后执行 docker run –name 容器名 -v /tmp:/tmp -p 对外开发的端口:项目启动的端口 镜像名:latest 。启动容器 六）、执行docker ps，查看容器启动是否正常启动。同时执行docker logs -f 容器名 –tail 500，查看容器启动日志，检查是否有异常 七）、最后浏览器访问一下，已确保部署成功。 全称大概需要几分钟的时间，虽然不算麻烦。可次数多了，就很麻烦了。有没有什么好的工具帮助我们完成这一系列操作呢？答案是肯定的。 Jenkins简介 The leading open source automation server, Jenkins provides hundreds of plugins to support building, deploying and automating any project. Jenkins 的logo是一个管家的形象，很贴切。对它的理解比较肤浅。他通过管理Git上的项目，来确保每次打包的jar都是最新的。同时在构建成功后执行我们输入的shell命令，来达到自动化部署的工作。 使用场景第一步：创建一个负责编译的Jenkins项目， 在Jenkins控制台页面，点击页面左上角的“新建”按钮。再输入项目名后，可以选择创建一个空项目，也可以在页面最下面选择copy from 其他项目。不管如何创建，我们需要Jenkins管理项目的源码，构建和构建后的操作。 第二步：创建一个负责运行的Jenkins项目 以同样的方式创建项目，在构建触发器上，选择第一步创建的项目，构建的Shell命令是先删除之前的容器，然后在重新运行容器。若之前的容器不存在，则会构建失败。所以第一次构建的时候把第一行命令删掉。解决方案傻乎乎的，只是因为没有花时间去处理。 第三步：选择编译项目，点击立即构建，当第一个项目构成成功后，会自动触发运行项目。等待两个项目都成功后，就可以访问浏览器，检查功能。 有了Jenkins，一切变得轻松很多。但他也有一个较大的弊端，就是使用前必须要先安装。特别是在客户的服务器上，也许别人就只跑这一个服务，你给别人整了一个Jenkins，似乎有点大材小用了。有没有好的解决方法？答案是肯定的。 Ansible简介 Ansible is an IT automation tool. It can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates. 从接触到使用Ansible大概有一天的时间，对它的理解也是比较肤浅。我单纯的认为，他可以帮助我们在服务器之间传输文件，同时还可以执行一些shell命令。抱着这样的想法，我们可以通过Jenkins完成自动化编译，再通过Ansible传输资源文件到部署的环境中，同时执行启动Shell命令。 使用场景第一步：修改Jenkins运行项目的构建Shell，将之前的docker run改成 1ansible-playbook ansible命令文件路径/app.yaml 第二步：创建Ansible脚本文件app.yaml，目录和第一步中设置的保存一致，模版大致如下 12345678910111213141516171819202122- hosts: &apos;需要部署的远程服务ip&apos; tasks: - name: &quot;关闭旧版本的容器&quot; shell: docker stop xxx ignore_errors: true - name: &quot;删除旧版本的容器&quot; shell: docker rm xxx ignore_errors: true - name: &quot;删除之前的旧文件&quot; shell: rm -rf /旧文件路径/* - name: &quot;传输Dockerfile文件&quot; copy: src=/文件目录/Dockerfile dest=/远程服务指定目录 - name: &quot;传输Jar文件&quot; copy: src=/jar目录/xxx.jar dest=/远程服务指定目录 - name: &quot;构建docker 镜像&quot; shell: chdir=/jar所在目录 nohup docker build -t 镜像名 . - name: &quot;启动容器&quot; shell: nohup docker run --name 容器名 -v /挂载路径/:/挂载路径/ -p 对外端口:服务端口 -d 镜像名:latest 第三步：在Jenkins上构建编译项目。 前后端项目的部署到这里，三种部署的流程就完成了。如果你熟悉Docker的方式构建，再用Jenkins和Ansible的时候，就会简单很多。我在实际开发中，项目是前后端分离的。公司做了两个方案， 第一种：前后端分开部署，即Jenkins上有四个项目。前端和后端各两个项目。这样的好处就是前后端互不影响。不会因为对方的错误而从新编译。缺点也是有的，很难保证对方部署的环境是最新的。 第二种：把前后端放在一个项目中，一次构建完成两个项目的打包部署。缺点是构建慢，优点就是保证两端的代码都是最新的，适合发布到预发布环境和正式环境。 那么，针对前后端一起部署的需求，Jenkins和Ansible同样也需要简单的修改。其思路就是Jenkins负责编译项目，将资源文件压缩，再通过Ansible上传到其他服务器上。执行解压，构建，启动的命令。 看起来视乎很简单，但有一个坑希望你们跨过去。前端打包需要npm或者其他工具，但是你的服务器上没有安装。此时请务必通过Jenkins控制台，或者用Jenkins帐号登录服务器安装这些工具。笔者就是通过root帐号登录服务器安装的npm，通过Jenkins编译时提示没有权限。","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"},{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}]},{"title":"ansible-playbook之roles实现","slug":"ansible-playbook之roles实现","date":"2019-03-17T10:19:21.000Z","updated":"2019-03-17T10:26:15.653Z","comments":true,"path":"Ansible/ansible-playbook之roles实现/","link":"","permalink":"http://blog.ozairs.com/Ansible/ansible-playbook之roles实现/","excerpt":"","text":"一、目标两台主机：192.168.50.138（安装ansible）、192.168.50.139 [webservers]192.168.50.138 httpd_point=80192.168.50.139 httpd_point=8080实现在两台主机上同时安装apache，提供配置文件，并启动。在139主机上提供mysql服务。 hosts: allremote_user: rootroles: apache hosts: 192.168.50.139remote_user: rootroles: apache mysql二、roles之apache1、创建目录 mkdir -pv /ansible_playbooks/roles/{apache,mysql}/{tasks,files,templates,meta,handlers,vars}2、复制一份httpd配置文件作为template cp /etc/httpd/conf/httpd.conf /ansible_playbooks/roles/apache/templates/编辑此配置文件做变量引用 Listen 3、编写tasks任务 [root@node1 apache]# vim tasks/main.yml name: install httpdyum: name=httpd state=latest name: install configtemplate: src=httpd.conf dest=/etc/httpd/conf/httpd.confnotify: restart apache name: start apacheservice: name=httpd state=started4、编写handlers [root@node1 apache]# vim handlers/main.yml name: restart apacheservice: name=httpd state=restarted三、roles之mysql1、复制一份mysql配置文件到files文件中 cp /etc/my.cnf /ansible_playbooks/roles/mysql/files/2、编写tasks任务[root@node1 mysql]# vim /ansible_playbooks/roles/mysql/tasks/main.yml name: install mysqlyum: name=mariadb state=latest name: install config-mysqlcopy: src=my.cnf dest=/etc/my.cnf name: start mariadbservice: name=mariadb state=started四、编写剧本 [root@node1 mysql]# vim /ansible_playbooks/site.yml hosts: allremote_user: rootroles: apache hosts: 192.168.50.139remote_user: rootroles: apache mysql五、执行剧本 [root@node1 handlers]# ansible-playbook /ansible_playbooks/site.yml PLAY [all] *** TASK [Gathering Facts] ***ok: [192.168.50.139]ok: [192.168.50.138] TASK [apache : install httpd] **ok: [192.168.50.138]ok: [192.168.50.139] TASK [apache : install config] ***ok: [192.168.50.139]ok: [192.168.50.138] TASK [apache : start apache] *ok: [192.168.50.139]ok: [192.168.50.138] PLAY [192.168.50.139] ** TASK [Gathering Facts] ***ok: [192.168.50.139] TASK [apache : install httpd] **ok: [192.168.50.139] TASK [apache : install config] ***ok: [192.168.50.139] TASK [apache : start apache] *ok: [192.168.50.139] TASK [mysql : install mysql] *ok: [192.168.50.139] TASK [mysql : install config-mysql] **changed: [192.168.50.139] TASK [mysql : start mariadb] *changed: [192.168.50.139] PLAY RECAP ***192.168.50.138 : ok=4 changed=0 unreachable=0 failed=0192.168.50.139 : ok=11 changed=2 unreachable=0 failed=0 成功！！！","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"}],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}]},{"title":"Ansible实战汇总","slug":"Ansible实战汇总","date":"2019-03-17T10:05:37.000Z","updated":"2019-03-31T12:05:28.334Z","comments":true,"path":"Ansible/Ansible实战汇总/","link":"","permalink":"http://blog.ozairs.com/Ansible/Ansible实战汇总/","excerpt":"","text":"Ansible 实战目录 一、Ansible与Terraform相结合 1、使用Ansible和Terraform在AWS上构建Docker Swarm集群； https://hackernoon.com/setup-docker-swarm-on-aws-using-ansible-terraform-daa1eabbc27d 二、Ansible部署Application 1、通过Ansible Playbook安装laraval App in VPS Ansible in action 三、Ansible操作Docker容器 1、使用 Ansible 高效交付 Docker 容器 https://www.ibm.com/developerworks/cn/cloud/library/cl-provision-docker-containers-ansible/index.html 2、基于 docker 的 jenkins-ansible-gitlab 实现自动化部署 https://www.jianshu.com/p/191f0c81c6bb","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"}],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}]},{"title":"为什么我们抛弃ECS而选择了Kubernetes","slug":"为什么我们抛弃ECS而选择了Kubernetes","date":"2019-03-17T05:18:22.000Z","updated":"2019-03-17T05:20:40.489Z","comments":true,"path":"Kubernetes/为什么我们抛弃ECS而选择了Kubernetes/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/为什么我们抛弃ECS而选择了Kubernetes/","excerpt":"","text":"在这篇文章中我们将会探讨2个主流的Docker编排框架：AWS的ECS（Elastic Container Service）和Google的Kubernetes。 3个月前，我们在 nanit.com 希望选择一个合适的Docker编排框架，ECS成为了我们的首选，毕竟，我们对AWS的服务较为熟悉，并且我们的基础设施都是建立在AWS的。经过一段时间的测试，我们发现ECS并不成熟，缺少一些我们需要的关键功能，因此我们开始尝试其他的框架：Kubernetes。令人意外的是，Kubernetes非常成熟，几乎支持我们需要的所有功能。对于我们来说，Kubernetes在ECS的主场完胜了ECS。接下来，就让我们一起来看看Kubernetes赢在哪些方面。 注意：ECS一直在更新，我们会尽可能的跟进这些内容，但部分内容可能被忽略了，希望读者不要介意。 构建集群（Cluster Setup）ECS:为了启动一个ECS集群，用户需要设置一个Auto Scaling Group。用户可以编辑user-data来将EC2实例添加到指定的ECS集群上。当ASG被设置，实例启动之后，用户可以在ECS控制台看到这部分内容。现在，用户可以开始进行task-definition，方式类似于Docker-compose。 Kubernetes：想要在AWS上启动一个Kubernetes，用户需要先启动一个具有一定权限的EC2实例（通过IAM）。这将会创建多个AWS constructs来支持你的集群：VPC、ASG、一些安全组（Security Groups）和一个Kubernetes主实例。集群需要几分钟来启动，之后用户就能够在上面运行自己的容器。 比较结果：使用这两种框架来启动一个集群都非常的简单和友好。 启动基础服务（Basic Service Setup）我们的任务是启动一个Nginx 镜像，并且让其他人能够访问这个Web服务。 ECS: 首先，我们需要创建一个ELB(Elastic Load Balancer)，它负责80端口的转发。然后，我们需要创建一个task-definition，它负责在80端口上启动一个Docker镜像。最后，需要创建一个Service，它会显示出有多少实例会同时运行。我们需要将它绑定到我们之前创建的ELB上。 Kubernetes：首先需要创建一个Replication Controller，它会显示出我们希望运行的Docker镜像和有多少镜像会同时运行。之后，我们需要创建一个Service object，这会启动一个ELB并且将ELB的流量转发到对应的容器上。 比较结果：Kubernetes的方式更舒服一些，更简洁。用户并不需要手工启动或者管理ELB。Kubernetes会完全负责管理：当用户创建了一个service，一个ELB会自动创建；当用户删除了一个service，它会自动从AWS上删除。 服务发现（Service Discovery）当你使用了微服务架构和Docker，一个好的服务发现解决方案是至关重要的。Docker容器总是在不同虚拟机中迁移，用户必须有一个可靠的方法来发现在集群内和集群外的服务。 ECS: ECS并没有提供任何服务发现的解决方案。我能想到的最好方法就是构建一个内部加载平衡器（internal load balancer），并且将每一个service附加到一个平衡器上。平衡器的host name不会被改变，然后你就能够利用这个host name来作为服务的端点。其他的方法还有集成一个外部的程序，比如 Consul 。 Kubernetes：我认为这是Kubernetes的亮点之一。Kubernetes内置了一个完全的解决方案。它是一个插件，因此用户可以选择是否使用，但我强烈建议使用。它能够和namespace一起很好的工作。简单来说，当你创建了一个Kubernetes服务，比如说叫做redis，你就能够在集群的任何地方引用redis这个名字，即便是跨虚拟机。这就像是让docker网络跨越了特定的虚拟机，连通了整个集群。Namespaces允许你将多个服务归纳到一个具有逻辑的组中。现在假设我们有两个命名空间，分别是production和staging，他们都包含有一个redis的服务。一个在production命名空间下的容器可以通过redis来引用在production命名空间下的redis服务，同样的，在stagin命名空间下的容器也能通过redis来引用到位于stagine命名空间下的redis服务。这种自动化识别使得用户不需要花费时间去配置信息就能够构建一个隔离的环境，并且你可以随意在所有的命名空间中使用redis来引用对应的服务，接下来kunernetes会为你自动解析它们。 比较结果：毫无疑问，Kubernetes小胜一局。使用Kubernetes，用户完全不用关心服务发现的事情，全部交给Kubernetes来做就好了：） 部署（Deployments）当我们升级一个服务的时候，即便还在部署，我们也想要确保它百分之百能用。我们的测试包括一个简单的NginX服务和一些简单的静态网页。我们启动了一个并发为30个请求的负载测试，并且在负载测试期间，我们会对该服务进行升级。 在部署期间，我们发现ECS丢失了比Kubernetes更多的请求。其中，Kubernetes丢失了0-2个请求，而ECS丢失了9-14个。 比较结果：说实话，我对ECS非常的失望。同样，我也对Kubernetes表示失望，但是它至少比ECS好多了。值得注意的是，Kubernetes 1.1.1版本应该会对轮询升级机制（rollong update mechanism）进行改善，还有一些其他的系统系能提升，这些改进都会使得这些数字变得更好看。 持久卷（Persistent Volumes）我们经常需要挂载一些持久性的文件系统到一个指定的容器上，MySQL就是一个典型的例子。 ECS：ECS支持Docker原生的解决方案——用户可以启动一个数据容器，然后使用volumes-from命令来挂载它到其他容器上。就拿MySQL来看，你首先需要设置一个mysql-data容器，这个容器仅仅拥有一个数据卷。然后设置另外一个mysql-db容器，这个容器使用volumes-from命令来挂载之前创建的数据卷容器。这个方法看起来不错，但是它是host-sepicific的，这意味着你的mysql-db容器不能够在主机之间移动。你必须指定mysql-db容器在哪一个主机上运行，以此来防止容器被重新分配到其他主机上，最终失去了持久性。 Kubernetes：除了从一个指定的主机上挂载数据卷，Kubernetes还提供了一个选项：挂载一个EBS（Elastic Book Store）数据卷。这意味着一个容器的持久性存储可以在多个不同的虚拟机之间保留。你再也不需要强制你的MySQL容器必须运行在哪一个具体的虚拟机上。 注意：EBS同一时间只能被一个虚拟机挂载，这意味着如果有一个服务，它有两个运行在不同虚拟机的容器，他们将不能够挂载和共享这个EBS。 比较结果：即便Kubernetes的EBS挂载有一定的限制，但它依旧非常的独特和有用。 健康检查（Health-Checks）确保拥有足够的服务容量是高可用性和冗余性的核心思想。健康检查就是用来确保服务不仅仅是运行的，并且它们还是健康和可操作的。 ECS：ECS使用ELB(Elastic Load Balancer)健康检查，这种方式有三个主要的缺点： \\1. ELB健康检查仅仅限于HTTP/TCP检查 \\2. 如果你想要对一个不开放TCP端口的服务进行检查，这是不行的。仅仅是为了能够进行健康检查，你就必须运行一个HTTP/TCP服务器。 \\3. 即便你拥有一个支持HTTP/TCP的服务，你还需要创建一个ELB，并将它绑定到这个服务上，这样才能进行健康检查。 Kubernetes：除了基于HTTP/TCP的健康检查，Kubernetes还提供了一种叫做Exec的方式。Exec可以让用户在容器中运行命令。如果命令结束，并且返回0则表示这个服务是健康的，否则这个服务很可能是不健康的，它会被其他的实例所替换。 比较结果：Kubernetes的方式更灵活，更简单配置。用户并不需要去启动一个冗余的HTTP/TCP服务器仅仅为了进行健康检查，并且即便服务没有绑定ELB，你也可以对它们进行健康检查。 端口管理（Port Management）从我们的上篇文章中可以看出，端口管理在Docker中是比较困难的。我们想通过一个简单的例子来说明Kubernetes如何比ECS更优雅的解决了这个问题。我们拥有一台虚拟机和两个监听80端口的网站。我们不能够在同一个虚拟机上开2个80端口，因此我们需要寻找一个方法来解决这个问题。 ECS:用户必须手工确定两个服务没有使用同一个端口。我们只有一台虚拟机，因此只能运行一个开放80端口的容器。当我们想要开启第二个开放80端口的容器时，这是不行的，因为我们没有多余的虚拟机了。也就是说，能够开放多少个x端口的服务取决于拥有多少个虚拟机。在小型集群中，这是非常容易满足的条件，但是当你的服务数量变得越来越多时，这将成为一个头疼的问题，因为当你想要扩充容器时，你必须确认你还有足够的端口。 Kubernetes：Kubernetes非常优雅的解决了这个问题。它为每一个虚拟机上的容器都分配了一个随机的端口。然后它创建了2个ELB，一个将80端口转发到容器A的随机端口上，另外一个转发到容器B的随机端口上。一个内部的路由机制会负责将数据包转发到对应容器端口。 比较结果：Kubernetes使用虚拟端口的方式代替绑定原始端口的方法，很好的解决了这个头疼的问题。 记录（Logging）没有什么系统不需要记录功能。 我从没有想过记录会成为一个大问题，但能够为你解决问题令我非常的高兴，即便这个问题非常简单。我们之前提到Kubernetes提供了一个服务发现的扩展功能，在这里，我想说的是记录的扩展功能。它含有两个不同的记录和度量收集（metric collection）的机制。第一种是著名的 ELK 方法，ELK会收集容器的所有记录，并且能够让用户通过Kibana接口来查询和可视化这些记录。第二种是InfluxDB，它使用 Grafana 作为可视化工具来查询系统信息，如CPU和内存使用情况。 比较结果：Kubernetes的扩展功能更胜一筹。当然，你会说我并不需要这些扩展，系统也能很好工作，但是，它们效果如此之好，并且能适用于99%的用例，为什么不使用呢？ECS并没有提供内置的记录功能，用户想要集成一个进去并不是很困难，但是这些并不能和Kubernetes提供的功能相提并论。 未知的云平台（Cloud Agnostic）其实，Kubernetes和ECS之间并不存在竞争：） ECS会专注于AWS平台，如果你已经在ECS上构建了你的基础架构，当你想要转移到其他云平台时，你将会遇到很多困难。 Kubernetes适用于多个云平台。你可以在AWS，Google Cloud，微软的ZURE，Rackspace等等上运行你的集群，并且运行效果或多或少都是相同的。在这里，或多或少指的是有一些功能只有部分云供应商提供。你必须确认你选择的新供应商能够支持Kubernetes中使用的功能，至少确保迁移是可能的。 开源软件（OSS）Kubernetes是开源的项目，而ECS不是。这意味着，所有的一切，从源代码到未来的发展路线都是对你开放的。发现了漏洞？你可以创建一个issue或者直接提交一个pull 请求来修复它。新的功能会被添加到每一个新版本，其中的贡献人数和pull请求是惊人的。 ECS有着不同的性质，我不能够在网上找到关于它未来发展路线的规划。你不能够获得一个漏洞和issue的列表，你必须深入到论坛上去寻找想要的答案。并且你寻找的答案往往都是缺乏实际的，并不能够提供任何帮助（请看 这里 ）。也许这仅仅是因为我个人的糟糕经历，但是不管怎么说，这都是令人烦躁和失望的。 比较结果：就我个人而言，我更喜欢开源软件。我喜欢Kubernetes的开放性，每个人都能够参与讨论和贡献代码。我相信社区的力量会给我们带来一个更好的产品。 多可用区域（Multi-AZ）当谈论到Kubernetes时，有一件事情困扰着我：它不支持AWS上的多可用区域集群（multiple availability-zones cluters）。这意味着所有EC2实例都集中在一个AZ上，这使得你的集群很可能会遭受到中断问题。 ECS有对Multi-AZ有很好的支持。 比较结果：在Kubernetes的issue上，已经有一些工作正在进行。我十分确定下个版本会很好的得到改善。因此ECS在这一点上的胜利并不会长久。 总结很多公司都开始使用Docker作为他们的主要基础设置，传递机制（delivery mechanism）和编排框架（orchestration frameworks）成为了系统的核心，并且影响着我们开发，迁移，运行，升级的方式。当我想要比较ECS和Kubernetes时，我找不到类似的文章。所以我认为把我们的经验公布出来非常的重要，这样其他人能够站在我们的肩膀上看的更远。 对于nanit.com来说，Kubernetes毫无疑问获得了胜利。如果你有任何的异议，请告诉我理由，我非常想要知道这些内容：）","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/tags/Kubernetes/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"Jenkins与Docker的自动化CI/CD实战","slug":"Jenkins与Docker的自动化CI-CD实战","date":"2019-03-17T02:48:26.000Z","updated":"2019-03-17T03:02:41.598Z","comments":true,"path":"DevOps/Jenkins与Docker的自动化CI-CD实战/","link":"","permalink":"http://blog.ozairs.com/DevOps/Jenkins与Docker的自动化CI-CD实战/","excerpt":"","text":"在互联网时代，对于每一家公司，软件开发和发布的重要性不言而喻，目前已经形成一套标准的流程，最重要的组成部分就是持续集成（CI）及持续部署、交付（CD）。本文基于Jenkins+Docker+Git实现一套CI自动化发布流程。 一、发布流程设计 工作流程：** 开发人员提交代码到Git版本仓库； Jenkins人工/定时触发项目构建； Jenkins拉取代码、代码编码、打包镜像、推送到镜像仓库； Jenkins在Docker主机创建容器并发布。 环境规划如下： 角色 IP Jenkins/Docker 192.168.0.217 Docker 192.168.0.218 Git/Registry 192.168.0.219 操作系统：CentOS7.4 二、部署Git仓库1# yum install git -y 创建Git用户并设置密码 12# useradd git# passwd git 创建仓库 1234# su - git# mkdir solo.git# cd solo.git# git --bare init 访问创建的这个仓库 1# git clone git@192.168.0.212:/home/git/solo.git 三、准备Jenkins环境Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于代码编译、部署、测试等工作。 Jenkins也是一个跨平台的，大多数主流的平台都支持，而且安装很简单，我们这里以部署war包方式安装它。官网下载地址：https://jenkins.io/download/ 在安装前需要具备Java环境，安装方式如下： 12345678# tar zxf jdk-8u45-linux-x64.tar.gz # mv jdk-8u45-linux-x64 /usr/local/jdk1.8 # vi /etc/profile JAVA_HOME=/usr/local/jdk1.8 PATH=$PATH:$JAVA_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME PATH CLASSPATH# source /etc/profile 在192.168.0.217主机安装Jenkins，下载Tomcat二进制包将war包到webapps下即可：** 12345678910111213141516# wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war # wget http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz # tar zxf apache-tomcat-8.5.32.tar.gz # mv apache-tomcat-8.5.32 /usr/local/tomcat-jenkins # rm /usr/local/tomcat-jenkins/webapps/* -rf # unzip jenkins.war -d /usr/local/tomcat-jenkins/webapps/ROOT # cd /usr/local/tomcat-jenkins/bin/ # ./startup.sh # tail ../logs/catalina.out -f ... Jenkins initial setup is required. An admin user has been created and a password generated. Please use the following password to proceed to installation: a5f1f7c167fd4b8ab62f9497d32d97db This may also be found at: /root/.jenkins/secrets/initialAdminPassword ... 部署成功，访问Jenkins：http://ip:8080 第一步：输入上面日志输出的密码：a5f1f7c167fd4b8ab62f9497d32d97db，或者从本机/root/.jenkins/secrets/initialAdminPassword文件获取，点击继续第二步：点击“选择插件来安装”第三步：保持默认，点击继续第四步：创建管理员用户，保存并完成第五步：设置Jenkins访问地址，保持默认，点击保存完成 安装完成，开始使用Jenkins： 四、部署私有镜像仓库Docker Hub作为Docker默认官方公共镜像；如果想自己搭建私有镜像仓库，官方也提供registry镜像，使得搭建私有仓库非常简单。在192.168.0.219部署： 1# docker run -d -v /opt/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry 接下来测试registry可用性。由于Docker CLI默认以HTTPS访问，而部署的registry并未提供HTTPS，因此，需要在pull镜像的Docker主机（192.168.0.217，192.168.0.218）添加HTTP可信任： 123 # vi /etc/docker/daemon.json &#123;&quot;insecure-registries&quot;:[&quot;192.168.0.219:5000&quot;]&#125;# service docker restart 五、安装Docker在192.168.0.217/192.168.0.218/192.168.0.219主机安装Docker，如下： 安装依赖包 1# yum install -y yum-utils device-mapper-persistent-data lvm2 添加Docker软件包源： 123# yum-config-manager \\--add-repo \\https://download.docker.com/linux/centos/docker-ce.repo 安装Docker CE 1# yum install docker-ce -y 配置加速器 1# curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://bc437cce.m.daocloud.io 启动并开机启动 12# systemctl start docker# systemctl enable docker 六、构建Tomcat基础镜像JAVA程序必须有JDK环境才可以运行，为了减少镜像大小及提高性能，这里直接把JDK放到宿主机上，容器以挂载形式使用。在192.168.0.217/192.168.0.218安装JDK： 12# tar zxvf jdk-8u45-linux-x64.tar.gz # mv jdk-8u45-linux-x64 /usr/local/jdk1.8 Tomcat基础镜像Dockerfile： 1234567891011121314151617# cat DockerfileFROM centos:7MAINTAINER www.aliangedu.comENV VERSION=8.5.32ENV JAVA_HOME /usr/local/jdkRUN yum install wget -yRUN wget http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v$&#123;VERSION&#125;/bin/apache-tomcat-$&#123;VERSION&#125;.tar.gz &amp;&amp; \\ tar zxf apache-tomcat-$&#123;VERSION&#125;.tar.gz &amp;&amp; \\ mv apache-tomcat-$&#123;VERSION&#125; /usr/local/tomcat &amp;&amp; \\ rm -rf apache-tomcat-$&#123;VERSION&#125;.tar.gz /usr/local/tomcat/webapps/* &amp;&amp; \\ mkdir /usr/local/tomcat/webapps/ROOTEXPOSE 8080CMD [&quot;catalina.sh&quot;, &quot;run&quot;] 构建镜像并上传到registry： 12# docker build -t 192.168.0.219:5000/tomcat-85 -f Dockerfile .# docker push 192.168.0.219:5000/tomcat-85 七、Jenkins配置全局工具配置主页面 -&gt; 系统管理 -&gt; 全局工具配置 指定JDK、Maven路径，Git保持默认：如果Jenkins主机没有git命令，需要安装Git：# yum install git -y 八、Jenkins安装必要插件1. Jenkins安装必要插件主页面 -&gt; 系统管理 -&gt;管理插件：安装SSH与Git Parameter插件。 插件说明： SSH：用于SSH远程Docker主机执行Shell命令 Git Parameter：动态获取Git仓库Branch、Tag 2. 配置SSH插件第一步：先创建一个用于连接Docker主机的凭据。主页面 -&gt; 凭据 -&gt; 系统 -&gt; 右击全局凭据 -&gt; 添加凭据：输入连接Docker主机的用户名和密码：第二步：添加SSH远程主机主页面 -&gt; 系统管理 -&gt; 系统设置 -&gt; SSH remote hosts： 九、上传JAVA项目代码到Git仓库从Github拉取开源JAVA博客系统solo： 12345678910111213# git clone https://github.com/b3log/solo# cd solo移除旧的推送地址，添加新的：# git remote remove origin # git remote add origin git@192.168.0.219:/home/git/solo.git提交代码到Git仓库并创建tag：# touch src/main/webapp/a.html# git add .# git commit -m “a”创建标签：# git tag 1.0.0推送到Git服务器：# git push origin 1.0.0 十、Jenkins创建项目并发布测试主页面 -&gt; 新建任务 -&gt; 输入任务名称，构建一个Maven项目：注意：如果没有显示“构建一个Maven项目”选项，需要在管理插件里安装“Maven Integration plugin”插件。配置Git参数化构建：动态获取Git仓库tag，与用户交互选择Tag发布：指定项目Git仓库地址：修改*/master为$Tag，Tag是上面动态获取的变量名，表示根据用户选择打代码版本。 设置maven构建命令选项： 利用pom.xml文件构建项目。在Jenkins本机镜像构建与推送到镜像仓库，并SSH远程连接到Docker主机使用推送的镜像创建容器：上图中，在Jenkins主机执行的Shell命令如下： 1234567891011REPOSITORY=192.168.0.219:5000/solo:$&#123;Tag&#125;# 构建镜像cat &gt; Dockerfile &lt;&lt; EOFFROM 192.168.0.219:5000/tomcat-85:latestRUN rm -rf /usr/local/tomcat/webapps/ROOTCOPY target/*.war /usr/local/tomcat/webapps/ROOT.warCMD [&quot;catalina.sh&quot;, &quot;run&quot;]EOFdocker build -t $REPOSITORY .# 上传镜像docker push $REPOSITORY 上图中，SSH远程Docker主机执行的Shell命令如下： 12345REPOSITORY=192.168.0.219:5000/solo:$&#123;Tag&#125;# 部署docker rm -f blog-solo |truedocker image rm $REPOSITORY |truedocker container run -d --name blog-solo -v /usr/local/jdk1.8:/usr/local/jdk -p 88:8080 $REPOSITORY 注：容器名称blog-solo，暴露宿主机端口88，即使用宿主机IP:88访问blog-solo项目。blog-solo项目已配置完成，开始构建： 选择tag，开始构建： 点击左下角构建历史里，右击第一个查看控制台输出： 浏览器访问solo项目：http://192.168.0.218:88如果输出上述页面说明是正常的，页面没有加载成功样式，需要修改下项目里访问地址。 至此，自动化CI环境搭建完成，你可以模拟提交代码并打tag测试自动化发布流程。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.ozairs.com/tags/Jenkins/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"把一个Node.js web应用程序给Docker化","slug":"把一个Node-js-web应用程序给Docker化","date":"2019-03-17T02:26:13.000Z","updated":"2019-03-17T03:02:41.595Z","comments":true,"path":"DevOps/把一个Node-js-web应用程序给Docker化/","link":"","permalink":"http://blog.ozairs.com/DevOps/把一个Node-js-web应用程序给Docker化/","excerpt":"","text":"本示例的目标是给你演示如何将一个 Node.js 的应用装入到 Docker 容器中。本教程旨在针对于开发人员，而 非 产品发布人员。此教程同样假定你有一个可以正常工作的 Docker 安装，并且对于 Node.js 的应用程序是如何组织的有一个大致的基本了解。 在本教程的第一部分我们在 Node.js 中创建一个 Web 的应用程序，然后我们为那个应用构建一个 Docker 镜像；最后我们将把那个镜像作为容器运行之。 Docker 允许你以应用程序所有的依赖全部打包成一个标准化的单元，这被成为一个容器。对于应用开发而言，一个容器就是一个蜕化到最基础的 Linux 操作系统。一个镜像是你加载到容器中的软件。 创建 Node.js 应用首先，创建一个新文件夹以便于容纳需要的所有文件，并且在此其中创建一个 package.json 文件，描述你应用程序以及需要的依赖： 12345678910111213&#123; \"name\": \"docker_web_app\", \"version\": \"1.0.0\", \"description\": \"Node.js on Docker\", \"author\": \"First Last &lt;first.last@example.com&gt;\", \"main\": \"server.js\", \"scripts\": &#123; \"start\": \"node server.js\" &#125;, \"dependencies\": &#123; \"express\": \"^4.16.1\" &#125;&#125; 配合着你的 package.json 请运行 npm install。如果你使用的 npm 是版本 5 或者之后的版本，这会自动生成一个 package-lock.json 文件，它将一起被拷贝进入你的 Docker 镜像中。 然后，创建一个 server.js 文件，使用 Express.js 框架定义一个 Web 应用： 12345678910111213141516'use strict';const express = require('express');// Constantsconst PORT = 8080;const HOST = '0.0.0.0';// Appconst app = express();app.get('/', (req, res) =&gt; &#123; res.send('Hello world\\n');&#125;);app.listen(PORT, HOST);console.log(`Running on http://$&#123;HOST&#125;:$&#123;PORT&#125;`); 在稍后的步骤中我们将看一下借助使用官方的 Docker 镜像，你如何在 Docker 镜像中运行这个应用。首先，你需要一个构建一个应用程序的 Docker 应用。 创建一个名称为 Dockerfile 的文件创建一个空文件，命名为 Dockerfile： 1touch Dockerfile 用你最喜欢的文本编辑器打开这个 Dockerfile。 我们要做的第一件事是定义我们需要从哪个镜像进行构建。这里我们将使用最新的 LTS（长期服务器支持版），Node 的版本号为 8。你可以从 Docker 站点 获取相关镜像： 1FROM node:8 下一步在镜像中创建一个文件夹存放应用程序代码，这将是你的应用程序工作目录： 12# Create app directoryWORKDIR /usr/src/app 此镜像中 Node.js 和 NPM 都已经安装，所以下一件事对于我们而言是使用 npm 安装你的应用程序的所有依赖。请注意，如果你的 npm 的版本是 4 或者更早的版本，package-lock.json 文件将不会自动生成。 12345678# Install app dependencies# A wildcard is used to ensure both package.json AND package-lock.json are copied# where available (npm@5+)COPY package*.json ./RUN npm install# If you are building your code for production# RUN npm ci --only=production 请注意，我们只是拷贝了 package.json 文件而非整个工作目录。这允许我们利用缓存 Docker 层的优势。bitJudo 对此有一个很好的解释，请 见此。 进一步说，对于生产环境而言，注释中提及的 npm ci 命令协助提供了一个更快、可靠、可再生的构建环境。欲知详情，可以参考此处。 在 Docker 镜像中使用 COPY 命令绑定你的应用程序： 12# Bundle app sourceCOPY . . 你的应用程序绑定的端口为 8080，所以你可以使用 EXPOSE 命令使它与 docker 的镜像做映射： 1EXPOSE 8080 最后但同样重要的事是，使用定义运行时的 CMD 定义命令来运行应用程序。这里我们使用最简单的 npm start 命令，它将运行 node server.js 启动你的服务器： 1CMD [ \"npm\", \"start\" ] 你的 Dockerfile 现在看上去是这个样子： 12345678910111213141516171819FROM node:8# Create app directoryWORKDIR /usr/src/app# Install app dependencies# A wildcard is used to ensure both package.json AND package-lock.json are copied# where available (npm@5+)COPY package*.json ./RUN npm install# If you are building your code for production# RUN npm ci --only=production# Bundle app sourceCOPY . .EXPOSE 8080CMD [ \"npm\", \"start\" ] .dockerignore 文件在 Dockerfile 的同一个文件夹中创建一个 .dockerignore 文件，带有以下内容： 12node_modulesnpm-debug.log 这将避免你的本地模块以及调试日志被拷贝进入到你的 Docker 镜像中，以至于把你镜像原有安装的模块给覆盖了。 构建你的镜像进入到 Dockerfile 所在的那个目录中，运行以下命令构建 Docker 镜像。开关符 -t 让你标记你的镜像，以至于让你以后很容易地用 docker images 找到它。 1$ docker build -t &lt;your username&gt;/node-web-app . Docker 现在将给出你的镜像列表： 123456$ docker images# ExampleREPOSITORY TAG ID CREATEDnode 8 1934b0b038d1 5 days ago&lt;your username&gt;/node-web-app latest d64d3505b0d2 1 minute ago 运行镜像使用 -d 模式运行镜像将以分离模式运行 Docker 容器，使得容器在后台自助运行。开关符 -p 在容器中把一个公共端口导向到私有的端口，请用以下命令运行你之前构建的镜像： 1$ docker run -p 49160:8080 -d &lt;your username&gt;/node-web-app 把你应用程序的输出打印出来： 12345678# Get container ID$ docker ps# Print app output$ docker logs &lt;container id&gt;# ExampleRunning on http://localhost:8080 如果你需要进入容器中，请运行 exec 命令： 12# Enter the container$ docker exec -it &lt;container id&gt; /bin/bash 测试为测试你的应用程序，给出与 Docker 映射过的端口号： 12345$ docker ps# ExampleID IMAGE COMMAND ... PORTSecce33b30ebf &lt;your username&gt;/node-web-app:latest npm start ... 49160-&gt;8080 在上面的例子中，在容器中 Docker 把端口号 8080 映射到你机器上的 49160 。 现在你可以使用 curl（如果需要的话请通过 sudo apt-get install curl 安装）调用你的程序了： 1234567891011$ curl -i localhost:49160HTTP/1.1 200 OKX-Powered-By: ExpressContent-Type: text/html; charset=utf-8Content-Length: 12ETag: W/\"c-M6tWOb/Y57lesdjQuHeB1P/qTV0\"Date: Mon, 13 Nov 2017 20:53:59 GMTConnection: keep-aliveHello world 我们希望本教程能够帮助你起步，在 Docker 中运行一个简单的 Node.js 应用程序。 你也可以在以下一些地方寻觅到更多有关于 Docker 和基于 Docker 的 Node.js 相关内容： 官方 Node.js 的 Docker 镜像 Node.js 基于 Docker 使用的最佳经验 官方 Docker 文档 在 StackOverFlow 上有关 Docker 标记内容 Docker Subreddit","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"NodeJs","slug":"NodeJs","permalink":"http://blog.ozairs.com/tags/NodeJs/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"CloudFormation CLI命令","slug":"CloudFormation-CLI命令","date":"2019-03-16T11:47:59.000Z","updated":"2019-03-16T11:52:06.439Z","comments":true,"path":"AWS/CloudFormation-CLI命令/","link":"","permalink":"http://blog.ozairs.com/AWS/CloudFormation-CLI命令/","excerpt":"","text":"Creating a StackYou must provide the stack name, the location of a valid template, and any input parameters. If you specify a local template file, AWS CloudFormation uploads it to an Amazon S3 bucket in your AWS account. 1$ aws cloudformation create-stack --stack-name myteststack --template-body file:///home/testuser/mytemplate.json --parameters ParameterKey=Parm1,ParameterValue=test1 ParameterKey=Parm2,ParameterValue=test2 Listing Your StacksNote The aws cloudformation list-stacks command returns information on deleted stacks for 90 days after they have been deleted. 1$ aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE Describing Your Stacks1$ aws cloudformation describe-stacks --stack-name myteststack By default, aws cloudformation describe-stacks returns parameter values. To prevent sensitive parameter values such as passwords from being returned, include a NoEcho property set to TRUE in your AWS CloudFormation template. Viewing Stack Event HistoryYou can track the status of the resources AWS CloudFormation is creating and deleting with the aws cloudformation describe-stack-events command. The amount of time to create or delete a stack depends on the complexity of your stack. 1$ aws cloudformation describe-stack-events --stack-name myteststack Listing Stack Resources1$ aws cloudformation list-stack-resources --stack-name myteststack Retrieving a TemplateAWS CloudFormation stores the template you use to create your stack as part of the stack. 1$ aws cloudformation get-template --stack-name myteststack Validating a TemplateYou can validate templates locally by using the –template-body parameter, or remotely with the –template-url parameter. 12$ aws cloudformation validate-template --template-url https://s3.amazonaws.com/cloudformation-templates-us-east-1/S3_Bucket.template$ aws cloudformation validate-template --template-body file:///home/local/test/sampletemplate.json Deleting a Stack1$ aws cloudformation delete-stack --stack-name myteststack","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"CloudFormation","slug":"CloudFormation","permalink":"http://blog.ozairs.com/tags/CloudFormation/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"Ansible常用模块","slug":"Ansible常用模块","date":"2019-03-16T11:25:04.000Z","updated":"2019-03-16T11:26:18.285Z","comments":true,"path":"Ansible/Ansible常用模块/","link":"","permalink":"http://blog.ozairs.com/Ansible/Ansible常用模块/","excerpt":"","text":"Ansible模块按功能分为：云模块、集群模块、 命令模块、数据库模块、文件模块、资产模块、消息模块、监控模块、网络模块、通知模块、包管理模块、源码控制模块、系统模块、单元模块、web设施模块、windows模块 具体的可以参考官网（http://docs.ansible.com/ansible/latest/list_of_all_modules.html）。这里从官方分类的模块里选择最常用的一些模块进行介绍。 1，ping模块。测试主机是否是通的 123456789[root@Monitor ansible]# ansible web1 -m pingServer5 | SUCCESS =&gt; &#123; \"changed\": false, \"ping\": \"pong\"&#125;Server6 | SUCCESS =&gt; &#123; \"changed\": false, \"ping\": \"pong\"&#125; 2，远程命令模块 123ansible webserver -m command -a \"free -m\" #远程命令。ansible webserver -m script -a \"/home/test.sh\" #远程主机执行主控服务器ansible上的脚本ansible webserver -m shell -a \"/home/test.sh\" #执行远程主机上的脚本命令 3，setup模块。主要用于获取主机信息，在playbooks里经常会用到的一个参数，gather_facts就与该模块相关。setup模块下经常使用的一个参数是filter参数 123ansible 10.212.52.252 -m setup -a 'filter=ansible_*_mb' //查看主机内存信息ansible 10.212.52.252 -m setup -a 'filter=ansible_eth[0-2]' //查看地接口为eth0-2的网卡信息ansible all -m setup --tree /tmp/facts //将所有主机的信息输入到/tmp/facts目录下，每台主机的信息输入到主机名文件中（/etc/ansible/hosts里的主机名） 4，stat模块。获取远程文件状态信息,包括atime、ctime、mtime、MD5、uid、gid等信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@Monitor ansible]# ansible 192.168.180.5 -m stat -a \"path=/etc/sysctl.conf \"192.168.180.5 | SUCCESS =&gt; &#123; \"changed\": false, \"stat\": &#123; \"atime\": 1504513902.6297896, \"checksum\": \"a27c7ce2e6002c37f3cb537ad997c6da7fd76480\", \"ctime\": 1480926522.4591811, \"dev\": 64768, \"executable\": false, \"exists\": true, \"gid\": 0, \"gr_name\": \"root\", \"inode\": 393634, \"isblk\": false, \"ischr\": false, \"isdir\": false, \"isfifo\": false, \"isgid\": false, \"islnk\": false, \"isreg\": true, \"issock\": false, \"isuid\": false, \"md5\": \"c97839af771c8447b9fc23090b4e8d0f\", \"mode\": \"0644\", \"mtime\": 1361531931.0, \"nlink\": 1, \"path\": \"/etc/sysctl.conf\", \"pw_name\": \"root\", \"readable\": true, \"rgrp\": true, \"roth\": true, \"rusr\": true, \"size\": 1150, \"uid\": 0, \"wgrp\": false, \"woth\": false, \"writeable\": true, \"wusr\": true, \"xgrp\": false, \"xoth\": false, \"xusr\": false &#125;&#125; 5，file模块。file模块主要用于远程主机上的文件操作，file模块包含如下选项： force：需要在两种情况下强制创建软链接，一种是源文件不存在但之后会建立的情况下；另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no group：定义文件/目录的属组 mode：定义文件/目录的权限 owner：定义文件/目录的属主 path：必选项，定义文件/目录的路径 recurse：递归的设置文件的属性，只对目录有效 src：要被链接的源文件的路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 1234567891011121314151617181920212223242526272829303132333435363738394041[root@Monitor ansible]# ansible 192.168.180.6 -m file -a \"src=/etc/fstab dest=/tmp/fstab state=link\" ########在远程主机180.6上创建远程软连接192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"dest\": \"/tmp/fstab\", \"gid\": 0, \"group\": \"root\", \"mode\": \"0777\", \"owner\": \"root\", \"size\": 10, \"src\": \"/etc/fstab\", \"state\": \"link\", \"uid\": 0&#125;[root@Monitor ansible]# ansible 192.168.180.6 -m file -a \"path=/tmp/test state=touch\" ############在远程主机180.6上创建test文件192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"dest\": \"/tmp/test\", \"gid\": 0, \"group\": \"root\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 5, \"state\": \"file\", \"uid\": 0&#125;[root@Monitor ansible]# ansible 192.168.180.6 -m file -a \"path=/tmp/test state=absent\" #############在远程主机删除文件192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"path\": \"/tmp/test\", \"state\": \"absent\"&#125;[root@Monitor ansible]# ansible 192.168.180.6 -m file -a \"path=/tmp/fstab state=absent\" #############在远程主机删除fstab软连接192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"path\": \"/tmp/fstab\", \"state\": \"absent\"&#125; 6，copy模块。实现复制文件到远程主机，copy模块包含如下选项： backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no content：用于替代”src”,可以直接设定指定文件的值 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 directory_mode：递归的设定目录的权限，默认为系统默认权限 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes others：所有的file模块里的选项都可以在这里使用 src：要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用”/“来结尾，则只复制目录里的内容，如果没有使用”/“来结尾，则包含目录在内的整个内容全部复制，类似于rsync。 以下的例子试下拷贝/etc/ansible/script.sh文件到主机组web1所有的主机/tmp下并更新文件属主和权限 12345678910111213141516[root@Monitor ansible]# ansible web1 -m copy -a \"src=/etc/ansible/script.sh dest=/tmp/ owner=appuser group=appuser mode=0755\" ###复制本地脚本到远程主机server6下并定义用户和组以及权限755Server6 | SUCCESS =&gt; &#123; \"changed\": true, \"checksum\": \"18ca258e92141948010f2e0896cf655cdb945a1d\", \"dest\": \"/tmp/script.sh\", \"gid\": 500, \"group\": \"appuser\", \"md5sum\": \"d5e15b2da056fdd7b7ba30100035de2e\", \"mode\": \"0755\", \"owner\": \"appuser\", \"size\": 30, \"src\": \"/root/.ansible/tmp/ansible-tmp-1504517543.07-102988847745614/source\", \"state\": \"file\", \"uid\": 500&#125; 7,service模块。用于远程主机的服务管理。该模块包含如下选项： arguments：给命令行提供一些选项 enabled：是否开机启动 yes|no name：必选项，服务名称 pattern：定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行 runlevel：运行级别 sleep：如果执行了restarted，在则stop和start之间沉睡几秒钟 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） 12345678####重启远程主机180.6的网卡服务[root@Monitor ansible]# ansible 192.168.180.6 -m service -a \"name=network state=restarted args=eth0\"192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"name\": \"network\", \"state\": \"started\"&#125; 8，cron模块。用于远程主机crontab配置，管理计划任务包含如下选项： backup：对远程主机上的原任务计划内容修改之前做备份 cron_file：如果指定该选项，则用该文件替换远程主机上的cron.d目录下的用户的任务计划 day：日（1-31，，/2,……） hour：小时（0-23，，/2，……） minute：分钟（0-59，，/2，……） month：月（1-12，，/2，……） weekday：周（0-7，*，……） job：要执行的任务，依赖于state=present name：该任务的描述 special_time：指定什么时候执行，参数：reboot,yearly,annually,monthly,weekly,daily,hourly state：确认该任务计划是创建还是删除 user：以哪个用户的身份执行 12345678910111213[root@Monitor ansible]# ansible 192.168.180.6 -m cron -a 'name=\"a job for reboot\" special_time=reboot job=\"/some/job.sh\"'192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"envs\": [], \"jobs\": [ \"a job for reboot\" ]&#125;##########客户端-bash-4.1# crontab -l#Ansible: a job for reboot@reboot /some/job.sh 9，yum模块。Linux平台软件包管理操作 常见的有yum apt 管理方式，其选项有： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 name：要进行操作的软件包的名字，也可以传递一个url或者一个本地的rpm包的路径 state：状态（present，absent，latest） 1234567891011121314151617181920[root@Monitor ansible]# ansible 192.168.180.6 -m yum -a \"name=curl state=latest\"192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\": [ \"已加载插件：fastestmirror\\n设置更新进程\\nLoading mirror speeds from cached hostfile\\n解决依赖关系\\n--&gt; 执行事务检查\\n---&gt; Package curl.x86_64 0:7.19.7-52.el6 will be 升级\\n---&gt; Package curl.x86_64 0:7.19.7-53.el6_9 will be an update\\n--&gt; 处理依赖关系 libcurl = 7.19.7-53.el6_9，它被软件包 curl-7.19.7-53.el6_9.x86_64 需要\\n--&gt; 执行事务检查\\n---&gt; Package libcurl.x86_64 0:7.19.7-52.el6 will be 升级\\n---&gt; Package libcurl.x86_64 0:7.19.7-53.el6_9 will be an update\\n--&gt; 完成依赖关系计算\\n\\n依赖关系解决\\n\\n================================================================================\\n 软件包 架构 版本 仓库 大小\\n================================================================================\\n正在升级:\\n curl x86_64 7.19.7-53.el6_9 updates 197 k\\n为依赖而更新:\\n libcurl x86_64 7.19.7-53.el6_9 updates 169 k\\n\\n事务概要\\n================================================================================\\nUpgrade 2 Package(s)\\n\\n总下载量：367 k\\n下载软件包：\\n--------------------------------------------------------------------------------\\n总计 3.1 MB/s | 367 kB 00:00 \\n运行 rpm_check_debug \\n执行事务测试\\n事务测试成功\\n执行事务\\n\\r 正在升级 : libcurl-7.19.7-53.el6_9.x86_64 1/4 \\n\\r 正在升级 : curl-7.19.7-53.el6_9.x86_64 2/4 \\n\\r 清理 : curl-7.19.7-52.el6.x86_64 3/4 \\n\\r 清理 : libcurl-7.19.7-52.el6.x86_64 4/4 \\n\\r Verifying : libcurl-7.19.7-53.el6_9.x86_64 1/4 \\n\\r Verifying : curl-7.19.7-53.el6_9.x86_64 2/4 \\n\\r Verifying : curl-7.19.7-52.el6.x86_64 3/4 \\n\\r Verifying : libcurl-7.19.7-52.el6.x86_64 4/4 \\n\\n更新完毕:\\n curl.x86_64 0:7.19.7-53.el6_9 \\n\\n作为依赖被升级:\\n libcurl.x86_64 0:7.19.7-53.el6_9 \\n\\n完毕！\\n\" ]&#125;#######远程客户端的主机180.6yum更新之前-bash-4.1# rpm -qa|grep curlpython-pycurl-7.19.0-9.el6.x86_64libcurl-7.19.7-52.el6.x86_64curl-7.19.7-52.el6.x86_64#######远程客户端的主机180.6yum更新之后-bash-4.1# rpm -qa|grep curlpython-pycurl-7.19.0-9.el6.x86_64libcurl-7.19.7-53.el6_9.x86_64curl-7.19.7-53.el6_9.x86_64 10.user模块。实现远程主机系统用户管理。 home：指定用户的家目录，需要与createhome配合使用 groups：指定用户的属组 uid：指定用的uid password：指定用户的密码 name：指定用户名 createhome：是否创建家目录 yes|no system：是否为系统用户 remove：当state=absent时，remove=yes则表示连同家目录一起删除，等价于userdel -r state：是创建还是删除 shell：指定用户的shell环境 1234567891011121314151617181920212223[root@Monitor ansible]# ansible 192.168.180.6 -m user -a 'name=www1 comment=lqb uid=1001 group=root ' ###新建www1用户192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"comment\": \"lqb\", \"createhome\": true, \"group\": 0, \"home\": \"/home/www1\", \"name\": \"www1\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 1001&#125;[root@Monitor ansible]# ansible 192.168.180.6 -m user -a 'name=www1 state=absent remove=yes' ########删除www1用户192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"force\": false, \"name\": \"www1\", \"remove\": true, \"state\": \"absent\"&#125; 11.rsynchronize模块。使用rsync同步文件，其参数如下： archive: 归档，相当于同时开启recursive(递归)、links、perms、times、owner、group、-D选项都为yes ，默认该项为开启 checksum: 跳过检测sum值，默认关闭 compress:是否开启压缩 copy_links：复制链接文件，默认为no ，注意后面还有一个links参数 delete: 删除不存在的文件，默认no dest：目录路径 dest_port：默认目录主机上的端口 ，默认是22，走的ssh协议 dirs：传速目录不进行递归，默认为no，即进行目录递归 rsync_opts：rsync参数部分 set_remote_user：主要用于/etc/ansible/hosts中定义或默认使用的用户与rsync使用的用户不同的情况 mode: push或pull 模块，push模的话，一般用于从本机向远程主机上传文件，pull 模式用于从远程主机上取文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344#############使用rsynchronize模块首先远程客户端要先按照rsync包才可以使用[root@Monitor ansible]# ansible 192.168.180.6 -a \"yum install rsync -y\"192.168.180.6 | SUCCESS | rc=0 &gt;&gt;已加载插件：fastestmirror设置安装进程Loading mirror speeds from cached hostfile解决依赖关系--&gt; 执行事务检查---&gt; Package rsync.x86_64 0:3.0.6-12.el6 will be 安装--&gt; 完成依赖关系计算依赖关系解决================================================================================ 软件包 架构 版本 仓库 大小================================================================================正在安装: rsync x86_64 3.0.6-12.el6 base 335 k事务概要================================================================================Install 1 Package(s)总下载量：335 kInstalled size: 682 k下载软件包：运行 rpm_check_debug 执行事务测试事务测试成功执行事务 正在安装 : rsync-3.0.6-12.el6.x86_64 1/1 Verifying : rsync-3.0.6-12.el6.x86_64 1/1 已安装: rsync.x86_64 0:3.0.6-12.el6 完毕！############远程客户端安装好rsync包后就可以在ansible服务端使用rsync进行同步了[root@Monitor ansible]# ansible 192.168.180.6 -m synchronize -a 'src=/etc/ansible/conf/hosts dest=/tmp/ '192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"cmd\": \"/usr/bin/rsync --delay-updates -F --compress --archive --rsh 'ssh -i /root/.ssh/id_rsa_web -S none -o StrictHostKeyChecking=no -o Port=22' --out-format='&lt;&lt;CHANGED&gt;&gt;%i %n%L' \\\"/etc/ansible/conf/hosts\\\" \\\"root@192.168.180.6:/tmp/\\\"\", \"msg\": \"&lt;f+++++++++ hosts\\n\", \"rc\": 0, \"stdout_lines\": [ \"&lt;f+++++++++ hosts\" ]&#125; 12.mount模块。主要配置挂载点的。主要的参数如下： dump fstype：必选项，挂载文件的类型 name：必选项，挂载点 opts：传递给mount命令的参数 src：必选项，要挂载的文件 state：必选项 present：只处理fstab中的配置 absent：删除挂载点 mounted：自动创建挂载点并挂载之 umounted：卸载 1234567891011121314151617181920212223242526272829303132333435363738###############把本地的磁盘挂载到远程主机180.6上[root@Monitor ansible]# ansible 192.168.180.6 -m mount -a 'name=/tmp/app src=/dev/sda2 fstype=ext4 state=mounted opts=rw'192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"dump\": \"0\", \"fstab\": \"/etc/fstab\", \"fstype\": \"ext4\", \"name\": \"/tmp/app\", \"opts\": \"rw\", \"passno\": \"0\", \"src\": \"/dev/sda2\"&#125;#############下面是查看远程主机是否挂载成功[root@Monitor ansible]# ansible 192.168.180.6 -a 'cat /etc/fstab'192.168.180.6 | SUCCESS | rc=0 &gt;&gt;## /etc/fstab# Created by anaconda on Wed Jan 18 14:50:09 2017## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=942820c4-9134-41da-9271-78ad0f8a33b2 / ext4 defaults 1 1UUID=e5d84663-09d2-429f-9f90-43a37b1a84a7 /opt ext4 defaults 1 2UUID=e9098124-206a-4116-a580-91d1d46fe8a9 swap swap defaults 0 0tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0/dev/sda2 /tmp/app ext4 rw 0 0[root@Monitor ansible]# ansible 192.168.180.6 -a 'df -h' 192.168.180.6 | SUCCESS | rc=0 &gt;&gt;Filesystem Size Used Avail Use% Mounted on/dev/sda1 87G 12G 71G 14% /tmpfs 935M 0 935M 0% /dev/shm/dev/sda2 9.9G 1.4G 8.1G 15% /opt/dev/sda2 9.9G 1.4G 8.1G 15% /tmp/app 13.get_url模块。该模块主要用于从http，ftp ,https等服务器上下载文件类似于wget。主要选项如下： sha256sum：下载完成后进行sha256 check； timeout：下载超时时间，默认10s url：下载的URL url_password、url_username：主要用于需要用户名密码进行验证的情况 use_proxy：是事使用代理，代理需事先在环境变更中定义 123456789101112131415161718192021222324252627282930313233##################从网站下载页面到/tmp/下[root@Monitor ansible]# ansible 192.168.180.6 -m get_url -a \"url=http://www.guojinbao.com dest=/tmp/guojinbao mode=0440 force=yes\" 192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"checksum_dest\": null, \"checksum_src\": \"75fa271ea83d05f2817027cf4009f9e9fda7ef88\", \"dest\": \"/tmp/guojinbao\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e9ea1af241cf68289f3286b99af24baa\", \"mode\": \"0440\", \"msg\": \"OK (unknown bytes)\", \"owner\": \"root\", \"size\": 38033, \"src\": \"/tmp/tmp47gp_m\", \"state\": \"file\", \"uid\": 0, \"url\": \"http://www.guojinbao.com\"&#125;########远程查看下载目录下有没有刚才下载的文件[root@Monitor ansible]# ansible 192.168.180.6 -a 'ls -lh /tmp/'192.168.180.6 | SUCCESS | rc=0 &gt;&gt;总用量 104Kdrwx------ 2 root root 4.0K 9月 5 16:01 ansible_zwKwyhdrwxr-xr-x. 7 appuser appuser 4.0K 1月 19 2017 app-r--r----- 1 root root 38K 9月 5 16:01 guojinbao-rw-r--r-- 1 root root 1.5K 9月 4 14:25 hosts-r--r----- 1 root root 38K 9月 5 15:59 index.htmldrwxr-xr-x. 3 root root 4.0K 9月 5 15:17 install-rwxr-xr-x 1 appuser appuser 30 9月 4 17:32 script.sh-rwxr-xr-x 1 root root 26 9月 4 15:52 test.sh-rw-------. 1 root root 0 1月 18 2017 yum.log 14.sysctl包管理模块。用于远程主机sysctl的配置。 12345678910111213141516171819202122[root@Monitor ansible]# ansible-doc -s sysctl ###########查看sysctl的使用说明- name: Manage entries in sysctl.conf. action: sysctl ignoreerrors # Use this option to ignore errors about unknown keys. name= # The dot-separated path (aka `key') specifying the sysctl variable. reload # If `yes', performs a `/sbin/sysctl -p' if the `sysctl_file' is updated. If `no', does not reload `sysctl' even if the `sysctl_file' is updated. state # Whether the entry should be present or absent in the sysctl file. sysctl_file # Specifies the absolute path to `sysctl.conf', if not `/etc/sysctl.c onf'. sysctl_set # Verify token value with the sysctl command and set with -w if necessary value # Desired value of the sysctl key. 12345[root@Monitor ansible]# ansible 192.168.180.6 -m sysctl -a \"name=kernel.panic value=3 sysctl_file=/etc/sysctl.conf\"192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true&#125; 15.unarchive模块。功能：解压缩，这个模块有两种用法： 1、将ansible主机上的压缩包在本地解压缩后传到远程主机上，这种情况下，copy=yes 2、将远程主机上的某个压缩包解压缩到指定路径下。这种情况下，需要设置copy=no 具体吃的参数如下： copy：在解压文件之前，是否先将文件复制到远程主机，默认为yes。若为no，则要求目标主机上压缩包必须存在。 creates：指定一个文件名，当该文件存在时，则解压指令不执行 dest：远程主机上的一个路径，即文件解压的路径 grop：解压后的目录或文件的属组 list_files：如果为yes，则会列出压缩包里的文件，默认为no，2.0版本新增的选项 mode：解决后文件的权限 src：如果copy为yes，则需要指定压缩文件的源路径 owner：解压后文件或目录的属主 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@Monitor ansible]# ansible 192.168.180.6 -m unarchive -a \"src=/tmp/install/zabbix-3.0.4.tar.gz dest=/tmp/ mode=0755\"192.168.180.6 | SUCCESS =&gt; &#123; \"changed\": true, \"dest\": \"/tmp/\", \"extract_results\": &#123; \"cmd\": [ \"/bin/gtar\", \"--extract\", \"-C\", \"/tmp/\", \"-z\", \"-f\", \"/root/.ansible/tmp/ansible-tmp-1504599995.75-84735087578916/source\" ], \"err\": \"\", \"out\": \"\", \"rc\": 0 &#125;, \"gid\": 0, \"group\": \"root\", \"handler\": \"TgzArchive\", \"mode\": \"01777\", \"owner\": \"root\", \"size\": 4096, \"src\": \"/root/.ansible/tmp/ansible-tmp-1504599995.75-84735087578916/source\", \"state\": \"directory\", \"uid\": 0&#125;########下面是查看路径下的zabbix解压包[root@Monitor ansible]# ansible 192.168.180.6 -a 'ls -alh /tmp'192.168.180.6 | SUCCESS | rc=0 &gt;&gt;总用量 120Kdrwxrwxrwt. 7 root root 4.0K 9月 5 16:28 .dr-xr-xr-x. 24 root root 4.0K 9月 1 09:45 ..drwx------ 2 root root 4.0K 9月 5 16:28 ansible_1zOyd2drwxr-xr-x. 7 appuser appuser 4.0K 1月 19 2017 app-r--r----- 1 root root 38K 9月 5 16:01 guojinbao-rw-r--r-- 1 root root 1.5K 9月 4 14:25 hostsdrwxrwxrwt 2 root root 4.0K 9月 1 09:45 .ICE-unix-r--r----- 1 root root 38K 9月 5 15:59 index.htmldrwxr-xr-x. 3 root root 4.0K 9月 5 15:17 install-rwxr-xr-x 1 appuser appuser 30 9月 4 17:32 script.sh-rwxr-xr-x 1 root root 26 9月 4 15:52 test.sh-rw-------. 1 root root 0 1月 18 2017 yum.logdrwxr-xr-x 13 www 1000 4.0K 7月 22 2016 zabbix-3.0.4 总之，以上就是ansible常用的模块，如果还需要其他的模块的话可以查看下官方文档（**http://docs.ansible.com/ansible/latest/list_of_all_modules.html）** 也可以通过命令来进行查看 1，查看所有的模块命令： ansible-doc -l 2，查看具体某个模块用法：ansible-doc -s MODULE_NAME","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"}],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}]},{"title":"三个技巧将Docker镜像体积压缩90%","slug":"三个技巧将Docker镜像体积压缩90","date":"2019-03-16T05:44:57.000Z","updated":"2019-03-16T05:52:11.404Z","comments":true,"path":"Docker/三个技巧将Docker镜像体积压缩90/","link":"","permalink":"http://blog.ozairs.com/Docker/三个技巧将Docker镜像体积压缩90/","excerpt":"","text":"在构建 Docker 容器时，应该尽量想办法获得体积更小的镜像，因为传输和部署体积较小的镜像速度更快。 但RUN语句总是会创建一个新层，而且在生成镜像之前还需要使用很多中间文件，在这种情况下，该如何获得体积更小的镜像呢？ 你可能已经注意到了，大多数 Dockerfiles 都使用了一些奇怪的技巧： 12345FROM ubuntuRUN apt-get update &amp;&amp; apt-get install vim 为什么使用 &amp;&amp;？而不是使用两个 RUN 语句代替呢？比如： 123456789FROM ubuntuRUN apt-get updateRUN apt-get install vim 从 Docker 1.10 开始，COPY、ADD和RUN语句会向镜像中添加新层。前面的示例创建了两个层而不是一个。 镜像的层就像 Git 的提交（commit）一样。 Docker 的层用于保存镜像的上一版本和当前版本之间的差异。就像 Git 的提交一样，如果你与其他存储库或镜像共享它们，就会很方便。 实际上，当你向注册表请求镜像时，只是下载你尚未拥有的层。这是一种非常高效地共享镜像的方式。 但额外的层并不是没有代价的。 层仍然会占用空间，你拥有的层越多，最终的镜像就越大。Git 存储库在这方面也是类似的，存储库的大小随着层数的增加而增加，因为 Git 必须保存提交之间的所有变更。 过去，将多个RUN语句组合在一行命令中或许是一种很好的做法，就像上面的第一个例子那样，但在现在看来，这样做并不妥。 通过Docker 多阶段构建将多个层压缩为一个 当 Git 存储库变大时，你可以选择将历史提交记录压缩为单个提交。 事实证明，在 Docker 中也可以使用多阶段构建达到类似的目的。 在这个示例中，你将构建一个 Node.js 容器。 让我们从 index.js 开始： 123456789101112131415161718192021const express = require(&apos;express&apos;)const app = express()app.get(&apos;/&apos;, (req, res) =&gt; res.send(&apos;Hello World!&apos;))app.listen(3000, () =&gt; &#123; console.log(`Example app listening on port 3000!`)&#125;) 和 package.json： 1234567891011121314151617181920212223242526272829303132333435363738394041&#123; &quot;name&quot;: &quot;hello-world&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;dependencies&quot;: &#123; &quot;express&quot;: &quot;^4.16.2&quot; &#125;, &quot;scripts&quot;: &#123; &quot;start&quot;: &quot;node index.js&quot; &#125;&#125; 你可以使用下面的 Dockerfile 来打包这个应用程序： 123456789101112131415161718192021FROM node:8EXPOSE 3000WORKDIR /appCOPY package.json index.js ./RUN npm installCMD [&quot;npm&quot;, &quot;start&quot;] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849FROM node:10MAINTAINER xialeistudio xialeistudio@gmail.comWORKDIR /usr/src/appENV TZ Asia/ShanghaiARG registry=https://registry.npm.taobao.orgARG disturl=https://npm.taobao.org/distRUN yarn config set disturl $disturlRUN yarn config set registry $registryCOPY package.json /usr/src/app/RUN yarn --frozen-lockfile --productionCOPY . /usr/src/appEXPOSE 8080CMD [ &quot;yarn&quot;, &quot;start:prod&quot; ] 然后开始构建镜像： 1$ docker build -t node-vanilla . 然后用以下方法验证它是否可以正常运行： 1$ docker run -p 3000:3000 -ti --rm --init node-vanilla 你应该能访问 http://localhost:3000，并收到“Hello World!”。 Dockerfile 中使用了一个 COPY 语句和一个 RUN 语句，所以按照预期，新镜像应该比基础镜像多出至少两个层： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677$ docker history node-vanillaIMAGE CREATED BY SIZE075d229d3f48 /bin/sh -c #(nop) CMD [&quot;npm&quot; &quot;start&quot;] 0Bbc8c3cc813ae /bin/sh -c npm install 2.91MBbac31afb6f42 /bin/sh -c #(nop) COPY multi:3071ddd474429e1… 364B500a9fbef90e /bin/sh -c #(nop) WORKDIR /app 0B78b28027dfbf /bin/sh -c #(nop) EXPOSE 3000 0Bb87c2ad8344d /bin/sh -c #(nop) CMD [&quot;node&quot;] 0B&lt;missing&gt; /bin/sh -c set -ex &amp;&amp; for key in 6A010… 4.17MB&lt;missing&gt; /bin/sh -c #(nop) ENV YARN_VERSION=1.3.2 0B&lt;missing&gt; /bin/sh -c ARCH= &amp;&amp; dpkgArch=&quot;$(dpkg --print… 56.9MB&lt;missing&gt; /bin/sh -c #(nop) ENV NODE_VERSION=8.9.4 0B&lt;missing&gt; /bin/sh -c set -ex &amp;&amp; for key in 94AE3… 129kB&lt;missing&gt; /bin/sh -c groupadd --gid 1000 node &amp;&amp; use… 335kB&lt;missing&gt; /bin/sh -c set -ex; apt-get update; apt-ge… 324MB&lt;missing&gt; /bin/sh -c apt-get update &amp;&amp; apt-get install… 123MB&lt;missing&gt; /bin/sh -c set -ex; if ! command -v gpg &gt; /… 0B&lt;missing&gt; /bin/sh -c apt-get update &amp;&amp; apt-get install… 44.6MB&lt;missing&gt; /bin/sh -c #(nop) CMD [&quot;bash&quot;] 0B&lt;missing&gt; /bin/sh -c #(nop) ADD file:1dd78a123212328bd… 123MB 但实际上，生成的镜像多了五个新层：每一个层对应 Dockerfile 里的一个语句。 现在，让我们来试试 Docker 的多阶段构建。 你可以继续使用与上面相同的 Dockerfile，只是现在要调用两次： 1234567891011121314151617181920212223242526272829FROM node:8 as buildWORKDIR /appCOPY package.json index.js ./RUN npm installFROM node:8COPY --from=build /app /EXPOSE 3000CMD [&quot;index.js&quot;] Dockerfile 的第一部分创建了三个层，然后这些层被合并并复制到第二个阶段。在第二阶段，镜像顶部又添加了额外的两个层，所以总共是三个层。 现在来验证一下。首先，构建容器： 1$ docker build -t node-multi-stage . 查看镜像的历史： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869$ docker history node-multi-stageIMAGE CREATED BY SIZE331b81a245b1 /bin/sh -c #(nop) CMD [&quot;index.js&quot;] 0Bbdfc932314af /bin/sh -c #(nop) EXPOSE 3000 0Bf8992f6c62a6 /bin/sh -c #(nop) COPY dir:e2b57dff89be62f77… 1.62MBb87c2ad8344d /bin/sh -c #(nop) CMD [&quot;node&quot;] 0B&lt;missing&gt; /bin/sh -c set -ex &amp;&amp; for key in 6A010… 4.17MB&lt;missing&gt; /bin/sh -c #(nop) ENV YARN_VERSION=1.3.2 0B&lt;missing&gt; /bin/sh -c ARCH= &amp;&amp; dpkgArch=&quot;$(dpkg --print… 56.9MB&lt;missing&gt; /bin/sh -c #(nop) ENV NODE_VERSION=8.9.4 0B&lt;missing&gt; /bin/sh -c set -ex &amp;&amp; for key in 94AE3… 129kB&lt;missing&gt; /bin/sh -c groupadd --gid 1000 node &amp;&amp; use… 335kB&lt;missing&gt; /bin/sh -c set -ex; apt-get update; apt-ge… 324MB&lt;missing&gt; /bin/sh -c apt-get update &amp;&amp; apt-get install… 123MB&lt;missing&gt; /bin/sh -c set -ex; if ! command -v gpg &gt; /… 0B&lt;missing&gt; /bin/sh -c apt-get update &amp;&amp; apt-get install… 44.6MB&lt;missing&gt; /bin/sh -c #(nop) CMD [&quot;bash&quot;] 0B&lt;missing&gt; /bin/sh -c #(nop) ADD file:1dd78a123212328bd… 123MB 文件大小是否已发生改变？ 123456789$ docker images | grep node-node-multi-stage 331b81a245b1 678MBnode-vanilla 075d229d3f48 679MB 最后一个镜像（node-multi-stage）更小一些。 你已经将镜像的体积减小了，即使它已经是一个很小的应用程序。 但整个镜像仍然很大！ 有什么办法可以让它变得更小吗？ 用 distroless 去除不必要的东西 这个镜像包含了 Node.js 以及 yarn、npm、bash 和其他的二进制文件。因为它也是基于 Ubuntu 的，所以你等于拥有了一个完整的操作系统，其中包括所有的小型二进制文件和实用程序。 但在运行容器时是不需要这些东西的，你需要的只是 Node.js。 Docker 容器应该只包含一个进程以及用于运行这个进程所需的最少的文件，你不需要整个操作系统。 实际上，你可以删除 Node.js 之外的所有内容。 但要怎么做？ 所幸的是，谷歌为我们提供了 distroless（https://github.com/GoogleCloudPlatform/distroless）。 以下是 distroless 存储库的描述： “distroless”镜像只包含应用程序及其运行时依赖项，不包含程序包管理器、shell 以及在标准 Linux 发行版中可以找到的任何其他程序。 这正是你所需要的！ 你可以对 Dockerfile 进行调整，以利用新的基础镜像，如下所示： 1234567891011121314151617181920212223242526272829FROM node:8 as buildWORKDIR /appCOPY package.json index.js ./RUN npm installFROM gcr.io/distroless/nodejsCOPY --from=build /app /EXPOSE 3000CMD [&quot;index.js&quot;] 你可以像往常一样编译镜像： 1$ docker build -t node-distroless . 这个镜像应该能正常运行。要验证它，可以像这样运行容器： 1$ docker run -p 3000:3000 -ti --rm --init node-distroless s现在可以访问 http://localhost:3000 页面。 不包含其他额外二进制文件的镜像是不是小多了？ 12345$ docker images | grep node-distrolessnode-distroless 7b4db3b7f1e5 76.7MB 只有 76.7MB！ 比之前的镜像小了 600MB！ 但在使用 distroless 时有一些事项需要注意。 当容器在运行时，如果你想要检查它，可以使用以下命令 attach 到正在运行的容器上： 1$ docker exec -ti &lt;insert_docker_id&gt; bash attach 到正在运行的容器并运行 bash 命令就像是建立了一个 SSH 会话一样。 但 distroless 版本是原始操作系统的精简版，没有了额外的二进制文件，所以容器里没有 shell！ 在没有 shell 的情况下，如何 attach 到正在运行的容器呢？ 答案是，你做不到。这既是个坏消息，也是个好消息。 之所以说是坏消息，因为你只能在容器中执行二进制文件。你可以运行的唯一的二进制文件是 Node.js： 1$ docker exec -ti &lt;insert_docker_id&gt; node 说它是个好消息，是因为如果攻击者利用你的应用程序获得对容器的访问权限将无法像访问 shell 那样造成太多破坏。换句话说，更少的二进制文件意味着更小的体积和更高的安全性，不过这是以痛苦的调试为代价的。 或许你不应在生产环境中 attach 和调试容器，而应该使用日志和监控。 但如果你确实需要调试，又想保持小体积该怎么办？ 小体积的 Alpine 基础镜像 你可以使用 Alpine 基础镜像替换 distroless 基础镜像。 Alpine Linux 是： 一个基于 musl libc 和 busybox 的面向安全的轻量级 Linux 发行版。 换句话说，它是一个体积更小也更安全的 Linux 发行版。 不过你不应该理所当然地认为他们声称的就一定是事实，让我们来看看它的镜像是否更小。 先修改 Dockerfile，让它使用 node:8-alpine： 1234567891011121314151617181920212223242526272829FROM node:8 as buildWORKDIR /appCOPY package.json index.js ./RUN npm installFROM node:8-alpineCOPY --from=build /app /EXPOSE 3000CMD [&quot;npm&quot;, &quot;start&quot;] 使用下面的命令构建镜像： 1$ docker build -t node-alpine . 现在可以检查一下镜像大小： 12345$ docker images | grep node-alpinenode-alpine aa1f85f8e724 69.7MB 69.7MB！ 甚至比 distrless 镜像还小！ 现在可以 attach 到正在运行的容器吗？让我们来试试。 让我们先启动容器： 12345$ docker run -p 3000:3000 -ti --rm --init node-alpineExample app listening on port 3000! 你可以使用以下命令 attach 到运行中的容器： 12345$ docker exec -ti 9d8e97e307d7 bashOCI runtime exec failed: exec failed: container_linux.go:296: starting container process caused &quot;exec: \\&quot;bash\\&quot;: executable file not found in $PATH&quot;: unknown 看来不行，但或许可以使用 shell？ 1$ docker exec -ti 9d8e97e307d7 sh / # 成功了！现在可以 attach 到正在运行的容器中了。 看起来很有希望，但还有一个问题。 Alpine 基础镜像是基于 muslc 的——C 语言的一个替代标准库，而大多数 Linux 发行版如 Ubuntu、Debian 和 CentOS 都是基于 glibc 的。这两个库应该实现相同的内核接口。 但它们的目的是不一样的： glibc 更常见，速度也更快； muslc 使用较少的空间，并侧重于安全性。 在编译应用程序时，大部分都是针对特定的 libc 进行编译的。如果你要将它们与另一个 libc 一起使用，则必须重新编译它们。 换句话说，基于 Alpine 基础镜像构建容器可能会导致非预期的行为，因为标准 C 库是不一样的。 你可能会注意到差异，特别是当你处理预编译的二进制文件（如 Node.js C++ 扩展）时。 例如，PhantomJS 的预构建包就不能在 Alpine 上运行。 你应该选择哪个基础镜像？ 你应该使用 Alpine、distroless 还是原始镜像？ 如果你是在生产环境中运行容器，并且更关心安全性，那么可能 distroless 镜像更合适。 添加到 Docker 镜像的每个二进制文件都会给整个应用程序增加一定的风险。 只在容器中安装一个二进制文件可以降低总体风险。 例如，如果攻击者能够利用运行在 distroless 上的应用程序的漏洞，他们将无法在容器中使用 shell，因为那里根本就没有 shell！ 请注意，OWASP 本身就建议尽量减少攻击表面。 如果你只关心更小的镜像体积，那么可以考虑基于 Alpine 的镜像。 它们的体积非常小，但代价是兼容性较差。Alpine 使用了略微不同的标准 C 库——muslc。你可能会时不时地遇到一些兼容性问题。 原始基础镜像非常适合用于测试和开发。 它虽然体积很大，但提供了与 Ubuntu 工作站一样的体验。此外，你还可以访问操作系统的所有二进制文件。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"如何编写最佳的Dockerfile","slug":"如何编写最佳的Dockerfile","date":"2019-03-16T05:28:24.000Z","updated":"2019-03-16T05:29:37.407Z","comments":true,"path":"Docker/如何编写最佳的Dockerfile/","link":"","permalink":"http://blog.ozairs.com/Docker/如何编写最佳的Dockerfile/","excerpt":"","text":"为了保证可读性，本文采用意译而非直译。另外，本文版权归原作者所有，翻译仅用于学习。 我已经使用Docker有一段时间了，其中编写Dockerfile是非常重要的一部分工作。在这篇博客中，我打算分享一些建议，帮助大家编写更好的Dockerfile。 目标: 更快的构建速度 更小的Docker镜像大小 更少的Docker镜像层 充分利用镜像缓存 增加Dockerfile可读性 让Docker容器使用起来更简单 总结 编写.dockerignore文件 容器只运行单个应用 将多个RUN指令合并为一个 基础镜像的标签不要用latest 每个RUN指令后删除多余文件 选择合适的基础镜像(alpine版本最好) 设置WORKDIR和CMD 使用ENTRYPOINT (可选) 在entrypoint脚本中使用exec COPY与ADD优先使用前者 合理调整COPY与RUN的顺序 设置默认的环境变量，映射端口和数据卷 使用LABEL设置镜像元数据 添加HEALTHCHECK 示例示例Dockerfile犯了几乎所有的错(当然我是故意的)。接下来，我会一步步优化它。假设我们需要使用Docker运行一个Node.js应用，下面就是它的Dockerfile(CMD指令太复杂了，所以我简化了，它是错误的，仅供参考)。 12345678910111213FROM ubuntuADD . /appRUN apt-get update RUN apt-get upgrade -y RUN apt-get install -y nodejs ssh mysql RUN cd /app &amp;&amp; npm install# this should start three processes, mysql and ssh# in the background and node app in foreground# isn&apos;t it beautifully terrible? &lt;3CMD mysql &amp; sshd &amp; npm start 构建镜像: 1docker build -t wtf . 1. 编写.dockerignore文件构建镜像时，Docker需要先准备context ，将所有需要的文件收集到进程中。默认的context包含Dockerfile目录中的所有文件，但是实际上，我们并不需要.git目录，node_modules目录等内容。 .dockerignore 的作用和语法类似于 .gitignore，可以忽略一些不需要的文件，这样可以有效加快镜像构建时间，同时减少Docker镜像的大小。示例如下: 12.git/node_modules/ 2. 容器只运行单个应用从技术角度讲，你可以在Docker容器中运行多个进程。你可以将数据库，前端，后端，ssh，supervisor都运行在同一个Docker容器中。但是，这会让你非常痛苦: 非常长的构建时间(修改前端之后，整个后端也需要重新构建) 非常大的镜像大小 多个应用的日志难以处理(不能直接使用stdout，否则多个应用的日志会混合到一起) 横向扩展时非常浪费资源(不同的应用需要运行的容器数并不相同) 僵尸进程问题 - 你需要选择合适的init进程 因此，我建议大家为每个应用构建单独的Docker镜像，然后使用 Docker Compose 运行多个Docker容器。 现在，我从Dockerfile中删除一些不需要的安装包，另外，SSH可以用docker exec替代。示例如下： 12345678910111213FROM ubuntuADD . /appRUN apt-get update RUN apt-get upgrade -y# we should remove ssh and mysql, and use# separate container for database RUN apt-get install -y nodejs # ssh mysql RUN cd /app &amp;&amp; npm installCMD npm start 3. 将多个RUN指令合并为一个Docker镜像是分层的，下面这些知识点非常重要: Dockerfile中的每个指令都会创建一个新的镜像层。 镜像层将被缓存和复用 当Dockerfile的指令修改了，复制的文件变化了，或者构建镜像时指定的变量不同了，对应的镜像层缓存就会失效 某一层的镜像缓存失效之后，它之后的镜像层缓存都会失效 镜像层是不可变的，如果我们再某一层中添加一个文件，然后在下一层中删除它，则镜像中依然会包含该文件(只是这个文件在Docker容器中不可见了)。 Docker镜像类似于洋葱。它们都有很多层。为了修改内层，则需要将外面的层都删掉。记住这一点的话，其他内容就很好理解了。 现在，我们将所有的RUN指令合并为一个。同时把apt-get upgrade删除，因为它会使得镜像构建非常不确定(我们只需要依赖基础镜像的更新就好了) 12345678910FROM ubuntuADD . /appRUN apt-get update \\ &amp;&amp; apt-get install -y nodejs \\ &amp;&amp; cd /app \\ &amp;&amp; npm installCMD npm start 记住一点，我们只能将变化频率一样的指令合并在一起。将node.js安装与npm模块安装放在一起的话，则每次修改源代码，都需要重新安装node.js，这显然不合适。因此，正确的写法是这样的: 1234567FROM ubuntuRUN apt-get update &amp;&amp; apt-get install -y nodejs ADD . /app RUN cd /app &amp;&amp; npm installCMD npm start 4. 基础镜像的标签不要用latest当镜像没有指定标签时，将默认使用latest 标签。因此， FROM ubuntu 指令等同于FROM ubuntu:latest。当时，当镜像更新时，latest标签会指向不同的镜像，这时构建镜像有可能失败。如果你的确需要使用最新版的基础镜像，可以使用latest标签，否则的话，最好指定确定的镜像标签。 示例Dockerfile应该使用16.04作为标签。 1234567FROM ubuntu:16.04 # it&apos;s that easy!RUN apt-get update &amp;&amp; apt-get install -y nodejs ADD . /app RUN cd /app &amp;&amp; npm installCMD npm start 5. 每个RUN指令后删除多余文件假设我们更新了apt-get源，下载，解压并安装了一些软件包，它们都保存在/var/lib/apt/lists/目录中。但是，运行应用时Docker镜像中并不需要这些文件。我们最好将它们删除，因为它会使Docker镜像变大。 示例Dockerfile中，我们可以删除/var/lib/apt/lists/目录中的文件(它们是由apt-get update生成的)。 1234567891011FROM ubuntu:16.04RUN apt-get update \\ &amp;&amp; apt-get install -y nodejs \\ # added lines &amp;&amp; rm -rf /var/lib/apt/lists/*ADD . /app RUN cd /app &amp;&amp; npm installCMD npm start 6. 选择合适的基础镜像(alpine版本最好)在示例中，我们选择了ubuntu作为基础镜像。但是我们只需要运行node程序，有必要使用一个通用的基础镜像吗？node镜像应该是更好的选择。 12345678FROM nodeADD . /app # we don&apos;t need to install node # anymore and use apt-getRUN cd /app &amp;&amp; npm installCMD npm start 更好的选择是alpine版本的node镜像。alpine是一个极小化的Linux发行版，只有4MB，这让它非常适合作为基础镜像。 123456FROM node:7-alpineADD . /app RUN cd /app &amp;&amp; npm installCMD npm start apk是Alpine的包管理工具。它与apt-get有些不同，但是非常容易上手。另外，它还有一些非常有用的特性，比如no-cache和 --virtual选项，它们都可以帮助我们减少镜像的大小。 7. 设置WORKDIR和 CMDWORKDIR指令可以设置默认目录，也就是运行RUN / CMD / ENTRYPOINT指令的地方。 CMD指令可以设置容器创建是执行的默认命令。另外，你应该讲命令写在一个数组中，数组中每个元素为命令的每个单词(参考官方文档)。 1234567FROM node:7-alpineWORKDIR /app ADD . /app RUN npm installCMD [&quot;npm&quot;, &quot;start&quot;] 8. 使用ENTRYPOINT (可选)ENTRYPOINT指令并不是必须的，因为它会增加复杂度。ENTRYPOINT是一个脚本，它会默认执行，并且将指定的命令错误其参数。它通常用于构建可执行的Docker镜像。entrypoint.sh如下: 123456789101112131415161718192021222324252627#!/usr/bin/env sh# $0 is a script name, # $1, $2, $3 etc are passed arguments# $1 is our commandCMD=$1case &quot;$CMD&quot; in &quot;dev&quot; ) npm install export NODE_ENV=development exec npm run dev ;; &quot;start&quot; ) # we can modify files here, using ENV variables passed in # &quot;docker create&quot; command. It can&apos;t be done during build process. echo &quot;db: $DATABASE_ADDRESS&quot; &gt;&gt; /app/config.yml export NODE_ENV=production exec npm start ;; * ) # Run custom command. Thanks to this line we can still use # &quot;docker run our_image /bin/bash&quot; and it will work exec $CMD $&#123;@:2&#125; ;;esac 示例Dockerfile: 12345678FROM node:7-alpineWORKDIR /app ADD . /app RUN npm installENTRYPOINT [&quot;./entrypoint.sh&quot;] CMD [&quot;start&quot;] 可以使用如下命令运行该镜像: 12345678# 运行开发版本docker run our-app dev # 运行生产版本docker run our-app start # 运行bashdocker run -it our-app /bin/bash 9. 在entrypoint脚本中使用exec在前文的entrypoint脚本中，我使用了exec命令运行node应用。不使用exec的话，我们则不能顺利地关闭容器，因为SIGTERM信号会被bash脚本进程吞没。exec命令启动的进程可以取代脚本进程，因此所有的信号都会正常工作。 10. COPY与ADD优先使用前者COPY指令非常简单，仅用于将文件拷贝到镜像中。ADD相对来讲复杂一些，可以用于下载远程文件以及解压压缩包(参考官方文档)。 123456789FROM node:7-alpineWORKDIR /appCOPY . /app RUN npm installENTRYPOINT [&quot;./entrypoint.sh&quot;] CMD [&quot;start&quot;] 11. 合理调整COPY与RUN的顺序我们应该把变化最少的部分放在Dockerfile的前面，这样可以充分利用镜像缓存。 示例中，源代码会经常变化，则每次构建镜像时都需要重新安装NPM模块，这显然不是我们希望看到的。因此我们可以先拷贝package.json，然后安装NPM模块，最后才拷贝其余的源代码。这样的话，即使源代码变化，也不需要重新安装NPM模块。 12345678910FROM node:7-alpineWORKDIR /appCOPY package.json /app RUN npm install COPY . /appENTRYPOINT [&quot;./entrypoint.sh&quot;] CMD [&quot;start&quot;] 12. 设置默认的环境变量，映射端口和数据卷运行Docker容器时很可能需要一些环境变量。在Dockerfile设置默认的环境变量是一种很好的方式。另外，我们应该在Dockerfile中设置映射端口和数据卷。示例如下: 12345678910111213141516171819FROM node:7-alpineENV PROJECT_DIR=/appWORKDIR $PROJECT_DIRCOPY package.json $PROJECT_DIR RUN npm install COPY . $PROJECT_DIRENV MEDIA_DIR=/media \\ NODE_ENV=production \\ APP_PORT=3000VOLUME $MEDIA_DIR EXPOSE $APP_PORTENTRYPOINT [&quot;./entrypoint.sh&quot;] CMD [&quot;start&quot;] ENV指令指定的环境变量在容器中可以使用。如果你只是需要指定构建镜像时的变量，你可以使用ARG指令。 13. 使用LABEL设置镜像元数据使用LABEL指令，可以为镜像设置元数据，例如镜像创建者或者镜像说明。旧版的Dockerfile语法使用MAINTAINER指令指定镜像创建者，但是它已经被弃用了。有时，一些外部程序需要用到镜像的元数据，例如nvidia-docker需要用到com.nvidia.volumes.needed。示例如下: 123FROM node:7-alpine LABEL maintainer &quot;jakub.skalecki@example.com&quot; ... 14. 添加HEALTHCHECK运行容器时，可以指定--restart always选项。这样的话，容器崩溃时，Docker守护进程(docker daemon)会重启容器。对于需要长时间运行的容器，这个选项非常有用。但是，如果容器的确在运行，但是不可(陷入死循环，配置错误)用怎么办？使用HEALTHCHECK指令可以让Docker周期性的检查容器的健康状况。我们只需要指定一个命令，如果一切正常的话返回0，否则返回1。对HEALTHCHECK感兴趣的话，可以参考这篇博客。示例如下: 1234567891011121314151617181920FROM node:7-alpine LABEL maintainer &quot;jakub.skalecki@example.com&quot;ENV PROJECT_DIR=/app WORKDIR $PROJECT_DIRCOPY package.json $PROJECT_DIR RUN npm install COPY . $PROJECT_DIRENV MEDIA_DIR=/media \\ NODE_ENV=production \\ APP_PORT=3000VOLUME $MEDIA_DIR EXPOSE $APP_PORT HEALTHCHECK CMD curl --fail http://localhost:$APP_PORT || exit 1ENTRYPOINT [&quot;./entrypoint.sh&quot;] CMD [&quot;start&quot;] 当请求失败时，curl --fail 命令返回非0状态。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"Docker三剑客之Docker Swarm","slug":"Docker三剑客之Docker-Swarm","date":"2019-03-16T04:03:40.000Z","updated":"2019-03-16T04:18:41.275Z","comments":true,"path":"Docker/Docker三剑客之Docker-Swarm/","link":"","permalink":"http://blog.ozairs.com/Docker/Docker三剑客之Docker-Swarm/","excerpt":"","text":"Docker Machine 创建 Docker 主机 Docker Swarm 配置集群节点 Docker Service 部署单个集群服务 Docker Stack 部署多个集群服务，以及 GUI 管理页面 docker-machine、docker swarm、docker node、docker service 和 docker stack 常用命令 Docker Swarm 和 Docker Compose 一样，都是 Docker 官方容器编排项目，但不同的是，Docker Compose 是一个在单个服务器或主机上创建多个容器的工具，而 Docker Swarm 则可以在多个服务器或主机上创建容器集群服务，对于微服务的部署，显然 Docker Swarm 会更加适合。 从 Docker 1.12.0 版本开始，Docker Swarm 已经包含在 Docker 引擎中（docker swarm），并且已经内置了服务发现工具，我们就不需要像之前一样，再配置 Etcd 或者 Consul 来进行服务发现配置了。 1. Docker Machine 创建 Docker 主机在进行 Docker Swarm 配置之前，我们还需要说下 Docker 另外一个官方工具 Docker Machine（也是 Docker 三剑客之一），其作用就是快速帮助我们搭建 Docker 主机环境，比如我们要使用 Docker Swarm，就必须有很多的 Docker 主机来进行操作，Docker Machine 就是最理想的工具。 因为我是在 Mac OS 上进行操作的，并且 Docker for Mac 已经包含了 Docker Machine（docker machine），所以我不需要再额外进行安装了，如果使用 Linux 系统的话，安装也非常简单，命令： 12$ sudo curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-machine$ sudo chmod +x /usr/local/bin/docker-machine 好了，我们先使用 Docker Machine 创建四个 Docker 主机，命令： 123456789$ docker-machine create -d virtualbox manager1 &amp;&amp; docker-machine create -d virtualbox manager2 &amp;&amp; docker-machine create -d virtualbox worker1 &amp;&amp; docker-machine create -d virtualbox worker2Running pre-create checks...(worker1) No default Boot2Docker ISO found locally, downloading the latest release...(worker1) Latest release for github.com/boot2docker/boot2docker is v17.11.0-ce(worker1) Downloading /Users/xishuai/.docker/machine/cache/boot2docker.iso from https://github.com/boot2docker/boot2docker/releases/download/v17.11.0-ce/boot2docker.iso... 执行上面命令，你会发现速度巨慢（如上），原因是从 GitHub 上下载一个boot2docker.iso文件（国内网络没办法），怎么解决呢？很简单，我们使用翻X的浏览器手动下载boot2docker.iso文件，然后拷贝到对应目录下（我电脑的目录/Users/xishuai/.docker/machine/cache/），然后再执行上面的命令，发现速度快的一批。 我们可以查看下创建的 Docker 主机信息，命令： 123456$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmanager1 - virtualbox Running tcp://192.168.99.100:2376 v17.11.0-ce manager2 - virtualbox Running tcp://192.168.99.101:2376 v17.11.0-ce worker1 - virtualbox Running tcp://192.168.99.102:2376 v17.11.0-ce worker2 - virtualbox Running tcp://192.168.99.103:2376 v17.11.0-ce 可以看到，我们创建了四个 Docker 主机（两个 Manager 和两个 Worker），我们还可以连接到任何一台服务器进行操作，命令： 12345678910111213141516$ docker-machine ssh manager1 ## . ## ## ## == ## ## ## ## ## === /&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\\___/ === ~~~ &#123;~~ ~~~~ ~~~ ~~~~ ~~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\_______/ _ _ ____ _ _| |__ ___ ___ | |_|___ \\ __| | ___ ___| | _____ _ __| &apos;_ \\ / _ \\ / _ \\| __| __) / _` |/ _ \\ / __| |/ / _ \\ &apos;__|| |_) | (_) | (_) | |_ / __/ (_| | (_) | (__| &lt; __/ ||_.__/ \\___/ \\___/ \\__|_____\\__,_|\\___/ \\___|_|\\_\\___|_|Boot2Docker version 17.11.0-ce, build HEAD : e620608 - Tue Nov 21 18:11:40 UTC 2017Docker version 17.11.0-ce, build 1caf76c 2. Docker Swarm 配置集群节点我们执行下面命令： 12345678$ docker-machine ssh manager1 &quot;docker swarm init --advertise-addr 192.168.99.100&quot;Swarm initialized: current node (n0ub7dpn90rxjq97dr0g8we0w) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-envtxo4dl6df2ar3qldcccfdg 192.168.99.100:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. 上面是在manager1主机上，创建一个 Docker Swarm 管理节点（初始化集群的时候，会自动把当前节点设置为管理节点）。 接着，我们在worker1和worker2主机上，创建两个工作节点，并加入到集群中，命令： 12345$ docker-machine ssh worker1 &quot;docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-envtxo4dl6df2ar3qldcccfdg 192.168.99.100:2377&quot;This node joined a swarm as a worker.$ docker-machine ssh worker2 &quot;docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-envtxo4dl6df2ar3qldcccfdg 192.168.99.100:2377&quot;This node joined a swarm as a worker. 还有另外一个manager2主机，需要配置为管理节点，我们需要先在manager1主机上，获取管理节点对应的token，然后再配置为管理节点，命令： 1234567$ docker-machine ssh manager1 &quot;docker swarm join-token manager&quot;To add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-0koz1b98sco8r5cn3g61eahnu 192.168.99.100:2377$ docker-machine ssh manager2 &quot;docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-0koz1b98sco8r5cn3g61eahnu 192.168.99.100:2377&quot;This node joined a swarm as a manager. 配置好之后，我们进入manager1主机内（上面的命令也可以在主机内执行），然后查看集群节点的信息，命令： 123456$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUSn0ub7dpn90rxjq97dr0g8we0w * manager1 Ready Active Leadert4cy67qp0bf2spgabsutwxnzt manager2 Ready Active Reachableif0kmzp4ww3oy57y7cha7v36t worker1 Ready Active jgg61cujzaeb3du5796fm0x2g worker2 Ready Active Leader表示当然集群的头，Reachable可以理解为头的候选人，头一挂掉它就顶上去了。 需要注意的是，我当天配置好之后，把所有的 Docker 主机都stop了，然后隔天重新start之后，出现了下面问题： 12docker node lsError response from daemon: rpc error: code = Unknown desc = The swarm does not have a leader. It&apos;s possible that too few managers are online. Make sure more than half of the managers are online. 好像是集群节点丢失了头，相关问题：如何处理 docker swarm 集群”The swarm does not have a leader”问题，按照文章进行解决： 12345678$ docker swarm init --force-new-clusterError response from daemon: could not choose an IP address to advertise since this system has multiple addresses on different interfaces (10.0.2.15 on eth0 and 192.168.99.102 on eth1) - specify one with --advertise-addr$ docker swarm init --force-new-cluster --advertise-addr 192.168.99.102Error response from daemon: This node is not a swarm manager. Worker nodes can&apos;t be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager.$ docker node ls卡死$ docker-machine restart manager1 重启不了，一直转圈 没办法，后来我只能删掉四个 Docker 主机，重新进行创建了。 3. Docker Service 部署单个集群服务在部署集群服务之前，我们需要做些准备工作，因为 Docker 主机中没有配置 Docker 镜像加速地址，所以在拉取官方镜像的时候，肯定会非常慢，除了配置 Docker 镜像加速地址之外，我们还可以使用 Docker 私有镜像仓库，来解决这个问题。 参考文章：Ubuntu Docker Registry 搭建私有仓库 这边，我再简单说明下配置步骤，首先，在 Mac OS 上执行下面命令： 12345678$ docker run -d -v /Users/xishuai/Documents/Docker:/var/lib/registry -p 5000:5000 --restart=always --name registry registry$ docker tag nginx 192.168.99.1:5000/nginx:latest &amp;&amp; docker push 192.168.99.1:5000/nginx:latest &amp;&amp; docker pull 192.168.99.1:5000/nginx:latest$ curl http://192.168.99.1:5000/v2/_catalog&#123;&quot;repositories&quot;:[&quot;nginx&quot;]&#125; 我们在 Mac OS 上创建了一个私有仓库容器，并把nginx镜像放到私有仓库中，因为没有使用 Https，所以在拉取和推送镜像的时候，会报如下错误（Mac OS 和 Docker 主机都会报错）： 123$ docker pull 192.168.99.1:5000/nginx:latestThe push refers to a repository [192.168.99.1:5000/nginx]Get https://192.168.99.1:5000/v1/_ping: http: server gave HTTP response to HTTPS client 解决方式，我们需要分别在四个 Docker 主机中添加配置（Docker for Mac 在管理界面配置即可），命令： 123$ sudo touch /etc/docker/daemon.json &amp;&amp; sudo chmod 777 /etc/docker/daemon.json &amp;&amp; sudo echo &apos;&#123; &quot;insecure-registries&quot;: [&quot;192.168.99.1:5000&quot;] &#125;&apos; &gt; /etc/docker/daemon.json 然后重启四个 Docker 主机（Docker for Mac 也需要重启），命令： 1234$ docker-machine restart manager1 &amp;&amp; docker-machine restart manager2 &amp;&amp; docker-machine restart worker1 &amp;&amp; docker-machine restart worker2 上面比较啰嗦，我们接下来正式部署集群服务，还是拿nginx镜像做为示例，命令（docker service create命令详细说明）： 12345678$ docker service create --replicas 4 -p 8088:80 --name nginx 192.168.99.1:5000/nginx:latestap8h8srb8yh3mni0h2nz61njzoverall progress: 4 out of 4 tasks 1/4: running [==================================================&gt;] 2/4: running [==================================================&gt;] 3/4: running [==================================================&gt;] 4/4: running [==================================================&gt;] verify: Service converged 需要注意的是，--replicas 4表示创建服务的实例个数（默认是一个），啥意思？比如4，就是在四个 Docker 主机上，分别创建一个nginx服务，如果是3，那就是三个 Docker 主机，或者你可以理解为 Docker 主机的个数，另外，REPLICAS会有进度显示，并且执行是异步的。 我们也可以手动设置实例个数，命令： 1$ docker service scale nginx=4 部署好服务后，我们就可以进行查看了，命令： 12345678910$ docker service lsID NAME MODE REPLICAS IMAGE PORTSap8h8srb8yh3 nginx replicated 4/4 192.168.99.1:5000/nginx:latest *:8080-&gt;8080/tcp$ docker service ps nginxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSl2rdrwzs5zog nginx.1 192.168.99.1:5000/nginx:latest manager1 Running Running about a minute ago vsfczzbwanx3 nginx.2 192.168.99.1:5000/nginx:latest manager2 Running Running about a minute ago qtbgw5h6dsi9 nginx.3 192.168.99.1:5000/nginx:latest worker Running Running about a minute ago za2ejnvb3n6z nginx.4 192.168.99.1:5000/nginx:latest worker2 Running Running about a minute ago 我们任意使用四个 Docker 主机中的一个 IP 地址，浏览器打开：http://192.168.99.100:8088/ 4. Docker Stack 部署多个集群服务，以及 GUI 管理页面docker service部署的是单个服务，我们可以使用docker stack进行多服务编排部署，使用的同样是docker-compose.yml配置文件，示例： 1234567891011121314151617181920212223242526272829303132version: &quot;3&quot;services: nginx: image: 192.168.99.1:5000/nginx:latest ports: - 8088:80 deploy: mode: replicated replicas: 4 visualizer: image: 192.168.99.1:5000/dockersamples/visualizer:latest ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: replicas: 1 placement: constraints: [node.role == manager] portainer: image: 192.168.99.1:5000/portainer/portainer:latest ports: - &quot;9000:9000&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: replicas: 1 placement: constraints: [node.role == manager] 如上所示，我们总共需要部署三个服务，出了nginx服务作为示例之外，visualizer（官方地址）和portainer（官方地址）都是集群 GUI 管理服务。 部署命令： 1234$ docker stack deploy -c docker-compose.yml deploy-demoCreating service deploy-demo_nginxCreating service deploy-demo_visualizerCreating service deploy-demo_portainer 部署成功之后，我们可以查看具体详情，命令： 123$ docker stack lsNAME SERVICESdeploy-demo 3 查看visualizerGUI 集群管理，浏览器打开：http://192.168.99.100:8080/ 查看portainerGUI 集群管理，需要先配置账号信息，浏览器打开：http://192.168.99.100:9000/ 可以看到，portainer比visualizer强大太多了，甚至我们所有的操作都可以在portainer上完成。 5. docker-machine、docker swarm、docker node、docker service 和 docker stack 常用命令docker-machine 常用命令 命令 说明 docker-machine create 创建一个 Docker 主机（常用-d virtualbox） docker-machine ls 查看所有的 Docker 主机 docker-machine ssh SSH 到主机上执行命令 docker-machine env 显示连接到某个主机需要的环境变量 docker-machine inspect 输出主机更多信息 docker-machine kill 停止某个主机 docker-machine restart 重启某台主机 docker-machine rm 删除某台主机 docker-machine scp 在主机之间复制文件 docker-machine start 启动一个主机 docker-machine status 查看主机状态 docker-machine stop 停止一个主机 docker swarm 常用命令 命令 说明 docker swarm init 初始化集群 docker swarm join-token worker 查看工作节点的 token docker swarm join-token manager 查看管理节点的 token docker swarm join 加入集群中 docker node 常用命令 命令 说明 docker node ls 查看所有集群节点 docker node rm 删除某个节点（-f强制删除） docker node inspect 查看节点详情 docker node demote 节点降级，由管理节点降级为工作节点 docker node promote 节点升级，由工作节点升级为管理节点 docker node update 更新节点 docker node ps 查看节点中的 Task 任务 docker service 常用命令 命令 说明 docker service create 部署服务 docker service inspect 查看服务详情 docker service logs 产看某个服务日志 docker service ls 查看所有服务详情 docker service rm 删除某个服务（-f强制删除） docker service scale 设置某个服务个数 docker service update 更新某个服务 docker stack 常用命令 命令 说明 docker stack deploy 部署新的堆栈或更新现有堆栈 docker stack ls 列出现有堆栈 docker stack ps 列出堆栈中的任务 docker stack rm 删除堆栈 docker stack services 列出堆栈中的服务 docker stack down 移除某个堆栈（不会删除数据） 参考资料： Get Started, Part 4: Swarms Docker 三剑客之 Docker Swarm Docker Swarm 入门一篇文章就够了 Docker 的命令之集群节点管理 Swarm node docker service 命令 Docker 命令行参考(37) – docker service create 创建一个服务 Docker Machine 是什么？ docker swarm 学习命令整理","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"Docker Swarm入门一篇文章就够了","slug":"Docker-Swarm入门一篇文章就够了","date":"2019-03-16T04:01:02.000Z","updated":"2019-03-16T04:18:27.583Z","comments":true,"path":"Docker/Docker-Swarm入门一篇文章就够了/","link":"","permalink":"http://blog.ozairs.com/Docker/Docker-Swarm入门一篇文章就够了/","excerpt":"","text":"Swarm 在 Docker 1.12 版本之前属于一个独立的项目，在 Docker 1.12 版本发布之后，该项目合并到了 Docker 中，成为 Docker 的一个子命令。目前，Swarm 是 Docker 社区提供的唯一一个原生支持 Docker 集群管理的工具。它可以把多个 Docker 主机组成的系统转换为单一的虚拟 Docker 主机，使得容器可以组成跨主机的子网网络。 1. Swarm 认识Swarm 是目前 Docker 官方唯一指定（绑定）的集群管理工具。Docker 1.12 内嵌了 swarm mode 集群管理模式。 为了方便演示跨主机网络，我们需要用到一个工具——Docker Machine，这个工具与 Docker Compose、Docker Swarm 并称 Docker 三剑客，下面我们来看看如何安装 Docker Machine： 123$ curl -L https://github.com/docker/machine/releases/download/v0.9.0-rc2/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; chmod +x /tmp/docker-machine &amp;&amp; sudo cp /tmp/docker-machine /usr/local/bin/docker-machine 安装过程和 Docker Compose 非常类似。现在 Docker 三剑客已经全部到齐了。 在开始之前，我们需要了解一些基本概念，有关集群的 Docker 命令如下： docker swarm：集群管理，子命令有 init, join,join-token, leave, update docker node：节点管理，子命令有 demote, inspect,ls, promote, rm, ps, update docker service：服务管理，子命令有 create, inspect, ps, ls ,rm , scale, update docker stack/deploy：试验特性，用于多应用部署，等正式版加进来再说。 2. 创建集群首先使用 Docker Machine 创建一个虚拟机作为 manger 节点。 1234567891011121314151617181920212223$ docker-machine create --driver virtualbox manager1 Running pre-create checks...(manager1) Unable to get the latest Boot2Docker ISO release version: Get https://api.github.com/repos/boot2docker/boot2docker/releases/latest: dial tcp: lookup api.github.com on [::1]:53: server misbehavingCreating machine...(manager1) Unable to get the latest Boot2Docker ISO release version: Get https://api.github.com/repos/boot2docker/boot2docker/releases/latest: dial tcp: lookup api.github.com on [::1]:53: server misbehaving(manager1) Copying /home/zuolan/.docker/machine/cache/boot2docker.iso to /home/zuolan/.docker/machine/machines/manager1/boot2docker.iso...(manager1) Creating VirtualBox VM...(manager1) Creating SSH key...(manager1) Starting the VM...(manager1) Check network to re-create if needed...(manager1) Found a new host-only adapter: &quot;vboxnet0&quot;(manager1) Waiting for an IP...Waiting for machine to be running, this may take a few minutes...Detecting operating system of created instance...Waiting for SSH to be available...Detecting the provisioner...Provisioning with boot2docker...Copying certs to the local machine directory...Copying certs to the remote machine...Setting Docker configuration on the remote daemon...Checking connection to Docker...Docker is up and running!To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env manager1 查看虚拟机的环境变量等信息，包括虚拟机的 IP 地址： 1234567$ docker-machine env manager1export DOCKER_TLS_VERIFY=&quot;1&quot;export DOCKER_HOST=&quot;tcp://192.168.99.100:2376&quot;export DOCKER_CERT_PATH=&quot;/home/zuolan/.docker/machine/machines/manager1&quot;export DOCKER_MACHINE_NAME=&quot;manager1&quot;# Run this command to configure your shell: # eval $(docker-machine env manager1) 然后再创建一个节点作为 work 节点。 1$ docker-machine create --driver virtualbox worker1 现在我们有了两个虚拟主机，使用 Machine 的命令可以查看： 1234$ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmanager1 - virtualbox Running tcp://192.168.99.100:2376 v1.12.3 worker1 - virtualbox Running tcp://192.168.99.101:2376 v1.12.3 但是目前这两台虚拟主机并没有什么联系，为了把它们联系起来，我们需要 Swarm 登场了。 因为我们使用的是 Docker Machine 创建的虚拟机，因此可以使用 docker-machine ssh 命令来操作虚拟机，在实际生产环境中，并不需要像下面那样操作，只需要执行 docker swarm 即可。 把 manager1 加入集群： 12345678910$ docker-machine ssh manager1 docker swarm init --listen-addr 192.168.99.100:2377 --advertise-addr 192.168.99.100Swarm initialized: current node (23lkbq7uovqsg550qfzup59t6) is now a manager.To add a worker to this swarm, run the following command: docker swarm join \\ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \\ 192.168.99.100:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. 用 –listen-addr 指定监听的 ip 与端口，实际的 Swarm 命令格式如下，本例使用 Docker Machine 来连接虚拟机而已： 1$ docker swarm init --listen-addr &lt;MANAGER-IP&gt;:&lt;PORT&gt; 接下来，再把 work1 加入集群中： 1234$ docker-machine ssh worker1 docker swarm join --token \\ SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \\ 192.168.99.100:2377This node joined a swarm as a worker. 上面 join 命令中可以添加 –listen-addr $WORKER1_IP:2377 作为监听准备，因为有时候可能会遇到把一个 work 节点提升为 manger 节点的可能，当然本例子没有这个打算就不添加这个参数了。 注意：如果你在新建集群时遇到双网卡情况，可以指定使用哪个 IP，例如上面的例子会有可能遇到下面的错误。 123$ docker-machine ssh manager1 docker swarm init --listen-addr $MANAGER1_IP:2377Error response from daemon: could not choose an IP address to advertise since this system has multiple addresses on different interfaces (10.0.2.15 on eth0 and 192.168.99.100 on eth1) - specify one with --advertise-addrexit status 1 发生错误的原因是因为有两个 IP 地址，而 Swarm 不知道用户想使用哪个，因此要指定 IP。 12345678910$ docker-machine ssh manager1 docker swarm init --advertise-addr 192.168.99.100 --listen-addr 192.168.99.100:2377 Swarm initialized: current node (ahvwxicunjd0z8g0eeosjztjx) is now a manager.To add a worker to this swarm, run the following command: docker swarm join \\ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \\ 192.168.99.100:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. 集群初始化成功。 现在我们新建了一个有两个节点的“集群”，现在进入其中一个管理节点使用 docker node 命令来查看节点信息： 1234$ docker-machine ssh manager1 docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS23lkbq7uovqsg550qfzup59t6 * manager1 Ready Active Leaderdqb3fim8zvcob8sycri3hy98a worker1 Ready Active 现在每个节点都归属于 Swarm，并都处在了待机状态。Manager1 是领导者，work1 是工人。 现在，我们继续新建虚拟机 manger2、worker2、worker3，现在已经有五个虚拟机了，使用 docker-machine ls 来查看虚拟机： 123456NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmanager1 - virtualbox Running tcp://192.168.99.100:2376 v1.12.3 manager2 - virtualbox Running tcp://192.168.99.105:2376 v1.12.3 worker1 - virtualbox Running tcp://192.168.99.102:2376 v1.12.3 worker2 - virtualbox Running tcp://192.168.99.103:2376 v1.12.3 worker3 - virtualbox Running tcp://192.168.99.104:2376 v1.12.3 然后我们把剩余的虚拟机也加到集群中。 添加 worker2 到集群中： 1234$ docker-machine ssh worker2 docker swarm join \\ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \\ 192.168.99.100:2377This node joined a swarm as a worker. 添加 worker3 到集群中： 1234$ docker-machine ssh worker3 docker swarm join \\ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-c036gwrakjejql06klrfc585r \\ 192.168.99.100:2377This node joined a swarm as a worker. 添加 manager2 到集群中： 先从 manager1 中获取 manager 的 token： 123456$ docker-machine ssh manager1 docker swarm join-token managerTo add a manager to this swarm, run the following command: docker swarm join \\ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-8tn855hkjdb6usrblo9iu700o \\192.168.99.100:2377 然后添加 manager2 到集群中： 1234$ docker-machine ssh manager2 docker swarm join \\ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-8tn855hkjdb6usrblo9iu700o \\ 192.168.99.100:2377This node joined a swarm as a manager. 现在再来查看集群信息： 1234567$ docker-machine ssh manager2 docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS16w80jnqy2k30yez4wbbaz1l8 worker1 Ready Active 2gkwhzakejj72n5xoxruet71z worker2 Ready Active 35kutfyn1ratch55fn7j3fs4x worker3 Ready Active a9r21g5iq1u6h31myprfwl8ln * manager2 Ready Active Reachabledpo7snxbz2a0dxvx6mf19p35z manager1 Ready Active Leader 3. 建立跨主机网络为了演示更清晰，下面我们把宿主机也加入到集群之中，这样我们使用 Docker 命令操作会清晰很多。 直接在本地执行加入集群命令： 1234$ docker swarm join \\ --token SWMTKN-1-3z5rzoey0u6onkvvm58f7vgkser5d7z8sfshlu7s4oz2gztlvj-8tn855hkjdb6usrblo9iu700o \\ 192.168.99.100:2377This node joined a swarm as a manager. 现在我们有三台 manager，三台 worker。其中一台是宿主机，五台虚拟机。 12345678$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS6z2rpk1t4xucffzlr2rpqb8u3 worker3 Ready Active 7qbr0xd747qena4awx8bx101s * user-pc Ready Active Reachable9v93sav79jqrg0c7051rcxxev manager2 Ready Active Reachablea1ner3zxj3ubsiw4l3p28wrkj worker1 Ready Active a5w7h8j83i11qqi4vlu948mad worker2 Ready Active d4h7vuekklpd6189fcudpfy18 manager1 Ready Active Leader 查看网络状态： 123456$ docker network lsNETWORK ID NAME DRIVER SCOPE764ff31881e5 bridge bridge local fbd9a977aa03 host host local 6p6xlousvsy2 ingress overlay swarm e81af24d643d none null local 可以看到在 swarm 上默认已有一个名为 ingress 的 overlay 网络, 默认在 swarm 里使用，本例子中会创建一个新的 overlay 网络。 123456789$ docker network create --driver overlay swarm_test4dm8cy9y5delvs5vd0ghdd89s$ docker network lsNETWORK ID NAME DRIVER SCOPE764ff31881e5 bridge bridge localfbd9a977aa03 host host local6p6xlousvsy2 ingress overlay swarme81af24d643d none null local4dm8cy9y5del swarm_test overlay swarm 这样一个跨主机网络就搭建好了，但是现在这个网络只是处于待机状态，下一小节我们会在这个网络上部署应用。 4. 在跨主机网络上部署应用首先我们上面创建的节点都是没有镜像的，因此我们要逐一 pull 镜像到节点中，这里我们使用前面搭建的私有仓库。 1234567891011121314151617181920212223242526272829303132333435$ docker-machine ssh manager1 docker pull reg.example.com/library/nginx:alpine alpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh manager2 docker pull reg.example.com/library/nginx:alpinealpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh worker1 docker pull reg.example.com/library/nginx:alpine alpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh worker2 docker pull reg.example.com/library/nginx:alpinealpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine$ docker-machine ssh worker3 docker pull reg.example.com/library/nginx:alpinealpine: Pulling from library/nginxe110a4a17941: Pulling fs layer... ...7648f5d87006: Pull completeDigest: sha256:65063cb82bf508fd5a731318e795b2abbfb0c22222f02ff5c6b30df7f23292feStatus: Downloaded newer image for reg.example.com/library/nginx:alpine 上面使用 docker pull 分别在五个虚拟机节点拉取 nginx:alpine 镜像。接下来我们要在五个节点部署一组 Nginx 服务。 部署的服务使用 swarm_test 跨主机网络。 12$ docker service create --replicas 2 --name helloworld --network=swarm_test nginx:alpine5gz0h2s5agh2d2libvzq6bhgs 查看服务状态： 123$ docker service lsID NAME REPLICAS IMAGE COMMAND5gz0h2s5agh2 helloworld 0/2 nginx:alpine 查看 helloworld 服务详情（为了方便阅读，已调整输出内容）： 1234$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORay081uome3 helloworld.1 nginx:alpine manager1 Running Preparing 2 seconds ago 16cvore0c96 helloworld.2 nginx:alpine worker2 Running Preparing 2 seconds ago 可以看到两个实例分别运行在两个节点上。 进入两个节点，查看服务状态（为了方便阅读，已调整输出内容）： 123456$ docker-machine ssh manager1 docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES119f787622c2 nginx:alpine &quot;nginx -g ...&quot; 4 minutes ago Up 4 minutes 80/tcp, 443/tcp hello ...$ docker-machine ssh worker2 docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5db707401a06 nginx:alpine &quot;nginx -g ...&quot; 4 minutes ago Up 4 minutes 80/tcp, 443/tcp hello ... 上面输出做了调整，实际的 NAMES 值为： 12helloworld.1.ay081uome3eejeg4mspa8pdlxhelloworld.2.16cvore0c96rby1vp0sny3mvt 记住上面这两个实例的名称。现在我们来看这两个跨主机的容器是否能互通： 首先使用 Machine 进入 manager1 节点，然后使用 docker exec -i 命令进入 helloworld.1 容器中 ping 运行在 worker2 节点的 helloworld.2 容器。 12345678$ docker-machine ssh manager1 docker exec -i helloworld.1.ay081uome3eejeg4mspa8pdlx \\ ping helloworld.2.16cvore0c96rby1vp0sny3mvtPING helloworld.2.16cvore0c96rby1vp0sny3mvt (10.0.0.4): 56 data bytes64 bytes from 10.0.0.4: seq=0 ttl=64 time=0.591 ms64 bytes from 10.0.0.4: seq=1 ttl=64 time=0.594 ms64 bytes from 10.0.0.4: seq=2 ttl=64 time=0.624 ms64 bytes from 10.0.0.4: seq=3 ttl=64 time=0.612 ms^C 然后使用 Machine 进入 worker2 节点，然后使用 docker exec -i 命令进入 helloworld.2 容器中 ping 运行在 manager1 节点的 helloworld.1 容器。 12345678$ docker-machine ssh worker2 docker exec -i helloworld.2.16cvore0c96rby1vp0sny3mvt \\ ping helloworld.1.ay081uome3eejeg4mspa8pdlx PING helloworld.1.ay081uome3eejeg4mspa8pdlx (10.0.0.3): 56 data bytes64 bytes from 10.0.0.3: seq=0 ttl=64 time=0.466 ms64 bytes from 10.0.0.3: seq=1 ttl=64 time=0.465 ms64 bytes from 10.0.0.3: seq=2 ttl=64 time=0.548 ms64 bytes from 10.0.0.3: seq=3 ttl=64 time=0.689 ms^C 可以看到这两个跨主机的服务集群里面各个容器是可以互相连接的。 为了体现 Swarm 集群的优势，我们可以使用虚拟机的 ping 命令来测试对方虚拟机内的容器。 1234567891011121314$ docker-machine ssh worker2 ping helloworld.1.ay081uome3eejeg4mspa8pdlxPING helloworld.1.ay081uome3eejeg4mspa8pdlx (221.179.46.190): 56 data bytes64 bytes from 221.179.46.190: seq=0 ttl=63 time=48.651 ms64 bytes from 221.179.46.190: seq=1 ttl=63 time=63.239 ms64 bytes from 221.179.46.190: seq=2 ttl=63 time=47.686 ms64 bytes from 221.179.46.190: seq=3 ttl=63 time=61.232 ms^C$ docker-machine ssh manager1 ping helloworld.2.16cvore0c96rby1vp0sny3mvtPING helloworld.2.16cvore0c96rby1vp0sny3mvt (221.179.46.194): 56 data bytes64 bytes from 221.179.46.194: seq=0 ttl=63 time=30.150 ms64 bytes from 221.179.46.194: seq=1 ttl=63 time=54.455 ms64 bytes from 221.179.46.194: seq=2 ttl=63 time=73.862 ms64 bytes from 221.179.46.194: seq=3 ttl=63 time=53.171 ms^C 上面我们使用了虚拟机内部的 ping 去测试容器的延迟，可以看到延迟明显比集群内部的 ping 值要高。 5. Swarm 集群负载现在我们已经学会了 Swarm 集群的部署方法，现在来搭建一个可访问的 Nginx 集群吧。体验最新版的 Swarm 所提供的自动服务发现与集群负载功能。 首先删掉上一节我们启动的 helloworld 服务： 12$ docker service rm helloworld helloworld 然后在新建一个服务，提供端口映射参数，使得外界可以访问这些 Nginx 服务： 12$ docker service create --replicas 2 --name helloworld -p 7080:80 --network=swarm_test nginx:alpine9gfziifbii7a6zdqt56kocyun 查看服务运行状态： 123$ docker service ls ID NAME REPLICAS IMAGE COMMAND9gfziifbii7a helloworld 2/2 nginx:alpine 不知你有没有发现，虽然我们使用 –replicas 参数的值都是一样的，但是上一节中获取服务状态时，REPLICAS 返回的是 0/2，现在的 REPLICAS 返回的是 2/2。 同样使用 docker service ps 查看服务详细状态时（下面输出已经手动调整为更易读的格式），可以看到实例的 CURRENT STATE 中是 Running 状态的，而上一节中的 CURRENT STATE 中全部是处于 Preparing 状态。 1234$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR9ikr3agyi... helloworld.1 nginx:alpine user-pc Running Running 13 seconds ago 7acmhj0u... helloworld.2 nginx:alpine worker2 Running Running 6 seconds ago 这就涉及到 Swarm 内置的发现机制了，目前 Docker 1.12 中 Swarm 已经内置了服务发现工具，我们不再需要像以前使用 Etcd 或者 Consul 这些工具来配置服务发现。对于一个容器来说如果没有外部通信但又是运行中的状态会被服务发现工具认为是 Preparing 状态，本小节例子中因为映射了端口，因此有了 Running 状态。 现在我们来看 Swarm 另一个有趣的功能，当我们杀死其中一个节点时，会发生什么。 首先 kill 掉 worker2 的实例： 12$ docker-machine ssh worker2 docker kill helloworld.2.7acmhj0udzusv1d7lu2tbuhu4helloworld.2.7acmhj0udzusv1d7lu2tbuhu4 稍等几秒，再来看服务状态： 12345678$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR9ikr3agyi... helloworld.1 nginx:alpine zuolan-pc Running Running 19 minutes ago 8f866igpl... helloworld.2 nginx:alpine manager1 Running Running 4 seconds ago 7acmhj0u... \\_ helloworld.2 nginx:alpine worker2 Shutdown Failed 11 seconds ago ...exit...$ docker service ls ID NAME REPLICAS IMAGE COMMAND9gfziifbii7a helloworld 2/2 nginx:alpine 可以看到即使我们 kill 掉其中一个实例，Swarm 也会迅速把停止的容器撤下来，同时在节点中启动一个新的实例顶上来。这样服务依旧还是两个实例在运行。 此时如果你想添加更多实例可以使用 scale 命令： 12$ docker service scale helloworld=3helloworld scaled to 3 查看服务详情，可以看到有三个实例启动了： 1234$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR9ikr3agyi... helloworld.1 nginx:alpine user-pc Running Running 30 minutes ago 8f866igpl... helloworld.2 nginx:alpine manager1 Running Running 11 minutes ago 7acmhj0u... \\_ helloworld.2 nginx:alpine worker2 Shutdown Failed 11 minutes ago exit1371vexr1jm... helloworld.3 nginx:alpine worker2 Running Running 4 seconds ago 现在如果想减少实例数量，一样可以使用 scale 命令： 12$ docker service scale helloworld=2helloworld scaled to 2 至此，Swarm的主要用法都已经介绍完了，主要讲述了 Swarm 集群网络的创建与部署。介绍了 Swarm 的常规应用，包括 Swarm 的服务发现、负载均衡等，然后使用 Swarm 来配置跨主机容器网络，并在上面部署应用。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"Docker-Compose入门","slug":"Docker-Compose入门","date":"2019-03-16T03:32:37.000Z","updated":"2019-03-16T04:18:55.022Z","comments":true,"path":"Docker/Docker-Compose入门/","link":"","permalink":"http://blog.ozairs.com/Docker/Docker-Compose入门/","excerpt":"","text":"Compose 是一个用户定义和运行多个容器的 Docker 应用程序。在 Compose 中你可以使用 YAML 文件来配置你的应用服务。然后，只需要一个简单的命令，就可以创建并启动你配置的所有服务。 使用 Compose 基本会有如下三步流程： 在 Dockfile 中定义你的应用环境，使其可以在任何地方复制。 在 docker-compose.yml 中定义组成应用程序的服务，以便它们可以在隔离的环境中一起运行。 最后，运行dcoker-compose up，Compose 将启动并运行整个应用程序。 开始使用 Docker Compose这里面将会在 Docker Compose 中构建一个简单的 Python 程序。应用程序将使用 Flask 框架，并在 Redis 中维护一个计数器。 先决条件 确认你已经安装了 Docker Engine 与 Docker Compose。你不需要安装 Python 或者 Redis，这两个都会在 Docker 镜像中提供。 第一步：定义应用依赖 为项目创建目录 12$ mkdir composetest$ cd composetest12 创建一个名为 app.py 的文件，并将如下内容粘贴进去： 1234567891011121314151617181920212223242526import timeimport redisfrom flask import Flaskapp = Flask(__name__)cache = redis.Redis(host='redis', port=6379)def get_hit_count(): retries = 5 while True: try: return cache.incr('hits') except redis.exceptions.ConnectionError as exc: if retries == 0: raise exc retries -= 1 time.sleep(0.5)@app.route('/')def hello(): count = get_hit_count() return 'Hello World! I have been seen &#123;&#125; times.\\n'.format(count)if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", debug=True)1234567891011121314151617181920212223242526 在这个例子中，redis 就是应用网络中 redis 容器的主机名。我们使用 Redis 的默认端口 6379。 在你的项目路径下创建另外一个叫做 requirements.txt 的文件，并将如下内容粘贴进去： 12flaskredis12 第二步：创建 Dockerfile在这一步中，你需要编写一个 Dockerfile 来构建一个 Docker 镜像。这个镜像包含 Python 应用的所有依赖，也包含 Python 其本身。 在你的项目路径下创建一个 Dockerfile 文件，并将如下内容粘贴进去： 12345FROM python:3.4-alpineADD . /codeWORKDIR /codeRUN pip install -r requirements.txtCMD [\"python\", \"app.py\"]12345 这会告诉容器： 构建一个基于 Python 3.4 的镜像 把当前目录添加到镜像中的 /code 路径下 把工作路径设置成 /code 安装 Python 依赖 设置容器的默认命令为 python app.py 有关如何编写 Dockerfiles 的更多信息，请参考 Docker user guide 与 Dockerfile reference。 第三步：在 Compose 文件中定义一个服务在工作路径下创建一个叫做 docker-compose.yml 并粘贴如下内容： 12345678version: '3'services: web: build: . ports: - \"5000:5000\" redis: image: \"redis:alpine\"12345678 这个 Compose 文件中定义了两个服务 web 与 redis。此 Web 服务： 使用当前目录 Dockerfile 构建出来的镜像 将容器上暴露的5000端口转发到主机的5000端口。我们使用 Flask Web 服务器的默认端口 5000。 而 Redis 服务使用从 Docker Hub 注册表中拉取的公有镜像。 第四步：在 Compose 中构建并运行你的应用 在你的项目路径下通过 docker-compose up 命令启动你的应用。 12345678910111213141516171819$ docker-compose upCreating network \"composetest_default\" with the default driverCreating composetest_web_1 ...Creating composetest_redis_1 ...Creating composetest_web_1Creating composetest_redis_1 ... doneAttaching to composetest_web_1, composetest_redis_1web_1 | * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)redis_1 | 1:C 17 Aug 22:11:10.480 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Ooredis_1 | 1:C 17 Aug 22:11:10.480 # Redis version=4.0.1, bits=64, commit=00000000, modified=0, pid=1, just startedredis_1 | 1:C 17 Aug 22:11:10.480 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.confweb_1 | * Restarting with statredis_1 | 1:M 17 Aug 22:11:10.483 * Running mode=standalone, port=6379.redis_1 | 1:M 17 Aug 22:11:10.483 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.web_1 | * Debugger is active!redis_1 | 1:M 17 Aug 22:11:10.483 # Server initializedredis_1 | 1:M 17 Aug 22:11:10.483 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.web_1 | * Debugger PIN: 330-787-903redis_1 | 1:M 17 Aug 22:11:10.483 * Ready to accept connections12345678910111213141516171819 Compose 拉取一个 Redis 镜像，以你自己的代码构建一个镜像，并启动你定义的服务。在这种情况下，代码在构建时静态拷贝到镜像中。 在浏览器中输入 http://0.0.0.0:5000 查看应用的运行情况。 你将在你的浏览器中看到如下信息： 1Hello World! I have been seen 1 times.1 刷新一下浏览器，数值将会增加。 1Hello World! I have been seen 2 times.1 切换到另外一个容器，输入 docker image ls 列举所有本地镜像。 镜像列表中将返回 reidis 与 web。 12345$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcomposetest_web latest e2c21aa48cc1 4 minutes ago 93.8MBpython 3.4-alpine 84e6077c7ab6 7 days ago 82.5MBredis alpine 9d8fa9aa0e5b 3 weeks ago 27.5MB12345 你也可以通过 docker inspect &lt;tag or id&gt; 来检查镜像。 停止镜像，即可以在你的项目路径下使用 docker-compose down ，也可以在原始的终端上使用 CTRL+C 停止当前启动着的应用。 第五步：编辑 Compose 文件添加一个绑定挂载在你的项目路径下编辑 docker-compose.yml 为 web 服务添加一个绑定挂载： 12345678910version: '3'services: web: build: . ports: - \"5000:5000\" volumes: - .:/code redis: image: \"redis:alpine\"12345678910 这个新的 volumes 键将当前路径（项目路径）与容器中的 /code 路径挂载到一起，允许你及时修改代码而不用重新构建镜像。 第六步：重新构建并在 Compose 中运行应用在你的项目路径下，输入 docker-compose up 命令使用更新后的 Compose 文件构建应用并启动。 123456789$ docker-compose upCreating network \"composetest_default\" with the default driverCreating composetest_web_1 ...Creating composetest_redis_1 ...Creating composetest_web_1Creating composetest_redis_1 ... doneAttaching to composetest_web_1, composetest_redis_1web_1 | * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)...123456789 再次检查 Web 浏览器中的 Hello World 消息，然后刷新以查看计数增量。 第七步：更新应用程序因为应用程序的代码通过 volume 挂载到容器中，你可以更改其代码并立即查看更改，而不必重新生成镜像。 修改 app.py 中的欢迎语并保存。例如，将 Hello World！ 改成 Hello from Docker!: 1return 'Hello from Docker! I have been seen &#123;&#125; times.\\n'.format(count)1 刷新你的浏览器。欢迎语已经更新，而计数器仍然在增长。 第八步：尝试一些其它命令如果你希望你的应用程序在后台运行，你可以将 -d 标记传递给 docker-compose up 并使用 docker-compose ps 来查看当前运行的应用。 123456789$ docker-compose up -dStarting composetest_redis_1...Starting composetest_web_1...$ docker-compose psName Command State Ports-------------------------------------------------------------------composetest_redis_1 /usr/local/bin/run Upcomposetest_web_1 /bin/sh -c python app.py Up 5000-&gt;5000/tcp123456789 docker-compose run 命令允许你为你的应用程序运行一次性命令。例如，查看哪些环境变量可以用于 web 服务： 1$ docker-compose run web env1 通过 docker-compose --help 查看所有可用的命令。 如果你使用 docker-compose up -d 启动了 Compose，你可能希望在它们运行完成后停止服务： 1$ docker-compose stop1 你可以停掉所有一切，使用 down 命令完全移除容器。传递 —volumes 还可以删除 Redis 容器中所使用的数据卷。 1$ docker-compose down --volumes","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/categories/Docker/"}]},{"title":"在Amazon ECS上部署Docker容器","slug":"在Amazon-ECS上部署Docker容器","date":"2019-03-16T02:17:06.000Z","updated":"2019-03-16T02:53:00.117Z","comments":true,"path":"AWS/在Amazon-ECS上部署Docker容器/","link":"","permalink":"http://blog.ozairs.com/AWS/在Amazon-ECS上部署Docker容器/","excerpt":"","text":"Amazon Elastic Container Service (Amazon ECS) 是用于在可扩展群集上运行 Docker 应用程序的 Amazon Web Service。在本教程中，您将了解如何在负载均衡器后面的 Amazon ECS 集群上运行支持 Docker 的示例应用程序，对该示例应用程序进行测试，然后删除您的资源以免产生费用。 在本教程中完成的所有操作均符合免费套餐条件。 管理 AWS 资源登录控制台 步骤 1：设置 Amazon ECS 的首次运行Amazon ECS 首次运行向导将引导您创建集群并启动示例 Web 应用程序。在此步骤中，您将进入 Amazon ECS 控制台并启动该向导。 a. 单击此处以打开 Amazon ECS 控制台首次运行向导。 b. 使用 Amazon ECS，您可以选择使用 Amazon Elastic Container Registry (Amazon ECR) 创建映像存储库，并向其推送一个映像作为首次运行向导的一部分（参见右侧的屏幕截图）。该功能目前在部分区域可用。 如果没有 Amazon ECR 选项，请跳至步骤 2。 如果有 Amazon ECR 选项，则取消选中 Deploy a sample application onto an Amazon ECS Cluster 旁边的复选框，然后选择 Continue。 步骤 2：创建任务定义任务定义类似于应用程序的蓝图。在此步骤中，您将指定一个任务定义，以便 Amazon ECS 分辨出将哪个 Docker 映像用于容器、该任务将使用多少个容器以及每个容器的资源分配情况。 任务定义预加载了默认的配置值。 查看默认值并选择 Next Step。 如果您希望修改配置或想要了解更多内容，请参阅任务定义参数。 步骤 3：配置服务您现已创建了任务定义，接下来是配置 Amazon ECS 服务。服务可启动并维护集群中任务定义的副本。例如，通过将某个应用程序作为服务来运行，Amazon ECS 将自动恢复任何已停止的任务并维持您所指定的副本数。 a. 配置服务选项： Service Name：默认的 sample-webapp 是一款由 AWS 提供的基于 Web 的“Hello World”应用程序。这意味着它可无限期运行，因此，通过将其作为服务来运行，如果任务的运行状况不佳或意外终止，该应用程序将重新启动。 Desired number of tasks：若不超出 AWS 免费套餐的范围，请保留默认值 1。此操作将为您的任务创建一个副本。 b. Elastic Load Balancing：您可以选择将负载均衡器与您的服务配合使用。Amazon ECS 可以创建 Elastic Load Balancing (ELB) 负载均衡器，以在启动任务的各个容器实例间分配流量。 Container name: host port：选择 Simple-app:80。 为示例应用程序设置 ELB listener protocol、ELB listener port 和 ELB health check 的默认值。有关负载均衡配置的更多信息，请参阅 Service Load Balancing。 c. 将负载均衡器挂载到 Amazon ECS 服务之前，必须先创建服务要使用的 Identity and Access Management (IAM) 角色。此操作将允许 Amazon ECS 调用 Amazon EC2 和 Elastic Load Balancing API，以在负载均衡器中注册和取消注册实例。 如果您还没有服务 IAM 角色，Amazon ECS 将创建一个名为 ecsServiceRole 的角色。 如果您有现有的 Amazon ECS 服务角色，请从下拉菜单中选择该角色。 d. 检查设置并选择 Next Step。 步骤 4：配置集群在集群上运行 Amazon ECS 任务，该集群是运行 Amazon ECS 容器代理的容器实例集合。在此步骤中，您将配置集群、检查安全设置并设置 IAM 角色。 a. 按照以下配置设置执行操作： Cluster name：输入 sample-cluster。 EC2 instance type：默认的 t2.micro 实例类型可确保您不超出免费套餐的范围。CPU 和内存资源越多的实例类型可以处理的任务就越多。有关不同实例类型的更多信息，请参阅 Amazon EC2 实例类型。 Number of instances：保留默认值 1 以启动一个要放置任务的集群中启动的 Amazon EC2 实例。集群中的实例越多，可在其上放置的任务就越多。 Key pair：稍后通过 SSH 连接到实例时需要密钥对。您可通过选择 None – unable to SSH、选择现有密钥对或在 Amazon EC2 控制台中创建一个密钥对以继续操作。 b.（可选）安全组：默认值 (Anywhere) 可允许从整个 Internet 进行访问。您还可以选择 CIDR 块以限制对实例的访问。 c. 容器实例 IAM 角色： 如果您没有 IAM 角色，Amazon ECS 向导将会为您创建一个。 如果您有现有的容器实例 IAM 角色，请从下拉菜单中选择该角色。 d. 选择 Review and Launch。 步骤 5：启动和查看资源在上述步骤中，您配置了任务定义（类似于应用程序蓝图）、Amazon ECS 服务（可启动并维护任务定义的副本）和集群（是运行容器代理的容器实例集合）。在此步骤中，您将检查、启动和查看您所创建的资源。 a. 在启动之前，您有最后一次机会来检查任务定义、任务配置和集群配置。 选择 Launch instance &amp; run service。 b. 您此时位于 Launch Status 页面上，该页面将显示启动状态并描述了过程的每一步。 启动完成后，选择 View service。 步骤 6：打开示例应用程序在此步骤中，您可通过将您的浏览器指向负载均衡器 DNS 名称来验证示例应用程序是否已启动并处于运行状态。 a. 在“sample-webapp”页面上，单击您的负载均衡器名称。 b. 现在将测试该示例应用程序： 复制 ELB DNS 名称。 将其粘贴到新的浏览器窗口中。 按键盘上的 Enter 键以查看示例应用程序（在本示例中为静态网页）。 步骤 7：删除资源在本教程中，您启动了三种资源：一个 Amazon ECS 集群、一个 Amazon EC2 实例和一个负载均衡器。在此步骤中，您将清除所有资源以免产生不必要的费用。 a. 重新导航至 Amazon ECS 控制台页面 单击集群名称 (sample-cluster)。 b. 选中 sample-webapp 旁边的复选框，然后单击 Update。 c. 为确保您不会意外删除带有活动任务的服务，您需要在 Amazon ECS 删除某个服务之前终止所有任务。 将任务数设置为 0，然后选择 Update Service。 更新服务之后，选择 Delete。 d. 删除通过集群启动的 Amazon EC2 实例： 进入 Amazon EC2 控制台 在左侧窗格中，选择 Instances。 选中名为 ECS Instance – EC2ContainerService-default 的实例旁边的复选框。 依次选择 Actions &gt; Instance State &gt; Terminate。 e. 删除负载均衡器： 在左侧窗格中，选择 Load Balancers。 选中您为服务创建的负载均衡器旁边的复选框（应以 EC2Contai-EcsElast 开头）。 右键单击并选择 Delete。 恭喜您！恭喜您！您已了解如何在 Amazon Elastic Container Service (Amazon ECS) 中配置、部署和删除支持 Docker 的应用程序。Amazon ECS 是一个可高度扩展的高性能容器管理服务，它支持 Docker 容器，并允许您在 Amazon EC2 实例的托管集群上轻松地运行应用程序。","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"ssh-key git多账户配置","slug":"ssh-key-git多账户配置","date":"2019-03-15T06:03:34.000Z","updated":"2019-03-15T06:05:03.611Z","comments":true,"path":"DevOps/ssh-key-git多账户配置/","link":"","permalink":"http://blog.ozairs.com/DevOps/ssh-key-git多账户配置/","excerpt":"","text":"在使用git的时候，一般我们使用的远程Git服务器是github，这时只需简单的生成ssh-key密钥对并将公钥添加到github中就可以使用ssh了。 但在公司开发使用内部的git时，一般在gitlab,使用的邮箱一般是公司的邮箱，那么就需要配置多个ssh-key账户了。 假设user使用github的邮箱为user1@163.com;user2使用gitlab的邮箱为user2@163.com,下面是配置过程： 首先进入用户主目录下的.ssh文件夹，我们生成的密钥对放在这儿 1$ cd ~/.ssh 分别为user1和user2生成密钥对： 默认三次回车生成key的名字为id_rsa，注意在生成第二个的时候不要使用默认名，否则会覆盖第一个，在以下位置为第二个输入名字 12345#新建SSH key$ ssh-keygen -t rsa -C &quot;user1@163.com&quot;$ ssh-keygen -t rsa -C &quot;user2@163.com&quot;#设置user2的命名为id_rsa_work Enter file in which to save the key (/c/Users/Administrator/.ssh/id_rsa): id_rsa_work 此时在.ssh目录下就有两个密钥对文件id_rsa和id_rsa_work,我们将公钥分别拷至对应的Git服务器 添加key到SSH agent中: 此时还无法使用第二个服务器，因为Git会默认只读取到id_rsa,为了让SSH识别新的私钥，需将其添加到SSH agent中： 12$ ssh-add ~/.ssh/id_rsa$ ssh-add ~/.ssh/id_rsa_work 如果出现Could not open a connection to your authentication agent的错误，就试着用以下命令： 123$ ssh-agent bash$ ssh-add ~/.ssh/id_rsa$ ssh-add ~/.ssh/id_rsa_work 成功会显示： 1Identity added: /c/Users/Windows用户名/.ssh/key名 (/c/Users/Windows用户名/.ssh/key名) 注意：ssh-add 这个命令不是用来永久性的记住你所使用的私钥的。实际上，它的作用只是把你指定的私钥添加到 ssh-agent 所管理的一个 session 当中。而 ssh-agent 是一个用于存储私钥的临时性的 session 服务，也就是说当你重启之后，ssh-agent 服务也就重置了。 创建并配置config文件使配置永久生效： 在.ssh目录下新建一个文本文件，命令为config，不需要后缀，bash下可直接使用touch config,编辑以下内容： 123456789101112# gitlabHost gitlab的IP HostName gitlab的Host //这里填你们公司的git网址即可 PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_work User user2# githubHost github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa User user1 其规则就是：从上至下读取config的内容，在每个Host下寻找对应的私钥。按照你的情况修改就可以。 使用：如果之前有设置全局用户名和邮箱的话，需要unset一下，可通过$ git config --list来查看全局配置 12$ git config --global --unset user.name$ git config --global --unset user.email 可以在不同的仓库下设置局部的用户名和邮箱用不同的账号登录，比如在公司的repository下: 12$ git config user.name &quot;user2&quot; $ git config user.email &quot;user2@163.com&quot; 测试： 1234$ ssh -T git@github.com#输出：Hi user1! You&apos;ve successfully authenticated, but GitHub does not provide shell access.$ ssh -T git@gitlab的IP#输出：Hi user2@163.com**, this is git@..... 测试成功。 如果出什么问题，可以通过ssh -vT git@github.com来输出编译信息，然后根据编译信息去解决问题。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"http://blog.ozairs.com/tags/ssh/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"使用Ansible进行自动化：构建VPC","slug":"使用Ansible进行自动化：构建VPC","date":"2019-03-14T11:19:52.000Z","updated":"2019-03-14T11:27:47.200Z","comments":true,"path":"Ansible/使用Ansible进行自动化：构建VPC/","link":"","permalink":"http://blog.ozairs.com/Ansible/使用Ansible进行自动化：构建VPC/","excerpt":"","text":"在本文中，我们将讨论如何使用Ansible在AWS VPC中自动配置云网络。如果你不确定你在这里做什么，也许可以偷看介绍。我们将构建的自动化范围将轻松配置以下所有内容： VPC和子网：创建VPC本身，以及跨三个可用区域的公共和私有子网：a，b和c Internet Gateway：为我们的公共资源配置网关以访问Internet NAT网关：配置NAT网关以允许我们的私有资源访问公共互联网 VPC路由表：定义路由以使我们的子网成为公共或私有（使用公共或NAT网关路由公共流量） 安全组：定义一些有用的安全组，用于限制仅在VPC内的通信，和/或允许来自公共互联网的SSH或HTTP / S流量 私有DNS：创建一个专用的Route53托管区域，用于解决VPC内的资源 请注意，本文不是为了解释这些AWS资源如何工作，甚至是如何配置它们，而是具体说明如何使用Ansible 自动化它们的配置。让我们开始吧！ VPC和子网配置主机和组变量我们将首先为我们的VPC定义一个Ansible主机。该主机将充当“逻辑主机”（因为它不是我们可以连接以运行命令的实际主机），它将代表所有VPC配置。因此，在我们的清单中，我们定义一个vpc具有单个vpc.ansibled（名称只是名称，没有特殊）主机的组，然后将该vpc组放入一个名为的高级“项目”组中project.ansibled。 现在让我们定义配置VPC和子网时需要的变量。在全球范围内，group_vars/all.yml我们只想定义默认情况下我们不想尝试与主机建立SSH连接，只需在本地运行Ansible任务（几乎所有的自动化都是AWS云和无服务器）： 我们的通用“所有”组的一般全局变量 我们的project.ansibled团队将进行一些繁重的工作并提供高级定义，例如VPC名称和我们的AWS凭证。我们将在此组中放置所有主机，以便在Ansible执行时可以使用此配置。所以在group_vars/project.ansibled.yml： 接下来，我们定义VPC本身的一些细节：VPC的IP地址块，安全组和子网配置。这些我们将定义为主机的主机变量vpc.ansibled，因为我们希望它们特定于此主机，而其他主机（当我们绕过它们时）将不需要自己引用这些定义。 我们的“vpc.ansibled”逻辑主机的特定配置 使用Ansible Vault保护敏感信息您可能想知道为什么存储我们的IAM凭证的vars aws_access_key和aws_secret_keyvars看起来像那样。鉴于我们要将自动化提交到存储库，我们需要确保此敏感信息不会以纯文本形式显示 - 输入Ansible Vault，Ansible的一项功能，允许我们加密文件和字符串，使它们成为可能安全的版本控制。 要生成我们可以在运行时解密的这些加密字符串，首先我们将加密密码写入（git-ignored，或者最好不在repo目录中）文件： 1echo“my_vault_pass”&gt;〜/ ansibled.vault 其次，将我们的纯文本值提供给ansible-vault程序，指定我们的密码文件，然后弹出一个加密的字符串，我们可以安全地存储在我们的Ansible vars中！ 您得到一个图像，因为Vault字符串在代码块中可怕地呈现 稍后，当我们想要执行自动化时，我们只需指定我们的保管库密码文件，或指定Ansible应该提示我们： 1234＃提示用户输入Vault密码ansible-playbook -i ansibled.inventory vpc.yml --ask-vault-pass＃从文件ansible-playbook -i ansibled.inventory vpc.yml中读取Vault密码--vault-password-file~ / ansibled.vault 任务我们的Ansible任务（“代码”）将全部存放在一个tasks/目录下，并存放在tasks/vpc/与创建VPC相关的所有任务的子目录下。然后，我们的playbook将在运行时动态地包含这些任务列表，允许我们组织我们的任务来创建模块化的“代码”块。 我们的VPC自动化的第一阶段将涉及以下步骤： 创建VPC 创建VPC子网 创建VPC安全组 为VPC创建Route53专用区域 有了我们的主要VPC组件，我们现在可以为我们的VPC配置路由和网关： 创建互联网网关 创建NAT网关（并更新VPC DNS） 为私有子网创建路由表 为公共子网创建路由表 剧本现在我们已经编写了一些构建我们的VPC的任务，我们只需要将它与一个剧本联系在一起。我们只是针对该vpc组，使用我们的AWS凭证详细信息填充我们的环境，并使用该include_tasks指令来提取我们的VPC任务。简单！ 直截了当地了解事实最后一个难题是为我们自动化的其他部分提供一种简单的方法来访问和利用我们刚刚提出的VPC基础设施的细节。例如，我们会希望能够容易地通过我们赋予他们的人类可读的名字（查找我们的VPC子网的ID private-a，public-b等等），就像我们建立我们的路由表上面的什么时候。因此，我们在以下位置创建“事实”任务列表tasks/vpc/facts.yml： 我们的VPC的这个“事实”任务列表现在可以包含在其他手册中以窥视AWS并发现有关我们VPC的一些重要信息！ 而且……行动！ 现在要自动构建我们的VPC，只需执行Ansible： 1234＃提示用户输入Vault密码ansible-playbook -i ansibled.inventory vpc.yml --ask-vault-pass＃从文件ansible-playbook -i ansibled.inventory vpc.yml中读取Vault密码--vault-password-file ansibled.vault 最后，在运行时拿一杯咖啡:)快乐的自动化！ 我喜欢自动化。这一系列的文章，自动化与Ansible，是一些Ansible bit’n bobs的记录，使我在管理软件基础设施时更轻松。 在GitHub或系列中的其他条目中全部检查： Ansible自动化：简介 Ansible自动化：构建VPC（本文） Ansible自动化：AWS Elasticsearch Ansible自动化：Aurora RDS集群 Ansible自动化：Logentries 【原文链接】：https://medium.com/@tomwwright/automating-with-ansible-building-a-vpc-c252944d3d2e","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}]},{"title":"Ansible进阶手册","slug":"Ansible进阶手册","date":"2019-03-14T09:07:52.000Z","updated":"2019-03-14T10:11:37.245Z","comments":true,"path":"Ansible/Ansible进阶手册/","link":"","permalink":"http://blog.ozairs.com/Ansible/Ansible进阶手册/","excerpt":"","text":"1. Playbook contain plays, plays contain tasks, tasks call modules2. Tasks run sequentially3. Handlers are triggered by tasks, and are run once, at the end of the plays. Ansible has many different ways to alter how playbooks run by using with_items, failed_when, changed_when, until, ignore_errors Ansible roles are a special kind of playbook that are fully self-contained with tasks, variables, configurations templates and other supporting files. 一、Ansible与AWS配合1、通过boto函数查询EC2实例 >&gt;&gt; import boto.ec2 >&gt;&gt; conn = boto.ec2.connect_to_region(“ap-southeast-2”) >&gt;&gt; statuses = conn.get_all_instance_status() >&gt;&gt; statuses [InstanceStatus:i-040f7235964b7d201] 二 、关于Module的调用 通过命令行方式调用Module: 123ansible webservers -m service -a &quot;name=httpd state=started&quot;ansible webservers -m pingansible webservers -m command -a &quot;/sbin/reboot -t now&quot; 通过Playbook调用Module: 12- name: reboot the servers action: command /sbin/reboot -t now 可以缩写为： 12- name: reboot the servers command: /sbin/reboot -t now 另外一种传参方式： 1234- name: restart webserver service: name: httpd state: restarted Ansible Tower方式 Ansible帮助命令 ansible help | less ansible-doc command 三 、Ansible的三种使用方式 命令行方式： Playbook调用方式： Ansible Tower：","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"}],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}]},{"title":"AWS云上的Puppet:快速入门参考部署","slug":"AWS云上的Puppet-快速入门参考部署","date":"2019-03-14T05:26:27.000Z","updated":"2019-04-22T03:33:52.467Z","comments":true,"path":"AWS/AWS云上的Puppet-快速入门参考部署/","link":"","permalink":"http://blog.ozairs.com/AWS/AWS云上的Puppet-快速入门参考部署/","excerpt":"","text":"本快速入门参考部署指南讨论在 Amazon Web Services (AWS) 云中部署和测试 Puppet Master 和 Puppet 代理所需的步骤。它还提供了用于查看和启动 AWS CloudFormation 模板（可自动进行部署）的链接，以及有关如何配置充当 Puppet 代理的 Amazon Elastic Compute Cloud (Amazon EC2) 实例的演练。 本指南面向计划在 AWS 云上实施或扩展 Puppet 工作负载的 IT 基础设施架构师、管理员和 DevOps 专家。 如果您拥有 AWS 账户且已熟悉 AWS 和 Puppet，可以启动快速入门以构建图 1 所示的架构。完成部署需要约 20 分钟。如果您是刚刚接触 AWS 或 Puppet，请查看实施详情，然后按照本指南后面部分提供的分步说明来启动快速入门。 https://fwd.aws/YBD5Y 如果您想更深一步地了解相关信息，则可以查看模板以了解自动执行此部署的 AWS CloudFormation 脚本。默认情况下，默认配置将部署三个使用 t2.medium 实例类型的服务器，但您也可以按需自定义模板。 https://fwd.aws/pkzpq 注意 运行本快速入门参考部署时，您需要支付所用的所有 AWS 服务的相关费用。价格可能会发生变化。有关完整详细信息，请参阅成本和许可证部分以及您所使用 AWS 服务的定价页面。 步骤 1.准备 AWS 账户 如果您还没有 AWS 账户，请按照屏幕说明在 https://aws.amazon.com 上创建一个。 作为注册流程的一部分，您会接到一个电话，并且需要通过手机键盘输入 PIN 码。 使用导航栏中的区域选择器选择要在 AWS 上将 Puppet 部署到的 AWS 区域。 Amazon EC2 位置由区域 和可用区 构成。区域分散存在，位于独立的地理区域。 图 2：选择 AWS 区域 提示 考虑选择最接近数据中心或企业网络的区域，以减少运行于 AWS 的系统与企业网络上的系统和用户之间的网络延迟。 在首选区域中创建一个密钥对。为此，在 Amazon EC2 控制台的导航窗格中，依次选择 Key Pairs (密钥对)、Create Key Pair (创建密钥对)，键入名称，然后选择 Create (创建)。 图 3：创建密钥对 Amazon EC2 使用公有密钥密码术来加密和解密登录信息。要登录实例，必须创建密钥对。对于 Windows 实例，我们使用密钥对通过 Amazon EC2 控制台获取管理员密码，然后使用远程桌面协议 (RDP) 登录，如 Amazon Elastic Compute Cloud 用户指南 中的分步说明所述。在 Linux 上，我们使用密钥对来对 SSH 登录进行身份验证。 如有必要，可针对 t2.medium 实例类型请求提高服务限制。为此，在 AWS Support Center 中，选择 Create Case，Service Limit Increase，EC2 instances，然后填写限制提高表中的字段。此实例类型的当前默认限制为 20 个实例。 如果您已有使用此实例类型的现有部署，并且可能会超过此参考部署的默认限制，则可能需要请求提高限制。新服务限制可能需要几天才能生效。有关更多信息，请参阅 AWS 文档中的 Amazon EC2 服务限制。 图 4：请求提高服务限制 步驟 2.启动 Puppet 堆栈此快速入门附带的自动化 AWS CloudFormation 模板将 Puppet 部署到 VPC 中。在启动堆栈之前，请确保您已完成前面的步骤。 在您的 AWS 账户中启动 AWS CloudFormation 模板。https://fwd.aws/YBD5Y 默认情况下，模板在 美国西部（俄勒冈） 区域中启动。您可以使用导航栏中的区域选择器来更改区域。 创建此堆栈需要大约 20 分钟时间。 注意 运行本快速入门参考部署时，您需要支付所用的 AWS 服务的费用。使用本快速入门不收取任何额外费用。有关完整详细信息，请参阅您将使用的每项 AWS 服务的定价页。 在 Select Template (选择模板) 页面上，保留 AWS CloudFormation 模板的默认 URL，然后选择 Next (下一步)。 在 Specify Details 页面上，查看模板的参数。下表描述了这些选项。 为 KeyPairName 参数提供值。此参数需要您进行输入。对于所有其他参数，模板提供可以自定义的默认设置。 安全配置： 参数标签 参数名称 默认值 说明 选择一个密钥对 KeyPairName 需要输入 公有/私有密钥对，使您能够在实例启动后安全地与它连接。创建 AWS 账户时，这是您在首选区域中创建的密钥对。 用于远程访问的源 IP RemoteAdminCIDR 需要输入 用于 SSH 和 RDP 访问的 CIDR 块或 IP 地址 (例如，1.1.1.1/32)。 AWS 快速入门配置： 参数标签 参数名称 默认值 说明 快速入门 S3 存储桶名称 QSS3BucketName aws-quickstart 安装快速入门模板和脚本的 S3 存储桶。如果您决定自定义或扩展快速入门以供您自己使用，请使用此参数来指定您为快速入门资产的副本创建的 S3 存储桶名称。存储桶名称可以包含数字、小写字母、大写字母和连字符，但不得以连字符开头或结尾。 快速入门 S3 键前缀 QSS3KeyPrefix quickstart-puppet/ S3 键名称前缀，用于模拟快速入门资产的副本的文件夹（如果您决定自定义或扩展快速入门以供您自己使用）。此前缀可以包含数字、小写字母、大写字母、连字符和正斜杠。 网络配置: 参数标签 参数名称 默认值 说明 VPC 的 CIDR 范围 VPCCIDR 10.0.0.0/16 Amazon VPC 的 CIDR 块。 VPC 中的子网的 CIDR 范围 SubnetCIDR 10.0.0.0/19 子网的 CIDR 块。 Puppet Master 的 IP 地址 PuppetMasterIP 10.0.0.10 Puppet Master 部署到的实例的 IP 地址。 Linux Puppet 代理的 IP 地址 PuppetAgentLinuxIP 10.0.0.11 Linux Puppet 代理部署到的实例的 IP 地址。 Windows Puppet 代理的 IP 地址 PuppetAgentWindowsIP 10.0.0.12 Windows Puppet 代理部署到的实例的 IP 地址。 在 Options (选项) 页面上，您可以为堆栈中的资源指定标签（键-值对）并设置其他选项。在完成此操作后，选择 Next (下一步)。 在 Review 页面上，查看并确认模板设置。选择 Capabilities 下的复选框，以确认模板将创建 IAM 资源。 选择 Create 以部署堆栈。 监控堆栈的状态。当状态显示 CREATE_COMPLETE 时，表示 Puppet 集群已准备就绪。 步驟 3.配置 Puppet 代理您可以按照本部分中的说明进行操作，来测试 AWS 上的 Puppet 设置。我们将查看 Puppet 代理的模块清单，应用配置并验证是否已成功应用配置。 审查模块和清单可通过多种方法将配置应用于代理节点（请参阅 Puppet 文档）。此快速入门对每个 Linux 和 Windows 节点使用模块，并在引导启动阶段将这些模块从 Amazon S3 下载到主节点。 Puppet 程序称作清单，它们是使用 Puppet 代码开发的。（有关 Puppet 语言的信息，请参阅 Puppet 文档。） 主清单的名称为 site.pp，并且位于清单文件夹中的主节点上。图 5 显示此快速入门中的主节点所使用的 site.pp 清单。 图 5：主清单 此清单包含三个节点声明： 第 1 行 – 定义默认情况下可应用于任何系统的节点块。我们不执行任何常见配置，因此大括号内没有代码。 第 3 行 – 为名为 linuxagent.example.com 的代理定义节点块。这是由快速入门启动的 Ubuntu 代理。我们引用名为 lampserver 的模块中的类，而不是将资源定义置于此节点块中。使用类是减少代码重复的绝佳方式。在这种情况下，当 Linux 代理应用其配置时，它将使用 lampserver 类中的代码来定义系统的状态。 第 7 行 – 为名为 windowsagent.example.com 的代理定义节点块。这是由快速入门启动的 Windows Server 2012 R2 代理。我们引用名为 iisserver 的模块中的类，而不是将资源定义置于此节点块中。当 Windows 代理应用其配置时，它将使用 iisserver 类中的代码来定义系统的状态。 接下来，我们来看看 lampserver 和 iisserver 类以了解其功能。 在名为 lampserver 的模块中定义 lampserver 类。模块的清单文件名为 init.pp，并且位于主节点上的 /etc/puppet/modules/lampserver/manifests 中。 图 6：lampserver 类 请注意以下与图 6 中显示的 lampserver 代码有关的内容： 第 1 行 – 这是主清单文件中引用的 lampserver 的类定义。 第 2 行 – exec 关键字定义资源声明。您可使用资源来描述系统的所需状态。在这里，我们使用 exec 资源来对节点执行 apt-update 命令。 第 6 行 – 包资源用于在节点上安装 Apache 2。请注意，require 语句可确保 apt-update 在能够安装此资源之前已运行。 第 11 行 – service 资源确保 Apache 2 服务正在运行。 第 15 行 – package 资源确保一旦成功执行 apt-update，就立即安装 MySQL 服务器。 第 20 行 – service 资源确保 MySQL 正在运行。 第 24 行 – package 资源确保一旦成功执行 apt-update，就立即安装 PHP 5。 第 29 行 – file 资源确保在默认 apache 根目录中创建名为 info.php 的新文件。这需要安装 Apache 2。PHP 代码将添加到文件内容中，以便在用户通过 Web 浏览器访问网站时提供有关 Web 服务器的信息性页面。 在名为 iisserver 的模块中定义 iisserver 类。模块的清单文件名为 init.pp，并且位于主节点上的 /etc/puppet/modules/iisserver/manifests 中。 图 7：iisserver 类 请注意以下与图 7 中显示的 iisserver 代码有关的内容： 第 1 行 – 这是主清单文件中引用的 iisserver 的类定义。 第 15 行 – windowsfeature 资源利用 Windows PowerShell 确保安装 IIS 和 ASP.NET 的所有必需组件。 第 19 行 – windowsfeature 资源安装用于 IIS 管理的管理工具。 第 25 行 – file 资源确保 Web 服务器根目录中有一个名为 info.aspx 的信息性 ASP.NET 网页。此网页的内容因空间限制而被截断 (图 7 中所示)，但它包含一个提供服务器相关信息的页面指令，就像 Linux 节点上的 info.php 一样。 除了创建您自己的模块之外，您还可以直接使用清单，或者利用 Puppet Forge 中预先存在的模块。有关编写模块和清单的详细信息，请参阅 Puppet 网站上的模块基础知识和培训课程。 连接到 Puppet 代理现在，您已了解示例模块的用途，已准备好远程连接到您的代理。 Linux 代理您将需要使用 SSH 从 VPC 外部连接到您的 Linux 代理。在 Amazon EC2 控制台中，选择标记有 LinuxAgent 的 EC2 实例，如图 8 所示。 图 8：选择 LinuxAgent 实例 在公有 DNS 名称中检索 LinuxAgent，按照适用于 Linux 实例的 Amazon EC2 用户指南中的说明操作，以将 SSH 客户端连接到实例。您将需要可用的密钥对才能建立远程 SSH 连接。 Windows 代理您可以使用 RDP 通过 Internet 连接到 Windows 代理。在 Amazon EC2 控制台中，选择标记有 WindowsAgent的 EC2 实例，如图 9 所示。 图 9：选择 WindowsAgent 实例 在公有 DNS 名称中检索 WindowsAgent，按照适用于 Microsoft Windows 实例的 Amazon EC2 用户指南中的说明操作，以建立连接。您将需要可用的密钥对才能解密 Windows 管理员密码并建立远程连接。 应用配置在此部分中，您将应用节点配置并验证一切是否已配置成功。 Linux 代理在通过 SSH 连接到 Linux 代理后，请运行以下命令以应用 lampserver 模块中的配置： 1sudo puppet agent --test 您应看到与图 10 中的内容类似的输出，这指示已成功应用配置。 图 10：Linux Puppet 代理输出 接下来，打开 Web 浏览器并导航到 info.php 页面。您将需要使用 LinuxAgent EC2 实例的公有 DNS 名称 — 例如，http://&lt;public DNS name&gt;/info.php。 图 11：测试 Apache Web 服务器 您应看到与图 11 中所示内容类似的 PHP 版本页面。这表示您已将配置成功应用于您的 Linux 代理。 Windows 代理在通过 RDP 连接到您的 Windows 代理后，在“Start”屏幕上查找 Start Command Prompt with Puppet 快捷方式。打开快捷方式的上下文 (右键单击) 菜单，然后选择 Run as administrator。运行以下命令以应用 iisserver 模块中的配置。 1puppet_interactive.bat 您应看到与图 12 中的内容类似的输出，这指示已成功应用配置。 图 12：Windows Puppet 代理输出 最后，打开 Web 浏览器并导航到 info.aspx 页面。您将需要使用 WindowsAgent EC2 实例的公有 DNS 名称 — 例如，http://&lt;public DNS name&gt;/info.aspx。 图 13：测试 IIS Web 服务器 您应看到与图 13 中所示内容类似的 IIS 版本页面。这表示您已将配置成功应用于您的 Windows 代理。","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"2019年DevOps必备面试问题","slug":"2019年DevOps必备面试问题","date":"2019-03-14T02:51:03.000Z","updated":"2019-03-14T03:34:20.327Z","comments":true,"path":"DevOps/2019年DevOps必备面试问题/","link":"","permalink":"http://blog.ozairs.com/DevOps/2019年DevOps必备面试问题/","excerpt":"","text":"您是DevOps工程师还是想进入DevOps？那么，未来就是你的。顶级研究公司Forrester宣布2018年为“ 企业DevOps年 ”，并估计全球有50％的组织正在实施DevOps。 在这篇博客中，我列出了几十个可能的问题，面试官会问潜在的DevOps员工。此列表是根据Edureka教练的专业知识精心制作的，他们是行业专家，来自60个国家的近30,000名Edureka DevOps学习者的经验。 要理解的关键是DevOps不仅仅是一种技术集合，而是一种思维方式，一种文化。DevOps需要一种将运营与发展相结合的文化转变，并需要一个相互关联的技术工具链来促进协作变革。由于DevOps理念仍处于初期阶段，因此DevOps的应用以及适应和协作所需的带宽因组织而异。但是，您可以开发DevOps技能组合，使您成为任何类型组织的理想候选人。 如果您想以周到，有条理的方式开发DevOps技能并获得DevOps工程师认证，我们很乐意为您提供帮助。完成Edureka DevOps认证课程后，我们承诺您将能够处理业内各种DevOps角色。 成为DevOps工程师有哪些要求？ 在寻求填写DevOps角色时，组织会寻找一套清晰的技能。其中最重要的是： 具有基础架构自动化工具的经验，如Chef，Puppet，Ansible，SaltStack或Windows PowerShell DSC。 熟练使用Ruby，Python，PHP或Java等网络语言。 人际关系技巧，可帮助您跨团队和角色进行沟通和协作。 顶级Devops面试问题这些是您在DevOps求职面试中可能遇到的首要问题： 一般DevOps面试问题 此类别将包含与任何特定DevOps阶段无关的问题。这里的问题旨在测试您对DevOps的理解，而不是关注特定工具或阶段。 Q1。DevOps和Agile之间的根本区别是什么？两者之间的差异列于下表中。 特征 DevOps的 敏捷 敏捷 开发和运营方面的敏捷性 只有发展的敏捷性 流程/实践 涉及CI，CD，CT等流程。 涉及敏捷Scrum，敏捷看板等实践。 重点关注领域 及时性和质量同等重要 及时性是主要优先事项 发布周期/开发冲刺 较小的发布周期和即时反馈 较小的发布周期 反馈来源 反馈来自自我（监测工具） 反馈来自客户 工作范围 敏捷性和自动化需求 只有敏捷 Q2。DevOps需要什么？据我所知，这个答案应该从解释一般市场趋势开始。公司不是发布大量功能，而是试图通过一系列发布列表来查看是否可以将小功能传输给客户。这具有许多优点，例如来自客户的快速反馈，更好的软件质量等，这反过来导致高的客户满意度。为实现这一目标，公司必须： 增加部署频率 降低新版本的故障率 缩短了修复之间的准备时间 新版本崩溃时平均恢复时间更快 DevOps满足所有这些要求，有助于实现无缝的软件交付。您可以举出像Etsy，Google和亚马逊这样的公司的例子，这些公司已经采用了DevOps来达到甚至五年前无法想象的性能水平。他们每天进行数十，数百甚至数千次代码部署，同时提供世界级的稳定性，可靠性和安全性。 如果我必须测试你对DevOps的了解，你应该知道Agile和DevOps之间的区别。下一个问题是针对这一点的。 Q3。DevOps与Agile / SDLC有何不同？我建议你按照以下说明进行操作： 敏捷是一套关于如何生产即开发软件的价值观和原则。示例：如果您有一些想法，并且希望将这些想法转变为可用的软件，则可以使用敏捷值和原则作为实现此目的的方法。但是，该软件可能只适用于开发人员的笔记本电脑或测试环境。您希望以安全，简单的方式快速，轻松，可重复地将该软件移植到生产基础架构中。要做到这一点，您需要DevOps工具和技术。 您可以总结一下，敏捷软件开发方法侧重于软件的开发，但另一方面，DevOps负责开发以及以最安全和最可靠的方式部署软件。这是一个博客，将为您提供有关DevOps演变的更多信息。 现在请记住，您在之前的答案中包含了DevOps工具，因此请准备好回答与此相关的一些问题。 Q4。哪些是最顶级的DevOps工具？你做过哪些工具？最受欢迎的DevOps工具如下所述： Git：版本控制系统工具 Jenkins：持续集成工具 Selenium：连续测试工具 Puppet，Chef，Ansible：配置管理和部署工具 Nagios：持续监控工具 Docker：容器化工具 如果需要，您还可以提及任何其他工具，但请确保在答案中包含上述工具。答案的第二部分有两种可能性： 如果您有上述所有工具的经验，那么您可以说我已经使用所有这些工具来开发高质量的软件并轻松，经常和可靠地部署这些软件。 如果您只有上述某些工具的经验，那么请提及这些工具，并说我对这些工具有专业性，并对其余工具进行了概述。 我们的DevOps认证课程包括最流行的DevOps工具的实际操作培训。找出下一批次开始的时间。 Q5。所有这些工具如何协同工作？下面给出了一个通用的逻辑流程，其中所有内容都自动进行无缝交付 但是，根据要求，此流程可能因组织而异。 开发人员开发代码，此源代码由Git等版本控制系统工具管理。 开发人员将此代码发送到Git存储库，并且代码中所做的任何更改都将提交到此存储库。 Jenkins使用Git插件从存储库中提取此代码，并使用Ant或Maven等工具构建它。 配置管理工具，如puppet部署和配置测试环境，然后Jenkins在测试环境中发布此代码，使用selenium等工具进行测试。 一旦代码被测试，Jenkins就会将其发送到生产服务器上进行部署（甚至生产服务器也由puppet等工具进行配置和维护）。 部署后，Nagios等工具会持续监控。 Docker容器提供测试环境来测试构建功能。 Q6。DevOps有哪些优势？对于这个答案，您可以使用您过去的经验并解释DevOps如何帮助您完成上一份工作。如果您没有任何此类经验，那么您可以提及以下优势。 技术优势： 持续的软件交付 修复不太复杂的问题 更快地解决问题 商业利益： 更快速地传递功能 更稳定的操作环境 更多时间可用于增加价值（而不是修复/维护） Q7。DevOps帮助我们实现的最重要的事情是什么？据我所知，DevOps帮助我们实现的最重要的事情是尽可能快地将更改投入生产，同时最大限度地降低软件质量保证和合规性的风险。这是DevOps的主要目标。在DevOps教程博客中了解更多信息。但是，您可以添加DevOps的许多其他积极效果。例如，团队之间更清晰的沟通和更好的工作关系，即Ops团队和开发团队共同合作提供高质量的软件，从而提高客户满意度。 Q8。解释DevOps可用于工业/现实生活中的用例。有许多行业正在使用DevOps，所以你可以提到任何这些用例，你也可以参考下面的例子：Etsy是一个点对点的电子商务网站，专注于手工或古董物品和用品，以及独特的工厂制造的物品。Etsy在缓慢，痛苦的网站更新中挣扎，经常导致网站崩溃。它影响了数百万Etsy用户的销售，这些用户通过在线市场销售商品并冒险将其推向竞争对手。在新技术管理团队的帮助下，Etsy从其瀑布模型转变为更敏捷的方法，瀑布模型每周两次进行4小时全站点部署。如今，它拥有完全自动化的部署管道，据报道，其持续交付实践每天导致50多次部署，中断更少。 Q9。解释您在过去曾与之合作过的组织的软件开发方面和技术操作方面的理解和专业知识。对于这个答案，分享您过去的经验并尝试解释您在以前的工作中的灵活性。您可以参考以下示例：DevOps工程师几乎总是在24/7关键业务在线环境中工作。我适应了随叫随到的职责，可以承担实时，实时系统的责任。我成功实现了自动化流程，以支持持续的软件部署 我有使用公共/私有云，Chef或Puppet等工具，使用Python和PHP等工具编写脚本和自动化的经验，以及Agile的背景知识。 Q10。DevOps的反模式有哪些？通常遵循一种模式。如果其他人普遍采用的模式对您的组织不起作用，并且您继续盲目地遵循它，那么您实际上采用的是反模式。有关于DevOps的神话。其中一些包括： DevOps是一个过程 敏捷等于DevOps？ 我们需要一个单独的DevOps组 Devops将解决我们所有的问题 DevOps意味着开发人员管理生产 DevOps是开发驱动的发布管理 DevOps不是开发驱动的。 DevOps不是IT运营驱动的。 我们不能做DevOps - 我们是独一无二的 我们不能做DevOps - 我们遇到了错误的人 版本控制系统（VCS）面试问题现在让我们来看看有关VCS的一些访谈问题。如果您希望获得像Git这样的VCS的实际操作培训，它将包含在我们的DevOps认证课程中。 Q1。什么是版本控制？这可能是您在面试中将面临的最简单的问题。我的建议是首先给出版本控制的定义。它是一个记录文件或文件集随时间变化的系统，以便您以后可以调用特定版本。版本控制系统由一个中央共享存储库组成，队友可以在其中提交对文件或文件集的更改。然后你可以提到版本控制的用途。 版本控制允许您： 将文件还原为以前的状态。 将整个项目还原为以前的状态。 比较一段时间内的变化 查看最后一次修改可能导致问题的内容。 谁介绍了一个问题，何时。 Q2。使用版本控制有什么好处？我建议你包括版本控制的以下优点： 使用版本控制系统（VCS），所有团队成员都可以随时在任何文件上自由工作。稍后VCS将允许您将所有更改合并到一个通用版本中。 所有过去的版本和变体都整齐地打包在VCS中。当您需要它时，您可以随时请求任何版本，您将获得完整项目的快照。 每次保存项目的新版本时，VCS都要求您提供已更改内容的简短说明。此外，您还可以查看文件内容的确切更改内容。这可以让您知道谁在项目中做了哪些更改。 像Git这样的分布式VCS允许所有团队成员拥有项目的完整历史记录，因此如果中央服务器出现故障，您可以使用任何团队成员的本地Git存储库。 Q3。描述您使用的分支策略。这个问题被要求测试你的分支经验，告诉他们你在以前的工作中如何使用分支以及它的用途是什么，你可以参考以下几点： 功能分支功能分支模型保留分支内特定功能的所有更改。当通过自动化测试对功能进行全面测试和验证时，该分支将合并到主服务器中。 任务分支在此模型中，每个任务都在其自己的分支上实现，任务键包含在分支名称中。很容易看出哪个代码实现了哪个任务，只需在分支名称中查找任务键。 发布分支一旦开发分支为发布获得了足够的功能，您就可以克隆该分支以形成发布分支。创建此分支将启动下一个发布周期，因此在此之后不能添加任何新功能，只有错误修复，文档生成和其他面向发布的任务应该在此分支中。一旦准备好发布，该版本将合并到主服务器并标记版本号。此外，它应该合并回到开发分支，自发布以来可能已经取得了进展。 最后告诉他们分支策略因组织而异，所以我知道基本的分支操作，如删除，合并，检查分支等。 Q4。您熟悉哪种VCS工具？你可以提到你曾经使用的VCS工具：“我已经使用过Git，它对SVN等其他VCS工具的一个主要优势就是它是一个分布式版本控制系统。”分布式VCS工具不一定依靠中央服务器来存储项目文件的所有版本。相反，每个开发人员都“克隆”存储库的副本，并在自己的硬盘上拥有项目的完整历史记录。 Q5。什么是Git？我建议您首先解释一下git的体系结构来尝试这个问题，如下图所示。您可以参考下面给出的解释： Git是一个分布式版本控制系统（DVCS）。它可以跟踪文件的更改，并允许您恢复到任何特定的更改。 与SVN等其他版本控制系统（VCS）相比，它的分布式架构具有许多优势，一个主要优点是它不依赖于中央服务器来存储项目文件的所有版本。相反，每个开发人员“克隆”我在下图中使用“本地存储库”显示的存储库副本，并在其硬盘驱动器上具有项目的完整历史记录，以便在出现服务器中断时，恢复所需的全部内容是你队友的本地Git存储库之一。 还有一个中央云存储库，开发人员可以在其中提交更改并与其他团队成员共享，如图所示，所有协作者都在提交更改“远程存储库”。 Q6。解释一些基本的Git命令？以下是一些基本的Git命令： Q7。在Git中，您如何还原已经被推送并公开的提交？此问题可以有两个答案，因此请确保包含两个答案，因为根据具体情况可以使用以下任何选项： 在新提交中删除或修复错误文件，并将其推送到远程存储库。这是修复错误的最自然方式。对文件进行必要的更改后，将其提交到远程存储库，我将使用git commit -m“commit message” 创建一个新的提交，撤消在错误提交中所做的所有更改。为此，我将使用命令git revert Q8。你如何将N次提交压缩成一次提交？将N个提交压缩到单个提交中有两种选择。在您的答案中包括以下两个选项： 如果要从头开始编写新的提交消息，请使用以下命令git reset -soft HEAD~N &amp;&amp;git commit 如果你想用现有提交消息的串联开始编辑新的提交消息，那么你需要提取这些消息并将它们传递给Git commit，我将使用git reset -soft HEAD~N &amp;&amp;git commit -edit -m “$（git log -format =％B -reverse .HEAD @ {N}）” DevOps认证培训观看课程预览 Q9。什么是Git bisect？你怎么用它来确定（回归）bug的来源？我建议你先给出一个Git bisect的小定义，Git bisect用于查找通过二进制搜索引入bug的提交。Git bisect的命令是git bisect &lt;子命令&gt; 现在你已经提到了上面的命令，解释一下这个命令会做什么，这个命令使用二进制搜索算法来查找项目历史中哪个提交引入了一个bug。您可以通过首先告诉它已知包含该错误的“错误”提交以及在引入错误之前已知的“良好”提交来使用它。然后Git bisect在这两个端点之间选择一个提交，并询问您所选的提交是“好”还是“坏”。它继续缩小范围，直到找到引入更改的确切提交。 Q10。什么是Git rebase以及它如何在合并之前用于解决功能分支中的冲突？根据我的说法，您应首先说git rebase是一个命令，它将另一个分支合并到您当前正在工作的分支中，并将所有位于重新分支之前的本地提交移到该历史记录的顶部。科。现在，一旦您为一个示例定义了Git rebase时间，以显示如何在合并之前使用它来解决功能分支中的冲突，如果从master创建了一个功能分支，那么主分支已经收到了新的提交，Git rebase可用于将要素分支移动到主要提示。该命令有效地将重放在master的tip处的功能分支中所做的更改，从而允许在该过程中解决冲突。完成后，这将允许功能分支相对容易地合并到主服务器中，有时作为简单的快进操作。 Q11。如何配置Git存储库以在提交之前运行代码健全性检查工具，并在测试失败时阻止它们？我建议你先介绍一下理智检查，理智或烟雾测试 确定继续测试是否可行和合理。现在解释如何实现这一点，这可以通过与存储库的预提交钩子相关的简单脚本来完成。即使在您需要输入提交消息之前，也会在提交之前触发预提交挂钩。在此脚本中，可以运行其他工具，例如linters，并对提交到存储库中的更改执行完整性检查。最后给出一个例子，你可以参考下面的脚本：＃！/ bin / sh files = $（git diff -cached -name-only -diff-filter = ACM | grep’.go $’）if [-z files] ; 然后退出0 fi unfmtd = $（gofmt -l $ files）如果[-z unfmtd]; 然后退出0 fi echo“一些.go文件不是fmt’d” 退出1此脚本检查是否需要通过标准Go源代码格式化工具gofmt传递任何即将提交的.go文件。通过以非零状态退出，脚本有效地阻止将提交应用于存储库。 Q12。如何找到特定提交中已更改的文件列表？对于这个答案，而不是只是告诉命令，解释这个命令究竟会做什么，所以你可以这么说，为了获得在特定提交中更改的列表文件使用命令git diff-tree -r {hash}给定提交哈希，这将列出在该提交中更改或添加的所有文件。-r标志使命令列表单个文件，而不是仅将它们折叠到根目录名称中。你也可以包括下面提到的点，虽然它是完全可选的，但有助于给面试官留下深刻的印象。输出还将包含一些额外的信息，可以通过包含两个标志来轻松抑制：git diff-tree -no-commit-id -name-only -r {hash}这里-no-commit-id将禁止提交哈希值出现在输出中，而-name-only只会打印文件名而不是它们的路径。 Q13。每次存储库通过推送接收新提交时，如何设置脚本运行？每次存储库通过push接收新提交时，有三种方法可以配置脚本运行，需要根据需要触发脚本的时间来定义预接收，更新或后接收挂钩。 将提交提交到目标存储库时，将调用目标存储库中的预接收挂钩。绑定到此挂钩的任何脚本都将在更新任何引用之前执行。这是一个有用的钩子，用于运行有助于实施开发策略的脚本。 Update钩子以类似于预接收钩子的方式工作，并且在实际进行任何更新之前也会触发。但是，对于已推送到目标存储库的每个提交，都会调用一次update钩子。 最后，在将更新接受到目标存储库之后，将调用存储库中的post-receive挂钩。这是配置简单部署脚本，调用一些持续集成系统，向存储库维护人员发送通知电子邮件等的理想场所。 钩子是每个Git存储库的本地存储，并且没有版本化。脚本可以在“.git”目录内的hooks目录中创建，也可以在别处创建，并且可以在目录中放置这些脚本的链接。 Q14。如果分支已经合并为主分支，你怎么知道Git？我建议你包括下面提到的命令：git branch -merged列出已合并到当前分支的分支。git branch -no-merged列出了尚未合并的分支。 持续整合问题现在，让我们来看看持续集成面试问题： Q1。持续集成是什么意思？我将建议您通过给出持续集成（CI）的小定义来开始这个答案。这是一种开发实践，需要开发人员每天多次将代码集成到共享存储库中。然后通过自动构建验证每个签入，允许团队尽早发现问题。我建议您解释一下如何在以前的工作中实施它。您可以参考以下给出的示例： 在上图中： 开发人员将代码签入其私有工作区。 完成后，他们将更改提交到共享存储库（版本控制存储库）。 CI服务器监视存储库并在发生更改时检出更改。 然后，CI服务器将提取这些更改并构建系统，并运行单元和集成测试。 CI服务器现在将通知团队成功构建。 如果构建或测试失败，CI服务器将向团队发出警报。 该团队将尽早解决问题。 这个过程不断重复。 Q2。为什么需要开发和测试的持续集成？对于这个答案，您应该关注持续集成的需求。我的建议是在你的答案中提到以下解释：开发和测试的持续集成通过在完成所有开发之后替换传统的测试实践来提高软件质量并减少交付时间。它允许Dev团队尽早检测和定位问题，因为开发人员需要每天多次（更频繁地）将代码集成到共享存储库中。然后自动测试每个登记入住。 Q3。持续集成的成功因素有哪些？在这里，您必须提到持续集成的要求。您可以在答案中包含以下几点： 维护代码存储库 自动化构建 使构建自我测试 每个人每天承诺到基线 应该构建每个提交（到基线） 保持快速构建 在生产环境的克隆中进行测试 让您轻松获得最新的可交付成果 每个人都可以看到最新版本的结果 自动部署 Q4。解释如何将Jenkins从一台服务器移动或复制到另一台服务器？我将通过将jobs目录从旧服务器复制到新服务器来完成此任务。有多种方法可以做到这一点; 我在下面提到过它们：你可以： 只需复制相应的作业目录，即可将作业从一个Jenkins安装移动到另一个。 通过使用其他名称克隆作业目录来制作现有作业的副本。 通过重命名目录重命名现有作业。请注意，如果更改作业名称，则需要更改尝试调用重命名作业的任何其他作业。 Q5。解释如何在Jenkins中创建备份和复制文件？回答这个问题真的很直接。要创建备份，您需要做的就是定期备份JENKINS_HOME目录。这包含所有构建作业配置，从属节点配置和构建历史记录。要创建Jenkins设置的备份，只需复制此目录即可。您还可以复制作业目录以克隆或复制作业或重命名目录。 Q6。解释如何设置Jenkins工作？我对这个答案的解决方法是首先提一下如何创建Jenkins的工作。转到Jenkins首页，选择“New Job”，然后选择“Build a free-style software project”。然后你可以告诉这个自由式工作的元素： 可选的SCM，例如源代码所在的CVS或Subversion。 用于控制Jenkins何时执行构建的可选触发器。 某种构建脚本，用于执行实际工作的构建（ant，maven，shell脚本，批处理文件等）。 从构建中收集信息的可选步骤，例如归档工件和/或记录javadoc和测试结果。 使用构建结果通知其他人/系统的可选步骤，例如发送电子邮件，IM，更新问题跟踪器等。 Q7。提到Jenkins中一些有用的插件。下面，我提到了一些重要的插件： Maven 2项目 亚马逊EC2 HTML发布者 复制工件 加入 绿球 Q8。你如何保护Jenkins？我保护Jenkins的方式如下所述。如果您有任何其他方式，请在下面的评论部分中提及： 确保全球安全。 确保Jenkins与我公司的用户目录与适当的插件集成。 确保启用矩阵/项目矩阵以微调访问。 使用自定义版本控制的脚本自动化在Jenkins中设置权限/特权的过程。 限制对Jenkins数据/文件夹的物理访问。 定期对其进行安全审核。 Jenkins是DevOps中广泛使用的众多流行工具之一。 持续测试面试问题：现在让我们继续讨论持续测试问题。 Q1。什么是连续测试？我将建议您遵循以下提到的解释：持续测试是将自动化测试作为软件交付管道的一部分执行的过程，以获得与最新构建相关的业务风险的即时反馈。通过这种方式，每个构建都会持续测试，允许开发团队获得快速反馈，以便他们可以防止这些问题进入软件交付生命周期的下一阶段。这大大加快了开发人员的工作流程，因为无需手动重建项目并在进行更改后重新运行所有测试。 Q2。什么是自动化测试？自动化测试或测试自动化是自动化手动过程以测试被测应用程序/系统的过程。自动化测试涉及使用单独的测试工具，使您可以创建可以重复执行的测试脚本，而不需要任何手动干预。 Q3。 自动化测试有哪些好处**？**我列举了自动化测试的一些优点。在您的答案中包含这些内容，您可以添加自己的经验，了解Continuous Testing如何帮助您以前的公司： 支持执行重复的测试用例 有助于测试大型测试矩阵 启用并行执行 鼓励无人看管的执行 提高准确性，从而减少人为产生的错误 节省时间和金钱 Q4。如何在DevOps生命周期中自动化测试？我已经提到了一个通用流程，您可以在其中参考：在DevOps中，开发人员需要将源代码中的所有更改提交到共享存储库。像Jenkins这样的持续集成工具每次在代码中进行更改时都会从此共享存储库中提取代码，并将其部署到连续测试中，这些工作由Selenium等工具完成，如下图所示。通过这种方式，与传统方法不同，代码的任何变化都会不断进行测试。 Q5。**为什么持续测试对DevOps很重要？**您可以通过说“连续测试允许立即测试代码中的任何更改来回答这个问题。这避免了在周期结束时进行“大爆炸”测试所产生的问题，例如发布延迟和质量问题。通过这种方式，持续测试可以促进更频繁和更好的质量发布。“ Q6。连续测试工具的关键要素是什么？连续测试的关键要素是： 风险评估：它涵盖风险缓解任务，技术债务，质量评估和测试覆盖范围优化，以确保构建准备好向下一阶段发展。 策略分析：确保所有流程符合组织不断发展的业务和合规性要求。 要求可追溯性：确保满足真正的要求，不需要返工。对象评估用于确定哪些需求存在风险，按预期工作或需要进一步验证。 高级分析：它在静态代码分析，变更影响分析和范围评估/优先级划分等领域使用自动化，以便首先防止缺陷并在每次迭代中完成更多工作。 测试优化：确保测试产生准确的结果并提供可操作的结果。方面包括测试数据管理，测试优化管理和测试维护 服务虚拟化：它确保访问真实的测试环境。服务可视化使您能够访问所需测试阶段的虚拟表单，从而缩短测试环境设置和可用性的浪费时间。 Q7。您熟悉哪种测试工具以及该工具的优点是什么？这里提到您使用过的测试工具，并相应地构建您的答案。我已经提到了一个例子：我已经在Selenium上工作，以确保高质量和更频繁的发布。 Selenium的一些优点是： 它是免费和开源的 它拥有庞大的用户群和帮助社区 它具有跨浏览器兼容性（Firefox，Chrome，Internet Explorer，Safari等） 它具有出色的平台兼容性（Windows，Mac OS，Linux等） 它支持多种编程语言（Java，C＃，Ruby，Python，Pearl等） 它有新的和定期的存储库开发 它支持分布式测试 Q8。Selenium支持哪些测试类型？Selenium支持两种类型的测试：回归测试：它是在修复错误的区域周围重新测试产品的行为。功能测试：它指的是单独测试软件功能（功能点）。 Q9。什么是Selenium IDE？我的建议是通过定义Selenium IDE来开始这个答案。它是Selenium脚本的集成开发环境。它作为Firefox扩展实现，允许您记录，编辑和调试测试。Selenium IDE包含整个Selenium Core，允许您在他们将运行的实际环境中轻松快速地记录和回放测试。现在，您的答案中包含一些优势。凭借自动完成支持和快速移动命令的能力，无论您喜欢何种类型的测试，Selenium IDE都是创建Selenium测试的理想环境。 Q10。Selenium中的Assert和Verify命令有什么区别？我在下面提到了Assert和Verify命令之间的区别： 断言命令检查给定条件是真还是假。假设我们断言给定元素是否存在于网页上。如果条件为真，则程序控制将执行下一个测试步骤。但是，如果条件为假，则执行将停止，并且不会执行进一步的测试。 Verify命令还会检查给定条件是true还是false。无论条件是真还是假，程序执行都不会停止，即验证期间的任何故障都不会停止执行，并且所有测试步骤都将被执行。 Q11。如何使用WebDriver启动浏览器？以下语法可用于启动Browser：WebDriver driver = new FirefoxDriver（）;WebDriver driver = new ChromeDriver（）;WebDriver driver = new InternetExplorerDriver（）; Q12。**我什么时候应该使用Selenium Grid？**对于这个答案，我的建议是给出Selenium Grid的一个小定义。它可以用于在多个平台和浏览器上同时执行相同或不同的测试脚本，以实现分布式测试执行。这允许在不同环境下进行测试并显着节省执行时间。 在我们的DevOps认证课程中，通过现场讲师指导的在线课程学习自动化测试和其他DevOps概念。 立即使用DevOps进行自动化测试&gt;&gt; 配置管理面试问题现在让我们来看看你对Configuration Management的了解程度。 Q1。配置管理流程的目标是什么？配置管理（CM）的目的是通过使开发或部署过程可控且可重复，确保产品或系统在其整个生命周期中的完整性，从而创建更高质量的产品或系统。CM流程允许有序管理系统信息和系统更改，以便： 修改能力， 提高性能， 可靠性或可维护性， 延长寿命， 降低成本， 降低风险和 责任或纠正缺陷。 Q2。资产管理和配置管理有什么区别？以下是资产管理和配置管理之间的一些差异： Q3。资产和配置项有什么区别？据我说，你应该首先解释资产。它具有财务价值以及附加的折旧率。IT资产只是它的一个子集。任何具有成本的组织和组织都将其用于资产价值计算和税收计算中的相关收益属于资产管理，此类项目称为资产。另一方面，配置项可能有也可能没有分配给它的财务值。它不会有任何与之相关的折旧。因此，它的生命不依赖于其财务价值，而是取决于该项目对该组织过时的时间。 现在，您可以举例说明两者之间的相似性和差异：1）相似性：服务器 - 它既是资产又是CI。2）差异：建筑 - 这是一种资产，但不是CI。文档 - 它是CI但不是资产 Q4。您对“基础设施作为代码”有何看法？它如何适用于DevOps方法？它的目的是什么？作为代码的基础架构（IAC）是一种IT基础架构，运营团队可以使用它来自动管理和通过代码进行配置，而不是使用手动过程。更快部署的公司会将软件等基础设施视为可以使用DevOps工具和流程管理的代码。利用这些工具，您可以更轻松，快速，安全，可靠地更改基础架构。 Q5。Puppet，Chef，SaltStack和Ansible中哪一个是最好的配置管理（CM）工具？为什么？这取决于组织的需求，因此在所有这些工具上提到几点：Puppet是最古老，最成熟的CM工具。Puppet是一个基于Ruby的配置管理工具，虽然它有一些免费功能，但Puppet很棒的大部分内容仅在付费版本中可用。不需要大量额外功能的组织会发现Puppet很有用，但那些需要更多自定义的组织可能需要升级到付费版本。Chef是用Ruby编写的，因此可以由熟悉该语言的人定制。它还包括免费功能，如果需要，还可以从开源升级到企业级。最重要的是，它是一个非常灵活的产品。Ansible是一个非常安全的选项，因为它使用Secure Shell。它是一个简单的工具，但除了配置管理之外，它还提供了许多其他服务。它非常容易学习，因此非常适合那些没有专职IT人员但仍需要配置管理工具的人。SaltStack是基于python的开源CM工具，适用于大型企业，但其学习曲线相当低。 Q6。什么是Puppet？我会建议你先给出一个小小的Puppet定义。它是一个配置管理工具，用于自动执行管理任务。现在您应该描述其架构以及Puppet如何管理其代理。Puppet有一个Master-Slave架构，其中Slave必须首先向Master发送证书签名请求，Master必须签署该证书才能在Puppet Master和Puppet Slave之间建立安全连接，如下图所示。Puppet Slave向Puppet Master和Puppet Master发送请求，然后在Slave上推送配置。请参阅下面的图解释上述说明。 Q7。**在客户端使用Puppet Master进行身份验证之前，需要对其证书进行签名和接受。你将如何自动完成这项任务？**最简单的方法是在puppet.conf中启用自动签名。请注意这是一个安全风险。如果您仍想这样做： 防火墙您的Puppet大师 - 将端口tcp / 8140限制为仅您信任的网络。 为每个“信任区域”创建Puppet大师，并且只在该Puppet大师清单中包含可信节点。 切勿使用完整的通配符，例如*。 Q8。描述通过Puppet自动化流程所取得的最重要的收益。对于这个答案，我建议你解释一下你过去使用Puppet的经历。您可以参考以下示例：我使用Puppet自动配置和部署Linux和Windows机器。除了将处理时间从一周缩短到10分钟之外，我还使用了角色和配置文件模式，并在README中记录了每个模块的用途，以确保其他人可以使用Git更新模块。我写的模块仍然在使用，但是我的团队成员和社区成员对它们进行了改进 Q9。您使用哪些开源或社区工具来使Puppet更强大？在这里，您需要提及工具以及如何使用这些工具使Puppet更强大。以下是一个供您参考的示例：更改和请求通过Jira出票，我们通过内部流程管理请求。然后，我们使用Git和Puppet的Code Manager应用程序根据最佳实践管理Puppet代码。此外，我们使用烧杯测试框架通过Jenkins中的持续集成管道运行所有Puppet更改。 Q10。什么是Puppet清单？这是一个非常重要的问题，所以请确保您正确的流程。据我说，你应该首先定义清单。每个节点（或Puppet Agent）都在Puppet Master中获得了配置细节，用本机Puppet语言编写。这些细节用Puppet可以理解的语言编写，称为Manifest。它们由Puppet代码组成，其文件名使用.pp扩展名。现在举个例子。您可以在Puppet Master中编写一个清单，用于创建文件并在连接到Puppet Master的所有Puppet Agent（Slaves）上安装apache。 Q11。 什么是Puppet模块以及它与Puppet Manifest的不同之处？对于这个答案，您可以使用下面提到的解释：Puppet模块是清单和数据（例如事实，文件和模板）的集合，它们具有特定的目录结构。模块对于组织Puppet代码很有用，因为它们允许您将代码拆分为多个清单。使用模块来组织几乎所有的Puppet清单是最佳实践。Puppet程序称为Manifest，它由Puppet代码组成，其文件名使用.pp扩展名。 Q12。 什么是Puppet的Facter？你应该回答Facter在Puppet中做了什么，所以根据我的说法，你应该说，“Facter收集有关Puppet Agent的基本信息（事实），如硬件细节，网络设置，操作系统类型和版本，IP地址，MAC地址， SSH密钥等等。这些事实随后在Puppet Master的清单中作为变量提供。“ Q13。什么是Chef？通过定义Chef来开始这个答案。它是一个强大的自动化平台，可将基础架构转换为代码。Chef是一个工具，您可以编写用于自动化流程的脚本。什么过程？几乎与IT相关的任何事情。现在您可以解释Chef的架构，它包括： Chef Server： Chef Server是基础架构配置数据的中央存储。Chef Server存储配置节点所需的数据并提供搜索功能，这是一个功能强大的工具，允许您根据数据动态驱动节点配置。 Chef Node： Node是使用Chef-client配置的任何主机。Chef-client在您的节点上运行，与Chef Server联系以获取配置节点所需的信息。由于Node是运行Chef-client软件的机器，因此节点有时被称为“客户端”。 Chef Workstation： Chef Workstation是您用来修改cookbook和其他配置数据的主机。 Q14。Chef的资源是什么？我的建议是先定义资源。资源代表一个基础架构及其所需的状态，例如应安装的软件包，应运行的服务或应生成的文件。您应该解释资源的功能，包括以下几点： 描述配置项的所需状态。 声明将该项目置于所需状态所需的步骤。 指定资源类型，例如包，模板或服务。 根据需要列出其他详细信息（也称为资源属性）。 分为配方，描述工作配置。 Q15。Chef的食谱是什么意思？对于这个答案，我建议你使用上面提到的流程：首先定义食谱。Recipe是描述特定配置或策略的资源集合。配方描述了配置系统部分所需的一切。定义之后，通过包括以下几点来解释食谱的功能： 安装和配置软件组件。 管理文件。 部署应用程序。 执行其他食谱。 Q16。 Cookbook与Chef中的食谱有何不同？对此的答案非常直接。您可以简单地说，“Recipe是一组资源，主要配置软件包或某些基础架构。“食谱”将食谱和其他信息整合在一起，比单独使用“食谱”更易于管理。“ Q17。 如果未在Chef中指定Resource的操作，会发生什么？我的建议是首先直接回答：当您未指定资源的操作时，Chef会应用默认操作。现在用一个例子解释一下，下面的资源：文件’C：\\ Users \\ Administrator \\ chef-repo \\ settings.ini’做内容’greeting = hello world’结束与下面的资源相同：文件’C：\\ Users \\管理\\Chef回购\\的Settings.ini”做的动作：创建内容“的问候语=你好世界结束的原因是：创造是文件资源的默认操作。 Q18。什么是Ansible模块？模块被认为是Ansible的工作单元。每个模块大多是独立的，可以用标准的脚本语言编写，如Python，Perl，Ruby，bash等。模块的一个指导属性是幂等性，这意味着即使一个操作重复多次，例如，从停电中恢复，它将始终将系统置于同一状态。 Q19。什么是Ansible的剧本？Playbooks是Ansible的配置，部署和编排语言。他们可以描述您希望远程系统实施的策略，或者描述一般IT流程中的一系列步骤。Playbooks设计为人类可读的，并以基本文本语言开发。在基本级别，可以使用playbooks来管理远程计算机的配置和部署。 Q20。 如何查看所有ansible_变量的列表？Ansible默认收集有关所管理机器的“事实”，这些事实可以在Playbooks和模板中访问。要查看有关计算机的所有可用事实的列表，可以将“设置”模块作为临时操作运行：Ansible -m setup hostname这将打印出所有可用事实的字典对于那个特定的主人。 Q21。如何设置应用程序的部署顺序？WebLogic Server 8.1允许您选择应用程序的加载顺序。请参阅Application中的Application MBean Load Order属性。WebLogic Server在部署应用程序之前部署服务器级资源（第一个JDBC，然后是JMS）。应用程序按以下顺序部署：连接器，然后是EJB，然后是Web应用程序。如果应用程序是EAR，则按照在application.xml部署描述符中声明它们的顺序加载各个组件。 Q22。我是否可以刷新已部署应用程序的静态组件而无需重新部署整个应用程序？是的，您可以使用weblogic.Deployer指定组件并使用以下语法定位服务器：java weblogic.Deployer -adminurl http：// admin：7001 -name appname -targets server1，server2 -deploy jsps / * .jsp Q23。如何关闭自动部署功能？自动部署功能每三秒检查一次应用程序文件夹，以确定是否有任何新应用程序或对现有应用程序的任何更改，然后动态部署这些更改。 为在开发模式下运行的服务器启用了自动部署功能。要禁用自动部署功能，请使用以下方法之一将服务器置于生产模式： 在管理控制台中，单击左窗格中的域名，然后在右窗格中选择“生产模式”复选框。 在命令行中，在启动域的管理服务器时包括以下参数：-Dweblogic.ProductionModeEnabled = true 为给定域中的所有WebLogic Server实例设置生产模式。 Q24。我什么时候应该使用external_stage选项？如果您想自己暂存应用程序，请使用weblogic.Deployer设置-external_stage，并希望通过自己的方式将其复制到目标。 持续监控面试问题让我们测试您对持续监控的了解。 Q1。为什么需要持续监控？我建议您使用下面提到的流程：持续监控可以及时发现问题或缺陷，并采取快速纠正措施，有助于降低组织的费用。持续监控提供解决方案，解决三个操作规程，称为： 持续审计 连续控制监测 持续交易检查 Q2。什么是Nagios？您可以通过首先提到Nagios是监视工具之一来回答这个问题。它用于DevOps文化中的系统，应用程序，服务和业务流程等的连续监视。如果发生故障，Nagios可以向技术人员提醒问题，允许他们在中断影响业务流程，最终用户或客户之前开始修复流程。使用Nagios，您无需解释为什么不可见的基础架构中断会影响您组织的底线。现在，一旦你定义了什么是Nagios，你可以提到使用Nagios可以实现的各种事情。通过使用Nagios，您可以： 在过时的系统导致故障之前规划基础架构升级。 在出现问题的第一个迹象时回答问题。 检测到问题时自动修复问题。 协调技术团队的回应。 确保您的组织的SLA得到满足。 确保IT基础架构中断对组织的底线影响最小。 监控整个基础架构和业务流程。 这就完成了这个问题的答案。可以根据讨论的方向添加诸如优点等的进一步细节。 Q3。Nagios如何运作？我将建议您按照以下解释来解答：Nagios在服务器上运行，通常作为守护进程或服务运行。Nagios定期运行驻留在同一服务器上的插件，它们会联系您网络或Internet上的主机或服务器。可以使用Web界面查看状态信息。如果发生某些事情，您还可以收到电子邮件或短信通知Nagios守护程序的行为类似于在某些时刻运行某些脚本的调度程序。它存储这些脚本的结果，并在这些结果发生变化时运行其他脚本。 现在期待关于Nagios组件的一些问题，如插件，NRPE等。 Q4。什么是Nagios的插件？通过定义插件开始这个答案。它们是脚本（Perl脚本，Shell脚本等），可以从命令行运行以检查主机或服务的状态。Nagios使用插件的结果来确定网络上主机和服务的当前状态。一旦定义了插件，解释为什么我们需要插件。只要需要检查主机或服务的状态，Nagios就会执行插件。插件将执行检查，然后只是将结果返回给Nagios。Nagios将处理从插件接收的结果并采取必要的操作。 Q5。Nagios中的NRPE（Nagios Remote Plugin Executor）是什么？对于这个答案，给出插件的简要定义。NRPE插件旨在允许您在远程Linux / Unix计算机上执行Nagios插件。这样做的主要原因是允许Nagios监视远程计算机上的“本地”资源（如CPU负载，内存使用情况等）。由于这些公共资源通常不会暴露给外部计算机，因此必须在远程Linux / Unix计算机上安装NRPE之类的代理。 我将建议您根据下图所示解释NRPE架构。NRPE插件由两部分组成： check_nrpe插件，驻留在本地监视机器上。 NRPE守护程序，在远程Linux / Unix机器上运行。 监视主机和远程主机之间存在SSL（安全套接字层）连接，如下图所示。 Q6。你对Nagios的被动检查是什么意思？据我所知，答案应该从解释被动检查开始。它们由外部应用程序/进程启动和执行，被动检查结果将提交给Nagios进行处理。然后解释被动检查的必要性。它们对于监视异步的服务非常有用，并且无法通过定期轮询其状态来有效监视。它们还可用于监视位于防火墙后面的服务，并且无法从监视主机主动检查。 Q7。 Nagios何时检查外部命令？确保在解释过程中坚持这个问题，所以我建议你按照下面提到的流程。Nagios在以下条件下检查外部命令： 由主配置文件中的command_check_interval选项指定的定期间隔，或 事件处理程序执行后立即执行。这是外部命令检查的常规循环的补充，并且在事件处理程序向Nagios提交命令时提供立即操作。 Q8。**Nagios中的主动和被动检查有什么区别？**对于这个答案，首先指出主动和被动检查的基本区别。主动检查和被动检查之间的主要区别在于Active检查由Nagios启动和执行，而被动检查由外部应用程序执行。如果您的面试官看起来不相信上述说明，那么您还可以提及主动和被动检查的一些关键功能：被动检查对于监控以下服务非常有用： 本质上是异步的，无法通过定期轮询其状态来有效监控。 位于防火墙后面，无法从监控主机主动检查。 Actives检查的主要功能如下： Nagios流程启动主动检查。 主动检查定期运行。 Q9。Nagios如何帮助分布式监控？面试官将期待与Nagios的分布式架构相关的答案。因此，我建议您以下面提到的格式回答：使用Nagios，您可以使用分布式监控方案监控整个企业，Nagios的本地从属实例执行监控任务并将结果报告给单个主站。您可以管理主服务器的所有配置，通知和报告，而从服务器可以完成所有工作。这种设计利用了Nagios利用被动检查的能力，即外部应用程序或将结果发送回Nagios的过程。在分布式配置中，这些外部应用程序是Nagios的其他实例。 Q10。解释Nagios的主要配置文件及其位置？首先提一下这个主配置文件包含的内容及其功能。主配置文件包含许多影响Nagios守护程序运行方式的指令。Nagios守护程序和CGI都读取此配置文件（它指定主配置文件的位置）。现在您可以知道它的存在位置以及创建方式。运行configure脚本时，将在Nagios分发的基本目录中创建示例主配置文件。主配置文件的默认名称是nagios.cfg。它通常放在Nagios安装的etc /子目录中（即/ usr / local / nagios / etc /）。 Q11。解释Flaip Detection在Nagios中的工作原理？我会建议你先解释Flapping。当服务或主机过于频繁地更改状态时会发生抖动，这会导致大量问题和恢复通知。定义Flapping后，解释Nagios如何检测Flapping。每当Nagios检查主机或服务的状态时，它将检查它是否已经开始或停止振荡。Nagios遵循以下给定的程序来做到这一点： 存储分析历史检查结果的主机或服务的最后21次检查的结果，并确定状态更改/转换发生的位置 使用状态转换来确定主机或服务的百分比状态更改值（更改度量） 比较百分比状态变化值与低和高拍打阈值 当主机或服务的百分比状态变化首先超过高振荡阈值时，确定主机或服务已开始振荡。当主机或服务的百分比状态低于低抖动阈值时，确定主机或服务已停止振荡。 Q12。在Nagios中影响递归和继承的三个主要变量是什么？根据我的说法，这个答案的正确格式应该是：首先命名变量，然后对每个变量做一个小解释： 名称 使用 寄存器 然后给出每个变量的简要说明。Name是其他对象使用的占位符。使用定义应使用其属性的“父”对象。寄存器的值可以为0（表示只有模板）和1（实际对象）。寄存器值永远不会被继承。 Q13。Nagios的意思是面向对象？回答这个问题非常直接。我将回答这个问题，“Nagios的一个特性是对象配置格式，因为您可以创建从其他对象定义继承属性的对象定义，从而创建名称。这简化并阐明了各个组件之间的关系。“ Q14。什么是Nagios的州跟踪？我会建议你先介绍一下State Salking。它用于记录目的。当为特定主机或服务启用Stalking时，Nagios将非常仔细地监视该主机或服务，并记录它在检查结果输出中看到的任何更改。根据您和访调员之间的讨论，您还可以添加“在以后分析日志文件时非常有用。在正常情况下，只有在主机或服务自上次检查后状态发生变化时，才会记录主机或服务检查的结果。“ 想要接受像Nagios这样的监控工具的培训吗？想获得DevOps工程师认证吗？请务必查看我们的DevOps硕士课程。 容器化和虚拟化面试问题让我们看看您对容器和虚拟机的了解程度。 Q1。什么是容器？我的建议是首先解释容器化的必要性，容器用于提供从开发人员的笔记本电脑到测试环境，从临时环境到生产的一致计算环境。现在给出一个容器的定义，一个容器由一个完整的运行时环境组成：一个应用程序，以及它所有的依赖项，库和其他二进制文件，以及运行它所需的配置文件，捆绑到一个包中。容纳应用程序平台及其依赖项消除了操作系统分发和底层基础架构的差异。 Q2。容器化相比虚拟化有哪些优势？以下是容器化优于虚拟化的优势： 容器提供实时配置和可伸缩性，但VM提供缓慢的配置 与VM相比，容器是轻量级的 与容器相比，VM的性能有限 与VM相比，容器具有更好的资源利用率 Q3。容器（在我们的例子中是Docker）与虚拟机管理程序虚拟化（vSphere）有何不同？有什么好处？以下是一些差异。确保在答案中包含这些差异： Q4。什么是Docker图像？我建议你使用下面提到的流程：Docker镜像是Docker容器的来源。换句话说，Docker镜像用于创建容器。使用build命令创建映像，并且在使用run启动时它们将生成容器。图像存储在Docker注册表中，例如registry.hub.docker.com，因为它们可能变得非常大，图像被设计为由其他图像层组成，允许在通过网络传输图像时发送最少量的数据。提示：请注意Dockerhub，以便回答有关预先可用图像的问题。 Q5。什么是Docker容器？这是一个非常重要的问题，所以请确保您不偏离主题。我建议您遵循下面提到的格式：Docker容器包括应用程序及其所有依赖项，但与其他容器共享内核，在主机操作系统的用户空间中作为独立进程运行。Docker容器不依赖于任何特定的基础架构：它们可以在任何计算机，任何基础架构和任何云中运行。现在解释如何创建Docker容器，可以通过创建Docker镜像然后运行它来创建Docker容器，也可以使用Dockerhub上存在的Docker镜像。Docker容器基本上是Docker镜像的运行时实例。 Q6。**什么是Docker中心？**回答这个问题非常直接。Docker hub是一个基于云的注册表服务，允许您链接到代码存储库，构建映像并测试它们，存储手动推送的映像以及指向Docker云的链接，以便您可以将映像部署到主机。它为整个开发流程中的容器映像发现，分发和变更管理，用户和团队协作以及工作流自动化提供了集中资源。 Q7。 Docker与其他容器技术有何不同？据我所知，您的答案应该在以下几点：Docker容器易于在云中部署。与其他技术相比，它可以在相同的硬件上运行更多的应用程序，使开发人员可以轻松快速创建，可立即运行的容器化应用程序，并使管理和部署应用程序变得更加容易。您甚至可以与您的应用程序共享容器。如果你还有一些要点可以添加，你可以这样做，但要确保上面的解释在你的答案中。 Q8。 什么是Docker Swarm？你应该通过解释Docker Swarn来开始这个答案。它是Docker的本机群集，它将Docker主机池转变为单个虚拟Docker主机。Docker Swarm提供标准的Docker API，任何已经与Docker守护进程通信的工具都可以使用Swarm透明地扩展到多个主机。我还建议您添加一些支持的工具： Dokku Docker撰写 Docker Machine Jenkins Q9。Dockerfile用于什么？根据我的回答应该从解释Dockerfile的使用开始。Docker可以通过读取Dockerfile中的指令自动构建图像。现在我建议你给出一个Dockerfle的小定义。Dockerfile是一个文本文档，其中包含用户可以在命令行上调用以组合图像的所有命令。使用docker构建用户可以创建一个连续执行多个命令行指令的自动构建。 现在期待一些问题来测试您使用Docker的体验。 Q10。 我可以在Docker中使用json而不是yaml作为我的compose文件吗？你可以使用json而不是yaml作为你的compose文件，使用带有compose的json文件，指定用于例如的文件名：docker-compose -f docker-compose.json up Q11。 告诉我们你在过去的职位中如何使用Docker？解释您如何使用Docker来帮助快速部署。解释你如何使用脚本化Docker并将Docker与Puppet，Chef或Jenkins等其他工具一起使用。如果您在Docker中没有过去的实践经验，并且在类似的空间中有过其他工具的经验，请诚实并解释相同的内容。在这种情况下，如果您可以在功能方面与Docker比较其他工具，这是有意义的。 Q12。如何创建Docker容器？我建议你直接回答这个问题。我们可以使用以下命令使用Docker镜像创建Docker容器：docker run -t -i 此命令将创建并启动容器。您还应该添加，如果要检查主机上具有状态的所有正在运行的容器的列表，请使用以下命令：docker ps -a Q13。如何停止并重新启动Docker容器？为了停止Docker容器，您可以使用以下命令：docker stop &lt;容器ID&gt;现在重新启动Docker容器，您可以使用：docker restart &lt;容器ID&gt; Q14。Docker容器可以扩展多远？像谷歌和Twitter这样的大型网络部署，以及像Heroku和dotCloud这样的平台提供商都运行在容器技术上，并行运行数十万甚至数百万个容器。 Q15。Docker运行的平台是什么？我将通过说Docker仅在Linux和云平台上运行来开始这个答案，然后我将提到以下Linux供应商： Ubuntu 12.04,13.04等 Fedora 19/20 + RHEL 6.5+ CentOS 6+ Gentoo的 ArchLinux的 openSUSE 12.3+ CRUX 3.0+ 云： 亚马逊EC2 Google Compute Engine Microsoft Azure Rackspace公司 请注意，Docker无法在Windows或Mac上运行。 Q16。当Docker容器退出时，我会丢失数据吗？你可以回答这个问题，当Dcoker容器退出时，我不会丢失我的数据。在您明确删除容器之前，应用程序写入磁盘的任何数据都会保留在其容器中。即使在容器停止之后，容器的文件系统仍然存在。 而且，就是这样！ 我希望这些问题可以帮助您破解DevOps面试。如果您对我们有任何疑问，请在评论部分提及，我们会尽快回复您。 如果您希望为DevOps角色构建强大的简历，请查看我们为您编写的博客。 您还可以通过Facebook，Twitter，Instagram，YouTube，LinkedIn甚至Pinterest与我们联系！ 想要开始您的DevOps学习之旅吗？没有比Edureka更好的地方了。我们的荒谬承诺保证了它！","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/tags/DevOps/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"利用 Puppet 实现自动化管理配置 Linux 计算机集群","slug":"利用-Puppet-实现自动化管理配置-Linux-计算机集群","date":"2019-03-14T01:18:33.000Z","updated":"2019-03-14T03:39:22.101Z","comments":true,"path":"DevOps/Puppet/利用-Puppet-实现自动化管理配置-Linux-计算机集群/","link":"","permalink":"http://blog.ozairs.com/DevOps/Puppet/利用-Puppet-实现自动化管理配置-Linux-计算机集群/","excerpt":"","text":"Puppet：开源系统配置和管理工具随着虚拟化和云计算技术的兴起，计算机集群的自动化管理和配置成为了数据中心运维管理的热点。对于 IaaS、Paas、Saas 来说，随着业务需求的提升，后台计算机集群的数量也会线性增加。对于数据中心的运维人员来说，如何自动化管理、配置这些大规模的计算机集群节点，对于数据中心的稳定运行以及运维成本控制都显得至关重要。 Puppet 是一个开源系统配置管理工具，它有着简明的架构以及良好的扩展性；同时，Puppet 还提供了自有的系统配置描述语言以及完善的公用库，非常适合用于管理和部署大规模集群系统。 Puppet 的系统架构Puppet 使用简明的 C/S 架构，分为 Puppet Server 和 Puppet Node。 图 1. Puppet 的架构 Puppet Server Puppet Server 是配置和管理整个集群的大脑，管理着所有节点。系统管理员在 Puppet Server 上用 Puppet 特有的配置描述语言为各个节点编写配置文件 (manifest)，配置文件描述了节点的目标状态——资源的集合。这些资源可以是文件、服务、软件包等等。各个节点会周期性的查询 Puppet Server，获得自己的最新配置文件，并且在本地应用这些配置文件，使得自身的资源和状态达到配置文件要求。 Puppet Node(Agent) 被 Puppet Master 管理着的计算机节点称为 Puppet node。Puppet node 会周期性的查询 Puppet Master，来获取自己的配置文件，并且在本地应用。在每次应用配置文件之后，Puppet node 会提供上传一份报告给 Puppet Master，以便以后的统计和分析。系统管理员也可以手动地在 Puppet Node 上执行命令，让 Puppet Node 立即查询 Puppet Server 获取自身最新的配置文件，并且在本地应用。 Puppet 的工作流程Puppet 的工作流程可以概括成这几步：定义、模拟、应用、报告。 图 2. Puppet 的工作流程 定义 (Define)管理员为各个节点编写配置文件，配置文件中定义了该节点所需要的资源的集合以及资源之间的关系。这些资源可以是文件、服务、软件包、可执行的命令等等。Puppet 内置的配置管理语言对这些资源提供了较为完整的底层抽象，减轻了编写配置文件的复杂度。 模拟 (Simulate)根据节点的配置文件，我们可以了解到该节点需要什么样的资源并且处于什么样的状态。配置文件描述了节点的状态，而不是具体的配置步骤。Puppet 会将配置文件 Manifest 编译成更为详细的一种配置文件 Catalog。通过 Catalog，Puppet 会根据节点的当前状态，模拟出节点达到该目标状态所需要的步骤。 应用 (Enforce)节点周期性地向 Puppet Server 来请求自己最新的配置文件。Puppet 会将节点的实际状态与节点配置文件中所表述的目标状态做比较，并根据得到的所需要的步骤，对节点执行操作，使其达到配置文件所表述的状态。 报告 (Report)当每次应用执行过后，节点都会给 Puppet Server 发送一份运行报告，报告该节点的状态，以便以后的分析和统计。 Puppet 配置语言介绍Puppet 配置管理语言中的核心概念是资源，资源可以是一个软件包，一个文件，一种服务等等。一个节点的状态可以用资源的集合以及他们之间的关系来表示。管理员不需要详细地描述配置和部署系统的具体步骤，Puppet 只需要管理员来描述系统的目标状态，即资源的集合以及它们之间的关系。Puppet 内置的执行引擎会根据节点的现有状态将配置文件转化为具体的执行步骤并且执行。 在 Puppet 中，类是一系列相关资源的集合；模块是一系列类的集合。Puppet 内置提供了一些常用的类和模块，同时用户可以定义自己的类和模块。通过类和模块使用，配置模块重用和共享变的非常容易。 安装和配置环境配置由于 Puppet Server 和节点之间通过主机名来通信，所以需要双方可以通过彼此的主机名来找到对应的 IP 地址。可以通过配置 DNS 或者配置/ets/hosts 文件来实现。 安装准备在安装官方提供的开源版本的 Puppet 软件之前，Puppet Server 和 agent 首先需要都安装官方的软件源 (Puppet 对各种 Linux 发行版都有提供支持，本文以 Ubuntu 14.04 系统为例)： 下载官方软件源的安装包： 1`wget https://apt.puppetlabs.com/puppetlabs-release-pc1-trusty.deb` 更新软件源： 1`sudo dpkg -i puppetlabs-release-pc1-trusty.deb``sudo apt-get update` 安装 Puppet Server 1`sudo apt-get install puppetserver` 启动 PuppetServer 1`sudo service puppetservice start` 安装 PuppetAgent 1`sudo apt-get install puppet-agent` 编辑/etc/puppetlabs/puppet/puppet.conf 文件，设置该 agent 的 puppet server 的地址： 1`[main]``server = puppetmaster` 注：puppetmaster 是 puppetserver 的主机名。 启动 puppet service 1`sudo /opt/puppetlabs/bin/puppet resource service puppet ensure=running enable=true` 编写第一个配置文件第一个 Hello World 配置文件作为第一个实例配置文件，我们想让节点做一件最简单的事情：在/etc/文件夹下面创建一个文件 helloworld.txt，文件的内容是”hello world from puppet!\\n”。 首先我们在 puppetserver 上进入/etc/puppetlabs/code/environments/production/manifests 文件夹，创建 site.pp 文件： 1`node puppetagent &#123;` `file &#123; &apos;helloworld&apos;:` ` ``path =&gt; &apos;/etc/helloworld.txt&apos;,`` ``owner =&gt; &apos;root&apos;,`` ``group =&gt; &apos;root&apos;,`` ``mode =&gt; &apos;655&apos;,`` ``content =&gt; &quot;hello world from puppet!\\n&quot;,`` ``&#125;` `&#125;` site.pp 就是节点的配置文件，里面可以包含对各个节点的配置描述。在实例配置文件中，”puppetagent”就是节点的主机名。包含在 puppetagent 中的配置描述就是该节点的资源集合的描述。 配置文件创建好后，节点会周期性地查询 PuppetServer 来获取自己的配置文件并在本地应用。当然 Puppet 也支持手动获取自己的配置。在本例中，我们通过手动的方式来进行配置更新。我们在 PuppetAgent 上手动执行命令： 1`root@puppetAgent:/opt/puppetlabs/bin# ./puppet agent --test``2016-05-21 14:24:14.858673 WARN puppetlabs.facter - locale environment variables were bad; `` ``continuing with LANG=C LC_ALL=C``Info: Using configured environment &apos;production&apos;``Info: Retrieving pluginfacts``Info: Retrieving plugin``Info: Caching catalog for puppetagent``Info: Applying configuration version &apos;1463811856&apos;``Notice: /Stage[main]/Main/Node[puppetagent]/File[helloworld]/ensure: `` ``defined content as &apos;&#123;md5&#125;c3aa68786c58c94ef6f3e2399920f268&apos;``Notice: Applied catalog in 0.02 seconds``root@puppetAgent:/opt/puppetlabs/bin# cat /etc/helloworld.txt ``hello world from puppet!` 我们看到节点成功从 Puppet Server 获取配置文件，并且在本地应用，对应的文件成功创建。 进阶：执行脚本任务作为进阶的任务，我们希望节点可以执行一些更加复杂一点的任务。我们希望节点可以从 PuppetServer 获取一个命令脚本，并且执行该脚本。 我们首先在/etc/puppetlabs/code/environments/production/modules 中创建一个名叫”test”的模块，在 test 模块下面创建一个”files”文件夹。在这个文件夹里的文件是可以被节点获取的。然后我们在这个”files”文件夹里创建一个 shell 脚本 test.sh，路径如下： /etc/puppetlabs/code/environments/production/modules/test/files/test.sh test.sh 文件内容： 1`touch /etc/helloworld.log``echo &quot;helloworld&quot; &gt;&gt; /etc/helloworld.log` 该脚本会在/etc/目录下创建 helloworld.log 文件，然后在文件里添加”hello world”内容。 进入目录/etc/puppetlabs/code/environments/production/manifests，然后我们再来编辑 site.pp 文件： 1`node puppetagent &#123;``file &#123; &apos;test.sh&apos;:`` ``path =&gt; &apos;/etc/test.sh&apos;,`` ``owner =&gt; &apos;root&apos;,`` ``group =&gt; &apos;root&apos;,`` ``mode =&gt; &apos;655&apos;,`` ``source =&gt; &apos;puppet:///modules/test/test.sh&apos;,`` ``&#125;``exec &#123; &apos;execute &apos;:`` ``command =&gt; &apos;bash /etc/test.sh&apos;,`` ``require =&gt; File[&apos;test.sh&apos;],`` ``path =&gt; [&quot;/bin/&quot;],``&#125;``&#125;` 其中，我们定义了两个资源：一个文件资源和一个执行命令资源。同时这两个资源有依赖关系，命令执行资源依赖于文件资源，所以 Puppet 会优先处理文件资源。执行命令资源会在文件资源存在后再执行。 我们看下客户端的执行结果： 1`root@puppetAgent:/opt/puppetlabs/bin# ./puppet agent --test``2016-05-21 15:39:39.817370 WARN puppetlabs.facter - locale environment variables were bad; `` ``continuing with LANG=C LC_ALL=C``Info: Using configured environment &apos;production&apos;``Info: Retrieving pluginfacts``Info: Retrieving plugin``Info: Caching catalog for puppetagent``Info: Applying configuration version &apos;1463816381&apos;``Notice: /Stage[main]/Main/Node[puppetagent]/File[test.sh]/ensure: `` ``defined content as &apos;&#123;md5&#125;2ce060ad2ddab2fe416ca8fb6f8da32a&apos;``Notice: /Stage[main]/Main/Node[puppetagent]/Exec[execute ]/returns: executed successfully``Notice: Applied catalog in 0.05 seconds``root@puppetAgent:/opt/puppetlabs/bin# cat /etc/helloworld.log ``helloworld` 我们可以看到，helloworld.log 文件被正确的创建，说明脚本文件被正确地执行。 结束语Puppet 是基于 Ruby 的开源系统配置和管理工具，它提供的独特的系统配置语言极大程度地简化了系统管理员管理和配置系统的过程。本文首先介绍了 Puppet 的系统架构和工作流程，并且介绍了 Puppet 独特的系统配置语言，之后我们简单介绍了安装和配置 Puppet 的具体步骤。最后，本文以两个实例介绍了如何在 Puppet 中为节点编写配置文件，来达到创建文件和执行命令的效果。希望本文能对系统管理员，Puppet 初学者有所帮助。 问题集问题1: Exiting; no certificate found and waitforcert is disabled 解决方案： https://fvtool.wordpress.com/2013/04/15/exiting-no-certificate-found-and-waitforcert-is-disabled-installing-puppet/","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}],"tags":[{"name":"Puppet","slug":"Puppet","permalink":"http://blog.ozairs.com/tags/Puppet/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}]},{"title":"Puppet实用命令指南","slug":"Puppet_command","date":"2019-03-14T00:45:41.000Z","updated":"2019-03-14T03:36:15.747Z","comments":true,"path":"DevOps/Puppet/Puppet_command/","link":"","permalink":"http://blog.ozairs.com/DevOps/Puppet/Puppet_command/","excerpt":"","text":"1、下载安装r10k Modulepuppet module install puppet/r10k –modulepath=/etc/puppetlabs/code/modules 2、puppet code与github repo同步r10k deploy environment -p","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}],"tags":[{"name":"Puppet","slug":"Puppet","permalink":"http://blog.ozairs.com/tags/Puppet/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}]},{"title":"","slug":"Git实用教程","date":"2019-03-13T11:16:43.451Z","updated":"2019-04-22T03:31:14.112Z","comments":true,"path":"uncategorized/Git实用教程/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Git实用教程/","excerpt":"","text":"&lt;Git实用教程&gt; 1、Git创建和切换Branch git brach example git checkout ‘example’ 2、查看Branch，Branch改名和删除Branch git branch git branch -m originname newname git branch -D branchname 3、提交代码到Staging Enviroment git add example （git add . ） 4、提交代码到正式环境 git commit -m “comment” 5、合并不同 branch的代码 git merge branchname 6、查看代码日志 git log","categories":[],"tags":[],"keywords":[]},{"title":"Git 和 GitHub 基础配置","slug":"Git-和-GitHub-基础配置","date":"2019-03-13T10:43:27.000Z","updated":"2019-03-13T10:52:52.605Z","comments":true,"path":"DevOps/Git-和-GitHub-基础配置/","link":"","permalink":"http://blog.ozairs.com/DevOps/Git-和-GitHub-基础配置/","excerpt":"","text":"前言在本系列的第一篇文章中着重介绍了 Git 的基础特性。本文作为本系列的第二篇文章将介绍 Git 和 GitHub 的基础配置，包括 Git 安装、使用 Git 克隆 GitHub 上的代码库、使用 Git 克隆远端代码仓库、Git 的基本配置和设置忽略提交规则。您在阅读完本文将有能力完成本地 Git 环境的基础配置，为接下来的 Git 日常使用做基础。 GitHub 是一个代码托管平台，如果开发者想要在本地进行开发工作，那么就需要使用到 Git 的客户端工具来连接到 GitHub，再克隆代码到本地。如果您是重度的 GUI 使用者，那么有很多 GUI 客户端可以选择，在 Git 的官网就专门有个页面列出了业内的 GUI 客户端。 但遗憾的是往往 GUI 客户端只能提供 Git 部分的功能，如果想要享受到 Git 自底向上强大的功能，使用命令行的方式来操作 Git 是不二之选。建议无论您是否擅长使用命令行工作，都可以尝试使用命令行方式来操作 Git。本文将只介绍如何从命令行来连接到 GitHub。 安装 Git使用命令行方式操作 Git 工具，需要本地安装 Git。注意，这里没有使用 “Git 客户端” 一词，因为 Git 作为一个开源版本控制系统，本身既可以作为客户端工具，也可以用于建立服务器端代码库，所以本质上 Git 作为工具来讲没有客户端和服务器端之分。 本地安装 Git 十分简单。 对于 Windows 用户，可以下载 Git For Windows 工具。下载安装成功之后，我们可以得到一个 Git Bash 工具，它是一个类 Linux Bash 工具。在该工具中我们可以直接执行 Git 相关命令。 对于 Mac 和 Linux 用户，只需通过对应的包管理工具安装即可，如清单 1 所示： 清单 1. Mac 和 Linux 下安装 Git1`$ brew install git # For Mac``$ apt-get install git # For Ubuntu``# yum install git # For RedHat EL, CentOS` 使用 Git 克隆 GitHub 代码库安装 Git 成功之后，我们就可以使用 Git 克隆 GitHub 上的代码库，本节仍然以我的代码库 repo-for-developerworks 为例。 GitHub 提供了两种克隆方式：HTTPS 和 SSH。我们可以点击仓库页面上的 Clone or download 按钮来查看用于克隆的链接，同时可以点击浮动框右上角的 Use SSH/Use HTTPS 换我们想要克隆的 link，如图 2 和 图 3 所示。注意，这里只是切换查看不同的链接，而不是设置代码库不同的链接方式。 由此我们可以获得两个 URL： HTTPS 链接：https://github.com/caozhi/repo-for-developerworks.git SSH 链接：`git@github.com:caozhi/repo-for-developerworks.git` 使用 HTTPS 进行克隆由于代码库是开放的，因此使用 HTTPS 方式克隆时，无需 GitHub 用户名密码，如清单 2 所示： 清单 2. 使用 HTTPS 进行克隆1`caozhi@ clone$ git clone https://github.com/caozhi/repo-for-developerworks.git``Cloning into &apos;repo-for-developerworks&apos;...``remote: Counting objects: 14, done.``remote: Compressing objects: 100% (9/9), done.``remote: Total 14 (delta 3), reused 5 (delta 1), pack-reused 0``Unpacking objects: 100% (14/14), done.` 顺便提一下，进行 pull 和 fetch 操作时也无需用户名密码认证。因为 GitHub 的机制允许随意免费下载任何公开的代码库，如若要 push 代码需经过认证或者经过作者同意才可。当要进行 push 时，会出现提示要求输入用户名密码，如清单 3 所示： 清单 3. HTTPS 方式下 push 代码1`caozhi@ repo-for-developerworks$ echo change &gt;&gt; README.md ## make some modification``caozhi@ repo-for-developerworks$ git add .``caozhi@ repo-for-developerworks$ git commit -m &quot;changes&quot;``[master d774ecf] changes`` ``1 file changed, 1 insertion(+)``caozhi@ repo-for-developerworks$ git push``Username for &apos;https://github.com&apos;: caozhi0321@gmail.com ## Enter GitHub account name``Password for &apos;https://caozhi0321@gmail.com@github.com&apos;: ## Enter Password``Counting objects: 6, done.``Delta compression using up to 8 threads.``Compressing objects: 100% (4/4), done.``Writing objects: 100% (6/6), 528 bytes | 528.00 KiB/s, done.``Total 6 (delta 2), reused 0 (delta 0)``remote: Resolving deltas: 100% (2/2), completed with 1 local object.``To https://github.com/caozhi/repo-for-developerworks.git`` ``075c130..d774ecf master -&gt; master` 使用 SSH 进行克隆使用 SSH 方式进行克隆，需要一步额外的配置 SSH-KEY 的操作。首先需要本地生成一个 SSH Key。我们可以借助 ssh-keygen 工具生成一对 RSA 的秘钥：私钥id_rsa 和公钥 id_rsa.pub。生成的秘钥文件会默认放在 home 目录下的 .ssh 目录下。 先将 id_rsa.pub 公钥文件的内容复制到剪贴板，如图 5 所示，使用 cat id_rsa.pub 命令可以查看公钥内容，随后将该公钥导入到 GitHub 里的账户之下。 在 GitHub 页面右上角的头像里点击展开一个下拉菜单，点击 Settings 可以打开个设置页面。 打开 SSH and GPG keys 的配置页面，点击右上角的 New SSH key 按钮。 在打开的页面中先设置一个您想导入的公钥的名称，再将前面复制的公钥内容粘贴到大文本框中，点击 Add SSH key 即可。 页面自动跳转回 SSH and GPG keys 设置页面，您可以看到在我的账号下成功新增了一个 SSH Key。 此时我们可以使用 SSH 的方式进行代码克隆，还可以使用 ssh -T 命令检测是否配置成功, 如清单 4 和 5 所示： 清单 4. 使用 SSH 方式克隆1`caozhi@ $ git clone git@github.com:caozhi/repo-for-developerworks.git``Cloning into &apos;repo-for-developerworks&apos;...``remote: Counting objects: 20, done.``remote: Compressing objects: 100% (12/12), done.``remote: Total 20 (delta 5), reused 10 (delta 2), pack-reused 0``Receiving objects: 100% (20/20), done.``Resolving deltas: 100% (5/5), done.` 清单 5. 检测 SSH 是否配置成功1`caozhi@bogon:~$ ssh -T git@github.com``Hi caozhi! You&apos;ve successfully authenticated, but GitHub does not provide shell access.` 使用 SSH 的方式进行克隆，将使得我们本地与 GitHub 之间建立了信任连接，也就意味着之后所有需要进行用户认证的地方都不再需要显式地用户名密码认证。例如 git push 会直接通过 SSH 进行认证。经验表明，使用 SSH 的另一个好处是在网络环境较差的情况下，其稳定性要高于 HTTPS 连接。 至此，我们成功地使用 Git 命令行方式克隆了代码库，之后就可以进行正常的日常开发。 使用 Git 克隆远程仓库当一个开发者刚进入某一项目，一般来说他所要做的第一件事是克隆远程仓库到本地，以进行本地开发工作。远程仓库可以是来自于 GitHub 或者 GitLab 等代码托管服务，也可以是项目组自己所搭设的 Git 服务器。无论是哪种远程仓库，都可以使用 git clone 命令 git clone &lt;repository&gt; [local_path] 将其从远端克隆到本地。命令中间的 &lt;repository&gt; 根据远端仓库提供的连接方式不同，其形式可能不同，例如： GitHub 的 HTTPS 连接：https://github.com/caozhi/repo-for-developerworks.git GitHub 的 SSH 连接：`git@github.com:caozhi/repo-for-developerworks.git` 自建仓库的 SSH 连接：`git_user@192.168.0.1:/usr/local/repo-for-developerworks.git` 其中前两种 GitHub 的连接方式，其仓库的连接字符串可以在 GitHub 的对应仓库页面中找到，如前图 2 和图 3所示。 第三种自建仓库的 URL 一般需要提供远端服务器上的账号、host 和路径。以上面例子中的连接字符串 `git_user@192.168.0.1:/usr/local/repo-for-developerworks.git` 为例： git_user 是服务器上对代码库目录有访问权限的账号。 192.168.0.1 是远端服务器的 IP，也可以是主机名或者 URL。 /usr/local/repo-for-developerworks.git 是服务器上代码库的根目录。 git clone 命令中的 local_path 指定了本地想要存放代码库的地址。该参数是可选参数，如果不指定该参数就会在本地新建一个以远程仓库名为命名的目录，然后以该目录为代码库根目录。图 10 展示了在空目录 clone_demo 中执行不带 local_path 参数的 clone 命令： 从截图可以看到，git clone 命令在 clone_demo 目录中创建了一个 repo-for-developerworks 的代码库目录。 从截图可以看到，git clone 命令在 clone_demo 目录中新建了一个我们指定的local_dev-repo 目录，并将其作为本地代码库的根目录。 我们知道一般操作系统将一个英文句点表示当前目录，因此从截图可以看出，当 local_path 指定为当前目录时，git clone 命令会直接将当前目录作为本地代码库的根目录。 当然 Git 还提供其它的连接方式如 File、FTP。感兴趣的读者可以自己使用 Git 搭一个 Git 服务器尝试使用 File 和 FTP 方式进行连接。 默认情况下，git clone 会将远端代码库全部克隆到本地。Git 还支持只克隆特定分支到本地。我们可以使用 git clone -b **branchname** --single-branch git@URL local_path 命令。 Git 的基本配置在克隆了代码库之后，我们一般仍需要对 Git 做一些基本的配置才能使用 Git 进行日常工作。Git 配置的作用域主要有三种：System、Global 和 Local，分别对应的配置文件地址为： System：/etc/gitconfig。系统级别有效。 Global：home 目录下的 ~/.gitconfig 文件。用户级别有效。 Local：代码库目录的 .git/config 文件。代码库级别有效。 另外我们也可以使用 git config --system -l，git config --global -l，git config --local -l 命令分别列出三个作用域下的配置。跟 Linux 操作系统的环境变量配置类似，Git 在执行命令中会首先查看 local 配置，如果没有找到所需配置会再查看 global 配置，最后再查看 system 配置。 在使用 git config 命令进行配置的时候，也可以使用 git config --system，git config --global，git config --local 三种不同的选项来修改不同作用域的配置。 下面介绍一些重要或有用的 Git 配置。 配置 user 信息配置 user 信息在 Git 中是十分重要的一个步骤, username 和 email 不能为空，它们将会被记录在每一条该 user 的 commit 信息中。 我们可以配置 user.name 和 user.email 的值来配置 user 信息，如清单 6 所示: 清单 6. 配置 user.name 和 user.email1`git config --global user.name &quot;caozhi&quot;``git config --global user.email &quot;caozhi0321@gmail.com&quot;` 也可以将上述命令中的 –global改成 –local来修改只对代码库作用域有效的配置。 配置命令的别名Git 提供了很多有用的命令，我们可以将一些比较常用的命令设置上别名，提高工作效率。例如我们可以将 git log --abbrev-commit 设置一个别名 lg，使得查看 log 时只需要显示 commit id 的短名称，如: git config --global alias.lg &quot;log --abbrev-commit&quot; 设置成功后就可以使用 git lg 来查看 commit 日志。 当然还可以设置一些其它的别名，如清单 7 所示: 清单 7. 配置 st 和 cm 别1`git config --global alias.st &quot;status&quot;``git config --global alias.cm &quot;commit&quot;` 别名可以根据自己的喜好和习惯去设置。将常用的命令设为短别名将大大提高工作效率。 查看配置配置成功后可以使用 git config --global -l 命令查看配置。 使用 Config 文件进行配置除了使用命令之外，也可以直接编辑 config 文件进行相关配置。 设置 Git 忽略提交规则在进行完代码库克隆和简单的配置之后，接下来我们可以根据项目需要配置一些文件忽略规则。跟大多数的代码库管理工具一样，Git 也可以对不需要被代码库所管理的文件或文件类型进行配置，使得提交代码时，这些文件不会被提交到代码库中。Git 是通过忽略清单.gitignore 文件进行配置的。 通常我们会考虑将如下类型的文件添加到忽略清单中: 编译过程的中间文件，例如 *.class 文件、*.o 文件、*.obj 文件等。 外部依赖的包或者工程编译的包，例如 jar 包、lib 包、dll 包或 war 包等。在有的项目实践中，可能会将这类依赖包也放到代码库中进行管理，通常这不是一个很好的策略，因为这样会显著地增加代码库的大小，降低开发者的工作效率。比较合理的方式是通过构建工具的依赖管理功能来管理这些依赖包，例如 Maven、Gradle 等。 编译过程中，通过某种机制自动生成的代码。某些项目中，可能会使用脚本或者 xsd schema 文件来生成代码；这类代码只需要将用于自动生成的脚本或者 schema 文件管理起来即可。 项目的配置文件。同一项目组的不同开发者可能有不同的项目配置，或者配置中包含敏感信息，例如账号密码等，这类配置文件也应该放到 ignore 清单里。 某些 IDE 的工程配置文件，例如 Eclipse 的 setting 和 project 文件、Idea 的.idea 目录等。 一些自动生成的系统文件，例如 Windows 的 Thumbs.db 或者 MacOS 的.DS_Store 文件等。 项目或者 IDE 的日志文件。 .gitignore 文件每行表示一个匹配模式（# 开头的行或者空行除外，# 用于注释）。它使用 glob 模式来进行匹配，glob 模式是一种简化的正则表达式，常用于来进行路径的模式匹配。我们可以在代码库的根目录或者任意子目录添加.gitignore 文件，特定目录下的.gitignore 文件使得忽略规则只在该目录及其子目录下有效。表 1 列出了常用的一些匹配模式的写法： 表 1. 常用匹配模式 模式 含义 示例 完整路径 忽略完整路径所定义的文件 dev/dev.conf /path 以 / 开头，只匹配当前目录下路径为 path 的文件 /a.java /a.cpp path 不以 / 开头，匹配当前目录及其子目录下所有文件 *.o web.xml path/ 以 / 结尾，用以只匹配目录；path 目录及其子目录和文件会被忽略；如果 path 是个文件，则不会被忽略 .settings/ 带 * 号的模式 置于文件中，用于匹配所有满足规则的文件 *.zip *.jar 带 ** 的模式 置于路径中，用于匹配满足 ** 前后的所有路径 Dev/**/dev.conf**/*.jar !path 在 ignore 文件中如果前面已经定义了某个模式，但是又有一些特殊文件我们不想被忽略，我们可以用 ! 来匹配 *.jar ## 忽略所有 jar 包 !server.jar ##希望 server.jar仍被跟踪 注意： 当某个文件已经被提交到代码库中被 Git 所管理起来之后，将该文件再添加进 .gitignore 文件是无效的，对该文件进行修改时，执行 git status 操作之后仍然会提示该文件已被修改。针对已经提交代码库的文件我们又想忽略其修改的场景，将会在本系列第四篇文章中介绍。 每个目录下都可以放单独的 .gitignore 文件以控制子目录的忽略规则。 即使已经在忽略列表里，当我们确实想要提交一些符合忽略规则的文件时，仍可以使用 git -f add 加具体的文件路径的方式将这些文件提交到库中。 GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表模板，可以在 https://github.com/github/gitignore 找到它。 结束语为使用 Git 和 GitHub 进行日常开发做准备，本文详细通过一些列演示向读者讲解了如何采用 SSH 和 HTTPS 两种方式从 GitHub 克隆代码库，如何进行本地 Git 开发环境的基础配置，如何配置 .gitignore 文件等。相信您在阅读完本文之后将有能力自己初始化一套本地的 Git 环境。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.ozairs.com/tags/git/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"Azure上的Terraform文档","slug":"Azure上的Terraform文档","date":"2019-03-13T03:48:43.000Z","updated":"2019-03-13T03:53:37.553Z","comments":true,"path":"DevOps/Azure上的Terraform文档/","link":"","permalink":"http://blog.ozairs.com/DevOps/Azure上的Terraform文档/","excerpt":"","text":"使用 Terraform 在 Azure 上可靠地版本化和创建基础结构。 使用我们的快速入门和教程了解如何创建资源、使用 Azure Terraform 模块和维护包含代码的基础结构。 快速入门配置 Terraform 并使用它在 Azure 中创建 Linux VM。 安装和配置 Terraform 创建 Linux VM 分步教程了解如何通过 Terraform 从代码创建 Azure 计算和网络基础结构。 使用 AKS 创建 Kubernetes 群集。 将 AKS 与作为入口控制器的应用程序网关配合使用来创建 Kubernetes 群集。 使用 Azure 市场映像创建启用了 MSI 身份验证的 Terraform VM。 使用 Azure Terraform 模块创建负载均衡的 VM 群集。 在 Azure Cloud Shell 中创建负载均衡的 VM 群集。 为 VM 规模集配置网络和存储 从 Packer 自定义映像预配 VM 规模集 示例常见部署任务的示例配置模板。 GitHub 引用 Azure Terraform 模块用于数据库的 Azure RM 用于负载均衡器的 Azure RM Azure RM 计算组 Azure RM 网络 Azure RM 计算","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/tags/Terraform/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"通过混沌式创新建立和增强应用程序价值","slug":"通过混沌式创新建立和增强应用程序价值","date":"2019-03-12T21:43:19.000Z","updated":"2019-03-13T11:34:06.083Z","comments":true,"path":"评论/通过混沌式创新建立和增强应用程序价值/","link":"","permalink":"http://blog.ozairs.com/评论/通过混沌式创新建立和增强应用程序价值/","excerpt":"","text":"应用程序现在是数字业务开发和交付其产品和服务的主要工具。此外，今天最知名的数字巨头（Facebook或Lyft）的估值飙升可归因于这些公司的应用程序组合。 简而言之，应用程序及其操作的数据是现代数字经济的货币。对于越来越多的公司来说，它们是一种资产负债表上的资产，这种资产可以带来巨大的价值创造。但也是一种可以被利用并带来可怕的价值破坏的资产。公司市值的单日跌幅最大 Facebook在2018年7月底的120亿美元下跌，占市值的19％ ，发生在该公司告诉投资者在剑桥分析公司丑闻导致用户增长放缓之后来自87m Facebook数据的数据被用来使外国势力干涉2016年美国总统选举。 虽然Facebook是数字原生的极端例子，但即使对于有抱负的数字公司来说，这一教训仍然适用。有效管理这个有价值但易受攻击的资源，一个组织的应用程序组合，必须超越IT的范围，扩展到整个C-Suite。随着应用程序的提升不仅仅是公司如何开展业务并越来越成为业务本身的基本要素，企业IT的角色也必须发展。在应用经济中，企业IT有两个必要条件：1）拥抱和实现混沌创新; 2）最大限度地降低企业风险。 混乱的创新？混乱长期以来被用作公司释放创新的工具。一些例子： 英特尔的安迪格罗夫曾经告诉人们，他们需要“让混沌统治，然后再陷入混乱”。这种方法在组织内部创造了一种文化，使混乱得以蓬勃发展，允许人们在正常模式之外思考，花时间进行实验，并提出真正伟大的想法。 谷歌创始人拉里佩奇和谢尔盖布林在他们2004年的首次公开招股信中强调了混沌创新需求背后的想法。这封信清楚地表明，“除了他们的常规项目之外，我们还鼓励我们的员工将20％的时间花在他们认为最有利于Google的事情上。” 这种方法带来了许多创新，包括AdSense，Gmail以及其他一些结构良好和大写的创意。 作为一名前管理顾问，我经常被问到这种思维方式是否适用于不仅仅是技术公司。MTV 最近调查了千禧一代的工作习惯，发现78％的人认为有一个“其他兴趣爱好可能很重要成为一个不同的职业。众所周知，各种类型的公司都明确容忍边工作边创业。 这些对混乱友好的公司了解这种开放性的好处。事实上，许多初创企业都是由在其他地方工作的同时创办公司的创始人孵化出来的，然后退出全职追求他们的激情。根据塔克商学院教授克里斯特里布尔（Chris Trimble）的说法，这些类型的政策让员工体验到了自由以及无法完全接受它的挫折：最好的混乱创新！ 对于当前和有抱负的数字业务，当应用程序开发人员可以自由地构建和部署新应用程序而不受可用性，稳定性，安全性或合规性问题的影响时，混乱的创新会蓬勃发展。开发人员供不应求。作为应用经济中最稀缺的资源，开发商浪费的每一秒都会影响公司的价值创造率。认真建立和增强应用资本的公司非常需要能够节省开发人员时间，减少不必要的复杂性和专业知识的解决方案，并使他们专注于快速部署他们关心的代码，并且业务价值最高。 F5如何帮助F5是多云应用服务的领导者。我们的多云应用程序服务以多种方式增强和保护您的应用程序价值。以下是一些： 改善应用程序的性能和最终用户体验 - 简而言之，我们世界一流的应用程序服务使您的应用程序更快。 通过提供现成的一流应用服务，提高开发人员的工作效率; 通过与CI / CD工具链的集成以及强大的自动化和编排解决方案; 通过简化政策附件和自助服务工具的工作流程; 并通过为应用程序本身提供可操作的见解。 改善您的企业安全/风险态势 - 提供易于连接的安全服务; 跨应用程序的一致策略管理，无论他们身在何处; 整个应用程序组合中的可视性和可视性。 为何选择F5？为什么不是其他应用服务提供商 我们的价值主张很简单： F5拥有业内最广泛，最深入的应用服务组合 F5为任何供应商提供最灵活的消费和多云部署选项 F5通过世界一流的客户支持组织为其提供支持 当F5成为企业级基础架构的核心部分时，它为业务提供了一定程度的保证，即其应用程序组合仍然可用，可靠且安全。 概括为了在数字经济中生存，每家公司都必须增强和保护他们的应用资本。该解决方案是一套一致的应用程序服务，可以应用于任何地方的任何应用程序。F5业界领先的多云应用服务可提高应用程序的性能和最终用户体验，提高开发人员的工作效率，并改善企业安全/风险状况。F5是增强和保护您的应用程序资本的最佳合作伙伴。","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"F5","slug":"F5","permalink":"http://blog.ozairs.com/tags/F5/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"Ansible入门教程","slug":"Ansible入门教程","date":"2019-03-12T10:44:39.000Z","updated":"2019-03-14T10:11:52.039Z","comments":true,"path":"Ansible/Ansible入门教程/","link":"","permalink":"http://blog.ozairs.com/Ansible/Ansible入门教程/","excerpt":"","text":"关于Ansible的一个好处是，将bash脚本转换为可执行任务是非常容易的。我们可以编写自己的配置程序，但是Ansible更加干净，因为它可以自动在执行任务之前获取上下文。ansible任务是幂等的，没有大量额外的编码，ansible可以一次又一次地安全运，而bash命令这种幂等性。 Ansible使用“facts”来确保任务的幂等安全运行， 它是在运行任务之前收集的系统和环境信息。ansible使用这些facts来检查状态，看看是否需要改变某些东西以获得所需的结果。这使得ansible可以让服务器一次又一次地运行可复制的任务。 1 安装当然我们需要先安装Ansible。任务可以从任何可安装的机器上运行。 1.1 Ubuntu在Ubuntu 16.04上安装Ansible的方法。 1sudo apt-get install -y ansible1 apt-get安装的ansible版本很低，建议使用pip方式安装 1sudo pip install ansible1 2 配置ansible的默认配置文件路径为 /etc/ansible，然而，一个常见的用途是将其安装在一个virtualenv中，在这种情况下，我们一般不会使用这些默认文件。我们可以根据需要在本地目录中创建配置文件。 2.1 管理服务器：Inventory文件您可以创建一个inventory文件，用于定义将要管理的服务器。这个文件可以命名为任何名字，但我们通常会命名为hosts或者项目的名称。在hosts文件中，我们可以定义一些要管理的服务器。这里我们将定义我们可能要在“web”标签下管理的两个服务器。标签是任意的。 123[web]192.168.22.10192.168.22.11123 现在已经够好了，如果需要，我们可以定义主机范围，多个组，可重用变量，并使用其他花哨的设置，包括创建动态的inventory。当我们在本地机器运行ansible时，我们不需要关心inventory文件中的内容，我将告诉您在本地和远程服务器上运行ansible。现在，让我们将hosts文件设置为指向本地主机local和remote虚拟远程主机。hosts文件： 12345[local]127.0.0.1[remote]192.168.1.212345 与本地主机和远程服务器连接的命令。 2.2 基础：运行命令我们开始对服务器运行任务。ansible会假定你的服务器具有SSH访问权限，通常基于SSH-Key。因为Ansible使用SSH，所以它需要能够SSH连接到服务器。但是，ansible将尝试以正在运行的当前用户身份进行连接。如果我正在运行ansible的用户是ubuntu，它将尝试以ubuntu连接其他服务器。 123456789# Run against localhost$ ansible -i ./hosts --connection=local local -m ping# Run against remote server$ ansible -i ./hosts remote -m ping127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;123456789 如果你是在cygwin下运行，遇到了“Failed to connect to the host via ssh: mux_client_request_session: read from master failed”的错误，可以执行: 1ansible -i ./hosts remote -v -m ping -u root --private-key=~/.ssh/id_rsa1 使用–connection=local告诉ansible不尝试通过SSH运行命令，因为我们只是影响本地主机。但是，我们仍然需要一个hosts文件，告诉我们连接到哪里。在任何情况下，我们可以看到从ansible得到的输出是一些JSON，它告诉我们Task（我们对ping模块的调用）是否进行了任何更改和结果。 命令说明： 12345678910-i ./hosts - 设置库存文件，命名为 hostsremote，local，all-使用这个标签的下定义的服务器hosts清单文件。“all”是针对文件中定义的每个服务器运行的特殊关键字-m ping- 使用“ping”模块，它只是运行ping命令并返回结果-c local| --connection=local - 在本地服务器上运行命令，而不是SSH一些常用命令：-i PATH --inventory=PATH 指定host文件的路径，默认是在/etc/ansible/hosts--private-key=PRIVATE_KEY_FILE_PATH 使用指定路径的秘钥建立认证连接-m DIRECTORY --module-path=DIRECTORY 指定module的目录来加载module，默认是/usr/share/ansible-c CONNECTION --connection=CONNECTION 指定建立连接的类型，一般有ssh ，local12345678910 2.2.1 模块（Modules）ansible使用“模块”来完成大部分的任务。模块可以做安装软件，复制文件，使用模板等等。 模块是使用Ansible 的方法因为它们可以使用可用的上下文（“Facts”），以便确定要完成任务需要做什么操作。如果我们没有模块，我们将运行任意的shell命令，我们也可以使用bash脚本。这是一个任意shell命令看起来像在Ansible（它使用的shell模块！）： 1234567# Run against a local serveransible -i ./hosts local --connection=local -b --become-user=root \\ -m shell -a &apos;apt-get install nginx&apos;# Run against a remote serveransible -i ./hosts remote -b --become-user=root all \\ -m shell -a &apos;apt-get install nginx&apos;1234567 这里，sudo apt-get install nginx命令将使用“shell”模块运行。命令说明: 123-b - “成为”，在运行命令时告诉可以成为另一个用户。--become-user=root - 以用户“root”运行以下命令（例如，使用命令使用“sudo”）。我们可以在此定义任何现有的用户。-a 用于将任何参数传递给定义的模块 -m123 但是这并不是特别强大。尽管能够一次在所有服务器上运行这些命令，但是我们仍然只能完成任何bash脚本可能执行的操作。如果我们使用了更合适的模块，我们可以运行命令来保证结果。可靠的模块确保我们可以一次又一次地运行相同的任务，而不会影响最终结果。要在Debian / Ubuntu服务器上安装软件，“apt”模块将运行相同的命令，但确保幂等。 12345678910111213141516171819# Run against a local serveransible -i ./hosts local --connection=local -b --become-user=root \\ -m apt -a &apos;name=nginx state=installed update_cache=true&apos;127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: false&#125;# Run against a remote serveransible -i ./hosts remote -b --become-user=root \\ -m apt -a &apos;name=nginx state=installed update_cache=true&apos;127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: false&#125;or：ansible -i ./hosts remote -v -m apt -a &apos;name=nginx state=installed update_cache=true&apos; -u test -s -K --private-key=~/.ssh/id_rsa12345678910111213141516171819 这将使用apt模块来更新存储库缓存并安装Nginx（如果没有安装）。运行任务的结果是”changed”: false。这表明没有变化; 我已经使用该shell模块安装了Nginx 。好的是，我可以一遍又一遍地运行这个命令，而不用担心它会改变预期的结果 - Nginx已经安装，Ansible知道，并且不尝试重新安装它。命令说明: 12345678910111213-i ./hosts - 设置inventory文件，命名为 hosts-b - “成”，告诉可以成为另一个用户来运行命令--become-user=root - 以用户“root”运行以下命令（例如，使用“sudo”命令）local| remote - 从库存文件中的本地或远程定义的主机上运行-m apt- 使用apt模块-a &apos;name=nginx state=installed update_cache=true&apos; - 提供apt模块的参数，包括软件包名称，所需的结束状态以及是否更新软件包存储库缓存常用命令：-u USERNAME --user=USERNAME 指定移动端的执行用户-U SUDO_USERNAME --sudo-user=USERNAME-s --sudo -u指定用户的时候，使用sudo获得root权限-k --ask-pass 提示输入ssh的密码，而不是使用基于ssh的密钥认证-K --ask-sudo-pass 提示输入sudo密码，与--sudo一起使用12345678910111213 我们可以通过这种特殊方式运行我们所需要的所有任务（通过模块），但是让我们来做这个更具管理性。我们将把这个任务移动到一个Playbook中，它可以运行和协调多个Tasks。 2.3 剧本（Playbooks）Playbook可以运行多个任务，并提供一些更高级的功能。让我们将上述任务移到一本剧本中。在ansible中剧本（playbooks）和角色（roles）都使用Yaml文件定义。创建文件nginx.yml： 123456789101112---# hosts could have been &quot;remote&quot; or &quot;all&quot; as well- hosts: local connection: local become: yes become_user: root tasks: - name: Install Nginx apt: name: nginx state: installed update_cache: true123456789101112 此任务与我们的ad-hoc命令完全相同，包括设置本地连接的使用。这将使用inventory文件中[local]标签下的服务器hosts。如果我们没有使用本地连接，我们会这样做： 12345678910---- hosts: remote become: yes become_user: root tasks: - name: Install Nginx apt: name: nginx state: installed update_cache: true12345678910 这将使用inventory文件中[remote]标签下的服务器hosts。 在我们的Tasks文件中使用become并become_user再次使用Ansible来sudo以root用户身份运行命令，然后传递Playbook文件。 使用一个yaml playbook文件，我们需要使用这个ansible-playbook命令，现在就更容易运行： 123456789101112$ ansible-playbook -i ./hosts nginx.ymlPLAY [local] ******************************************************************GATHERING FACTS ***************************************************************ok: [127.0.0.1]TASK: [Install Nginx] *********************************************************ok: [127.0.0.1]PLAY RECAP ********************************************************************127.0.0.1 : ok=2 changed=0 unreachable=0 failed=0123456789101112 我们在运行过程中获得了一些有用的反馈，包括“可执行任务”运行及其结果。在这里我们看到所有运行都OK，但没有改变。我已经安装了Nginx 2.3.1 处理程序（Handlers）处理程序与任务完全相同（它可以做task可以做的任何事），但只有当另一个任务调用它时才会运行。您可以将其视为事件系统的一部分; 处理程序将通过其侦听的事件调用进行操作。这对于运行任务后可能需要的“辅助”操作非常有用，例如在配置更改后安装或重新加载服务后启动新服务。 123456789101112131415161718192021---# Example shows using the local machine still# Remove &apos;connection&apos; and set hosts to &apos;remote&apos; for a remote connection- hosts: local connection: local become: yes become_user: root tasks: - name: Install Nginx apt: name: nginx state: installed update_cache: true notify: - Start Nginx handlers: - name: Start Nginx service: name: nginx state: started123456789101112131415161718192021 这里我们添加一个notify指令到安装任务。这将在任务运行后通知名为“Start Nginx”的处理程序。 然后我们可以创建名为“Start Nginx”的处理程序。此处理程序是通知“Start Nginx”时调用的任务。这个特定的处理程序使用服务模块，它可以启动，停止，重启，重新加载（等等）系统服务。在这种情况下，我们告诉Ansible，我们要启动Nginx。让我们再次运行这本Playbook： 123456789101112131415$ ansible-playbook -i ./hosts nginx.ymlPLAY [local] ******************************************************************GATHERING FACTS ***************************************************************ok: [127.0.0.1]TASK: [Install Nginx] *********************************************************ok: [127.0.0.1]NOTIFIED: [nginx | Start Nginx] ***********************************************ok: [127.0.0.1]PLAY RECAP ********************************************************************127.0.0.1 : ok=2 changed=0 unreachable=0 failed=0123456789101112131415 我们得到类似的输出，但是这次Handler是运行的。通知程序只在运行任务时运行。 Note：如果我已经安装了Nginx，则安装Nginx任务将不会运行，通知程序也将不会被调用。我们可以使用Playbook来运行多个任务，添加变量，定义其他设置，甚至包括其他的剧本。 2.3.2 更多的任务（More Tasks）接下来，我们可以为此Playbook添加更多的任务，并探索其他一些功能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445---# Example shows using the local machine still# Remove &apos;connection&apos; and set hosts to &apos;remote&apos; for a remote connection- hosts: local connection: local become: yes become_user: root vars: - docroot: /var/www/serversforhackers.com/public tasks: - name: Add Nginx Repository apt_repository: repo: ppa:nginx/stable state: present register: ppastable - name: Install Nginx apt: pkg: nginx state: installed update_cache: true when: ppastable|success notify: - Start Nginx - name: Create Web Root file: path: &apos;&#123;&#123; docroot &#125;&#125;&apos; mode: 775 state: directory owner: www-data group: www-data notify: - Reload Nginx handlers: - name: Start Nginx service: name: nginx state: started - name: Reload Nginx service: name: nginx state: reloaded123456789101112131415161718192021222324252627282930313233343536373839404142434445 现在有三个任务： 123Add Nginx Repository- 使用apt_repository模块添加Nginx稳定PPA以获取最新的稳定版本的Nginx 。Install Nginx - 使用Apt模块安装Nginx。Create Web Root - 最后创建一个Web根目录。123 新的register和when指令，可以实现在某些事情发生后让ansible执行任务的功能。 Note: 您还可以注册模块操作的结果，并使用定义的变量根据注册（register）的变量值有条件（when）地执行操作。例如，注册通过shell模块运行命令的结果可以让您访问该命令的stdout。同时还使用了一个变量。docroot变量在定义vars部分。然后将其用作创建定义目录的文件模块的目标参数。 需要注意的是，path配置使用括号NaN，这是Jinja2的模板。为了使Ansible能够在括号内解析Jinja2模板变量，该行必须是单引号或双引号 - 例如，path: ‘’而不是path: 。不使用引号将导致错误。这个playbook可以用通常的命令运行： 1ansible-playbook -i ./hosts nginx.yml1 所以，我们已经运行了一些ad-hoc命令，使用了可复制的模块，并将一些相关任务组织到一个手册中。 接下来，我们将通过将Playbook组织成一个角色进一步获得可靠性，这有助于我们组织相关项目，如文件和模板，同时还帮助我们组织更复杂的相关任务和操作。 2.4 角色（roles）角色很适合组织多个相关任务并封装完成这些任务所需的数据。例如，安装Nginx可能涉及添加软件包存储库，安装软件包和设置配置。此外，真实的配置通常需要额外的数据，如变量，文件，动态模板等等。这些工具可以与Playbook一起使用，但是我们可以通过将相关任务和数据组织成一个角色（role， 相关的结构）很快就能做得更好。角色有一个这样的目录结构： 12345678roles rolename - files - handlers - meta - templates - tasks - vars12345678 在每个子目录中（eg： files，handlers等等），Ansible将自动搜索并读取叫做main.yml的yaml文件。接下来我们将分解nginx.yml文件内容为不同的组件，并将每个组件放在相应的目录中，以创建一个更干净，更完整的配置工具集。 2.4.1 创建角色（Creating a Role）我们可以使用ansible-galaxy命令来创建一个新角色。此工具可用于将角色保存到Ansible的公共注册表，但是我通常只是使用它来在本地创建role的基础目录结构。 我们来看看如何设置： 123456789101112# Head to our previously created directorycd ~/ansible-example# In case we left our virtualenv at some point source .venv/bin/activate# Create a roles directorymkdir rolescd roles# Bootstrap a new role named &quot;nginx&quot;ansible-galaxy init nginx123456789101112 目录名称roles是一种惯例，在运行一个playbook时可以用来查找角色。该目录应该始终被命名roles，但并不强制。在roles目录中运行 ansible-galaxy init nginx 命令将创建新角色所需的目录和文件。 我们来看看我们新建的nginx角色的每个部分~/ansible-example/roles/nginx。 2.4.2 文件（files）首先，在files目录中，我们可以添加我们要复制到我们的服务器中的文件。对于nginx，我经常复制H5BP的Nginx组件配置。我只需从Github下载最新的信息，进行一些调整，并将它们放入files目录中。 12345~/ansible-example - roles - - nginx - - - files - - - - h5bp12345 我们稍后会看到，H5BP配置文件将通过复制模块添加到服务器。 2.4.3 处理程序（handlers）我们可以把曾经在nginx.yml 剧本中的定义的所有处理程序放入到handlers目录中。约定必须包含main.yml文件。 handlers/main.yml 内容： 12345678910---- name: Start Nginx service: name: nginx state: started- name: Reload Nginx service: name: nginx state: reloaded12345678910 一旦handlers/main.yml中的处理程序定义好了，我们可以自由地从其他的yaml配置中引用它们。 2.4.4 元（meta）meta目录中的main.yml文件包含Role元数据，包含的依赖关系。如果这个角色依赖于另一个角色，我们可以在这里定义。例如，nginx角色取决于安装SSL证书的ssl角色。约定必须包含main.yml文件。meta/main.yml 内容： 123---dependencies: - &#123; role: ssl &#125;123 如果我调用了“nginx”角色，它将尝试首先运行“ssl”角色。否则我们可以省略此文件，或将角色定义为没有依赖关系： 12---dependencies: []12 2.4.5 模板（templates）基于Python的Jinja2模板引擎（和django的模板引擎很类似），模板文件可以包含模板变量。这里的文件应该以.j2为类型后缀（eg.uwsgi.j2），提倡但是不强制，也可以取其他的名字。类似于files，在templates目录中没有main.yml文件，只包含.j2后缀的模板文件。这是一个Nginx服务器（“虚拟主机”）配置的例子。请注意，它使用了稍后在vars/main.yml文件中定义的一些变量。我们的示例中的Nginx配置文件位于templates/serversforhackers.com.conf.j2： 1234567891011121314151617181920212223242526272829303132333435363738server &#123; # Enforce the use of HTTPS listen 80 default_server; server_name &#123;&#123; domain &#125;&#125;; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443 ssl default_server; root /var/www/&#123;&#123; domain &#125;&#125;/public; index index.html index.htm index.php; access_log /var/log/nginx/&#123;&#123; domain &#125;&#125;.log; error_log /var/log/nginx/&#123;&#123; domain &#125;&#125;-error.log error; server_name &#123;&#123; domain &#125;&#125;; charset utf-8; include h5bp/basic.conf; ssl_certificate &#123;&#123; ssl_crt &#125;&#125;; ssl_certificate_key &#123;&#123; ssl_key &#125;&#125;; include h5bp/directive-only/ssl.conf; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location = /favicon.ico &#123; log_not_found off; access_log off; &#125; location = /robots.txt &#123; log_not_found off; access_log off; &#125; location ~ \\.php$ &#123; include snippets/fastcgi.conf; fastcgi_pass unix:/var/run/php7.1-fpm.sock; &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738 这是一个相当标准的用于PHP应用程序的Nginx配置。这里有三个变量： 域ssl_crtssl_key这三个变量将在变量部分（vars）中定义。 2.4.6 变量（vars）在使用任务集成所有事情之前，让我们来看看变量。该vars目录包含一个main.yml文件（如handlers和meta目录一样），在main.yml中我们可以列出将要使用的所有变量。以下是该vars/main.yml文件的内容： 1234---domain: serversforhackers.comssl_key: /etc/ssl/sfh/sfh.keyssl_crt: /etc/ssl/sfh/sfh.crt1234 我们可以在这个角色的其他地方使用这三个变量。我们在上面的模板中看到它们的使用，但是我们也可以在我们定义的任务中看到它们。 Note:如果您有敏感信息添加到变量文件中，则可以使用ansible-vault加密文件，下面将对此进行说明。2.4.7 任务（tasks）终于到了将一切都是放在一系列的任务中的时候了。使用角色时运行的主文件是tasks/main.yml文件。看看我们的用例将会是什么样的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364---- name: Add Nginx Repository apt_repository: repo: ppa:nginx/stable state: present- name: Install Nginx apt: pkg: nginx state: installed update_cache: true notify: - Start Nginx- name: Add H5BP Config copy: src: h5bp dest: /etc/nginx owner: root group: root- name: Disable Default Site Configuration file: dest: /etc/nginx/sites-enabled/default state: absent# `dest` in quotes as a variable is used!- name: Add SFH Site Config register: sfhconfig template: src: serversforhackers.com.j2 dest: &apos;/etc/nginx/sites-available/&#123;&#123; domain &#125;&#125;.conf&apos; owner: root group: root# `src`/`dest` in quotes as a variable is used!- name: Enable SFH Site Config file: src: &apos;/etc/nginx/sites-available/&#123;&#123; domain &#125;&#125;.conf&apos; dest: &apos;/etc/nginx/sites-enabled/&#123;&#123; domain &#125;&#125;.conf&apos; state: link# `dest` in quotes as a variable is used!- name: Create Web root file: dest: &apos;/var/www/&#123;&#123; domain &#125;&#125;/public&apos; mode: 775 state: directory owner: www-data group: www-data notify: - Reload Nginx# `dest` in quotes as a variable is used!- name: Web Root Permissions file: dest: &apos;/var/www/&#123;&#123; domain &#125;&#125;&apos; mode: 775 state: directory owner: www-data group: www-data recurse: yes notify: - Reload Nginx12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 这一系列任务使得Nginx能被完整的安装。任务按照出现的顺序完成以下工作： 123456781 添加nginx / stable库2 安装并启动Nginx3 添加H5BP配置文件4 从sites-enabled目录中删除文件的符号链接来禁用默认的Nginx配置5 将serversforhackers.com.conf.j2虚拟主机模板复制到Nginx配置中，渲染模板6 通过将其符号链接到sites-enabled目录来启用Nginx服务器配置7 创建Web根目录8 更改项目根目录的权限（递归），该目录位于之前创建的Web根目录之上12345678 有一些新的模块（和一些我们已经涵盖的新用途），包括复制，模板和文件模块。通过设置每个模块的参数，我们可以做一些有趣的事情，例如确保文件“不存在”（如果存在则删除它们）的state: absent，或者通过创建一个文件作为符号链接的state: link。您应该检查每个模块的文档，以查看可以用它们完成哪些有趣和有用的事情。 2.4.8 运行角色（Running the Role）要对服务器运行一个或多个角色，我们将重新使用另一个playbook。该playbook与roles目录位于同一个目录中，同一层级。当我们用ansible-playbook命令运行的时候需要先cd进入到该目录中。让我们创建一个“主”的yaml文件（被ansible-playbook命令执行的文件），该文件定义要使用的角色以及运行它们的主机：文件~/ansible-example/server.yml位于与roles目录相同的目录中： 123456---# run locally here, yadda yadda yadda- hosts: local connection: local roles: - nginx123456 所以，我们只是定义角色，而不是在本Playbook文件中定义所有的变量和任务。角色负责具体细节。 然后我们可以运行角色： 1ansible-playbook -i ./hosts server.yml1 以下是运行Nginx角色的Playbook文件的输出： 12345678910111213141516171819202122232425262728293031323334353637PLAY [all] ********************************************************************GATHERING FACTS ***************************************************************ok: [127.0.0.1]TASK: [nginx | Add Nginx Repository] ******************************************changed: [127.0.0.1]TASK: [nginx | Install Nginx] *************************************************changed: [127.0.0.1]TASK: [nginx | Add H5BP Config] ***********************************************changed: [127.0.0.1]TASK: [nginx | Disable Default Site] ******************************************changed: [127.0.0.1]TASK: [nginx | Add SFH Site Config] *******************************************changed: [127.0.0.1]TASK: [nginx | Enable SFH Site Config] ****************************************changed: [127.0.0.1]TASK: [nginx | Create Web root] ***********************************************changed: [127.0.0.1]TASK: [nginx | Web Root Permissions] ******************************************ok: [127.0.0.1]NOTIFIED: [nginx | Start Nginx] ***********************************************ok: [127.0.0.1]NOTIFIED: [nginx | Reload Nginx] **********************************************changed: [127.0.0.1]PLAY RECAP ********************************************************************127.0.0.1 : ok=8 changed=7 unreachable=0 failed=012345678910111213141516171819202122232425262728293031323334353637 我们将所有各种组件放在一起，形成一致的角色，现在已经安装并配置了Nginx！ 2.5 事实(Facts)请注意，运行剧本时的第一行总是“收集事实”。在运行任何任务之前，Ansible将收集有关其配置的系统的信息。这些被称为事实，并且包括广泛的系统信息，如CPU核心数量，可用的ipv4和ipv6网络，挂载的磁盘，Linux发行版等等。 事实在“任务”或“模板”配置中通常很有用。例如，Nginx通常设置为使用与CPU内核一样多的工作处理器。知道这一点，您可以选择如下设置nginx.conf.j2文件的模板： 12345user www-data;worker_processes &#123;&#123; ansible_processor_cores &#125;&#125;;pid /var/run/nginx.pid;# And other configurations...12345 或者如果你具有多个CPU的服务器，则可以使用： 12345user www-data;worker_processes &#123;&#123; ansible_processor_cores * ansible_processor_count &#125;&#125;;pid /var/run/nginx.pid;# And other configurations...12345 所有的ansible facts全局变量都是以“anisble_”为前缀，并且可以在其他任何地方使用。尝试对你的本地机器运行以下内容以查看可用的事实： 123456# Run against a local server# Note that we say to use &quot;localhost&quot; instead of defining a hosts file here!ansible -m setup --connection=local localhost# Run against a remote serveransible -i ./hosts remote -m setup123456 2.6 加密（Vault）我们经常需要将敏感数据存储在我们的模板，文件或变量文件中; 这样安全性有一定要求的情况是不可避免的（当我们将这些敏感数据文件推送到远程Git仓库时，这是一个痛苦的事情）。Ansible有一个叫做Ansible Vault的解决方案。Vault允许您加密任何Yaml文件，通常将其作用与变量文件，Vault不会加密文件和模板，只能使用Yaml文件。在创建加密文件时，系统会询问您必须使用的密码，以便稍后在调用角色或Playbook时进行编辑。将密码保存在安全的地方。 例如我们可以创建一个新的变量文件： 12ansible-vault create vars/main.ymlVault Password:12 输入加密密码后，该文件将在您的默认编辑器（通常是Vim或Nano）中打开。默认使用的编辑器由EDITOR环境变量定义。默认值通常是Vim。如果您不是Vim用户，可以通过设置环境变量来快速更改： 1EDITOR=nano ansible-vault edit vars/main.yml1 在大多数情况下，我们将使用ansible-vault create|edit /path/to/file.yml。更多可用的命令如下： 12345create - 创建一个新文件并进行加密decrypt - 从加密文件创建明文文件edit - 编辑已经存在的加密文件encrypt - 加密现有的纯文本文件rekey - 在加密文件中设置新密码12345 如果你有一个现有的配置文件要加密，请使用 ansible-vault encrypt /path/to/file.yml。 示例： users角色我们创建一个名为“users”的角色： 12cd ~/ansible-example/rolesansible-galaxy init users12 创建新用户并设置密码时，我使用Vault 。在用户角色中，您可以设置带有用户密码和公钥的变量文件，以添加到用户的authorized_keys文件（从而提供SSH访问权限）。公共SSH密钥在技术上是安全的，一般公众可以看到 - 所有人都可以使用它来允许你访问自己的服务器。在没有配对私钥的情况下，公钥是不能获得系统访问权限的，我们没有将密钥加入此角色。以下是可以使用Vault创建和加密的示例变量文件。在编辑它时，它是纯文本。 ~/ansible-example/roles/users/vars/main.yml： 123admin_password: $6$lpQ1DqjZQ25gq9YW$mHZAmGhFpPVVv0JCYUFaDovu8u5EqvQi.Ihdeploy_password: $6$edOqVumZrYW9$d5zj1Ok/G80DrnckixhkQDpXl0fACDfNx2EHnCcommon_public_key: ssh-rsa ALongSSHPublicKeyHere123 请注意，用户的密码也是散列的。您可以阅读Ansible有关生成加密密码的文档，用户模块需要设置用户密码。作为一个快速入门，它在Ubuntu上看起来像这样： 1234567# The whois package makes the mkpasswd# command available on Ubuntu$ sudo apt-get install -y whois# Create a password hash$ mkpasswd --method=SHA-512Password:1234567 这将生成一个散列密码供你与user模块一起使用。 Note：变量文件中的密码是散列的，但我仍然喜欢加密包含散列密码的yaml文件。这些文件通常包含未标记的数据，如API令牌或SSH私钥，使加密非常重要。一旦你设置了用户密码并将公钥添加到变量文件中，我们就可以加密此文件，然后在任务中使用这些加密变量。 1ansible-vault encrypt roles/users/vars/main.yml1 然后我们可以编辑我们的任务文件，使用（加密）变量添加新用户： 这是文件~/ansible-example/roles/users/tasks/main.yml： 12345678910111213141516171819202122232425262728---- name: Create Admin User user: name: admin password: &apos;&#123;&#123; admin_password &#125;&#125;&apos; groups: sudo append: yes shell: /bin/bash- name: Add Admin Authorized Key authorized_key: user: admin key: &apos;&#123;&#123; common_public_key &#125;&#125;&apos; state: present- name: Create Deploy User user: name: deploy password: &apos;&#123;&#123; deploy_password &#125;&#125;&apos; groups: www-data append: yes shell: /bin/bash- name: Add Deployer Authorized Key authorized_key: user: deploy key: &apos;&#123;&#123; common_public_key &#125;&#125;&apos; state: present12345678910111213141516171819202122232425262728 这些任务使用该user模块来创建新用户，传递变量文件中设置的密码。它还使用该authorized_key模块将SSH公钥作为SSH授权密钥添加到每个用户的服务器中。加密变量的使用像在常规任务文件中使用一样。但是，为了运行此角色，我们需要告诉Ansible请求输入vault密码，以便它可以解密变量。编辑我们的server.ymlPlaybook文件，调用user角色： 12345678---# Local connection here, yadda yadda yadda- hosts: local connection: local sudo: yes roles: - nginx - user12345678 要运行此Playbook，我们需要告知Ansible请求vault的密码，因为我们正在运行包含加密文件的角色： 1ansible-playbook --ask-vault-pass -i ./hosts server.yml1 3 总结本篇文章带着做了如下工作： 安装了ansible 配置了ansible inventory文件（仅在不使用connection: local 时才需要） 同时在多个服务器上执行幂等的 ad-hoc命令 创建一个基本的Playbook来运行多个任务（tasks），并使用了处理程序（handlers） 将多个任务抽象为一个角色，以保持所有Nginx相关的操作在一个角色内 展示了如何设置依赖关系 展示了如何注册任务的“依赖”执行关系，当一个任务执行成功后再执行另一个任务 展示了如何在我们的任务中使用更多的模板，文件和变量 展示了如何整合使用ansible事实(facts) 展示了如何使用ansible的vault来增加我们的变量的安全性","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"}],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/categories/Ansible/"}]},{"title":"马克·扎克伯格：关于Facebook的事实","slug":"马克·扎克伯格：关于Facebook的事实","date":"2019-03-12T07:31:04.000Z","updated":"2019-03-12T07:35:37.837Z","comments":true,"path":"评论/马克·扎克伯格：关于Facebook的事实/","link":"","permalink":"http://blog.ozairs.com/评论/马克·扎克伯格：关于Facebook的事实/","excerpt":"","text":"Facebook 下个月将满15岁。当我开始Facebook时，我并没有尝试建立一家全球性公司。我意识到你几乎可以找到互联网上的任何东西 - 音乐，书籍和信息 - 除了最重要的东西：人。所以我建立了一个人们可以用来连接和互相学习的服务。多年来，数十亿人发现这很有用，我们已经建立了更多的服务，世界各地的人们每天都喜欢和使用它们。 最近我听到很多关于我们商业模式的问题，所以我想解释一下我们如何运作的原则。 我相信每个人都应该有发言权并能够联系。如果我们致力于为每个人服务，那么我们需要一个每个人都能负担得起的服务。最好的方法是免费提供服务，广告使我们能够做到。 人们一直告诉我们，如果他们要看广告，他们希望它们具有相关性。这意味着我们需要了解他们的兴趣。因此，基于人们喜欢的页面，点击的内容以及其他信号，我们会创建类别 - 例如，喜欢有关园艺和西班牙生活的页面的人 - 然后向广告客户收取费用以向该类别展示广告。虽然在互联网出现之前广告已经存在，但在线广告可以实现更精确的定位，从而实现更具相关性的广告。 互联网还可以提供更大的透明度，并控制您所看到的广告，而不是电视，广播或印刷品。在Facebook上，您可以控制我们用来向您展示广告的信息，并且您可以阻止任何广告客户与您联系。您可以找到为什么看到广告并更改偏好以获取您感兴趣的广告。您还可以使用我们的透明度工具查看广告客户向其他人展示的每个广告。 不过，有些人担心这种模式的复杂性。在普通交易中，您向公司支付其提供的产品或服务。在这里，您可以免费获得我们的服务 - 我们会与广告客户分开工作，向您展示相关广告。这个模型可能会感觉不透明，我们都不信任我们不理解的系统。 有时这意味着人们认为我们做的事情是我们不做的。例如，我们不会出售人们的数据，即使经常报告我们这样做。事实上，向广告商出售人们的信息将违背我们的商业利益，因为这会降低我们对广告商的服务的独特价值。我们有强烈的动机来保护人们的信息不被其他任何人访问。 有人担心广告会导致我们与使用我们服务的人之间的利益错位。我经常被问到是否有动力增加Facebook的参与度，因为这会产生更多的广告房地产，即使这不符合人们的最佳利益。 我们非常注重帮助人们分享和联系更多，因为我们服务的目的是帮助人们与家人，朋友和社区保持联系。但从商业角度来看，重要的是他们的时间花得很好，或者他们不会长期使用我们的服务。Clickbait和其他垃圾可能在短期内推动参与，但我们故意展示这一点是愚蠢的，因为它不是人们想要的。 另一个问题是，我们是否会留下有害或分裂的内容，因为它会促进参与。我们没有。人们一直告诉我们他们不想看到这些内容。广告商不希望他们的品牌靠近它。坏内容仍然存在的唯一原因是我们用来审查它的人和人工智能系统并不完美 - 不是因为我们有动机忽视它。我们的系统仍在不断发展和完善。 最后，重要的问题是广告模式是否鼓励像我们这样的公司使用和存储比我们更多的信息。 毫无疑问，我们会收集一些广告信息，但这些信息对于安全和运营我们的服务通常也很重要。例如，公司经常将代码放在他们的应用程序和网站中，因此当一个人签出某个项目时，他们会发送提醒以完成购买。但是这种类型的信号对于检测欺诈或虚假账户也很重要。 我们让人们完全控制我们是否将这些信息用于广告，但我们不会让他们控制我们如何使用它来保护安全或运营我们的服务。当我们要求人们允许使用这些信息来改进他们的广告时，作为我们遵守欧盟通用数据保护法规的一部分，绝大多数人同意，因为他们更喜欢更相关的广告。 最后，我认为数据最重要的原则是透明度，选择和控制。我们需要明确我们使用信息的方式，人们需要明确选择如何使用信息。我们认为，通过互联网对这些原则进行编纂的监管对每个人都有好处。 要做到这一点很重要，因为这种商业模式有明显的好处。数十亿人获得免费服务，与他们关心的人保持联系并表达自己。小型企业 - 创造了全球大部分就业机会和经济增长 - 可以获得帮助他们茁壮成长的工具。Facebook上有超过9000万家小企业，它们构成了我们业务的很大一部分。大多数人买不起电视广告或广告牌，但现在他们可以使用大公司之前可以使用的工具。在一项全球调查中，Facebook上有一半的企业表示，自从他们加入以来，他们已经雇佣了更多的人。他们正在利用我们的服务创造数百万个就业机会。 对我们而言，技术始终是将权力交给尽可能多的人。如果你相信一个每个人都有机会利用自己的声音和平等的机会被人聆听的世界，任何人都可以从头开始创业，那么构建为每个人服务的技术都很重要。这就是我们每天都在建设的世界，我们的商业模式使其成为可能。 扎克伯格先生是Facebook的创始人兼首席执行官。","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"Facebook","slug":"Facebook","permalink":"http://blog.ozairs.com/tags/Facebook/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"跨平台配置工具Terraform常用命令","slug":"跨平台配置工具Terraform常用命令","date":"2019-03-11T08:57:13.000Z","updated":"2019-03-11T09:07:31.479Z","comments":true,"path":"DevOps/跨平台配置工具Terraform常用命令/","link":"","permalink":"http://blog.ozairs.com/DevOps/跨平台配置工具Terraform常用命令/","excerpt":"","text":"Terraform是一个 IT 基础架构自动化编排工具，它的口号是 “Write, Plan, and create Infrastructure as Code”, 基础架构即代码。具体的说就是可以用代码来管理维护 IT 资源，比如针对 AWS，我们可以用它创建，修改，删除 S3 Bucket, Lambda, EC2 实例，Kinesis， VPC 等各种资源。并且在真正运行之前可以看到执行计划(即干运行-dryrun)。由于状态保存到文件中，因此能够离线方式查看资源情况 – 当然，前提是不要在 Terraform 之外对资源进行修改。 Terraform 配置的状态除了能够保存在本地文件中，也可以保存到 Consul, S3, azure, http, swift 等处。 Terraform 是一个高度可扩展的工具，通过 Provider 来支持新的基础架构，AWS 不过为目前官方内建 68 个 Providers 中的一个。其他能用 Terraform 的地方有 Alicloud(阿里云, 实名制备案才能用), Google Cloud, Heroku, Kubernetes, Microsoft Azure, MySQL, RabbitMQ, Docker 等等。愿意的话可以写自己的 Provider, 如搞个 Kafka 的话，用来管理 Topic 等的创建，维护工作。 Terraform 之前我们对 AWS 的操作用的是 awscli, 或 Serverless。awscli 什么都能做，但它是无状态的，必须明确用不同的命令来创建，修改和删除。Serverless 不是用来管理基础架构的，用它创建 Lambda 时创建资源都是很麻烦的事。AWS 提供的 CloudFormation 才是与 Terraform 较类似的工具，但是看到用法就头疼。 下面从最简单例子开始，看看怎么用 Terraform 创建，删改，修改 S3 Bucket。本地系统为 Mac OS。 1. Terraform 安装 brew install terraform 安装后 shell 命令就是 terraform, 常用的是 terraform init, terraform plan, terraform apply 2. 创建配置文件像 git 一样，每个 Terraform 项目需要自己单独的目录空间，所以我们创建一个 terraform-learning 目录 mkdir terraform-learningcd terraform-learning 该目录下的所有 *.tf 文件都会被 Terraform 加载，在初始化 Terraform 工作空间之前必须至少要有一个 *.tf 文件。我们这里建立文件 main.tf, 内容如下 Terraform 配置的语法是该公司 HashiCorp 独创的 HCL(HashiCorp configuration language), 它可以兼容 JSON 格式。 上面 tf 文件在 Vim 中的语法加亮是安装的 hashivim/vim-terraform 插件。 我们写好了 *.tf 文件后可以调用 terraform fmt 对配置文件进行格式化，它比较喜欢被 Java 弃用的等号对齐的格式。 3. 配置文件介绍从正式跨入 terraform 命令正题之前先来大概的介绍一下上面那个 main.tf 文件。 1) provider “aws” 部分，它指定选用什么 provider, 以及验证信息。aws 既允许指定 access_key 和 secret_key provider “aws” { region = “us-east-1” access_key = “your-access-key-here” secret_key = “your-secret-key-here”} 也能够指定证书文件中的 profile provider “aws” { region = “us-east-1” shared_credentials_file = “~/.aws/credentials” //不指定的话，默认值是 “~/.aws/credentials” profile = “yanbin” //不指定的话，默认值是 “default”} 如果是使用 shared_credentials_file 中的 profile, 请确定您以预先生成好的 credentials 文件及有效的 profile。 更多关于 AWS Provider 的配置请参考 https://www.terraform.io/docs/providers/aws/index.html 2) resource “aws_s3_bucket” “s3_bucket” 部分 这只是我们今天举的一个小例子，点击链接 aws_s3_bucket 查看 S3 Bucket 所有的配置项。Terraform 能够管理的所有 AWS 资源也能从前面那个链接中看到。 如果 bucket yanbin-test-bucket 不存在的话，运行 terraform apply 将会创建它，否则试图更新该 bucket。此例子只指定了 bucket 的 acl 和 tag 信息。terraform destroy 用来删除已存在的 bucket。 注意：terraform 配置文件中只指定要管理的资源对象，并不关心操作资源的行为–创建，修改，删除操作。操作行为与 Terraform 的状态有关系，无则创建，有则修改，更名会拆分为除旧立新两个操作，terraform destroy 用于显式删除资源。后面实例操作时会讲到。 注：resource &quot;aws_s3_bucket&quot; &quot;s3_bucket&quot; { 中，resource 后第一个是 type, 即资源名，第二个参是 name。其实 “s3_bucket” 在这里没什么用，只是一个描述或助记符而已。(2017-08-28): 更正一下，在作为变量引用的时候就要用到它，例如在后面要为 Lambda 创建一个 S3 Event 的 Trigger, 就要写成 event_source_arn = &quot;${aws_s3_bucket.s3_bucket.arn}&quot;, 引用时不需要知道实际的名称。 4. 初始化工作目录在初始化 Terraform 工作目录之前， 其他命令如 apply, plan 多是不可用的，提示需要初始化工作目录，命令是 terraform init 它要做的事情像是 git init 加上 npm install，执行完了 terraform init 之后会在当前目录中生成 .terraform 目录，并依照 *.tf 文件中的配置下载相应的插件。 5. 执行 Terraform 管理命令有了前面的准备之后，终于可以开始运行 Terraform 的管理命令了。Terraform 在正式执行之前提供了预览执行计划的机会，让我们清楚的了解将要做什么 terraform plan 由此计划还能知道关于 aws_s3_bucket 有些什么配置项，比如配置中可以加上 acceleration_status = &quot;Enabled&quot; terraform apply 这样便在 AWS 上创建了一个 S3 bucket “yanbin-test-bucket”, 同时会在当前目录中生成一个状态文件 terraform.tfstate, 它是一个标准的 JSON 文件。这个文件对 Terraform 来说很重要，它会影响 terraform plan 的决策，虽然不会影响到实际的执行效果。我们可以把它存到远端，如 S3 或 Consul。terraform state [list|mv|pull|push|rm|show] 用来操作状态文件。 此时什么也不改，再次执行 terraform plan, 会显示没什么要做的 aws_s3_bucket.s3_bucket: Refreshing state… (ID: yanbin-test-bucket)No changes. Infrastructure is up-to-date. 如果对 main.tf 作点小改，改个 tag 属性，再次 terraform plan ~ aws_s3_bucket.s3_buckettags.Name: “Created by Terraform” =&gt; “sCreated by Terraform” Plan: 0 to add, 1 to change, 0 to destroy. 为什么说 terraform plan 是基于状态文件 terraform.tfstate 作出的呢？我们可以删除这个状态文件，然后执行 terraform plan 看看 + aws_s3_bucket.s3_bucket ….. bucket: “yanbin-test-bucket” …… tags.Environment: “QA” …… Plan: 1 to add, 0 to change, 0 to destroy. Terraform 由于缺乏 terraform.tfstate 对比，所以认为是要添加一个 bucket, 但是实际执行 terraform apply 时，连接到远端 AWS, 发现该 bucket 已存在就只是进行更新。terraform apply 总能给出正确的操作结果。同理如果状态文件中说有那个 bucket, terraform plan 会说是更新，但 AWS 没有那个 bucket，实际执行 terraform apply 也会进行添加的。 资源更名如果把 main.tf 中的 bucket = “yanbin-test-bucket” 改成 bucket = “yanbin-test-bucket-rename” 即欲为 bucket 更名，用 terraform plan 看下计划 实际上 terraform apply 也是先删除旧的，再创建新的。Terraform 像 git 一样用不同颜色和 +/- 号来显示变动操作 最后是 terraform destroy 命令，把 *.tf 文件中配置的所有资源从 AWS 上清理掉。 关于 Terraform 工作目录中文件命名Terraform 运行时会读取工作目录中所有的 *.tf, *.tfvars 文件，所以我们不必把所有的东西都写在单个文件中去，应按职责分列在不同的文件中，例如： provider.tf – provider 配置terraform.tfvars – 配置 provider 要用到的变量varable.tf – 通用变量resource.tf – 资源定义data.tf – 包文件定义output.tf – 输出 以此篇最简单的入门出发，以后可以深入了解 Lambda, Lambda 触发器，及 API Gateway, EC2 实例怎么用 Terraform 来管理，也知晓了资源的可用属性应该到哪里去查。 一个小提示：在执行像 terraform plan 或 terraform apply 等命令的时候，可以按下 ctrl + c 让控制台输出详细的日志信息。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/tags/Terraform/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"Kubernetes之kubectl常用命令","slug":"Kubernetes之kubectl常用命令","date":"2019-03-10T06:03:57.000Z","updated":"2019-03-17T05:27:25.027Z","comments":true,"path":"Kubernetes/Kubernetes之kubectl常用命令/","link":"","permalink":"http://blog.ozairs.com/Kubernetes/Kubernetes之kubectl常用命令/","excerpt":"","text":"这篇主要介绍一下kubernetes相关的命令，供初接触kubernetes的参考。 kubernetes通过kube-apiserver作为整个集群管理的入口。Apiserver是整个集群的主管理节点，用户通过Apiserver配置和组织集群，同时集群中各个节点同etcd存储的交互也是通过Apiserver进行交互。Apiserver实现了一套RESTfull的接口，用户可以直接使用API同Apiserver交互。另外官方还提供了一个客户端kubectl随工具集打包，用于可直接通过kubectl以命令行的方式同集群交互。 由于博主水平有限，本文主要介绍一些博主在日常中经常使用到的命令，另外最近正式release的kubernetes 1.2中新加入的的一些feature，由于博主也还没有深入研究，所以不会太多涉及。 Help类似于所有的命令行工具工具，kubectl也可以直接执行或 | 可获得命令的帮助信息。如下图所示，kubectl使用方式为：Usage： kubectl [flags] kubectl [commond]另外所有的命令选项都可以通过执行 –help获得特定命令的帮助信息。 getget命令用于获取集群的一个或一些resource信息。使用–help查看详细信息。kubectl的帮助信息、示例相当详细，而且简单易懂。建议大家习惯使用帮助信息。kubectl可以列出集群所有resource的详细。resource包括集群节点、运行的pod，ReplicationController，service等。Usage:kubectl get [(-o|–output=)json|yaml|wide|go-template=…|go-template-file=…|jsonpath=…|jsonpath-file=…] (TYPE [NAME | -l label] | TYPE/NAME …) [flags] [flags]1）例如获取pod信息，可以直接使用”kubectl get po“获取当前运行的所有pods的信息，或使用”kubectl get po -o wide“获取pod运行在哪个节点上的信息。注:集群中可以创建多个namespace，未显示的指定namespace的情况下，所有操作都是针对default namespace。如下图所示列出了default 和kube-system的pods： 2）获取namespace信息 kubectl get namespace3）类似可以使用”kubectl get rc”, “kubectl get svc”, “kubectl get nodes”等获取其他resource信息。4）获取一些更具体的信息，可以通过使用选项“-o”。如：（1）kubectl get po -o yaml 以yawl格式输出pod的详细信息。 （2）kubectl get po -o json 以jison格式输出pod的详细信息。 （3）另外还可以使用”-o=custom-columns=“定义直接获取指定内容的值。如前面使用json和ymal格式的输出中，metadata.labels.app的值可以使用如下命令获取。kubectl get po rc-nginx-2-btv4j -o=custom-columns=LABELS:.metadata.labels.app其中LABELS为显示的列标题，”.metadata.labels.app”为查询的域名 （4）其他资源也可以使用类似的方式。 describedescribe类似于get，同样用于获取resource的相关信息。不同的是，get获得的是更详细的resource个性的详细信息，describe获得的是resource集群相关的信息。describe命令同get类似，但是describe不支持-o选项，对于同一类型resource，describe输出的信息格式，内容域相同。 注：如果发现是查询某个resource的信息，使用get命令能够获取更加详尽的信息。但是如果想要查询某个resource的状态，如某个pod并不是在running状态，这时需要获取更详尽的状态信息时，就应该使用describe命令。kubectl describe po rc-nginx-2-btv4j createkubectl命令用于根据文件或输入创建集群resource。如果已经定义了相应resource的yaml或son文件，直接kubectl create -f filename即可创建文件内定义的resource。也可以直接只用子命令[namespace/secret/configmap/serviceaccount]等直接创建相应的resource。从追踪和维护的角度出发，建议使用json或yaml的方式定义资源。 如，前面get中获取的两个nginx pod的replication controller文件内容如下。文件名为：rc-nginx.yamlapiVersion: v1kind: ReplicationControllermetadata: name: rc-nginx-2spec: replicas: 2 template: metadata: labels:app: nginx-2 spec: containers: name: nginx-2image: xingwangc.docker.rg/nginxports: containerPort: 80直接使用create则可以基于rc-nginx.yaml文件创建出ReplicationController（rc），rc会创建两个副本：kubectl create -f rc-nginx.yaml创建后，使用“kubectl get rc”可以看到一个名为rc-nginx-2的ReplicationController将被创建，同时“kubectl get po”的结果中会多出两个前缀为“rc-nginx-2-”的pod。关于kubernetes集群中resource，pod， ReplicationController…等后续会新开博文详细介绍。 replacereplace命令用于对已有资源进行更新、替换。如前面create中创建的nginx，当我们需要更新resource的一些属性的时候，如果修改副本数量，增加、修改label，更改image版本，修改端口等。都可以直接修改原yaml文件，然后执行replace命令。 注：名字不能被更更新。另外，如果是更新label，原有标签的pod将会与更新label后的rc断开联系，有新label的rc将会创建指定副本数的新的pod，但是默认并不会删除原来的pod。所以此时如果使用get po将会发现pod数翻倍，进一步check会发现原来的pod已经不会被新rc控制，此处只介绍命令不详谈此问题，好奇者可自行实验。kubectl replace -f rc-nginx.yaml patch如果一个容器已经在运行，这时需要对一些容器属性进行修改，又不想删除容器，或不方便通过replace的方式进行更新。kubernetes还提供了一种在容器运行时，直接对容器进行修改的方式，就是patch命令。 如前面创建pod的label是app=nginx-2，如果在运行过程中，需要把其label改为app=nginx-3，这patch命令如下：kubectl patch pod rc-nginx-2-kpiqt -p ‘{“metadata”:{“labels”:{“app”:”nginx-3”}}}’ edit edit提供了另一种更新resource源的操作，通过edit能够灵活的在一个common的resource基础上，发展出更过的significant resource。例如，使用edit直接更新前面创建的pod的命令为： kubectl edit po rc-nginx-btv4j 上面命令的效果等效于： kubectl get po rc-nginx-btv4j -o yaml &gt;&gt; /tmp/nginx-tmp.yaml vim /tmp/nginx-tmp.yaml /do some changes here / kubectl replace -f /tmp/nginx-tmp.yaml Delete 根据resource名或label删除resource。 kubectl delete -f rc-nginx.yaml kubectl delete po rc-nginx-btv4j kubectl delete po -lapp=nginx-2 apply apply命令提供了比patch，edit等更严格的更新resource的方式。通过apply，用户可以将resource的configuration使用source control的方式维护在版本库中。每次有更新时，将配置文件push到server，然后使用kubectl apply将更新应用到resource。kubernetes会在引用更新前将当前配置文件中的配置同已经应用的配置做比较，并只更新更改的部分，而不会主动更改任何用户未指定的部分。 apply命令的使用方式同replace相同，不同的是，apply不会删除原有resource，然后创建新的。apply直接在原有resource的基础上进行更新。同时kubectl apply还会resource中添加一条注释，标记当前的apply。类似于git操作。 logslogs命令用于显示pod运行中，容器内程序输出到标准输出的内容。跟docker的logs命令类似。如果要获得tail -f 的方式，也可以使用-f选项。kubectl logs rc-nginx-2-kpiqt rolling-update rolling-update是一个非常重要的命令，对于已经部署并且正在运行的业务，rolling-update提供了不中断业务的更新方式。rolling-update每次起一个新的pod，等新pod完全起来后删除一个旧的pod，然后再起一个新的pod替换旧的pod，直到替换掉所有的pod。 rolling-update需要确保新的版本有不同的name，Version和label，否则会报错 。 kubectl rolling-update rc-nginx-2 -f rc-nginx.yaml 如果在升级过程中，发现有问题还可以中途停止update，并回滚到前面版本 kubectl rolling-update rc-nginx-2 —rollback rolling-update还有很多其他选项提供丰富的功能，如—update-period指定间隔周期，使用时可以使用-h查看help信息 scale scale用于程序在负载加重或缩小时副本进行扩容或缩小，如前面创建的nginx有两个副本，可以轻松的使用scale命令对副本数进行扩展或缩小。 扩展副本数到4： kubectl scale rc rc-nginx-3 —replicas=4 重新缩减副本数到2： kubectl scale rc rc-nginx-3 —replicas=2 autoscale scale虽然能够很方便的对副本数进行扩展或缩小，但是仍然需要人工介入，不能实时自动的根据系统负载对副本数进行扩、缩。autoscale命令提供了自动根据pod负载对其副本进行扩缩的功能。 autoscale命令会给一个rc指定一个副本数的范围，在实际运行中根据pod中运行的程序的负载自动在指定的范围内对pod进行扩容或缩容。如前面创建的nginx，可以用如下命令指定副本范围在1~4 kubectl autoscale rc rc-nginx-3 —min=1 —max=4 cordon, drain, uncordon 这三个命令是正式release的1.2新加入的命令，三个命令一起介绍，是因为三个命令配合使用可以实现节点的维护。在1.2之前，因为没有相应的命令支持，如果要维护一个节点，只能stop该节点上的kubelet将该节点退出集群，是集群不在将新的pod调度到该节点上。如果该节点上本生就没有pod在运行，则不会对业务有任何影响。如果该节点上有pod正在运行，kubelet停止后，master会发现该节点不可达，而将该节点标记为notReady状态，不会将新的节点调度到该节点上。同时，会在其他节点上创建新的pod替换该节点上的pod。这种方式虽然能够保证集群的健壮性，但是任然有些暴力，如果业务只有一个副本，而且该副本正好运行在被维护节点上的话，可能仍然会造成业务的短暂中断。 1.2中新加入的这3个命令可以保证维护节点时，平滑的将被维护节点上的业务迁移到其他节点上，保证业务不受影响。如下图所示是一个整个的节点维护的流程（为了方便demo增加了一些查看节点信息的操作）：1）首先查看当前集群所有节点状态，可以看到共四个节点都处于ready状态；2）查看当前nginx两个副本分别运行在d-node1和k-node2两个节点上；3）使用cordon命令将d-node1标记为不可调度；4）再使用kubectl get nodes查看节点状态，发现d-node1虽然还处于Ready状态，但是同时还被禁能了调度，这意味着新的pod将不会被调度到d-node1上。4）再查看nginx状态，没有任何变化，两个副本仍运行在d-node1和k-node2上；5）执行drain命令，将运行在d-node1上运行的pod平滑的赶到其他节点上；6）再查看nginx的状态发现，d-node1上的副本已经被迁移到k-node1上；这时候就可以对d-node1进行一些节点维护的操作，如升级内核，升级Docker等；7）节点维护完后，使用uncordon命令解锁d-node1，使其重新变得可调度；8）检查节点状态，发现d-node1重新变回Ready状态。 attach attach命令类似于docker的attach命令，可以直接查看容器中以daemon形式运行的进程的输出，效果类似于logs -f，退出查看使用ctrl-c。如果一个pod中有多个容器，要查看具体的某个容器的的输出，需要在pod名后使用-c containers name指定运行的容器。如下示例的命令为查看kube-system namespace中的kube-dns-v9-rcfuk pod中的skydns容器的输出。 kubectl attach kube-dns-v9-rcfuk -c skydns —namespace=kube-system exec exec命令同样类似于docker的exec命令，为在一个已经运行的容器中执行一条shell命令，如果一个pod容器中，有多个容器，需要使用-c选项指定容器。 port-forward 转发一个本地端口到容器端口，博主一般都是使用yaml的方式编排容器，所以基本不使用此命令。 proxy 博主只尝试过使用nginx作为kubernetes多master HA方式的代理，没有使用过此命令为kubernetes api server运行过proxy run 类似于docker的run命令，直接运行一个image。 label 为kubernetes集群的resource打标签，如前面实例中提到的为rc打标签对rc分组。还可以对nodes打标签，这样在编排容器时，可以为容器指定nodeSelector将容器调度到指定lable的机器上，如如果集群中有IO密集型，计算密集型的机器分组，可以将不同的机器打上不同标签，然后将不同特征的容器调度到不同分组上。 在1.2之前的版本中，使用kubectl get nodes则可以列出所有节点的信息，包括节点标签，1.2版本中不再列出节点的标签信息，如果需要查看节点被打了哪些标签，需要使用describe查看节点的信息。 其他其他还有如cluster-info信息可以查看当前集群的一些信息，Version查看集群版本信息等，还有一些集群配置相关的命令等。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/tags/Kubernetes/"}],"keywords":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/categories/Kubernetes/"}]},{"title":"停止、删除所有的docker容器和镜像","slug":"停止、删除所有的docker容器和镜像","date":"2019-03-09T23:48:08.000Z","updated":"2019-03-09T23:51:57.312Z","comments":true,"path":"DevOps/停止、删除所有的docker容器和镜像/","link":"","permalink":"http://blog.ozairs.com/DevOps/停止、删除所有的docker容器和镜像/","excerpt":"","text":"这些命令总是记不住，或者说不用心去记，所以记录在本文中，以便将来查询。 列出所有的容器 ID1docker ps -aq 停止所有的容器1docker stop $(docker ps -aq) 删除所有的容器1docker rm $(docker ps -aq) 删除所有的镜像1docker rmi $(docker images -q) 复制文件12docker cp mycontainer:/opt/file.txt /opt/local/docker cp /opt/local/file.txt mycontainer:/opt/ 更新: @snakeliwei 的提醒， 现在的docker有了专门清理资源(container、image、网络)的命令。 docker 1.13 中增加了 docker system prune的命令，针对container、image可以使用docker container prune、docker image prune命令。 docker image prune --force --all或者docker image prune -f -a` : 删除所有不使用的镜像 docker container prune -f: 删除所有停止的容器","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"世界上十大图书馆之一——维多利亚州立图书馆","slug":"世界上十大图书馆之一——维多利亚州立图书馆","date":"2019-03-08T04:01:41.000Z","updated":"2019-03-08T23:50:45.407Z","comments":true,"path":"旅行/世界上十大图书馆之一——维多利亚州立图书馆/","link":"","permalink":"http://blog.ozairs.com/旅行/世界上十大图书馆之一——维多利亚州立图书馆/","excerpt":"","text":"维多利亚州立图书馆State Library of Victoria位于墨尔本的市中心，地理位置绝佳，就在热闹的Melbourne Central车站正对面。 在图￼书馆前方大草皮上是大家歇息的好去处，只要有太阳的时候，墨尔本人是绝对不会错过在这里晒日光浴的任何机会。 距离图书馆入口处不远的地方，有大西洋棋让大家切磋一下棋艺。 而在Swanston St and La Trobe St交叉口的人行道上，有个像是图书馆沉到地底的公共艺术。 图书馆前方有不少铜像，正前方的雕像是大法官Redmond Barry。 这座图书馆成立于1854年，与墨尔本大学同年完工。州立图书馆为当地建筑师Joseph Reed设计，在之前的文章介绍过，这位设计师还包办设计了墨尔本其它著名的建筑物。像是皇家展览馆、墨尔本市政厅、圣米迦勒联合教会等等 在1856年维多利亚州立图书馆正式对外开放，经过了一个半世纪的发展，藏书体系越来越完善，目前该馆有超过两百多万的图书，以及一百多万件的地图、手稿、报册、图册等文献，馆藏范围种类繁多，史料价值高，完整的保存着维多利亚的文化。 图书馆内部有宽敞的展览大厅、画廊、简报厅、会议室、书报区，还有一个放置电玩的多媒体休闲室，馆方也充分的利用这些场地举办论坛、表演、讲座等活动。 除了丰富的藏书外，馆内还有陈列油画、雕像等艺术品，是一个集学习、哲学、科学及艺术的殿堂，在此不仅仅为学生、作家和爱思考的人提供一个便利的资源中心，它也是维多利亚州人文历史的主要记载地。 大部分游客都是为了馆内的圆顶阅览室而来，这部分于1913年开放，其八角空间可容纳一万本书及五百位以上的阅览者。 阅览室上方的圆顶，采用自然透光的设计，1913年由三位建筑师Bates、Peebles、Smarts的设计，仿效英国图书馆The British Library和华盛顿国会图书馆Library of Congress的圆顶。 楼梯旁还保留着早期的旋转楼梯，但现今已不再使用。 在图书馆的顶楼还有一幅三公尺高的莎士比亚之窗Shakespeare window，是澳大利亚第一幅人物像彩色玻璃拼花窗Stained glass window。 墨尔本能有个这么美的图书馆实在太幸运了，若是有机会来到墨尔本的话一定要来这走走。","categories":[{"name":"旅行","slug":"旅行","permalink":"http://blog.ozairs.com/categories/旅行/"}],"tags":[{"name":"澳洲","slug":"澳洲","permalink":"http://blog.ozairs.com/tags/澳洲/"}],"keywords":[{"name":"旅行","slug":"旅行","permalink":"http://blog.ozairs.com/categories/旅行/"}]},{"title":"墨尔本斯巴达挑战赛侧记","slug":"墨尔本斯巴达挑战赛侧记","date":"2019-03-02T10:54:01.000Z","updated":"2019-03-02T11:33:31.534Z","comments":true,"path":"uncategorized/墨尔本斯巴达挑战赛侧记/","link":"","permalink":"http://blog.ozairs.com/uncategorized/墨尔本斯巴达挑战赛侧记/","excerpt":"","text":"今年是墨尔本斯巴达越野挑战赛正赛的日子，虽然墨尔本的气温仍然居高不下，但是依然无法抵挡大批粉丝对于这项赛事的热情。今年的比赛得到了凯西市政府的大力支持，作为东道主，我也有幸作为志愿者参加了这项一年一度的重要赛事。 【赛事的主旨】 今年的墨尔本斯巴达挑战赛，是首次在凯西市举办，在Tooradin Estate的一个史诗般的新场地中，选手们有机会穿越泥泞，跳过火，征服障碍。 斯巴达挑战的宗旨，就是要让选手们组成一个团队或独自行进，并找出像斯巴达一样参加比赛意味着什么通过挑战赛，选手们将会看到自己征服障碍，如奥林巴斯，长矛，大力神升降机，戒指等等！ 【赛事的类型】 1、5公里竞速赛 这是斯巴达挑战赛最短的距离，选手们需要翻越20-23 障碍。比赛适合各级运动员使用; 从斯巴达的第一次选手到经验丰富的选手。 2、斯巴达超级赛，13公里，24-29 障碍 这是斯巴达挑战赛中距离赛事。由于比竞速赛的距离更长，障碍更多，超级赛将测试您的耐力，毅力和勇气。这个13公里的超级大道包含超过25个特色斯巴达障碍物，通过更加坚固和更加崎岖的地形。 3、2合1挑战赛 在同一天同时参加超级赛和竞速赛，并节省一些现金。通过获得竞速赛和超级赛奖牌，你将成为Spartan Trifecta的三分之二！ 4、儿童挑战赛 斯巴达挑战赛都是为了让自己变得泥泞而且充满乐趣！赛事的使命是鼓励孩子们出去，活跃，享受自己。这就是为什么我们的斯巴达儿童比赛鼓励年轻的斯巴达人在非竞争，安全和支持的环境中拥有一大堆泥泞的乐趣来征服他们的目标！孩子们会跑步，平衡，走路，爬行，爬上充满乐趣的障碍课程，帮助他们了解成为斯巴达人的感受！比赛经过专门设计，适合所有年龄段和健身水平的孩子。 斯巴达儿童挑战赛是1-2公里纯净的泥泞快乐。所有障碍都是成人障碍物的微型版本，并包含巨大的充气滑梯等附加功能，让孩子在参赛过程中，享受赛事带来的最大快乐。 孩子们可以进入两个不同的类别。有3到8岁的Spartan Juniors（完成1节课程）和9-13岁（完成2圈）的Big Kids类别。 成年人可以选择跟随课程并帮助他们的孩子。父母也可以选择与孩子或观众一起跑步。 【参赛观感】 今天虽然又是一个炎热的酷暑，特别是挑战赛的过程中，选手们要走草地，过泥塘，翻越各种障碍，可以说比赛是对身体机能的一次极限挑战，也是对于意志品质的一次终极考验。只有克服了身体和意志的障碍，才能成为一名真正的斯巴达勇士。 很荣幸今天能作为志愿者，参加斯巴达挑战赛正赛。作为斯巴达竞赛的志愿者，虽然牺牲了周末的时间，但是能有机会感受到斯巴达赛及选手们冲天的参赛热情，并且能够参与到比赛中，让选手和和观众们拥有史诗般的体验，也算是一种难得而又珍贵的体验了。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ozairs.com/tags/随笔/"}],"keywords":[]},{"title":"关于自己你需要知道的10件事","slug":"关于自己你需要知道的10件事-1","date":"2019-03-01T10:42:42.000Z","updated":"2019-03-01T10:45:18.793Z","comments":true,"path":"uncategorized/关于自己你需要知道的10件事-1/","link":"","permalink":"http://blog.ozairs.com/uncategorized/关于自己你需要知道的10件事-1/","excerpt":"","text":"我最近在INC发现了这篇文章，并且非常喜欢文中提到的挑战自己的方式，你是否问过自己以下这些棘手的问题。 无论我们的年龄，在生命的每个阶段，我们都应该花点时间进行评估，进行自我评估。我们应该知道我们是谁，理解我们想要什么。我们应该问自己一些棘手的问题，清楚地看到自己，并在必要时进行调整。这并不能保证成功，但它可以保证您对自己的生活方式感到满意。以下是我们应该始终能够对自己说的一些事情： \\1. 我遵从我内心的声音。即使有更轻松的选择，我也相信自己内心的声音能够引导我。我做了正确的事情，我忠于自己。 \\2. 我总是很积极。我把每一种情况视为祝福或教训。我一直保持着希望和乐观的态度。 \\3. 我很负责。我已经获得了信任，并对自己负责。我没有找借口，也没有责备别人。我是演出的明星，我很尊重我。 4.我很感激。我很感激我的生命。每个开门和关门，我都很感激。我很感激未来的希望。 \\5. 我选择原谅。我已经原谅了任何冤枉我的人。我原谅，因为我永远无法完全理解他们的处境，因为抱怨只会让我失望。 \\6. 我不留遗憾。好的，坏的，或者其他的，我永远不会后悔任何机会，即使结果很糟糕。我一直爱着，微笑，并尽我所能地生活，我永远不会后悔。 \\7. 我对自己诚实。我能够看着镜子里的脸，告诉他们真相。我是谁，我想成为谁，我喜欢什么，想要改变什么，我在哪里以及我想去哪里。这就是梦想成为现实的方式。 \\8. 我为自己感到骄傲。我为自己的成就感到自豪。大多数情况下，我为我这个人感到骄傲。最后，我会因为善良，诚实，勤奋，奉献和公平的人而被人们铭记。 \\9. 我不是一个轻言放弃的人。我不说，’我做不到’。我从不放弃，我从不放弃。我全力以赴。 \\10. 我还没完。只要我有气息，我就会继续生活，笑，给予，并尝试。如果只是一个裂缝，总会有一扇门打开。 俗话说“我们必须先学会爱自己”。给自己一个休息时间。改变你的想法，试着去做到最好。 【The Original Article】I recently came across this article in INC and loved the way it challenged you to consider whether you had asked yourself the tough questions. Regardless of our age, at each stage of life, we should take a moment to take stock, to do a self-evaluation. We should know who we are and understand what we want. We should ask ourselves the tough questions, see ourselves clearly, and make adjustments if necessary. This doesn’t guarantee success but it guarantees that you will feel good about how you are living your life. Here are some things we should always be able to say about ourselves: \\1. I have followed my heart. I have trusted my inner voice to lead me even when there were easier roads. I have done the ‘right’ thing. I have been true to myself. \\2. I have looked for the positive. I have treated every situation as a blessing or a lesson. I have kept hope and optimism on the forefront. \\3. I am responsible. I have taken credit and held myself accountable. I’ve made no excuses, nor blamed another. I am the star of my show, and I own up to me. \\4. I am grateful. I am grateful for the life I’ve been given. I’m grateful for every opened and closed door. I am grateful for the hope of more to come. \\5. I have forgiven. I have forgiven any and everyone who has wronged me. I forgive because I can never fully understand their situation and because holding a grudge only holds me back. \\6. I have no regrets. Good, bad, or otherwise, I will never regret any opportunity, even if it turned out badly. I have loved, laughed, and lived to the best of my ability, and I will never be sorry. \\7. I am honest with myself. I am able to look at the face in the mirror and tell them the truth. Who I am and who I want to be, what I love and what I want to change, where I am and where I want to go. This is how dreams become reality. \\8. I am proud of myself. I am proud of my accomplishments. Mostly, I am proud of the person I am. In the end, I will be remembered for the kind, honest, hard-working, giving, and fair person that I am. \\9. I am not a quitter. I do not say, ‘I can’t’. I never give up, and I never give in. I give my all to every endeavour. \\10. I am not finished. As long as I have breath, I will continue to live and laugh and give, and try. There is always a door that is open if only just a crack. As the old saying goes, “we must first love ourselves”. Give yourself a break. Change what you, and be the best you can be.","categories":[],"tags":[{"name":"励志","slug":"励志","permalink":"http://blog.ozairs.com/tags/励志/"}],"keywords":[]},{"title":"Why do I need a cover letter","slug":"Why-do-I-need-a-cover-letter","date":"2019-02-23T12:03:18.000Z","updated":"2019-02-23T12:04:19.345Z","comments":true,"path":"uncategorized/Why-do-I-need-a-cover-letter/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Why-do-I-need-a-cover-letter/","excerpt":"","text":"If you have ever read one of the job ads I’ve posted, you would have seen my request for a cover letter. After reading some of the responses to that request, I’m sure the initial thought might have been, “Why the do I need a cover letter?” There’s no doubt I have read a bucket load of cover letters. Those that I have read which are poor far outweigh those that are good. It’s like comparing the sheer size of Jupiter to the Forest Moon of Endor; small and non-existent. Many of you, I am sure, wonder why you should bother at all. I tend to agree if the purpose of your cover letter is to be general and vague. Believe it or not, there have been times when I have called a candidate on the strength of their cover letter, alone. So, what makes one cover letter stand out over another in my opinion? Before I get to that, I want to share an experience in my career that has led to my opinion and writing this blog post. Before establishing my recruitment business, I worked in IT as a BDM for over a decade. In that time, I worked on countless proposals for my customers. It was always a collaborative process. My job was to get the frame of the document and the requirements clear. I would engage experts to provide the technical content of our solution. I would speak to relevant internal teams and third parties around our commercial model. Once I had all the information I needed, there was only one thing left to do. I needed to write my executive summary. I read a great book many years ago called Persuasive Business Proposals – Writing to Win More Customers, Clients, and Contracts by Tom Sant. On page 138, the chapter headed Executive Summary, the first line sets the theme of that chapter; The executive summary is the single most important part of your proposal. This line and the entire chapter changed how I wrote proposals forever. It resulted in me progressing to more shortlists and winning more deals. I even had a customer once ask me to write an executive summary to explain a proposal I hadn’t even written. The very premise of an executive summary in a business proposal got me thinking how similar one is, or should be, to a cover letter. If you are selling yourself to an employer, should you treat your resume as a business proposal? If so, why are you not introducing your solution (you) to the hiring manager’s problem with an effective executive summary? Tom goes on to say; the executive summary is the only part that’s likely to be read by everybody involved in making the decision. In fact, it’s the only part of your proposal that some decision makers will read at all. Now, I know in a recruitment process that’s unlikely to happen. Your resume will get read at some point, but there are some significant parallels to draw here. If a stakeholder can progress a proposal based on an executive summary, your cover letter can make a big impact too. I remember the old way I used to write a proposal and the way my customer would read them. I’d articulate my understanding of the problem and the outcome they were aiming to achieve. I’d relate their situation to the broader market. Our solution would then follow and the technical justification to support my claim. All important stuff. There would be pages and pages of diagrams, tables, jargon and blah blah blah. They’d read page after page until they found one of the most important things they were looking for to see if the discussion was worth continuing. The price. It was one of the most critical pieces of the puzzle, and yet I had it hidden in the shadows of my document. It’s no wonder people read my proposals like a Herald Sun reading sports enthusiast, from back to front. The first time I put my pricing in the executive summary was a real test of nerves. I was shitting myself. “What if they reject us before even looking at our solution?” However, that didn’t happen. The most important information was at the front. Our understanding of the problem, the key themes of our solution to address it and the price. The rest of the business proposal became the supporting documentation. What I found was it gave us more air time with our customer than we had before. It demonstrated a level of confidence in our solution. I found that more customers wanted to get me in to discuss the detail of the solution. A cover letter that addresses your customer, in the same way, will show the same confidence. It will demonstrate that you understand the role and why, in short, you are the right person for the job. An executive summary always exists as a part of the business proposal document. You want to make sure it’s the first thing your customer reads. I think cover letters should be the same. Not a separate document, but the first page of your resume. If you have two documents, your cover letter is less likely to be read after the resume has been opened first. Usually, recruiters will only attach one document with a candidate in their databases. For future roles, it’s beneficial to have everything in the same document. A cover letter in the resume will offer another page of content to where keywords can be found. Over my time, I have read countless cover letters that read like the narrative of a novel. Usually, they are one or two pages, densely populated with words. At first glance, they seem like a fair investment of time to read. However, for a cover letter, such a style doesn’t address the time-poor nature of your reader. Make your cover letter one page, the first thing someone sees. Be specific. Use dot points and have them well spaced (one and a half spaces works well for me) so they are easy to read. When you find a job advertisement you want to apply for, focus on the requirements section. Ask yourself, “what are the three critical things I think these guys are looking for?” Those lines will be explicit in the skill or experience they’re after. This is what you should prioritise and address in your cover letter. Don’t bother with the general requirements as you’ll only respond with general statements. These are the requirements like ‘excellent communication skills’ or ‘works well in a team.’ These things you can demonstrate in an interview. A good cover letter cuts specific words or phrases out of the advertisement. They do this, so it couldn’t be any clearer what they are trying to address. It’s a risk leaving it to chance that your audience will be able to interpret your resume in the way you want. This is where you should help them out. Point directly to the experience or skill. Say, “there, that’s where I did it!” And point to it from your cover letter. Being able to highlight what you think is important will help a recruiter find what they are looking for. However, if anything, it will help you qualify if, in fact, you are right for the job. The role of a recruitment consultant is not easy. Many of us are working on ten, twenty, even more positions at a given time. If you consider putting forward three or four candidates per role, that’s a lot to manage. We coordinate client briefings, write advertisements and drive proactive campaigns. We accept applications, conduct phone screenings and send out rejection emails. We organise interviews, build shortlists, lock in candidates to meet with clients. We help with salary negotiations, references and sending out offers. And all the time, keep our bosses off our backs maintaining weekly KPI’s. It ain’t easy, and we’re often left feeling like a panting sheepdog at the end of each day. We receive hundreds of applications per role. With limited minutes in the day, the trick, as a recruiter, is to find what you need as quickly as possible. You want to find what you need, pick up the phone and progress the candidate to the next stage. It’s like a game of Crash Bandicoot; every requirement you meet grants you another few seconds of reading time. However, offer a passage of boring fluff, and you go backwards. And if you do make it to the end of the level, that’s when you get the call from a recruiter. They are ringing to have an in-depth discussion with you about your application. There is no doubt that applying for a job through an advertisement is one of the hardest things to do. How do you stand out through words on a page? With so many lousy cover letters out there, I believe this is where you can answer that question. In the process, you will save the recruiter time trying to find what they’re looking for in your resume. If you think of it like this: the executive summary, your cover letter, is the map to the island of your resume. Be bold and tell a hiring manager exactly where to find what they are looking for. Tell them why you are right for the job, and maybe, you’ll be that next candidate who stands out from the crowd.","categories":[],"tags":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/tags/求职/"}],"keywords":[]},{"title":"Are Australia’s ‘secondary’ cities still a bargain, or have they run their race?","slug":"Are-Australia’s-‘secondary’-cities-still-a-bargain-or-have-they-run-their-race","date":"2019-02-21T00:21:58.000Z","updated":"2019-02-21T00:39:45.031Z","comments":true,"path":"uncategorized/Are-Australia’s-‘secondary’-cities-still-a-bargain-or-have-they-run-their-race/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Are-Australia’s-‘secondary’-cities-still-a-bargain-or-have-they-run-their-race/","excerpt":"","text":"Australia’s capital cities may be coming off the boil, but what of their metropolitan siblings? Secondary cities such as Geelong, Newcastle and Launceston have been on a run, proving more affordable options for buyers after prices shot up in the closest major capital city. But with prices in some capitals declining – most notably in Sydney and Melbourne – some secondary cities now don’t look quite as good value as they did a year or two ago. The outlook for prices in major regional cities Newcastle, Wollongong, Gold Coast, Sunshine Coast, Geelong and Launceston is analysed below. Secondary cities boomed after major cities became too expensiveWhen capital city prices become too expensive for first-home buyers and investors, aspiring capital city home buyers often look to nearby regional cities as a cheaper alternative. These secondary cities are often close enough to a major capital that people can commute to the capital city for work. Price growth in major cities and secondary cities generally track pretty closely together, but sometimes with a delay of around a year. For some cities, the major city in some city-pairs can lead turning points in the price growth of the secondary city. Sydneysiders consider Newcastle and Wollongong, Melburnians often look to Geelong, and Launceston, Tasmania’s second-largest city, is considered after Hobart. In Queensland, the typical house in Brisbane is cheaper than in the Gold Coast and the Sunshine Coast, but these coastal cities are both within commuting distance to Brisbane and are obvious alternatives to Queensland’s capital. Property prices in Wollongong, Newcastle and Geelong began rising a year or two after Sydney and Melbourne property prices began taking off around 2013. Launceston house prices have increased significantly since 2017, a couple of years after Hobart’s price boom started in 2015. While price growth has been more subdued up north, Sunshine Coast and Gold Coast house prices have increased by more than those in Brisbane. Notes: Capital city house prices are Australian Property Monitor city regions and are a stratified median price. Secondary cities are ABS Significant Urban Areas and are a raw median price. Most secondary cities have experienced stronger house price growth than their nearest capital cityMedian house price, December quarter 2015 2016 2017 2018 Per cent change,**2015-2018** Sydney $1,015,559 $1,131,882 $1,180,024 $1,062,619 5% Wollongong $585,000 $665,000 $718,000 $705,000 21% Newcastle $453,000 $495,000 $535,000 $558,000 23% Melbourne $718,853 $811,393 $909,463 $833,321 16% Geelong $435,000 $465,000 $518,000 $557,500 28% Hobart $347,841 $377,316 $440,970 $479,685 38% Launceston $285,000 $285,000 $310,000 $344,000 21% Brisbane $517,843 $546,984 $566,602 $566,058 9% Gold Coast $545,000 $590,000 $620,000 $622,500 14% Sunshine Coast $540,000 $560,000 $615,000 $620,000 15% What’s in store for secondary cities house prices?Several indicators are used to predict price growth in secondary cities in the coming years. The first method is comparing the ratio of the median price in a capital city with the secondary city’s median house price. The higher the capital city/secondary city price ratio, the more expensive the capital is compared to the secondary city (for example, a ratio of 2 indicates a typical house in the capital city is twice as expensive as the secondary city). If a capital city/secondary city price ratio is below average, then this may indicate the secondary city is overvalued, suggesting the secondary city may see weaker price growth in the near future (and vice versa). Buyer interest in an area – using changes in the number of views per listing from Domain’s website and apps, a leading indicator of future price growth – is also analysed. The economic outlook and job prospects in secondary cities, including the interconnectedness of the secondary city with the closest capital city, are also considered. Sydney-WollongongWhile Wollongong’s economy is performing well, its prices are likely to stagnate or fall in the year ahead. The main reason is that the Sydney/Wollongong price ratio has fallen just below the 2010-2018 average and is back close to the level over the 2003-2013 period, where the median house price in Sydney prices was approximately 50 per cent higher than in Wollongong (see graph below). This fall in the price ratio was due to Sydney house prices falling by more than Wollongong house prices over the past two years. While prices are likely to remain fairly stagnant over the next one to two years, Wollongong’s improving job market and growing links to Sydney should provide support to Wollongong property prices in the medium term. Wollongong has seen strong jobs growth in the past couple of years, with the unemployment rate for the Wollongong LGA falling from almost 7 per cent in 2016 to 4.5 per cent in 2018. Wollongong is also a growing commuter town: in 2016, more than 21,000 people commuted from Wollongong to Sydney for work (the second largest regional city to capital city commuting pair, behind the Gold Coast to Brisbane). Wollongong and Illawarra residents may also benefit from the construction of the Badgerys Creek airport, which will be just over an hour’s drive from Wollongong, although construction is not expected to finish until 2026. Sydney-NewcastleNewcastle is likely to see weak price growth or modest price falls in the next year or two. The Sydney/Newcastle price ratio has fallen below the 2010-2018 average as prices have grown slowly in Newcastle over the past year, but fell by 10 per cent in Sydney. This indicates Newcastle houses may be becoming overvalued compared to Sydney. Buyer interest in Newcastle also appears to be waning. Domain’s views-per-listing measure for Newcastle fell by 2 per cent over 2018 as there were fewer buyers or they began looking elsewhere. Another reason property price growth in Newcastle might be subdued is that there is no clear jobs boom on the horizon in the region. Newcastle’s unemployment rate has hovered around 6 per cent over the past couple of years, which is above Sydney’s unemployment rate of 4 per cent. Melbourne-GeelongThe Melbourne/Geelong house price ratio fell significantly over 2018 as house prices increased in Geelong and fell in Melbourne. The Melbourne/Geelong price ratio now sits at 1.5, meaning a typical house in Melbourne is 50 per cent more expensive than a typical Geelong house. The ratio is now below the 2010-2018 average. With Melbourne house prices forecast to continue falling in 2019, Geelong’s relative affordability will decline further, so this may also see prices in Geelong stagnate or fall modestly. The Geelong market is already losing momentum, with house price growth slowing in Geelong over 2018 and Domain’s views-per-listing measure for Geelong falling at the end of 2018. While the analysis of the Melbourne/Geelong price ratio suggests Geelong prices may fall, there are some promising signs for Geelong’s economy. Some sectors are seeing jobs growth, particularly government jobs, and the city is on the rebound after the end of car manufacturing in 2016. Geelong’s unemployment rate has hovered around 6 per cent since 2016, but a very low unemployment rate in Melbourne of 4 per cent (down from 6 per cent over the past year) may help push Geelong’s unemployment rate lower. Geelong is increasingly interconnected with Melbourne, which should see the Geelong property market become further tied to the Melbourne market. There are a number of transport infrastructure projects planned, or underway, that should improve travel times between Geelong and Melbourne, including the West Gate tunnel project and planned improvements to the Geelong-Melbourne rail service. These projects – combined with strong population growth and lots of homebuilding in Geelong and surrounding towns – mean the number of commuters from Geelong to Melbourne will likely increase from the 15,000 commuters in 2016. Hobart-LauncestonAn above-average Hobart/Launceston price ratio, increasing buyer interest and brighter economic prospects all indicate that Launceston may see further price growth over the next one to two years. Price growth in Launceston, Tasmania’s second-largest city, is closely correlated with price growth in Hobart. As Hobart’s prices boomed over the past few years – house prices have increased by more than 40 per cent since early 2015 – Launceston has become relatively cheaper. The Hobart/Launceston price ratio has increased, with a typical house in Hobart now 40 per cent more expensive than a typical Launceston house, up from a 20 per cent difference a few years ago. But Launceston prices have also grown strongly since 2017, resulting in the price ratio stabilising, with the relative affordability of Launceston likely to encourage some investors and migrants to buy in Launceston instead of Hobart. There is also growing buyer interest in Launceston. Views per listing in Launceston increased by about 40 per cent over 2018. Launceston’s economic prospects are also improving. Unemployment recently fell to its lowest level in more than seven years, although it remains elevated at 6.8 per cent. Launceston is the subject of a City Deal partnership between federal, state and local governments to boost the Launceston economy. The annual MONA-FOMA festival has been moved from Hobart to Launceston, so Launceston may benefit from some of the “MONA-effect” that has boosted Hobart’s economy. A weaker Australian dollar should continue to support Tasmania’s economy by boosting tourist numbers to Tasmania, as well as making Tasmania’s exports cheaper for overseas buyers. Unlike other city-pairs considered in this article, few people travel between Launceston and Hobart for work (only 275 people commuted from Launceston to Hobart in 2016). Brisbane-Gold Coast and Brisbane-Sunshine CoastModerate price growth in the Gold Coast and the Sunshine Coast compared to slower price growth in Brisbane over the past two years has made a house in Brisbane relatively cheap compared to the coastal cities. The Brisbane/Gold Coast and Brisbane/Sunshine Coast price ratios have fallen and now sit below the 2010-2018 average, suggesting the coastal cities are slightly overvalued. Because the smaller Queensland cities have a higher median price than Brisbane, the Brisbane/Gold Coast and Brisbane/Sunshine Coast price ratios are below 1, meaning a typical Brisbane house is about 10 per cent cheaper than in the Gold Coast and the Sunshine Coast. South-east Queensland is highly interconnected. More than 30,000 people commuted from the Gold Coast to Brisbane for work in 2016, the biggest city pair in Australia, while 8400 people commuted from the Sunshine Coast to Brisbane. Job prospects have been better in the Gold Coast than in the other cities. The Gold Coast’s unemployment rate has fallen from 5.5 per cent in late 2016 to 4.3 per cent at the end of 2018, whereas the unemployment rate hovered around 6 per cent in Brisbane in 2018 and increased to 6.5 per cent in 2018 in the Sunshine Coast. The price ratios suggest Gold Coast and Sunshine Coast house prices may grow more slowly than Brisbane in 2019. But the Domain views-per-listing measure for the Gold Coast and the Sunshine Coast increased in the second half of 2018, and job prospects look better in the Gold Coast, suggesting there is scope for further price growth for both secondary cities. The outlookSecondary cities are closely tied to the performance of their closest capital. Over the next few years, as jobs continue to concentrate in Australia’s major cities, secondary cities will likely become even more closely linked to their nearest capital city. The outlook for some capital cities is for further falls in 2019 before prices bottom-out later in the year, so the likelihood is secondary cities will see prices stagnate or fall in 2019, although Launceston looks to be an exception.","categories":[],"tags":[{"name":"Property","slug":"Property","permalink":"http://blog.ozairs.com/tags/Property/"}],"keywords":[]},{"title":"10 Most Popular DevOps Interview Questions and Answers","slug":"10-Most-Popular-DevOps-Interview-Questions-and-Answers","date":"2019-02-20T08:28:55.000Z","updated":"2019-02-20T08:31:15.366Z","comments":true,"path":"uncategorized/10-Most-Popular-DevOps-Interview-Questions-and-Answers/","link":"","permalink":"http://blog.ozairs.com/uncategorized/10-Most-Popular-DevOps-Interview-Questions-and-Answers/","excerpt":"","text":"Until recently, development engineers often worked in isolation, restricting their knowledge and skill sets to coding and testing, while operations engineers would focus on delivery and infrastructure configuration jobs, with minimal knowledge about software development. However, with the fast-paced growth of the IT domain and technology advancements, the traditional approach of most IT companies has seen a paradigm shift. The culture of DevOps, although in its infancy, acts as the perfect bridge between IT development and operations and has become a popular methodology for software development in recent years. An article entitled, “The DevOps Hiring Boom” claims that as many as 80 percent of Fortune 1000 organizations are expected to adopt DevOps by 2019. A survey conducted by Indeed.comshows that the average annual salary of a DevOps engineer in the U.S. is approximately $123,439. If you’ve started cross-training to prepare for development and operations roles in the IT industry, you know it’s a challenging field that will take some real preparation to break into. Here are some of the most common DevOps interview questions and answers that can help you while you prepare for DevOps roles in the industry. Want to become certified DevOps Practitioner? Q1. What do you know about DevOps? A1. Your answer must be simple and straightforward. Begin by explaining the growing importance of DevOps in the IT industry. Discuss how such an approach aims to synergize the efforts of the development and operations teams to accelerate the delivery of software products, with a minimal failure rate. Include how DevOps is a value-added practice, where development and operations engineers join hands throughout the product or service lifecycle, right from the design stage to the point of deployment. Q2. Why has DevOps gained prominence over the last few years? A2. Before talking about the growing popularity of DevOps, discuss the current industry scenario. Begin with some examples of how big players such as Netflix and Facebook are investing in DevOps to automate and accelerate application deployment and how this has helped them grow their business. Using Facebook as an example, you would point to Facebook’s continuous deployment and code ownership models and how these have helped it scale up but ensure quality of experience at the same time. Hundreds of lines of code are implemented without affecting the quality, stability, and security. Your next use case should be Netflix. This streaming and on-demand video company, follows similar practices with fully automated processes and systems. Mention the user base of these two organizations: Facebook has 2 billion users while Netflix streams online content to more than 100 millions users worldwide. These are great examples of how DevOps can help organizations to ensure higher success rates for releases, reduce lead time between bug fixes, streamline and continuous delivery through automation, and an overall reduction in manpower costs. Q3. Which are some of the most popular DevOps tools? Do you have experience working with any of these tools? A3. The more popular DevOps tools include: ​ a. Selenium ​ b. Puppet ​ c. Chef ​ d. Git ​ e. Jenkins ​ f. Ansible ​ g. Docker Want to master all these DevOps tools? Thoroughly describe any tools that you are confident about, what it’s abilities are and why you prefer using it. For example, if you have expertise in Git, you would tell the interviewer that Git is a distributed Version Control System (VCS) tool that allows the user to track file changes and revert to specific changes when required. Discuss how Git’s distributed architecture gives it an added edge where developers make changes locally, and can have the entire project history on their local Git repositories, which can be later shared with other team members. Now that you have mentioned VCS, be ready for the next obvious question. Q4. What is version control and why should VCS be used? A4. Define version control and talk about how this system records any changes made to one or more files and saves them in a centralized repository. VCS tools will help you recall previous versions and perform the following: Go through the changes made over a period of time and check what works versus what doesn’t. Revert specific files or specific projects back to an older version. Examine issues or errors that have occurred due to a particular change. Using VCS gives developers the flexibility to simultaneously work on a particular file and all modifications can be logically combined later. Q5. Is there a difference between Agile and DevOps? If yes, please explain. A5. As a DevOps engineer, interview questions like this are quite expected. Start by describing the obvious overlap between DevOps and Agile. Although implementation of DevOps is always in sync with Agile methodologies, there is a clear difference between the two. The principles of Agile are associated to seamless production or development of a piece of software. On the other hand, DevOps deals with development, followed by deployment of the software, ensuring faster turnaround time, minimum errors, and reliability. If you are preparing for senior DevOps roles, prepare for these specific Chef DevOps interview questions. Q6. Why are configuration management processes and tools important? A6. Talk about multiple software builds, releases, revisions, and versions for each software or testware that is being developed. Move on to explain the need for storing and maintaining data, keeping track of development builds and simplified troubleshooting. Don’t forget to mention the key CM tools that can be used to achieve these objectives. Talk about how tools like Puppet, Ansible, and Chef help in automating software deployment and configuration on several servers. Q7. How is Chef used as a CM tool? A7. Chef is considered to be one of the preferred industry-wide CM tools. Facebook migrated its infrastructure and backend IT to the Chef platform, for example. Explain how Chef helps you to avoid delays by automating processes. The scripts are written in Ruby. It can integrate with cloud-based platforms and configure new systems. It provides many libraries for infrastructure development that can later be deployed within a software. Thanks to its centralized management system, one Chef server is enough to be used as the center for deploying various policies. Q8. How would you explain the concept of “infrastructure as code” (IaC)? A8. It is a good idea to talk about IaC as a concept, which is sometimes referred to as a programmable infrastructure, where infrastructure is perceived in the same way as any other code. Describe how the traditional approach to managing infrastructure is taking a back seat and how manual configurations, obsolete tools, and custom scripts are becoming less reliable. Next, accentuate the benefits of IaC and how changes to IT infrastructure can be implemented in a faster, safer and easier manner using IaC. Include the other benefits of IaC like applying regular unit testing and integration testing to infrastructure configurations, and maintaining up-to-date infrastructure documentation. If you have completed a certification on Amazon Web Services (AWS), and are interviewing for niche roles such as AWS-certified DevOps engineer, here are some AWS DevOps interview questions that you must be prepared for: Q9. What is the role of AWS in DevOps? A9. When asked this question in an interview, get straight to the point by explaining that AWS is a cloud-based service provided by Amazon that ensures scalability through unlimited computing power and storage. AWS empowers IT enterprises to develop and deliver sophisticated products and deploy applications on the cloud. Some of its key services include Amazon CloudFront, Amazon SimpleDB, Amazon Relational Database Service, and Amazon Elastic Computer Cloud. Discuss the various cloud platforms and emphasize any big data projects that you have handled in the past using cloud infrastructure. Q10. How is IaC implemented using AWS? A10. Start by talking about the age-old mechanisms of writing commands onto script files and testing them in a separate environment before deployment and how this approach is being replaced by IaC. Similar to the codes written for other services, with the help of AWS, IaC allows developers to write, test, and maintain infrastructure entities in a descriptive manner, using formats such as JSON or YAML. This enables easier development and faster deployment of infrastructure changes. As a DevOps engineer, an in-depth knowledge of processes, tools, and relevant technology are essential. You must also have a holistic understanding of the products, services, and systems in place. If your answers matched the answers we’ve provided above, you’re in great shape for future DevOps interviews. Good luck! If you’re looking for answers to specific DevOps interview questions that aren’t addressed here, ask them in the comments below. Our DevOps experts will help you craft the perfect answer.","categories":[],"tags":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/tags/求职/"}],"keywords":[]},{"title":"比尔盖茨夫妇发布2019年度公开信 分享9大意外","slug":"比尔盖茨夫妇发布2019年度公开信-分享9大意外","date":"2019-02-13T12:47:09.000Z","updated":"2019-02-13T12:49:13.236Z","comments":true,"path":"uncategorized/比尔盖茨夫妇发布2019年度公开信-分享9大意外/","link":"","permalink":"http://blog.ozairs.com/uncategorized/比尔盖茨夫妇发布2019年度公开信-分享9大意外/","excerpt":"","text":"比尔盖茨的微博账号上发布了和《比尔和梅琳达·盖茨：我们的2019年度公开信》内容，他们在信中分享了9件让他们意外的事情，希望能借此鼓舞大众。 [TechWeb]盖茨夫妇首先回顾到，“二十五年前，我们读到的一篇文章中提到，贫困国家每年有数十万儿童死于腹泻。这个出乎我们意料的数字，促使我们确立了盖茨基金会的理念。” 他们表示，“在今年的公开信里，我们希望和大家分享一路走来的另外九大意外。有些让人忧虑，有些给人启迪，但无一不激励我们采取行动。我们希望大家也能获得同样的鼓舞，并付诸行动。只有这样，世界才能变得更好。” 1。 非洲是最年轻的大陆 全球老龄化趋势仍在持续，但非洲的年龄（几乎）没变。非洲人口的年龄中位数只有18岁，北美则是35岁。未来几十年，非洲的年轻人数量将一直保持上升。 盖茨夫妇认为，恰当的投资无疑将释放非洲的巨大潜力。非洲年轻人决定了整个大陆，乃至全世界的未来。 2。家庭基因检测既能帮助发现“连环手”，又能预防早产 3。今后四十年，全世界每个月都将新建一个纽约市 随着城市人口在未来几十年的持续增长，全球建筑体量到2060年预计将会翻倍，相当于从现在开始每月新建一个纽约市。这需要大量钢铁水泥。我们需要想办法在不加剧气候变化的前提下实现这一切。 4。 数据也存在性别歧视 比尔盖茨谈到，“我每天花大量时间研究健康和发展方面的数据。关于妇女和女童的数据如此之少，让我始料未及。我想主要原因在于，我们人为地将某些问题划分为“女性问题”和其它问题，而女性问题通常得不到深入研究。这将妨碍人类整体的进步。” 文章还谈到，“数据会催生更好的决策和政策，帮助我们制定目标、评估进展，也让倡导和问责成为可能。” 5。 跟青少年学习愤怒管理 越来越多的研究表明，如果能对年轻人进行干预，辅导他们控制冲动，也许能帮他们更安全地应对这些情况（言语不合，暴力相向，后果是非死即伤），从而留在学校，远离麻烦。这就是Becoming a Man（成为一个男人，缩写BAM）这样的项目所做的事。 6。全球的也是民族的 本国利益至上并不意味着对其他国家置之不理。事实证明，我们恰恰应该反其道而行之。 7。厕所还是一百年前的老样子 全球迄今还有20多亿人用不上卫生的厕所。他们的粪便未经处理就进入环境，每天导致近800名儿童死亡。引进发达国家的卫生设施行不通，因为配套的下水道系统建设成本过高，而且需要大量的水资源。 8。 课本正在变得过时 9。 在贫困女性手中，手机的作用能发挥到最大 盖茨夫妇还表示，对未来依旧乐观，“其中一个原因是我们深信创新的力量。但更重要的是，我们亲眼看到，对于我们在年信中谈及的每一个挑战，都有很多人在奉献着自己的智慧、资源甚至生命。” 盖茨夫妇最后表示，“我们把今年的年度公开信献给我们亲爱的朋友、微软（106.89， 1.64， 1.56%）联合创始人、去年十月罹患癌症去世的保罗-艾伦……每当Jimi Hendrix的音乐响起，我们都会想起他。”","categories":[],"tags":[{"name":"Bill Gates","slug":"Bill-Gates","permalink":"http://blog.ozairs.com/tags/Bill-Gates/"}],"keywords":[]},{"title":"关于Raid0,Raid1,Raid5,Raid10的总结","slug":"关于Raid0-Raid1-Raid5-Raid10的总结","date":"2019-02-13T11:46:34.000Z","updated":"2019-02-13T11:50:42.714Z","comments":true,"path":"Jobs/关于Raid0-Raid1-Raid5-Raid10的总结/","link":"","permalink":"http://blog.ozairs.com/Jobs/关于Raid0-Raid1-Raid5-Raid10的总结/","excerpt":"","text":"RAID0 定义： RAID 0又称为Stripe或Striping，它代表了所有RAID级别中最高的存储性能。RAID 0提高存储性能的原理是把连续的数据分散到多个磁盘上存取，这样，系统有数据请求就可以被多个磁盘并行的执行，每个磁盘执行属于它自己的那部分数据请求。这种数据上的并行操作可以充分利用总线的带宽，显著提高磁盘整体存取性能。 工作原理： 系统向三个磁盘组成的逻辑硬盘（RAID0 磁盘组）发出的I/O数据请求被转化为3项操作，其中的每一项操作都对应于一块物理硬盘。通过建立RAID 0，原先顺序的数据请求被分散到所有的三块硬盘中同时执行。从理论上讲，三块硬盘的并行操作使同一时间内磁盘读写速度提升了3倍。 但由于总线带宽等多种因素的影响，实际的提升速率肯定会低于理论值，但是，大量数据并行传输与串行传输比较，提速效果显著显然毋庸置疑。 优缺点： 读写性能是所有RAID级别中最高的。 RAID 0的缺点是不提供数据冗余，因此一旦用户数据损坏，损坏的数据将无法得到恢复。RAID0运行时只要其中任一块硬盘出现问题就会导致整个数据的故障。一般不建议企业用户单独使用。 总结： 磁盘空间使用率：100%，故成本最低。 读性能：N*单块磁盘的读性能 写性能：N*单块磁盘的写性能 冗余：无，任何一块磁盘损坏都将导致数据不可用。 RAID1 定义： RAID 1通过磁盘数据镜像实现数据冗余，在成对的独立磁盘上产生互为备份的数据。当原始数据繁忙时，可直接从镜像拷贝中读取数据，因此RAID 1可以提高读取性能。RAID 1是磁盘阵列中单位成本最高的，但提供了很高的数据安全性和可用性。当一个磁盘失效时，系统可以自动切换到镜像磁盘上读写，而不需要重组失效的数据。 工作原理： RAID1是将一个两块硬盘所构成RAID磁盘阵列，其容量仅等于一块硬盘的容量，因为另一块只是当作数据“镜像”。RAID1磁盘阵列显然是最可靠的一种阵列，因为它总是保持一份完整的数据备份。它的性能自然没有RAID0磁盘阵列那样好，但其数据读取确实较单一硬盘来的快，因为数据会从两块硬盘中较快的一块中读出。RAID1磁盘阵列的写入速度通常较慢，因为数据得分别写入两块硬盘中并做比较。RAID1磁盘阵列一般支持“热交换”，就是说阵列中硬盘的移除或替换可以在系统运行时进行，无须中断退出系统。RAID1磁盘阵列是十分安全的，不过也是较贵一种RAID磁盘阵列解决方案，因为两块硬盘仅能提供一块硬盘的容量。RAID1磁盘阵列主要用在数据安全性很高，而且要求能够快速恢复被破坏的数据的场合。 在这里，需要注意的是，读只能在一块磁盘上进行，并不会进行并行读取，性能取决于硬盘中较快的一块。写的话通常比单块磁盘要慢，虽然是并行写，即对两块磁盘的写入是同时进行的，但因为要比较两块硬盘中的数据，所以性能比单块磁盘慢。 优缺点： RAID1通过硬盘数据镜像实现数据的冗余，保护数据安全，在两块盘上产生互为备份的数据，当原始数据繁忙时，可直接从镜像备份中读取数据，因此RAID1可以提供读取性能。RAID1是硬盘中单位成本最高的，但提供了很高的数据安全性和可用性，当一个硬盘失效时，系统可以自动切换到镜像硬盘上读/写，并且不需要重组失效的数据。 总结： 磁盘空间使用率：50%，故成本最高。 读性能：只能在一个磁盘上读取，取决于磁盘中较快的那块盘 写性能：两块磁盘都要写入，虽然是并行写入，但因为要比对，故性能单块磁盘慢。 冗余：只要系统中任何一对镜像盘中有一块磁盘可以使用，甚至可以在一半数量的硬盘出现问题时系统都可以正常运行。 RAID 5 定义： RAID 5是RAID 0和RAID 1的折中方案。RAID 5具有和RAID0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID5的磁盘空间利用率要比RAID 1高，存储成本相对较低，是目前运用较多的一种解决方案。 工作原理： RAID5把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上，其中任意N-1块磁盘上都存储完整的数据，也就是说有相当于一块磁盘容量的空间用于存储奇偶校验信息。因此当RAID5的一个磁盘发生损坏后，不会影响数据的完整性，从而保证了数据安全。当损坏的磁盘被替换后，RAID还会自动利用剩下奇偶校验信息去重建此磁盘上的数据，来保持RAID5的高可靠性。 做raid 5阵列所有磁盘容量必须一样大，当容量不同时，会以最小的容量为准。 最好硬盘转速一样，否则会影响性能，而且可用空间=磁盘数n-1，Raid 5 没有独立的奇偶校验盘，所有校验信息分散放在所有磁盘上， 只占用一个磁盘的容量。 总结： 磁盘空间利用率：(N-1)/N，即只浪费一块磁盘用于奇偶校验。 读性能：(n-1)*单块磁盘的读性能，接近RAID0的读性能。 写性能：比单块磁盘的写性能要差（这点不是很明白，不是可以并行写入么？） 冗余：只允许一块磁盘损坏。 RAID10 定义： RAID10也被称为镜象阵列条带。象RAID0一样，数据跨磁盘抽取；象RAID1一样，每个磁盘都有一个镜象磁盘, 所以RAID 10的另一种会说法是 RAID 0+1。RAID10提供100%的数据冗余，支持更大的卷尺寸，但价格也相对较高。对大多数只要求具有冗余度而不必考虑价格的应用来说，RAID10提供最好的性能。使用RAID10，可以获得更好的可靠性，因为即使两个物理驱动器发生故障（每个阵列中一个），数据仍然可以得到保护。RAID10需要4 + 2*N 个磁盘驱动器（N &gt;=0)， 而且只能使用其中一半(或更小, 如果磁盘大小不一)的磁盘用量, 例如 4 个 250G 的硬盘使用RAID10 阵列， 实际容量是 500G。 实现原理： Raid10其实结构非常简单，首先创建2个独立的Raid1，然后将这两个独立的Raid1组成一个Raid0，当往这个逻辑Raid中写数据时，数据被有序的写入两个Raid1中。磁盘1和磁盘2组成一个Raid1，磁盘3和磁盘4又组成另外一个Raid1;这两个Raid1组成了一个新的Raid0。如写在硬盘1上的数据1、3、5、7，写在硬盘2中则为数据1、3、5、7，硬盘中的数据为0、2、4、6，硬盘4中的数据则为0、2、4、6，因此数据在这四个硬盘上组合成Raid10，且具有raid0和raid1两者的特性。虽然Raid10方案造成了50%的磁盘浪费，但是它提供了200%的速度和单磁盘损坏的数据安全性，并且当同时损坏的磁盘不在同一Raid1中，就能保证数据安全性。假如磁盘中的某一块盘坏了，整个逻辑磁盘仍能正常工作的。当我们需要恢复RAID10中损坏的磁盘时，只需要更换新的硬盘，按照RAID10的工作原理来进行数据恢复，恢复数据过程中系统仍能正常工作。原先的数据会同步恢复到更换的硬盘中。 总结： 磁盘空间利用率：50%。 读性能：N/2*单块硬盘的读性能 写性能：N/2*单块硬盘的写性能 冗余：只要一对镜像盘中有一块磁盘可以使用就没问题。","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Raid Storage","slug":"Raid-Storage","permalink":"http://blog.ozairs.com/tags/Raid-Storage/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"An In-Depth Guide to the Differences Between SAN and NAS","slug":"An-In-Depth-Guide-to-the-Differences-Between-SAN-and-NAS","date":"2019-02-13T11:29:13.000Z","updated":"2019-02-13T11:53:19.228Z","comments":true,"path":"Jobs/An-In-Depth-Guide-to-the-Differences-Between-SAN-and-NAS/","link":"","permalink":"http://blog.ozairs.com/Jobs/An-In-Depth-Guide-to-the-Differences-Between-SAN-and-NAS/","excerpt":"","text":"Storage area networks (SANs) and network attached storage (NAS) both provide networked storage solutions. A NAS is a single storage device that operates on data files, while a SAN is a local network of multiple devices. A NAS unit includes a dedicated hardware device that connects to a local area network, usually through an Ethernet connection. This NAS server authenticates clients and manages file operations in much the same manner as traditional file servers, through well-established network protocols. To reduce the costs that occur with traditional file servers, NAS devices generally run an embedded operating system on simplified hardware and lack peripherals like a monitoror keyboard and are instead managed through a browser tool. A SAN commonly utilizes Fibre Channel interconnects and connects a set of storage devices that are able to share data with one another. Important NAS and SAN BenefitsThe administrator of a home or small business network can connect one NAS device to a local area network. The device itself is a network node, much like computers and other TCP/IP devices, all of which maintain their own IP address and can effectively communicate with other networked devices. Given that the network attached storage device is attached to the network, all the other devices on that same network have easy access to it (given that proper permissions are set up). Because of their centralized nature, NAS devices offer an easy way for multiple users to access the same data, which is important in situations where users are collaborating on projects or utilizing the same company standards. Using a software program provided with the NAS hardware, a network administrator can set up automatic or manual backups and file copies between the NAS and all the other connected devices. Therefore, a NAS device is also useful for the opposite reason: to offload local data to the network storage device’s much larger storage container. This is useful not only to ensure that users do not lose data, since the NAS can be backed up on a regular schedule regardless of the end-user’s ability to back up, but also to give other network devices a place to keep large files, especially large files that are often shared among other network users. Without a NAS, users have to find another (often slower) means to send data to other devices on the network, like over email or physically with flash drives. The NAS holds many gigabytes or terabytes of data, and administrators can add additional storage capacity to their network by installing additional NAS devices, although each NAS operates independently. Administrators of large enterprise networks may require many terabytes of centralized file storage or extremely high-speed file transfer operations. While installing an army of many NAS devices is not a practical option, administrators can instead install a SAN containing a high-performance disk array to provide the needed scalability and performance. However, SANs are not always physical. You can also create virtual SANs (VSANs) that are defined by a software program. Virtual SANs are easier to manage and offer better scalability since they’re hardware independent and controlled entirely by easy-to-change software. SAN/NAS ConvergenceAs internet technologies like TCP/IP and Ethernet proliferate worldwide, some SAN products are making the transition from Fibre Channel to the same IP-based approach NAS uses. Also, with the rapid improvements in disk storage technology, today’s NAS devices now offer capacities and performance that once were only possible with SAN. These two industry factors have led to a partial convergence of NAS and SAN approaches to network storage, effectively creating high-speed, high-capacity, centrally located network devices. When SAN and NAS are joined together into one device in this way, it’s sometimes referred to as “unified SAN,” and it’s often the case that the device is a NAS device that simply utilizes the same technology behind SAN.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://blog.ozairs.com/tags/Storage/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"AWS面试经验分享","slug":"AWS面试经验分享","date":"2019-02-12T10:40:02.000Z","updated":"2019-02-12T10:48:04.314Z","comments":true,"path":"求职/AWS面试经验分享/","link":"","permalink":"http://blog.ozairs.com/求职/AWS面试经验分享/","excerpt":"","text":"AWS的全名是Amazon Web Services，也就是亚马逊旗下的子公司，专门做云计算，业务遍及全球近200个国家，也是云计算行业的领头羊（有兴趣可以看看这个链接）。依照AWS Senior VP Andy Jassy的话来讲是：“We are building the fastest growing technology business on earth.”我于2014年6月拿到此公司offer，在香港和台湾从事对客户或潜伏客户的培训工作，隶属于亚太区的培训与认证部门（APAC Training &amp; Certification）。这篇文章回顾了我面试及头半年的工作，和一些个人的感想。基于公司政策要求，其中不触及面试具体细节、工作具体内容（包括人名），产品介绍及评论。 “云计算”是个有趣的名词，由于现在这个环境下，普通大众想听不到它都难，但多数却完全不知道究竟是甚么。其实狭义且不严格地理解云计算，就是把计算资源像我们生活中水、电、气这类基础设施1样，按需供应计费，提供相对统1的标准或接口给其他厂商（生态圈）或终究客户使用。如果不明白计算资源怎样能像水电1样供应，可以联想1下平时使用的电脑，你在意的其实不是它的CPU内存硬盘网络等计算资源（简单统称方便理解），你在意的是输入的内容能得到你所需要的输出，不论这个输出是字符、图片、视频、音频、游戏画面、其他交互内容等等。那末“云计算”这里说的其实就是将你不在意的那些东西（CPU内存硬盘网络）和你在意的输入输出（比如键盘鼠标、显示器）分离，用户只具有基本的输入输出和网络连接服务，其他的全部放到远端。用户需要就启动使用并付费，不需要就像水电1样关掉。这是其中1个重点：资源分离。分离才方便做其他事情，具体好处这里就不说了。另外还需提及的是，对平时使用的电脑，不论你用还是不用，只要你买回来那末你已为其计算资源付费终了了，这样是否是很划算呢？你1年用1天和用360天，为计算资源付一样的费用，这其实其实不公道。个人使用还行，但企业就很不划算了，这就是按需分配计算资源的必要性，为了公道的利用及分配资源。 这篇文章不是教学文章，所以只是帮助不懂的朋友粗浅了解1下甚么是“云计算”。其实云计算还分好几类，上面提到的只是说基础设施层面的服务。其他层面的举个例子：想一想你手机上的App，它们也是云计算的1部份。由于他们也是你根据你的需求下载得手机上为你提供服务。所以云计算可以认为是Web Service，即通过网络为客户提供服务，这些服务源自于硬件与软件的组合或结合。我的工作就是介绍亚马逊的云计算服务给客户，让他们理解并学会使用亚马逊的云计算产品。我只负责香港和台湾，大陆培训业务与我无关，所以香港台湾的朋友如果要参加AWS的培训，多半会看到我（Michael Chen）。目前我所负责的区域就我1个人在做培训，也是香港台湾地区的第1个培训师。目前培训过的客户大小公司（世界500强到初创企业）都有，具体就不说了。 面试经历 面试 是1个有趣（折腾且漫长）的进程。由于我并没有主动申请这个职位，也不知道有这个职位在招聘，也没有猎头来找我（Amazon不通过猎头觅人）。当时（2013年）我还在联科团体工作，对AWS的职位只是偷偷想过，但种种缘由未有任何行动。直到： 2013年5月28日，AWS的Z在LinkedIn上和我联系，问我是不是有兴趣做“Ecosystem Solutions Architect”（以后简称SA）。我其实不认识Z，但看到这个消息确切很惊讶，1是没想到会有AWS的人通过LinkedIn和我联系，2是觉得自己的资格还不够，有这个机会却极可能抓不住。我坦诚告知Z说，我看了职位介绍，觉得自己不合适，但还是很愿意与他交换，问他是不是还希望继续。Z答应了，我却很忐忑。 2013年6月24日，与Z终究见面，才发现他只说英语（我进AWS后发现他也能说广东话，不过基本不说）。他觉得我还行，然后需要再与其他同事评估，给了简历。我当时我觉得不合适SA，但培训比较合适，但从他和公司的角度，最需要的还是SA，我接受了他的建议。 2013年7月15日，如我所料，内部评估结果觉得我不适合做SA。Z说可以推荐我去做培训这个职位。 2013年8月6日，向Z推荐L做SA，不过Z觉得不适合，问A（AWS亚太区培训认证主管）是不是和我联系，我回复还未联系。这位L后来进了Facebook，题外话就不多说了。 2013年8月22日，与Z分享Gartner IaaS魔力象限报告。Gartner是全球知名的IT咨询机构，它的这个报告系列在IT界有很好的公信力。报告说AWS全球领先，计算资源超过其他14位竞争对手总和的5倍。英文原文是：It is the overwhelming market share leader, with more than five times the cloud IaaS compute capacity in use than the aggregate total of the other 14 providers in this Magic Quadrant.（全文链接：Magic Quadrant for Cloud Infrastructure as a Service） 2013年10月2日，发邮件给Z国庆祝愿。 2013年11月18日，我在联科团体获升职，与Z分享。Z恭喜后又问我是不是还有兴趣加入AWS，他会再次帮我争取拿到培训的面试机会。大约过了34天，HR给我电话，顺利过关。 2013年12月6日，经过若干次与A约面试时间，终究与其电话面试，英语吞吞吐吐地过关，还需要看看粤语及技术方面。 2013年12月17日，技术兼粤语面试，粤语没问题，但好几个技术问题不会，以为应聘就此结束。回到家，内心非常难受。还是写了邮件与Z报告了情况。过了1段时间，得到继续面试的消息，我没想到居然还有机会。其间下班后在家狂看Glassdoor，学习AWS。 2014年1月30日，经过若干次来回讨论面试时间，从1月中旬最后定到了1月30日（除夕）。非常辛苦的1对1面试，1共5个小时不中断，有香港台湾的主管、亚太区培训认证主管、高级培训师、销售等好几个人车轮战，软技能和硬技能（AWS相干技术）、培训表达（英文与粤语）等都有触及，问得非常得仔细。面试犯了1些小错，整体顺利。 2014年2月3日，Bar Raiser（简单理解就是提高面试门坎的人）面试。其中有几个NoSQL的技术问题，都没有回答得很好。其他问题应当回答正确。当时感觉非常挫败，觉得最后1轮失败，很是惋惜。 2014年2月11日，讨论后结果是positive！我被录取了。 2014年2月14日，情人节签约。 2014年6月11日，经过非常麻烦的签证办理手续，终究开始上班。 从2013年5月28日到2014年6月11日，全部进程几近是1整年。从上面的描写中你或许能感遭到我当时经历如此漫长的煎熬与纠结吧，他人都在开心过年的时候，我在纠结 面试 及结果，好在终究成功了。另外，这全部进程中还有1些其他的事情： 2014年5月5日至2014年6月9日，陪老婆生孩子坐月子等各种生育相干事情。 2014年3月23日，推荐M应聘Business Development职位，2014年4月17日，M顺利闯关成功。 工作经历 工作经历用1句话就说完了：6月入职飞新加坡，7月飞曼谷，8月飞台北和西雅图，9月飞悉尼，10月再次飞台北，11月飞拉斯维加斯为AWS re:Invent大会帮忙，12月回武汉办理大陆户口注销事宜，这也是为了以后能更方便地去台湾商务旅行。看着飞很多，其实多半时间都在香港，出差1般是1周左右。具体内容就不说了，有几点值得提1下： 第1次培训是在台北，也是试讲，要被评估，若不合格还要重新再试讲评估。第1次用全英语讲课长达4天，这4天说的英语比我310多年说的都多，而且这几天平均每天睡4个钟头。好在最后1切顺利。但努力空间很大，需要认真学习和练习。在我提交完培训报告后，同事和老板都回邮件，说实话，挺给我信心的：“Great start Michael, the first one I am sure will always be the hardest to get through. But you are learning from the master in D too. Well done and good report.”“AWESOME report full of a lot of great information about our customers, their needs and provides AWS with the information required to help them further from a product/services and adoption perspective all the way back to training.” 以后在香港用英文培训，台北用普通话培训。每次培训完后，客户都要评分，每次写报告看分数都心跳加速，真是压力山东大学。今年我的整体分数在4.44（满分5分）。这个分数不算高，但就我个人而言，我觉得是客观的分数。 记得2014年3月听D在香港用英语对着4百来人做公然演讲培训时，1位AWS同事过来拍拍我肩膀，半开玩笑地说，明年此时就是你来演讲了哦！我想这么快啊！我能行吗？很难想象1年后我就可以面对几百人用英语演讲，我非常怀疑我有这个实力并且能做得如D那样好。结果入职不到半年，10月就在台北演讲，11月就在香港演讲，最后评价都还不错（台北4.5+，香港4.1+，这里不做与同事的横向比较）。回头来想一想，有些时候，你不能不需要1些压力来逼迫你提高，以做到自己都不敢想象的事情。 我1直觉得很难的AWS Solution Architect认证，居然也顺利通过。对那些在企业工作很多年的人来讲，这个认证其实其实不难。但我在企业才工作3年半，之前10年的工作都在两个大学里教书做科研，这其中的难度和跨度，对我是很大的（这里只是对我个人而言，不适用于其他人）。 百姓网的CEO王建硕曾在其博客里说过他“所看到的伟大的公司，或成功的生意人，发现他们有1种惊人的类似的地方，总结出来就是：对贡献有豪情，对回报有信心。”贡献的是为了兴趣，而不是为了回报。如果做事1定是为了某种回报，那末这件事情会很难坚持久长。这个观点丁香园的冯大辉也转载在其微信公众号的文章中：“只有对贡献有豪情，不在意回报的时候，你才能坚持做1件事情，就像伟大的公司有1个贡献的理念，才可以持久地保持豪情，在获得巨大的成功以后，接着日复1日地寻觅更大的贡献。”这类理念与豪情是对回报有信心的来源。 我算不上成功，算不上勤奋，乃至算不上坚持。真正了解我的人知道这是实话，比如我老婆肯定知道上面这句话不是谦虚:) 你看这个博客的更新频率都愈来愈低，说忙是理由也是借口。在信息碎片化的今天，能坚持写博客的人貌似不多，还能坚持定阅浏览博客的人也不多，我周围几个90后同事乃至已很少用Facebook而用Instagram。我说了上面这么多乱78糟的话，是为了让自己重新再检讨1下，继续坚持下去。我已草拟了2015年每天需要完成的事情，包括这个博客和健身。固然整体安排还是以工作为主，不会把写博客放到重要的事情列表上，但保持每周1篇的更新频率是应当的，除非出差或其他不可抗因素没法更新。我欠下的游记都差不多足数了，呵呵。 写博客纯属不写不舒服斯基。想一想博客能带给我甚么回报呢？金钱的回报基本没有，倒是帮很多人拿到了1些学校和公司的offer，解决了1些人在旅游和其他方面的问题。真实的咨询公司我没进去，倒做起了虚拟咨询，有趣。","categories":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/categories/求职/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/categories/求职/"}]},{"title":"详解澳洲房屋物业费计算方式","slug":"How-to-calculate-the-property-rate-in-Australia","date":"2019-02-07T06:23:32.000Z","updated":"2019-02-07T09:34:08.331Z","comments":true,"path":"uncategorized/How-to-calculate-the-property-rate-in-Australia/","link":"","permalink":"http://blog.ozairs.com/uncategorized/How-to-calculate-the-property-rate-in-Australia/","excerpt":"","text":"每年，墨尔本市政府会计算您房屋的费率，以资助当地社区的建设，维护和服务。 关于房屋的费率的计算方式如下： 将房屋的财产价值乘以市政府为社区项目和服务提供资金所需的“美元汇率” 增加收到的任何废物服务的成本 加征防火税 减去您有资格获得的任何优惠 房屋物业费计算举例 确定您房屋的资本改善价值（CIV）为400,000美元。 确定’美元汇率’为0.00244201。 将400,000乘以0.00244201，基本利率为976.80美元。 增加您收到的任何废物服务和消防税的成本。 减去您有资格获得的任何让步。 如何进行房屋评估市政府每年都会按照维多利亚州政府法律，对当地的房产进行评估。实际操作过程中，会使用合格的估价师根据以下因素评估您的房产： 最近在该地区的销售 它的位置 土地的质量和位置 建筑物的大小，年龄和状况 如果您对不同意房屋估价如果您不同意您的房产估价，可以和当地市政府联系： 市政府评估团队成员可以： 更详细地解释我们如何评估您的财产 听取并理解您的反对意见 建议您可以采取哪些进一步措施 如何计算美元汇率通过以下方式计算出美元汇率： 计算提供所有计划和服务所需的费率收入总额 将此金额除以当地房产总价值 这个数字是通过市政府每年的预算流程和每年的变化来确定的。","categories":[],"tags":[{"name":"Property","slug":"Property","permalink":"http://blog.ozairs.com/tags/Property/"}],"keywords":[]},{"title":"Git从入门到熟练使用","slug":"Git从入门到熟练使用","date":"2019-02-06T06:41:25.000Z","updated":"2019-02-06T09:50:08.384Z","comments":true,"path":"Web开发/Git从入门到熟练使用/","link":"","permalink":"http://blog.ozairs.com/Web开发/Git从入门到熟练使用/","excerpt":"","text":"Git 基础基本原理 客户端并不是只提取最新版本的文件快照，而是把代码仓库完整的镜像下来。这样一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。每一次的克隆操作，实际上都是一次对代码仓库的完整备份。 Git的优势直接记录快照 Git 更像是把数据看作是对小型文件系统的一组快照。 每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。 为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 快照流。 如图，在version2中的 B 即是因为 File B 没有改变，所以直接存储了一个指向 FileB 的链接。只有修改了的文件才会产生一个新的文件，覆盖原来的文件。 几乎所有操作都在本地执行 在 Git 中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。因为你在本地磁盘上就有项目的完整历史，所以大部分操作看起来瞬间完成。 Git保证完整性 Git 中所有数据在存储前都计算校验和，然后以校验和来引用。Git 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。Git 数据库中保存的信息都是以文件内容的哈希值来确定的，而不是文件名。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。 Git一般只添加数据 你执行的 Git 操作，几乎只往 Git 数据库中增加数据。 很难让 Git 执行任何不可逆操作，或者让它以任何方式清除数据。 同别的 VCS 一样，未提交更新时有可能丢失或弄乱修改的内容；但是一旦你提交快照到 Git 中，就难以再丢失数据，特别是如果你定期的推送数据库到其它仓库的话。这个特性使得我们可以尽情的尝试对Git进行操作而不用害怕把它改坏了，只需要回滚即可。 需要注意的重点三种状态 已提交 committed ：数据已经保存在本地 Git 仓库 已修改 modified ： 修改了文件，但是还没保存在仓库中 已暂存 staged ： 对一个已修改的文件的当前版本做了标记 工作目录，暂存区域及Git仓库.png 三个区域 工作目录 Working Directory ：对项目的某个版本独立提取出来的内容，这些从Git仓库的压缩数据库提取出来的文件，放在磁盘上供你使用或修改。 暂存区域 Staging Area ：是一个文件，保存了下次将提交的文件列表，是待提交文件的暂存区域。一般在Git仓库的目录中，有时也被称为索引。 Git仓库：用来保存项目的元数据和对象数据库的地方。是Git中最重要的部分，从其他计算机克隆仓库时拷贝的就是这里的数据 基本的Git工作流程 在工作目录中修改文件 暂存文件，将文件的快照存储在暂存区域 提交更新，找到暂存区域的位置，将快照永久性存储到Git仓库目录 提交状态：如果Git目录中保存着特定版本的文件，就属于已提交状态。 暂存状态：如果做了修改并且已经放入暂存区域，就属于暂存状态。 已修改状态：如果自上次取出后，做了修改但是还没有存在暂存区域，就是已修改状态。 基本的Git操作流程基础设置 首先最基础的是需要配置用户信息 12$ git config --global user.name &quot;lanya&quot;$ git config --global user.email shenglanya@corp.netease.com 关于 config 的种类 1234567Config file location# global 表示配置全局信息，配置之后无论你在该系统上做任何事情，Git都会使用这些信息。 --global use global config file --system use system config file --local use repository config file -f, --file &lt;file&gt; use given config file --blob &lt;blob-id&gt; read config from given blob object 接着需要检查你的配置信息，使用 $ git config --list指令检查全部配置信息,结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051core.excludesfile=~/.gitignorecore.legacyheaders=falsecore.quotepath=falsemergetool.keepbackup=truepush.default=simplecolor.ui=autocolor.interactive=autorepack.usedeltabaseoffset=truealias.s=statusalias.a=!git add . &amp;&amp; git statusalias.au=!git add -u . &amp;&amp; git statusalias.aa=!git add . &amp;&amp; git add -u . &amp;&amp; git statusalias.c=commitalias.cm=commit -malias.ca=commit --amendalias.ac=!git add . &amp;&amp; git commitalias.acm=!git add . &amp;&amp; git commit -malias.l=log --graph --all --pretty=format:&apos;%C(yellow)%h%C(cyan)%d%Creset %s %C(white)- %an, %ar%Creset&apos;alias.ll=log --stat --abbrev-commitalias.lg=log --color --graph --pretty=format:&apos;%C(bold white)%h%Creset -%C(bold green)%d%Creset %s %C(bold green)(%cr)%Creset %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit --date=relativealias.llg=log --color --graph --pretty=format:&apos;%C(bold white)%H %d%Creset%n%s%n%+b%C(bold blue)%an &lt;%ae&gt;%Creset %C(bold green)%cr (%ci)&apos; --abbrev-commitalias.d=diffalias.master=checkout masteralias.spull=svn rebasealias.spush=svn dcommitalias.alias=!git config --list | grep &apos;alias\\.&apos; | sed &apos;s/alias\\.\\([^=]*\\)=\\(.*\\)/\\1\\ =&gt; \\2/&apos; | sortinclude.path=~/.gitcincludeinclude.path=.githubconfiginclude.path=.gitcredentialdiff.exif.textconv=exifcredential.helper=osxkeychaincore.excludesfile=/Users/shenglanya/.gitignore_globaldifftool.sourcetree.cmd=opendiff &quot;$LOCAL&quot; &quot;$REMOTE&quot;difftool.sourcetree.path=mergetool.sourcetree.cmd=/Applications/Sourcetree.app/Contents/Resources/opendiff-w.sh &quot;$LOCAL&quot; &quot;$REMOTE&quot; -ancestor &quot;$BASE&quot; -merge &quot;$MERGED&quot;mergetool.sourcetree.trustexitcode=trueuser.name=shenglanyauser.email=shenglanya@corp.netease.comcommit.template=/Users/shenglanya/.stCommitMsgcore.repositoryformatversion=0core.filemode=truecore.bare=falsecore.logallrefupdates=truecore.ignorecase=truecore.precomposeunicode=trueremote.origin.url=https://git.ms.netease.com/netease-precious-metals-client/ios-client.gitremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*branch.essential.remote=originbranch.essential.merge=refs/heads/essentialbranch.r_4.4.remote=originbranch.r_4.4.merge=refs/heads/r_4.4 使用 $ git config &lt;key&gt;来检查某一项配置信息 12$ git config user.nameshenglanya 查阅帮助手册方法 以下方法均可找到 Git 命令手册 123$ git help &lt;verb&gt;$ git &lt;verb&gt; --help$ man git-&lt;verb&gt; 获取Git仓库方法一：在现有目录中初始化仓库（创建一个新的自己的仓库） git init该命令将创建一个名为 .git的子目录，这个子目录含有你在初始化的Git仓库中所有的必须文件，这些文件是Git仓库的骨干。但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。 如果你是在一个已经存在文件的文件夹（而不是空文件夹）中初始化 Git 仓库来进行版本控制的话，你应该开始跟踪这些文件并提交。 你可通过 git add命令来实现对指定文件的跟踪，然后执行 git commit提交： 123$ git add *.c$ git add LICENSE$ git commit -m &apos;initial project version&apos; 具体操作流程 12345678910111213141516# 首先$ git initInitialized empty Git repository in /Users/shenglanya/Desktop/.git/#然后使用 ls -a 可查看隐藏文件，发现存在名为 .git 的子目录$ ls -a. .DS_Store .localized.. .git pic# 接着进入子目录,发现此目录中包含你初始化仓库中所有的必须文件，这些文件是 Git 仓库的骨干$ cd .git$ lsHEAD config hooks objectsbranches description info refs# 接着需要跟踪项目里的文件，需要注意的是，当创建一个新的项目里的文件时，它默认是未被跟踪的，所以此时我们需要手动的将它添加到版本控制中，也就是被跟踪 方法二：克隆现有仓库（clone别人的） 如果你想获得一份已经存在了的 Git 仓库的拷贝，比如说，你想为某个开源项目贡献自己的一份力，这时就要用到 git clone命令。Git 克隆的是该 Git 仓库服务器上的几乎所有数据，而不是仅仅复制完成你的工作所需要文件。 当你执行 git clone命令的时候，默认配置下远程 Git 仓库中的每一个文件的每一个版本都将被拉取下来。 1$ git clone https://github.com/libgit2/libgit2 Git 支持多种数据传输协议。 上面的例子使用的是 https://协议，不过你也可以使用 git://协议或者使用 SSH 传输协议，比如 user@server:path/to/repo.git。 记录每次更新到仓库 你工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。 检查当前文件状态 要查看哪些文件处于什么状态，可以用 git status命令。 如果在克隆仓库后立即使用此命令，会看到类似这样的输出： 123$ git statusOn branch masternothing to commit, working directory clean 这说明你现在的工作目录相当干净。表示所有已跟踪文件在上次提交后都未被更改过。 此外，上面的信息还表明，当前目录下没有出现任何处于未跟踪状态的新文件，否则 Git 会在这里列出来。 最后，该命令还显示了当前所在分支，并告诉你这个分支同远程服务器上对应的分支没有偏离。 现在，分支名是 “master”,这是默认的分支名。 如果你在当前已经有仓库管理的项目中添加了一个文件，名字叫做 README 。然后使用 git status命令，你会发现会出现： 123456789$ echo &apos;My Project&apos; &gt; README$ git statusOn branch masterUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) READMEnothing added to commit but untracked files present (use &quot;git add&quot; to track) 表示 README 还未被跟踪，表示 Git 之前的提交中没有这些文件。Git也不会自动跟踪它，这使得你不必担心将生成的二进制文件或者其他不想被包含的文件包含进来。若你想跟踪它，则需要明明白白的告诉它你想跟踪这个文件，使用 git add指令。 跟踪新文件 使用 git add可以跟踪新文件。所以可以使用 git add README, 然后再运行 git status会看到 12345678910111213141516171819202122232425262728293031$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/工作目录，暂存区域及Git仓库.pngUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) pic/实习学习笔记.md# 使用 git add 后$ git add pic/实习学习笔记.md$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/实习学习笔记.md new file: pic/工作目录，暂存区域及Git仓库.png 只要在 Changes to be committed这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。 你可能会想起之前我们使用 git init后就运行了 git add (files)命令，开始跟踪当前目录下的文件。 git add命令使用文件或目录的路径作为参数；如果参数是目录的路径，该命令将递归地跟踪该目录下的所有文件。 关于 git add指令还有别的作用： 用于追踪新文件 用于将已跟踪的文件放入暂存区 用于合并时把有冲突的文件标记为已解决 暂存已修改文件 修改已被跟踪的文件。比如说修改了一个名为 实习学习笔记.md 的文件，然后运行 git status 1234567891011121314151617181920212223242526272829303132333435$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/实习学习笔记.md new file: pic/工作目录，暂存区域及Git仓库.png# 说明已跟踪文件内容发生了变化，但是还未放入暂存区。如果想暂存这次更新，需要使用 git add 指令。 git add 指令是一个多功能命令：可以用它来跟踪新文件，或者把已经跟踪的文件放到暂存区中，还能用于合并时把有冲突的文件标记为已解决状态等。Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: pic/实习学习笔记.md # 使用 git add 指令将其添加到暂存区$ git add pic/实习学习笔记.md$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/实习学习笔记.md new file: pic/工作目录，暂存区域及Git仓库.png 需要注意的是，当已经使用了 git add指令暂存的版本又经过修改之后，需在再重新使用 git add指令将最新的修改放入暂存区，否则此时暂存区里只有上一次修改的内容。 提交文件到仓库 使用 git commit指令可以使得暂存在暂存区的文件被提交到仓库中去。 1234567$ git commit[master (root-commit) 2713657] 第一次的修改提交 4 files changed, 22 insertions(+) create mode 100644 pic/git存储项目虽时间改变的快照.png create mode 100644 pic/lifecycle.png create mode 100644 pic/实习学习笔记.md create mode 100644 pic/工作目录，暂存区域及Git仓库.png 基本的 Git 操作指令git status 命令概述 使用 git status时，实际上可以使用更为方便的指令来达到更为紧凑的格式输出。比如使用 git status -s 123456789101112131415161718$ git status -s# M 靠右的 M 表示修改过的文件并且还未被放入暂存区 M README # MM 靠左的 M 表示该文件被修改后放入了暂存区，靠右的表示修改过的文件并且还未被放入暂存区，所以 Rakefile 文件被修改过后放入了暂存区，但是之后又进行了修改，还未将最后一次修改放入暂存区MM Rakefile# A 表示新添加到暂存区的文件A lib/git.rb# M 靠左的 M 表示该文件被修改后放入了暂存区M lib/simplegit.rb# ?? 表示还未被跟踪?? LICENSE.txt # 所以此时暂存区中的文件有 Rakefile, lib/git.rb, lib/simplegit.rb git diff 命令概述 git diff可以说是 git status的具体版本，git status只能查看修改了哪些文件，而 git diff能够具体到该文件的某一部分。通常有以下两个用法 当前做的更新哪些还没有暂存？ 首先修改 pic/实习学习笔记.md 文件，然后使用 git status 指令 123456789$ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: pic/实习学习笔记.md # 表示该文件修改后还没有暂存 此时使用 git diff可以查看当前未暂存文件更新了哪些部分 12345678$ git diffdiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex 2b4e07b..a50f1a2 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。+* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵 此时就可以查看未暂存文件修改的部分了。 有哪些更新已经暂存起来了准备好了下次提交？ 可以使用 git diff --staged指令查看，首先需要使用 git add指令将刚刚修改的文件加入暂存区 123456789$ git add pic/实习学习笔记.mdshenglanyadeMacBook-Pro:desktop shenglanya$ git diff --stageddiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex 2b4e07b..a50f1a2 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。+* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵 当我们将文件暂存后继续编辑时，使用 git status指令查看如下： 1234567891011121314$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: pic/实习学习笔记.mdChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: pic/实习学习笔记.md# 该文件同时出现在了暂存区和修改部分。 现在运行 git diff查看暂存前后的变化 12345678git diffdiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex a50f1a2..2b4e07b 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵+* 有额外时间的话，需要将之前没读完的书继续读下去。 再使用 git diff --staged查看变化 12345678$ git diff --stageddiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex 2b4e07b..a50f1a2 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。+* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵 表示这个指令查看的是暂存区中文件的修改。 git commit 命令概述 当使用 git commit命令提交暂存区域的文件时，一定要确认是否还有什么修改过或新建的文件还未放入暂存区，否则一旦提交，这些文件或修改都会只留在本地磁盘，不会加入版本控制中。所以每次提交前都需要执行 git status命令来查看是否都暂存起来了 可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行 1234567$ git commit -m &quot;Story 182: Fix benchmarks for speed&quot;# 表示当前在 master 分支上提交的，本次提交的完整 SHA-1 校验和是 463dc4f[master 463dc4f] Story 182: Fix benchmarks for speed 2 files changed, 2 insertions(+) create mode 100644 README 注意：提交的是放在暂存区的快照，任何还未暂存的仍然保持已修改状态，可以在下次提交时再纳入版本管理。每一次提交都是对项目的一次快照，以后可以回到这个状态或进行比较。 使用 git commit -a可以跳过暂存这一步骤，git 会自动把所有已经跟踪过的文件暂存起来并且提交，即跳过 git add步骤。 git rm 命令概述 要从 Git 中移除某个文件，就必须从已经跟踪的文件清单中删除，然后提交。 删除有两种方式 第一种是简单的从暂存区中删除。但是文件还在被跟踪着。 第二种是直接在未暂存区域中移除文件，表示直接将文件移除版本控制中。不再跟踪。 下面来演示一下，首先对工作区域中的文件删除,使用 rm pic/实习学习笔记.md 123456789101112$ rm pic/实习学习笔记.md$ git statusOn branch masterChanges not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) deleted: pic/实习学习笔记.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)# 此时将文件从暂存区域中删除，但是文件还在被追踪 然后再将文件从跟踪中删除，这里两种指令 $ git rm pic/实习学习笔记.md和 $ git add pic/实习学习笔记.md都能达到同样效果。 1234567$ git add pic/实习学习笔记.md$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) deleted: pic/实习学习笔记.md 需要注意的是，如果删除文件之前文件修改过并且已经放入了暂存区域，则必须使用强制删除选项-f才能将其删除。主要是为了防止误删。 当我们想要将文件从 Git 仓库中删除但是却想让他仍在我们的工作区域中时，（即保存在本地磁盘并且不被 Git 跟踪），为了达到这一目的，使用 --cached选项。 1234$ git rm --cached pic/git存储项目虽时间改变的快照.pngrm &apos;pic/git存储项目虽时间改变的快照.png&apos;# 执行完此命令后，pic/git存储项目虽时间改变的快照.png 文件还在本地磁盘上，并没有被删除。 git mv 命令概述 Git 并不显式的跟踪文件移动操作。所以如果 Git 重命名某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 当我们想在 Git 中对文件进行改名可以使用 git mv a b方式来操作 123456$ git mv pic/实习学习笔记.md pic/note.md$ git diff --stageddiff --git a/pic/实习学习笔记.md b/pic/note.mdsimilarity index 100%rename from pic/实习学习笔记.mdrename to pic/note.md git mv等价于 123$ mv pic/实习学习笔记.md pic/note.md$ git rm pic/实习学习笔记.md$ git add pic/note.md 忽略文件 我们有时会有些文件不需要 Git 来进行管理，也不希望他们总是出现在未跟踪列表中，所以此时，我们可以创建一个名为 .gitignore 的文件，并在其中列出要忽略掉文件模式。 123456789101112# 先创建此忽略文件并向其中添加需要忽略的文件$ vi .gitignore# 查看此文件$ cat .gitignore.localized# 表示忽略所有以 .o 或 .a 结尾的文件*.[oa]# 表示忽略所有以波浪符（~）结尾的文件*~ 一些规范如下 所有空行或者以 ＃开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。glob 即是指 shell 简化了的正则表达式。 其中 * 可以匹配 0 ~ n 个字符 ？ 只能匹配一个字符 [0-9]表示匹配所有 0 到 9 的数字 表示匹配任意中间目录 比如 `a//z`可以匹配 a/z, a/b/z, a/b/c/z 等 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 git stash 命令概述 当我们已经在一个分支上修改文件后，如果必须要切换到其他分支展开其他的工作，而当前分支的工作还没有完成，此时我们需要使用 $ git stash或 $ git stash save命令将当前分支上的工作暂存到栈上，这时你的工作目录就干净了，就可以切换到其他分支工作，等工作完成后，再切换回原来的分支，可以使用 $ git stash apply将你刚刚的储藏重新应用。如果想查看你当前一共有多少个储藏，可以使用 $ git stash list来查看。如果你并不想应用最新的分支，而是想应用某一个早些时间的分支，你可以使用 $ git stash apply stash@{1}，其中最后一个括号内的数字为你某一次提交到工作栈上的暂存记录。如果你不指定 apply 的参数，git 将认为你想要应用最近一次的储藏。 当我们返回原本的分支后，使用 $ git stash apply指令恢复了工作栈中暂存的数据，但是如果当你提交这个分支之前，已经在暂存区缓存了一部分工作内容，并且使用 stash 保存了工作状态，此时当你恢复工作栈中的数据后，实际上暂存区中的内容将会被移出暂存区，而被放在了工作目录中修改的部分，你需要手动将它再放回暂存区，否则可以使用 $ git stash apply --index来尝试重新将暂存区的文件恢复到暂存区中。当你把这个修改放入暂存区后，实际上堆栈上还有这个修改的记录，此时你可以使用 $ git stash drop stash@{1}来从栈中移除它，或者直接使用 $ git stash pop来应用储藏栈这样它就会自动从储藏栈上消失了。 $ git stash --keep-index指令的作用在于告诉 Git 不要储藏任何你通过 git add 命令已经暂存的东西，也就是说比如你现在已经修改了一部分工作目录中的内容，并且还有一部分已经被你暂存了下来。此时你暂时不想继续改工作目录中的内容了，可是你也不想将它暂存到暂存区，此时可以使用这个指令将它暂存到工作栈上。 12345678910$ git status -sM index.html M lib/simplegit.rb$ git stash --keep-indexSaved working directory and index state WIP on master: 1b65b17 added the index fileHEAD is now at 1b65b17 added the index file$ git status -sM index.html $ git stash -u可以储藏还未跟踪的文件到工作栈 $ git stash branch如果使用 stash 储藏了一些工作，然后继续在储藏的分支上工作，在重新应用 stash 储藏的文件工作时可能会有问题。 如果应用尝试修改刚刚储藏的修改的文件，也就是两次同时修改了一个文件，你会得到一个合并冲突并不得不解决它。 如果想要一个轻松的方式来再次测试储藏的改动，可以运行 git stash branch创建一个新分支，检出储藏工作时所在的提交，重新在那应用工作，然后在应用成功后扔掉储藏 1234567891011121314$ git stash branch testchangesSwitched to a new branch &quot;testchanges&quot;# On branch testchanges# Changes to be committed:# (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)## modified: index.html## Changed but not updated:# (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)## modified: lib/simplegit.rb#Dropped refs/stash@&#123;0&#125; (f0dfc4d5dc332d1cee34a634182e168c4efc3359) $ git stash -all可以移除工作目录中所有未跟踪的文件并且存储在工作栈上，相应的一个不怎么安全的方法是 $ git clean直接清除了内容，无法追溯回。不过可以使用 git clean命令去除冗余文件或者清理工作目录。 使用git clean -f -d命令来移除工作目录中所有未追踪的文件以及空的子目录。 -f意味着 强制或 “确定移除”。在使用 $ git clean之前，我们可以先使用 $ git clean -d -n来看一下这样做的后果是什么，也就是有什么文件会被移除。 git log 命令概述 在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 此时便需要 git log命令。默认不加其他参数时， git log惠安提交时间列出所有更新。 123456789101112131415161718$ git logcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add piccommit ec50914561593b769a98ff468de6697a6d964cbdAuthor: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:33:36 2018 +0800 xiugaicommit a7372097ab8f063e17beca6fa8f82a15bb11c5e3Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:20:05 2018 +0800 提交 常用选项 -p,用来显示每次提交的内容差异，可以加上 -2 来仅仅显示最近两次提交 12345678910111213141516171819202122$ git log -pcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add picdiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differcommit ec50914561593b769a98ff468de6697a6d964cbdAuthor: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:33:36 2018 +0800 xiugaidiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngdeleted file mode 100644index 1036a42..0000000Binary files a/pic/git存储项目虽时间改变的快照.png and /dev/null differ --stat选项可以看到每次提交的简略统计信息 1234567891011121314151617181920212223$ git log --statcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add pic pic/git存储项目虽时间改变的快照.png | Bin 0 -&gt; 20722 bytes 1 file changed, 0 insertions(+), 0 deletions(-)commit ec50914561593b769a98ff468de6697a6d964cbdAuthor: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:33:36 2018 +0800 xiugai pic/git存储项目虽时间改变的快照.png | Bin 20722 -&gt; 0 bytes pic/实习学习笔记.md | 22 ++++++++++++++++++++++ 2 files changed, 22 insertions(+)commit a7372097ab8f063e17beca6fa8f82a15bb11c5e3Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:20:05 2018 +0800 常用选项 --pretty可以指定使用不同于默认格式的方式展示提交信息。比如 oneline将每个提交放在一行显示，查看到提交数很大时非常有用。另外还有 short`full`等。 12345$ git log --pretty=onelinefb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master) add picec50914561593b769a98ff468de6697a6d964cbd xiugaia7372097ab8f063e17beca6fa8f82a15bb11c5e3 提交2713657f264a3a019580dc3a489d303fade5dc5c 第一次的修改提交 format选项可以定制要显示的记录格式。这样的输出对后期提取分析格外有用。 12345$git log --pretty=format:&quot;%h - %an, %ar : s&quot;fb40f7a - shenglanya, 60 minutes ago : add picec50914 - shenglanya, 61 minutes ago : xiugaia737209 - shenglanya, 74 minutes ago : 提交2713657 - shenglanya, 3 hours ago : 第一次的修改提交 常用选项以及其代表意义 12345678910111213141516选项 说明%H 提交对象（commit）的完整哈希字串%h 提交对象的简短哈希字串%T 树对象（tree）的完整哈希字串%t 树对象的简短哈希字串%P 父对象（parent）的完整哈希字串%p 父对象的简短哈希字串%an 作者（author）的名字%ae 作者的电子邮件地址%ad 作者修订日期（可以用 --date= 选项定制格式）%ar 作者修订日期，按多久以前的方式显示%cn 提交者（committer）的名字%ce 提交者的电子邮件地址%cd 提交日期%cr 提交日期，按多久以前的方式显示%s 提交说明 选项 --graph可以形象的展示分支，合并历史 123456789101112131415161718$ git log --pretty --graph* commit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)| Author: shenglanya &lt;shenglanya@corp.netease.com&gt;| Date: Wed Mar 7 11:34:54 2018 +0800| | add pic| * commit ec50914561593b769a98ff468de6697a6d964cbd| Author: shenglanya &lt;shenglanya@corp.netease.com&gt;| Date: Wed Mar 7 11:33:36 2018 +0800| | xiugai| * commit a7372097ab8f063e17beca6fa8f82a15bb11c5e3| Author: shenglanya &lt;shenglanya@corp.netease.com&gt;| Date: Wed Mar 7 11:20:05 2018 +0800| | 提交 git log 的常用选项 12345678910选项 说明-p 按补丁格式显示每个更新之间的差异。--stat 显示每次更新的文件修改统计信息。--shortstat 只显示 --stat 中最后的行数修改添加移除统计。--name-only 仅在提交信息后显示已修改的文件清单。--name-status 显示新增、修改、删除的文件清单。--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。--graph 显示 ASCII 图形表示的分支合并历史。--pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。 限制 git log输出的选项 12345678选项 说明-(n) 仅显示最近的 n 条提交--since, --after仅显示指定时间之后的提交。--until, --before仅显示指定时间之前的提交。--author 仅显示指定作者相关的提交。--committer 仅显示指定提交者相关的提交。--grep 仅显示含指定关键字的提交-S 仅显示添加或移除了某个关键字的提交 撤销操作指令 重新提交：有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend选项的提交命令尝试重新提交：$ git commit --amend这个命令将暂存区中的文件提交，如果自从上次提交以来还未做任何修改，则快照保持不变，你修改的只有提交信息。例如你提交后发现忘记了暂存某些需要的修改，可以像下面这样操作： 12345$ git commit -m &apos;initial commit&apos;$ git add forgotten_file$ git commit --amend# 最终只会有一个提交，第二次提交将代替第一次提交的结果 取消暂存的文件：可以使用 git reset HEAD yourfile来进行取消暂存区域内文件的暂存操作。 撤销对文件的修改：如果你不想保存对文件的修改，如何方便的将其还原成上次提交的样子？使用 $ gitcheckout -- pic/实习学习笔记.md撤销之前所做的修改。 Git 远程仓库的使用 查看远程仓库: 使用 git remote命令可以列出你指定的每个远程服务器的简写。如果已经克隆了自己的仓库，那么至少能看到 origin 123$ cd ios-client$ git remoteorigin 可以指定参数 -v 可以查看你的读写权限 123$ git remote -vorigin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (fetch)origin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (push) 添加远程仓库： 运行 git remote add &lt;shortname&gt; &lt;url&gt;添加一个新的远程 Git 仓库 12345678$ git remoteorigin$ git remote add test https://github.com/lanyasheng/NTAlgorithm.git$ git remote -vorigin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (fetch)origin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (push)test https://github.com/lanyasheng/NTAlgorithm.git (fetch)test https://github.com/lanyasheng/NTAlgorithm.git (push) 现在就可以使用 test 来代替整个 URL ，例如使用 git fetch test来拉取远端 Git 仓库中有但你没有的信息。 12345678$ git fetch testwarning: no common commitsremote: Counting objects: 84, done.remote: Total 84 (delta 0), reused 0 (delta 0), pack-reused 83Unpacking objects: 100% (84/84), done.From https://github.com/lanyasheng/NTAlgorithm * [new branch] develop -&gt; test/develop * [new branch] master -&gt; test/master 现在可以在本地访问 test/master 分支了，实际上对应远端的 master 分支。 从仓库中抓取: git fetch会访问远端仓库，从中拉取所有你没有的信息。执行完后，你会拥有该仓库的所有分支引用可以用来随时合并和查看。当使用了 git clone命令克隆一个远端仓库时，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。git fetch origin会抓取克隆（或上一次抓取）后新推送的所有工作。 必须注意 git fetch命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 当准备好时你必须手动将其合并入你的工作。 从仓库上拉取: git pull可以用来自动的抓取然后合并远程分支到当前分支，前提是你有一个分支设置为跟踪一个远程的分支。所以 git pull == git fetch + git merge。默认情况下， git clone会自动设置本地的 master 分支跟踪远程仓库的 master 分支，运行 git pull通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。 推送到远程分支：git push [remote-name][branch-name]指令可以将你的项目推送到服务器。例如当你想将 master 推到 origin 时，可以使用 $ git push origin master只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送 查看远程仓库: 如果想查看一个远程仓库的更多信息，可以使用 $ git remote show test 123456789101112131415$ git remote show test* remote test Fetch URL: https://github.com/lanyasheng/NTAlgorithm.git Push URL: https://github.com/lanyasheng/NTAlgorithm.git HEAD branch: master Remote branches: develop tracked master tracked Local branches configured for &apos;git pull&apos;: develop merges with remote develop master merges with remote master Local refs configured for &apos;git push&apos;: develop pushes to develop (local out of date) master pushes to master (local out of date) 这个命令列出了当你在特定的分支上执行 git push会自动地推送到哪一个远程分支。 它也同样地列出了哪些远程分支不在你的本地，哪些远程分支已经从服务器上移除了，还有当你执行 git pull时哪些分支会自动合并 远程仓库的移除与命名：运行 git remote rename &lt;shortname&gt; &lt;url&gt;重命名远程仓库 1234$ git remote rename test testNea$ git remoteorigintestNea 移除远程仓库: 123$ git remote rm testNea$ git remoteorigin Git 标签创建标签 轻量标签 — 就像一个不会改变的分支，只是一个特定提交的引用，创建轻量标签只需要提供版本号即可。git tag v1.4-1w 123456789101112$ git tag v1.4-1w$ git showcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master, tag: v1.4-1w, tag: v1.3)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add picdiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differ 附注标签 — 一个存储在 Git 数据库中的一个完整对象，他们可以被校验。其中包含打标签者的名字，电子邮件地址、日期时间，标签信息。并且可以使用 GNU Privacy Guard （GPG）签名与验证。可以使用$ git tag -a v1.3这样就给当前版本打上了 v1.3 标签。也可以使用 $ git tag -a v1.3 -m &#39;my version 1.3&#39;这样就直接标备注了。 git show可以查看标签信息与对应的提交信息 123456789101112$ git tag -a v1.3$ git showcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master, tag: v1.3)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add picdiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differ 后期打标签 也可以对过去提交打标签。例如提交历史如下 123456$ git log --pretty=onelinefb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master, tag: v1.4-1w, tag: v1.3) add picec50914561593b769a98ff468de6697a6d964cbd xiugaia7372097ab8f063e17beca6fa8f82a15bb11c5e3 提交20c944dba3f056aef30aada88d0a452e8faffcbc hehe2713657f264a3a019580dc3a489d303fade5dc5c 第一次的修改提交 可以使用 $ git tag -a v1.2 2713657表示对该校验和的版本打上标签。 123456789101112131415161718192021222324252627$ git tagv1.2v1.3v1.4-1w$ git show v1.2tag v1.2Tagger: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 15:00:31 2018 +0800对之前的打标签`commit 2713657f264a3a019580dc3a489d303fade5dc5c (tag: v1.2)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 09:41:21 2018 +0800 第一次的修改提交diff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differdiff --git a/pic/lifecycle.png b/pic/lifecycle.pngnew file mode 100644index 0000000..922b02cBinary files /dev/null and b/pic/lifecycle.png differdiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdnew file mode 100644 Git 分支分支简介简介 Git 保存到不是文件的变化或差异，而是一系列不同时刻的文件快照。当提交时，Git 会保存一个提交的对象。该提交对象会包含一个指向暂存内容快照的指针，还会包含作者姓名和邮箱，提交时输入的信息以及指向他的父对象的指针。首次提交产生的提交对象没有父对象，普通提交操作产生的提交对象有一个父对象，而由多个分支合并产生的提交对象有多个父对象。 我们假设现在有一个工作目录，里面包含了三个将要被暂存和提交的文件。 暂存操作会为每一个文件计算校验和然后会把当前版本的文件快照保存到 Git 仓库中，最终将校验和加入到暂存区域等待提交： 创建分支 Git 创建新分支的本质就是创建一个可以移动的新的指针。比如创建一个 testing 分支。$ git branch testing这会在当前所提交的对象上创建一个指针，此时如图： two-branches.png 如何判断 Git 当前在哪一个分支？此时就要依靠 HEAD 指针。该指针指向当前所在的本地分支。如图 此时 HEAD 指针指向 master 指针，也就是实际上 HEAD 指针指向的时当前所在的本地分支。在本例中，我们仍在 master 分支上，因为 git branch命令仅仅是创建了一个新分支，并没有切换到它上面。可以使用以下命令来查看各个分支当前所指的对象 123456$ git log --oneline --decorate5a5f9fe (HEAD -&gt; master) renamefb40f7a (tag: v1.4-1w, tag: v1.3, testing) add picec50914 xiugaia737209 提交2713657 (tag: v1.2) 第一次的修改提交 可以看到，当前 HEAD 和 master 分支均指向 5a5f9fe 开头的对象 分支切换 使用 git checkout命令可以切换分支 1234567$ git checkout testingSwitched to branch &apos;testing&apos;$ git log --oneline --decoratefb40f7a (HEAD -&gt; testing, tag: v1.4-1w, tag: v1.3) add picec50914 xiugaia737209 提交2713657 (tag: v1.2) 第一次的修改提交 可以看到，此时 HEAD 指针指向了 testing 指针，表示当前的本地分支切换为 testing 分支。然后在 testing 分支上进行一些操作 12345678910111213$ git commit -a -m &apos;made a change on tesing&apos;[testing 844332b] made a change on tesing 3 files changed, 1 insertion(+) create mode 100644 pic/head-to-master.png create mode 100644 pic/test.md create mode 100644 pic/two-branches.png$ git log --oneline --decorate844332b (HEAD -&gt; testing) made a change on tesingfb40f7a (tag: v1.4-1w, tag: v1.3) add picec50914 xiugaia737209 提交20c944d hehe2713657 (tag: v1.2) 第一次的修改提交 此时可以发现 HEAD 指针指向 testing 指针指向了新提交的文件。[图片上传失败…(image-dde0a4-1520604809580)] 此时再切换到 master 分支看一下 12345678$ git checkout masterSwitched to branch &apos;master&apos;$ git log --oneline --decorate5a5f9fe (HEAD -&gt; master) renamefb40f7a (tag: v1.4-1w, tag: v1.3) add picec50914 xiugaia737209 提交2713657 (tag: v1.2) 第一次的修改提交 可以发现此时 master 分支还指向刚刚它指向的位置，也就是[图片上传失败…(image-85e5da-1520604809580)] git checkout master一共做了两件事： 使 HEAD 指向 master 分支 将工作目录恢复成 master 分支所指向的快照内容，也就是忽略 testing 分支所做的修改。 若我们此时再对 master 分支上的文件上进行修改，就会产生分叉。因为你刚创建了一个新分支，并且切换过去进行了一些工作，然后后切换回了 master 分支进行了一些额外的工作。上述改动针对的是不同分支，你可以在不同分支之间来回切换并在某一时刻将他们合并。 项目分叉历史 可以使用 git log命令查看分叉历史。运行 git log --oneline --decorate --graph —all，他会输出你的提交历史各个分支的指向以及项目的分支分叉情况。 12345678910$ git log --oneline --decorate --graph --all* b551643 (HEAD -&gt; master) made a change on master* 5a5f9fe rename| * 844332b (testing) made a change on tesing|/ * fb40f7a (tag: v1.4-1w, tag: v1.3) add pic* ec50914 xiugai* a737209 提交* 20c944d hehe* 2713657 (tag: v1.2) 第一次的修改提交 由于 Git 的分支实际上只是包含所指对象的校验和，创建一个新分支仅仅相当于往一个文件中写入 41 个字节。 分支操作分支的新建与合并 具体实例总结在此文章中 分支的新建与合并 需要注意的地方： 首先当你想直接从当前分支创建并切换到新分支时，可以使用 $ git checkout -b yourname来进行操作，这个命令等价于 $ git branch yourname + $ git checkout yourname 当你在新分支上工作时，突然需要切换到之前开始分叉的 master 分支并且需要在 master 分支上开一个新的分支进行工作，则首先需要暂存你在 yourname 分支上还未进行暂存的修改，然后将其提交到仓库。否则可能会跟你即将检出的分支产生冲突。 当你在 master 分支上开了一个新分支并且已经解决完问题后，可以将 master 和 hotfix 进行合并，使用 1$ git checkout master, $ git merge hotfix 进行合并。 - 快进 （Fast forward）：在合并时，如果当前的 master 分支是你要合并分支的直接上游，则 Git 会直接将 master 指针向前推进到 hotfix 上面。然后就可以将 hotfix 进行删除。 使用 `$ git branch -d hotfix` - 合并提交：而如果 master 不是你要合并分支的直接上游，比如此时 master 分支已经指向了原本 hotfix 指向的位置，则将它与 yourname 分支合并起来会比较麻烦。由于此时 master 分支已经更新了，如果我们需要它新的内容可以将 master 合并到 yourname 上，如果不需要可以直接等 yourname 分支任务完成后，将其合并到 master 上面。如果我们想将 yourname 合并到 master 上，首先会记录他们两个指针所指向的最后一个快照，然后记录他们共同的祖先快照，最后将三方合并的结果做一个新的快照并且自动创建一个新的提交指向它。合并后可以删除 yourname 分支。 遇到冲突的分之合并：可以直接使用 git status状态来查看具体是哪个文件产生了冲突，然后直接打开该文件删除乱码部分和不需要的部分。 分支管理(git branch 命令) $ git branch命令不仅可以创建或删除分支，当不加参数时，其作用为可以查看当前分支 123$ git branch* master testing 其中 * 表示当前分支 $ git branch -v可以查看每个分支的最后一次提交 123$ git branch -v* master b551643 made a change on master testing 844332b made a change on tesing $ git branch --merged可以查看哪些分支已经合并到当前分支上，同理 $ git branch --no-merged 1234$ git branch --merged* master$ git branch --no-merged testing $ git branch -d yourname可以用来删除已经合并的分支，如果是未合并的分支则会报错。 分支开发工作流程 长期分支（最常用） 如只在 master 上保留稳定的代码，有可能仅仅是已经发布的代码。还有一些其他的分支如 develop 和 next 平行分支用来进行后续开发，一旦在在这些分支上达到了稳定，再将他们合并到 master 分支上。这样在确保这些已完成的特性分支能够通过所有的测试，并且不会引入 bug 后再将他们合并到 master 上等待下一次发布。 特性分支 特性分支被用来实现单一特性或相关工作，一旦工作完成它就会被删除。这项技术可以使你快速的进行上下文切换。当你做这么多操作时，这些分支要确保存于本地，而不会与服务器进行交互。 远程分支 远程引用是指对远程仓库的引用，包括分支标签等。他们是你不能移动的本地引用，当你做任何网络通信操作时，他们会自动移动。远程跟踪分支像是你上次连接到远程仓库时，那些分支所处状态的书签。他们的命名格式为 (remote)/(branch) 。如果你想要看你最后一次与远程 origin 分支通信时 master 分支的状态，则可以查看 origin / master 分支。你与同事合作解决一个问题并且他们推送了一个 iss53分支，你可能有自己的本地 iss53分支；但是在服务器上的分支会指向 origin/iss53的提交。 当与远端仓库共同工作时，如果你不抓取fetch远端 orgin/master ，则它将会一直指向在你上次 fetch 的那个文件。此时即使你本地的 master 已经指向很远的地方了，远端的 orgin/master 还依旧指向你上次 fetch 的那个位置。直到你下一次 fetch。 需要注意的问题 当我们使用分支合并时，要确定是谁合并到谁：当我们需要使用其他分支的内容时，可以把其他分支合并到我们的分支上。但是当我们在开发时，有时可能是从 master 或 develop 分支上拉取的工作分支，此时如果 master 或 develop 分支有更新并且我们需要用到，可以将 master 或 develop 分支拉取到我们的分支。否则，则应该等开发完毕后，将我们的分支合并到 master 或 develop 分支上。当开发完毕后，首先需要检出 master 分支，然后将工作分支合并到 master 上即可。 $ git checkout master $ git merge workBranch。合并完成后，可以将工作分支删除。$ git branch -d workBranch，需要注意的是，当我们删除的分支还包含未提交的内容，分支删除会失效。强制删除可以使用 -D 当 merge 出现冲突时，我们可以先 $ git status来查看是哪里出现了问题，然后 cd 进入该文件，直接将冲突部分删除即可解决问题。合并完成后再次执行 $ git status来查看问题是否解决。若问题解决，即可提交。 当已经使用了 git add指令暂存的版本又经过修改之后，需在再重新使用 git add指令将最新的修改放入暂存区，否则此时暂存区里只有上一次修改的内容 $ git commit指令仅仅是将暂存区内的文件快照提交到本地仓库中，想要推送到远程仓库则还需要 push 操作，在 push 操作之前我们需要先 $ git fetch操作将远程仓库的需要合并的文件抓取到本地，然后进行合并，合并完成后使用 $ git status指令进行查看，没问题后再推送到远端。这里其实也可以使用 $ git pull来拉取远端分支的快照，但是这容易产生冲突，若产生冲突则可以找到产生冲突的文件，修改冲突部分再重新提交。提交完成后若想删掉远端工作分支，则可以使用 $ git push origin --delete指令。 当我们想删除本地暂存区中的内容，可以使用$ git rm --cache 文件名指令，当我们想删除工作区的某个文件可以使用 $ git rm -f。 当我们想要删除错误提交到本地仓库的 commit $ git reset --soft 版本库ID仅仅撤销已经提交的版本库，不会修改暂存区和工作区 $ git reset --mixed 版本库ID仅仅撤销提交到版本库和暂存区的内容，不会修改工作区的内容 $ git reset --hard 版本库ID将工作区，暂存区，和版本库记录恢复到指定版本。 $ git stash branch如果使用 stash 储藏了一些工作，然后继续在储藏的分支上工作，在重新应用 stash 储藏的文件工作时可能会有问题。 如果应用尝试修改刚刚储藏的修改的文件，也就是两次同时修改了一个文件，你会得到一个合并冲突并不得不解决它。 如果想要一个轻松的方式来再次测试储藏的改动，可以运行 git stash branch创建一个新分支，检出储藏工作时所在的提交，重新在那应用工作，然后在应用成功后自动扔掉储藏。 可以使用 $ git stash -all来清除工作目录中所有冗余的未被跟踪的文件，并且他们会被存储在工作栈上，当你想要恢复时也可以使用 $ git stash apply恢复使用。 当在本地新创建一个分支时，需要先 push 到远端仓库，远端仓库才会有这个分支，否则会报错 123456789101112131415161718192021222324252627282930error: the requested upstream branch &apos;origin/f_tradeReverse&apos; does not existhint:hint: If you are planning on basing your work on an upstreamhint: branch that already exists at the remote, you may need tohint: run &quot;git fetch&quot; to retrieve it.hint:hint: If you are planning to push out a new local branch thathint: will track its remote counterpart, you may want to usehint: &quot;git push -u&quot; to set the upstream config as you push.$ git fetch$ git statusOn branch f_tradeReversenothing to commit, working tree clean$ git pushfatal: The current branch f_tradeReverse has no upstream branch.To push the current branch and set the remote as upstream, use git push --set-upstream origin f_tradeReverse$ git push --set-upstream origin f_tradeReverseUsername for &apos;https://git.ms.netease.com&apos;: shenglanyaPassword for &apos;https://shenglanya@git.ms.netease.com&apos;:Total 0 (delta 0), reused 0 (delta 0)remote:remote: Create merge request for f_tradeReverse:remote: https://git.ms.netease.com/preciousmetals/LDPMTrade/merge_requests/new?merge_request%5Bsource_branch%5D=f_tradeReverseremote:To https://git.ms.netease.com/preciousmetals/LDPMTrade.git * [new branch] f_tradeReverse -&gt; f_tradeReverseBranch &apos;f_tradeReverse&apos; set up to track remote branch &apos;f_tradeReverse&apos; from &apos;origin&apos;. git 拉取远程分支并且创建本地分支 $ git checkout -b 本地分支名x origin/远程分支名x 如果写错名字，重命名远程为dev1。思路：删除远程分支、重命名本地分支、重新提交一个远程分支 1、git push –delete origin dev——删除远程分支 2、git branch -m dev dev1——重命名本地分支为dev1 3、git push origin dev1——重新推送远端仓库分支名称为dev1 如何删除本地的文件的修改？ 如果是删除已经暂存的文件，则直接使用 $ git reset HEAD 文件名 如果是要删除未暂存的文件，使用 $ git checkout --文件名这样会使得这个文件去掉所有还未暂存的修改 如果删除未跟踪的文件，使用 $ git clean -df 删除不想要的修改 $ git stash &amp;&amp; $ git stash clear 删除本地分支 $ git branch -D BranchName 删除远端分支 删除本地的远端分支 $ git branch -r -D origin/BranchName 删除远端服务器的分支 $ git push origin -d BranchName 打 tag 在本地打 tag ：$ git tag 4.20.1 将 tag 推送到远端 ： $ git push origin :4.20.1 查看远端分支 $ git branch -r 从远端拉取分支 $ git checkout -b x origin/x 总结 本次 Git 基础学习总结到现在就告一段落，文章由于时间，精力和自己本身能力原因并未能够完整的写完，留到日后的学习工作中当有时间和精力，以及对 Git 的使用更加了解后，将继续完善。","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://blog.ozairs.com/tags/Git/"}],"keywords":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}]},{"title":"How to network like a pro at social events","slug":"How-to-network-like-a-pro-at-social-events","date":"2019-02-05T02:45:31.000Z","updated":"2019-02-05T05:47:46.560Z","comments":true,"path":"Jobs/How-to-network-like-a-pro-at-social-events/","link":"","permalink":"http://blog.ozairs.com/Jobs/How-to-network-like-a-pro-at-social-events/","excerpt":"","text":"With the Christmas party season just around the corner, now is the time to brush up on your networking skills. Your friends and family can help you network and help in your job search, but you never know who you might meet at a BBQ, Christmas drinks, or extended family get-together. You don’t want to miss out on the perfect opportunity to land your next job. Here’s our top tips on how to network like a pro at social events. Accept invitationsThis might sound obvious, but if you don’t get out there, you won’t meet people. Networking can be a numbers game. The more people you meet, the more chances you have of meeting someone who can help you find a new job. So say yes, yes, yes to those invitations! Introduce yourselfEveryone has contacts – don’t forget to introduce yourself to everyone you meet. To feel more confident, it helps to have an introduction and some ice-breaker questions ready to go. It doesn’t have to be a formal party for you to use these, any gathering where there are a group of people is the prime opportunity to connect. You could be at a game of backyard cricket, watching your kids play sport, or just enjoying a BBQ with mates. While it’s great to introduce yourself to everyone you meet, this doesn’t mean hassling everyone at a party to give you a job. Networking is about building relationships – these may or may not lead a job offer but they can have many other benefits. Be conversational and genuinely interested in what other people have to say. Avoid constantly talking about yourself and don’t just talk about how badly you need a job. Dress to impressIf you are looking to professionally network at Christmas parties, it is important to dress well. You want people to remember you for the right reasons. If you dress well, ask questions, listen well and speak confidently to people you meet, you will leave a good impression. If you’re chatting to someone and the conversation veers towards your career, make sure you have your elevator pitch ready to go. Remember, if you are using social events to network to find a job, you need to act professionally at all times. Don’t go heavy on the alcohol and act like you would at a formal networking event. Take notes about the people you meetTake notes of people who you think could be a good contact or who offer you help. Get their LinkedIn contact details, business card or email address. Jot down something about your conversation as it will help jog your memory later. Follow upMake sure you follow up with anyone you connect with. Integrity is a key attribute people look for when networking or hiring. If you say you’re going to contact someone, do it. Otherwise, you’ll undo all the hard work you did when you first met the person. Follow up with an email, LinkedIn message or phone call. Stay positiveIf you’ve been looking for work for awhile, it can be hard to remain positive. Being social might be the last thing you feel like doing, but going to different events can be a surprising way to meet people and build professional networks. Networking can also be a fun way to boost your job search, and beats sitting in front of the computer all day.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Australia","slug":"Australia","permalink":"http://blog.ozairs.com/tags/Australia/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"Top 10 job interview questions and how to answer them","slug":"Top-10-job-interview-questions-and-how-to-answer-them","date":"2019-02-05T02:27:07.000Z","updated":"2019-02-05T06:37:13.726Z","comments":true,"path":"Jobs/Top-10-job-interview-questions-and-how-to-answer-them/","link":"","permalink":"http://blog.ozairs.com/Jobs/Top-10-job-interview-questions-and-how-to-answer-them/","excerpt":"","text":"Top 10 job interview questions and how to answer themIf you’ve got an interview coming up there’s a good chance you’ll be asked at least one of these top 10 job interview questions. Don’t get nervous, we’ve got you covered. How to answer the top 10 job interview questionsThe key to a successful job interview to think about what an employer might ask you, and prepare some answers. Here’s some good and bad examples of how to answer the top 10 job interview questions. 1. Tell me about yourselfEmployers ask this to see how you’ll fit in. They already have a copy of your resume, so you don’t need to go over everything on it. Give a quick summary of your key qualities, skills, experience and goals. Some people call this an elevator pitch. Good: “I am passionate about giving customers excellent services and experiences. My background is in hotels and restaurants, where I learnt the power of hard work and enthusiasm. I want to shift my focus and take on opportunities in tourism management.” Bad: Don’t tell your interviewer what you did on the weekend or your favourite TV show (unless it’s actually relevant to the job). 2. What are your strengths?This is a great opportunity to sell yourself, but you need to give examples. Good: “I’m a great project manager. In my last job as a chef my role expanded to ordering food for the kitchen. As a result, the kitchen no longer ran out of food before the end of a shift and customer numbers increased by 30 per cent.” Bad: Don’t give an answer that you can’t back up. Anyone can say they’re hard working. You need to explain how and why. 3. What are your weaknesses?Don’t be afraid of this question. The ability to identify a weakness is actually a strength! But, you need to say what you have done or plan to do to fix any weakness. Good: “I don’t have experience using spreadsheets in the workplace. But I asked a friend to show me the basics, and I am doing a course online to learn more.” Bad: Don’t say you don’t have any weaknesses. It will make you sound like you lack self-awareness. “I work too hard” won’t cut it either. Bonus tip: Don’t list a weakness that is a key part of the job you’re interviewing for. Don’t say you can’t spell if you’re trying to get a job as a writer. Don’t say you are bad at talking to people if you’re trying to get a sales job. 4. Why do you want to work here?An employer wants to know if you’re really interested in the job or if you just want a paycheck. Do some research on the company. Talk about the products or services they sell and why you like them. Good: “I know you recently won an award for your new recyclable coffee cups. I’m passionate about the environment and I want to work for a company that reflects my values.” Bad: Don’t say that you just want a job. 5. Why should we hire you?Employers want to know why you’re a perfect fit for the job. Tell them how hiring you will help solve their problems. If you’ve done your research you can work out what these problems are. Good: You found out the company has opened five new stores in your city, and is hiring a lot of new staff. Tell them you were responsible for training new staff in your last job and have skills in this area. Bad: Don’t just say you’d be an asset to the team. Explain why. 5. What has been your biggest achievement at work?Talk about an achievement you’re proud of that relates to the job. Use examples from study or your personal life if you don’t have a work one. Good: If the job ad you responded to said you need to be a hard worker; you might say: “At my old job at a fast food restaurant I got an award for serving the most customers in a month.” Bad: Don’t say that you don’t have any achievements! 6. What has been your biggest obstacle or problem at work and how have you overcome it?Use an example that relates to the job you’re going for. Good: A customer at the record store you worked at was not happy the store had sold out of a new album and was threatening to buy it online. You solved it by asking the manager to order extra copies, and suggested that in future the manager could order extra stock of the store’s top five releases. Bad: Don’t say that you’ve never had an obstacle. Everybody has. 7. Where do you see yourself in five years?Employers want to know how the job lines up with your ambitions and values, and whether you’re likely to stick around or leave after a few months. If you’re not sure what the future holds, that’s OK – you can say the position will help you decide. Good: For a sales position, you could say, “Within two years I would like to be seen as an expert in customer management and have increased my average monthly sales by 50 per cent.” Bad: Don’t say that you don’t know. And don’t go in the other direction and something unrealistic like you want to be company CEO. 8. Why do you want to leave your current job / Why did you leave your last job?Regardless of the actual reason you left, NEVER badmouth your last employer. Think of a way to be diplomatic about why you left. Good: “My company was cutting back and my position changed in a way that didn’t match my goals” or “I’m looking for a new challenge and to grow my career”. Bad: “The hours were terrible, they didn’t pay me enough, I hated it.” 9. What are your salary expectations?Most jobs will specify a salary range in the advertisement. If you’re feeling bold, aim for the top! But note that it’s generally not a good idea to discuss salary at the first interview, unless the employer raises it first. Good: “Your ad said the salary range for this job was between $45,000 and $55,000. Based on my experience and qualifications I expect a salary at the top end of your range.” An employer might want a specific answer. Do your research and find out what other people get paid to do the job. Bad: Don’t ask for a salary that’s too high (you might price yourself out of the job) or too low (you need to be able to buy groceries every week!) 10. Do you have any questions?This is a great opportunity to impress an employer. An interview is a two-way street and a good chance to see if you like the organisation, too. Think of a few questions beforehand, and try to come up with a question based on something said during the interview also. Good: You’re being interviewed for a job at a bike hire shop. When you checked out the store’s website you noticed the page to hire bikes was broken. Ask if this is being repaired or improved. Bad: Don’t say that you don’t have any questions. You won’t seem interested in the job.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Australia","slug":"Australia","permalink":"http://blog.ozairs.com/tags/Australia/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"Tips to help you get a job","slug":"Tips-to-help-you-get-a-job","date":"2019-02-05T02:02:59.000Z","updated":"2019-02-05T05:08:13.456Z","comments":true,"path":"Jobs/Tips-to-help-you-get-a-job/","link":"","permalink":"http://blog.ozairs.com/Jobs/Tips-to-help-you-get-a-job/","excerpt":"","text":"It’s New Year’s Day 2019, it’s 38 degrees and I am lying in the river with some of my best friends talking about what lies ahead for 2019. Janet, who’s a bit of a procrastinator, says “This is the year of 100 for me. I am going to swim 100 kilometres this year. I am going to clean all the clutter from my apartment in the first 100 days. I’m going to save an extra $100 a month.” Janet took things she thought were insurmountable and broke them into simple goals. She didn’t make general New Year resolutions like getting fit, losing weight, cleaning up her house. Janet made her goals clear. She broke them down into things she could do and show she had done. It got us all talking about goals and how to achieve them. Just like The White Stripes song Little Acorns, it’s important to break down your goals into bite-size chunks. Like a squirrel putting away acorns for the winter, you do it one acorn at a time. How to get a job in 2019?The first thing to do is break down your job search into bite-size chunks and set goals to achieve them. Here’s some job search tips to get you going. 1. Freshen up your resumeStart the year with a fresh resume. Make sure it’s up to date and includes any voluntary work you’ve been doing over the break. Don’t forget any holiday casual work. It’s also time to rewrite your About Me section. There’s some great tips on jobactive.gov.au if you need some examples. Why not create a range of different resumes for different jobs? Create 5 resumes in 5 days. 2. Make a list of businesses to cold callOne-in-three jobs aren’t advertised at all. The best way to get your foot in the door is to cold call places you’d like to work in your suburb or town. Take a walk this week and spot the places you’d like to work. Make a list of 10 places and contact them all in 10 days. You could have a job before the end of January! There’s some great tips on youtube.com/jobactivejobsto build your confidence to cold call places. 3. Pick a job that’s ripe for youIt’s peak fruit picking season, that means lots of fruit and vegetable picking jobs right across Australia. You could have a job in less than 5 days with harvest work. If you have never considered it, you could have regular work right now. Remember, picking fruit is a great stepping stone to a great job. It shows other employers you’re reliable and a hard worker. Just hit the Search button on this page to see all the fruit and vegie jobs – or read more about it. You could apply for a harvest job today and be picking next week! 4. Find out where the most jobs areSome industries are booming. Australia is going through an infrastructure boom. New schools are going up. New roads being built. There’s a new railway line being built inland. The health industry is also going crazy with enormous demand for carers. One of the best ways to get a job is to apply for jobs in industries that are going gangbusters. The Labour Market Information Portal may sound boring but it will tell you where the best places are to get a job. Take a look at the Industry Employment Projections Report and pick 5 industries to focus your job search on.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Australia","slug":"Australia","permalink":"http://blog.ozairs.com/tags/Australia/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"HEXO主题配置","slug":"HEXO主题配置","date":"2019-02-03T02:54:06.000Z","updated":"2019-02-03T06:22:56.520Z","comments":true,"path":"Web开发/HEXO主题配置/","link":"","permalink":"http://blog.ozairs.com/Web开发/HEXO主题配置/","excerpt":"","text":"您可以在 _config.yml 中修改大部分的配置。 网站 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 author 您的名字 language 网站使用的语言 timezone 网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。 其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。 网址 参数 描述 默认值 url 网址 root 网站根目录 permalink 文章的 永久链接 格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 网站存放在子目录 如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url设为 http://yoursite.com/blog 并把 root 设为 /blog/。 目录 参数 描述 默认值 source_dir 资源文件夹，这个文件夹用来存放内容。 source public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public tag_dir 标签文件夹 tags archive_dir 归档文件夹 archives category_dir 分类文件夹 categories code_dir Include code 文件夹 downloads/code i18n_dir 国际化（i18n）文件夹 :lang skip_render 跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。 提示 如果您刚刚开始接触Hexo，通常没有必要修改这一部分的值。 文章 参数 描述 默认值 new_post_name 新文章的文件名称 :title.md default_layout 预设布局 post auto_spacing 在中文和英文之间加入空格 false titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置 相对地址 默认情况下，Hexo生成的超链接都是绝对地址。例如，如果您的网站域名为example.com,您有一篇文章名为hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。 分类 &amp; 标签 参数 描述 默认值 default_category 默认分类 uncategorized category_map 分类别名 tag_map 标签别名 日期 / 时间格式Hexo 使用 Moment.js 来解析和显示时间。 参数 描述 默认值 date_format 日期格式 YYYY-MM-DD time_format 时间格式 H:mm:ss 分页 参数 描述 默认值 per_page 每页显示的文章量 (0 = 关闭分页功能) 10 pagination_dir 分页目录 page 扩展 参数 描述 theme 当前主题名称。值为false时禁用主题 deploy 部署部分的设置","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.ozairs.com/tags/Hexo/"}],"keywords":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}]},{"title":"MacOS安装使用Node.js","slug":"MacOS安装使用Node-js","date":"2019-02-02T10:43:45.000Z","updated":"2019-02-02T13:46:32.849Z","comments":true,"path":"Web开发/MacOS安装使用Node-js/","link":"","permalink":"http://blog.ozairs.com/Web开发/MacOS安装使用Node-js/","excerpt":"","text":"\\1. 到官网https://nodejs.org/zh-cn/download/下载，选择Macintosh Installer, 如下： \\2. 按预设的下一步，Node.js版本为v6.10.0, NPM版本为v3.10.10 \\3. 过程可能要输入用户密码 \\4. 安装成功如下： \\5. 用终端验证是否成功安装, 输入 node -v \\6. console.log(1+2), 得到结果3 \\7. 我Mac的Eclipse不支援EcmaScript 6, 例如 let 等ES6的关键子在Eclipse都验证不过去。 大概Google下了，找到一个JavaScript支援很不错的IDE，网址如下： https://www.jetbrains.com/webstorm/ 下载完，create一个工程，然后新增一个JavaScript文件： \\8. 将hello_weekend配置为Node.js来debug \\9. Node interpreter设置为Node.js的安装路径 \\10. Script如下： 123456789101112/** * Created by prolink on 17/3/19. */var http = require(&apos;http&apos;);var server = http.createServer(function (req, res) &#123; res.writeHead(200); res.end(&apos;Hello World&apos;);&#125;);server.listen(8088); \\11. 这个http返回Hello World，并在该行鼠标左键点击设置断点 \\12. debug该文件 \\13. 成功启动之后看到Console有相关的资讯 \\14. Chrome浏览器输入 http://localhost:8088/， 可以看到已经命中断点 ，在Console中可以改变变量的值，例如在这里不返回Hello World了，改成返回Hello Weekend，如下图，输入完之后按回车，可以看到true \\15. 看看浏览器得到的就是刚才debug时候重设的值 \\16. 如果仅仅做到这步，WebStorm还不支援ECMAScript 6，打开 Preferences -&gt; Languages &amp; Franeworks -&gt; JavaScript, 如下图将预设的ECMAScript 5.1改为ECMAScript 6 \\17. ES6毕竟是2015年才发布的，形容性并不好，为了让您编写的ES6的程式码可以有更好的相容性，可以用Babel file watcher来监视并自动转码ES5. 12prolinkdeMacBook-Pro:milo_demo prolink$ sudo npm install -g babel-cliprolinkdeMacBook-Pro:milo_demo prolink$ cd /Users/prolink/WebstormProjects/milo_demo 按上一步进入工程目录之后，安装babel-preset-env, 参考 https://babeljs.io/docs/plugins/preset-env/ 1sudo npm install babel-preset-env --save-dev \\18. 打开 Preferences -&gt; Tools -&gt; File Watchers, 添加Bable, 如下： 如果安装一切顺利，当您编辑JS文件时候，会自动在工程目录中同步编译到dist目录中。","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}],"tags":[{"name":"Node.js","slug":"Node-js","permalink":"http://blog.ozairs.com/tags/Node-js/"}],"keywords":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-01-27T04:05:03.506Z","updated":"2019-01-27T04:53:20.343Z","comments":true,"path":"uncategorized/hello-world/","link":"","permalink":"http://blog.ozairs.com/uncategorized/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[],"keywords":[]},{"title":"Serverless Overview","slug":"Serverless-Overview","date":"2019-01-26T10:58:05.000Z","updated":"2019-01-27T04:53:20.340Z","comments":true,"path":"uncategorized/Serverless-Overview/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Serverless-Overview/","excerpt":"","text":"今年有人提出了2018年微服务将疯狂至死，可见微服务的争论从未停止过。在这我将自己对微服务的理解整理了一下，希望对大家有所帮助。 1.什么是微服务 1）一组小的服务（大小没有特别的标准，只要同一团队的工程师理解服务的标识一致即可）2）独立的进程（java的tomcat，nodejs等）3）轻量级的通信（不是soap，是http协议）4）基于业务能力（类似用户服务，商品服务等等）5）独立部署（迭代速度快）6）无集中式管理（无须统一技术栈，可以根据不同的服务或者团队进行灵活选择）ps：微服务的先行者Netflix公司，开源了一些好的微服务框架，后续会有介绍。 怎么权衡微服务的利于弊 利：强模块边界 。（模块化的演化过程：类–&gt;组件/类库（sdk）–&gt;服务(service)，方式越来越灵活）可独立部署。技术多样性。弊：分布式复杂性。最终一致性。（各个服务的团队，数据也是分散式治理，会出现不一致的问题）运维复杂性。测试复杂性。 企业在什么时候考虑引入微服务 从生产力和系统的复杂性这两个方面来看。公司一开始的时候，业务复杂性不高，这时候是验证商业模式的时候，业务简单，用单体服务反而生产力很高。随着公司的发展，业务复杂性慢慢提高，这时候就可以采用微服务来提升生产力了。至于这个转化的点，需要团队的架构师来进行各方面衡量，就个人经验而言，团队发展到百人以上，采用微服务就很有必要了。有些架构师是具有微服务架构能力，所以设计系统时就直接设计成了微服务，而不是通过单服务慢慢演化发展成微服务。在这里我并不推荐这种做法，因为一开始对业务领域并不是很了解，并且业务模式还没有得到验证，这时候上微服务风险比较高，很有可能失败。所以建议大家在单服务的应用成熟时，并且对业务领域比较熟悉的时候，如果发现单服务无法适应业务发展时，再考虑微服务的设计和架构。4.微服务的组织架构 如上图左边，传统的企业中，团队是按职能划分的。开发一个项目时，会从不同的职能团队找人进行开发，开发完成后，再各自回到自己的职能团队，这种模式实践证明，效率还是比较低的。如上图右边，围绕每个业务线或产品，按服务划分团队。团队成员从架构到运维，形成一个完整的闭环。一直围绕在产品周围，进行不断的迭代。不会像传统的团队一样离开。这样开发效率会比较高。至于这种团队的规模，建议按照亚马逊的两个披萨原则，大概10人左右比较好。5：怎么理解中台战略和微服务 中台战略的由来：马云2015年去欧洲的一家公司supersell参观，发现这个公司的创新能力非常强，团队的规模很小，但是开发效率很高。他们就是采用中台战略。马云感触很深，回国后就在集团内部推出了中台战略。 简单的理解就是把传统的前后台体系中的后台进行了细分。阿里巴巴提出了大中台小前台的战略。就是强化业务和技术中台，把前端的应用变得更小更灵活。当中台越强大，能力就越强，越能更好的快速响应前台的业务需求。打个比喻，就是土壤越肥沃，越适合生长不同的生物，打造好的生态系统。6：服务分层 每个公司的服务分层都不相同，有的公司服务没有分层，有的怎分层很多。目前业界没有统一的标准。下面推荐一个比较容易理解的两层结构。 1：基础服务： 比如一个电商网站，商品服务和订单服务就属于基础服务（核心领域服务）。缓存服务，监控服务，消息队列等也属于基础服务（公共服务）2：聚合服务 ：例如网关服务就算一种聚合服务（适配服务）。这是一种逻辑划分，不是物理划分，实际设计的东西很多很复杂。7：微服务的技术架构体系 下图是一个成型的互联网微服务的架构体系： 1：接入层 负载均衡作用，运维团队负责2：网关层 反向路由，安全验证，限流等3：业务服务层 基础服务和领域服务4：支撑服务层5：平台服务6：基础设施层 运维团队负责。（或者阿里云）8：微服务的服务发现的三种方式 第一种：如下图所示，传统的服务发现（大部分公司的做法）。服务上线后，通知运维，申请域名，配置路由。调用方通过dns域名解析，经过负载均衡路由，进行服务访问。缺点： LB的单点风险，服务穿透LB，性能也不是太好 第二种：也叫客户端发现方式。如下图所示。通过服务注册的方式，服务提供者先注册服务。消费者通过注册中心获取相应服务。并且把LB的功能移动到了消费者的进程内，消费者根据自身路由去获取相应服务。优点是，没有了LB单点问题，也没有了LB的中间一跳，性能也比较好。但是这种方式有一个非常明显的缺点就是具有非常强的耦合性。针对不同的语言，每个服务的客户端都得实现一套服务发现的功能。 第三种：也叫服务端发现方式，如下图所示。和第二种很相似。但是LB功能独立进程单独部署，所以解决了客户端多语言开发的问题。唯一的缺点就是运维成比较高，每个节点都得部署一个LB的代理，例如nginx。 9.微服务网关 网关就好比一个公司的门卫。屏蔽内部细节，统一对外服务接口。 下图是一个网关所处位置的示例图。 10：Netflix Zuul网关介绍 核心就是一个servlet，通过filter机制实现的。主要分为三类过滤器：前置过滤器，过滤器和后置过滤器。主要特色是，这些过滤器可以动态插拔，就是如果需要增加减少过滤器，可以不用重启，直接生效。原理就是：通过一个db维护过滤器（上图蓝色部分），如果增加过滤器，就将新过滤器编译完成后push到db中，有线程会定期扫描db，发现新的过滤器后，会上传到网关的相应文件目录下，并通知过滤器loader进行加载相应的过滤器。 整个网关调用的流程上图从左变http Request开始经过三类过滤器，最终到最右边的Http Response，这就是Zull网关的整个调用流程。11：微服务的路由发现体系 整个微服务的路由发现体系，一般由服务注册中心和网关两部分组成。以NetFlix为例子，Eureka和Zull这两个组件支撑了netFlix整个的路由发现体系。如下图所示，首先外部请求发送到网关，网关去服务注册中心获取相应的服务，进行调用。其次内部服务间的调用，也通过服务注册中心进行的 12.微服务配置中心 目前大部分公司都是把配置写到配置文件中，遇到修改配置的情况，成本很高。并且没有修改配置的记录，出问题很难追溯。配置中心就接解决了以上的问题。可配置内容：数据库连接，业务参数等等 配置中心就是一个web服务，配置人员通过后台页面修改配置，各个服务就会得到新的配置参数。实现方式主要有两种，一种是push，另一种是pull。两张方式各有优缺点。push实时性较好，但是遇到网络抖动，会丢失消息。pull不会丢失消息但是实时性差一些。大家可以同时两种方式使用，实现一个比较好的效果。如下图所示，这是一个国内知名互联网公司的配置中心架构图。 开源地址：http://github.com/ctripcorp/appollo13：RPC遇到了REST 内部一些核心服务，性能要求比较高的可以采用RPC，对外服务的一般可以采用rest。14：服务框架和治理 微服务很多的时候，就需要有治理了。一个好的微服务框架一般分为以下14个部分。如下图所示。这就是开篇所说的，微服务涉及的东西很多，有些初创公司和业务不成熟的产品是不太适合的，成本比较高。目前国内比较好的微服务框架就是阿里巴巴的DUBBO了,国外的就是spring cloud,大家可以去研究一下. 15：监控体系 监控是微服务治理的重要环节。一般分为以下四层。如下图所示。 监控的内容分为五个部分：日志监控，Metrics监控（服务调用情况），调用链监控，告警系统和健康检查。日志监控，国内常用的就是ELK+KAFKA来实现。健康检查和Metrics，像spring boot会自带。Nagios也是一个很好的开源监控框架。16:Trace调用链监控 调用链监控是用来追踪微服务之前依赖的路径和问题定位。例如阿里的鹰眼系统。主要原理就是子节点会记录父节点的id信息。 下图是目前比较流行的调用链监控框架。 17：微服务的限流熔断 假设服务A依赖服务B和服务C，而B服务和C服务有可能继续依赖其他的服务，继续下去会使得调用链路过长。如果在A的链路上某个或几个被调用的子服务不可用或延迟较高，则会导致调用A服务的请求被堵住，堵住的请求会消耗占用掉系统的线程、io等资源，当该类请求越来越多，占用的计算机资源越来越多的时候，会导致系统瓶颈出现，造成其他的请求同样不可用，最终导致业务系统崩溃。一般情况对于服务依赖的保护主要有两种方式：熔断和限流。目前最流行的就是Hystrix的熔断框架。下图是Hystrix的断路器原理图： 限流方式可以采用zuul的API限流方法。18.Docker 容器部署技术&amp;持续交付流水线 随着微服务的流行，容器技术也相应的被大家重视起来。容器技术主要解决了以下两个问题：1：环境一致性问题。例如java的jar/war包部署会依赖于环境的问题（操着系统的版本，jdk版本问题）。2：镜像部署问题。例如java，rubby，nodejs等等的发布系统是不一样的，每个环境都得很麻烦的部署一遍，采用docker镜像，就屏蔽了这类问题。下图是Docker容器部署的一个完整过程。 更重要的是，拥有如此多服务的集群环境迁移、复制也非常轻松，只需选择好各服务对应的Docker服务镜像、配置好相互之间访问地址就能很快搭建出一份完全一样的新集群。19.容器调度和发布体系 目前基于容器的调度平台有Kubernetes，mesos，omega。下图是mesos的一个简单架构示意图。 下图是一个完整的容器发布体系 在此我向大家推荐一个架构学习交流群。交流学习群号：478030634 里面会分享一些资深架构师录制的视频录像：有Spring，MyBatis，Netty源码分析，高并发、高性能、分布式、微服务架构的原理，JVM性能优化、分布式架构等这些成为架构师必备的知识体系。还能领取免费的学习资源，目前受益良多 大家觉得文章对你还是有一点点帮助的，大家可以点击下方二维码进行关注。 《Java烂猪皮》 公众号聊的不仅仅是Java技术知识，还有面试等干货，后期还有大量架构干货。大家一起关注吧！关注烂猪皮，你会了解的更多…………..","categories":[],"tags":[{"name":"Serverless","slug":"Serverless","permalink":"http://blog.ozairs.com/tags/Serverless/"}],"keywords":[]},{"title":"Use-of-Terraform","slug":"Terraform使用","date":"2019-01-12T23:49:25.000Z","updated":"2019-01-27T04:53:20.344Z","comments":true,"path":"uncategorized/Terraform使用/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Terraform使用/","excerpt":"","text":"Terraform 是一个 IT 基础架构自动化编排工具，它的口号是 “Write, Plan, and create Infrastructure as Code”, 基础架构即代码。具体的说就是可以用代码来管理维护 IT 资源，比如针对 AWS，我们可以用它创建，修改，删除 S3 Bucket, Lambda, EC2 实例，Kinesis， VPC 等各种资源。并且在真正运行之前可以看到执行计划(即干运行-dryrun)。由于状态保存到文件中，因此能够离线方式查看资源情况 – 当然，前提是不要在 Terraform 之外对资源进行修改。 Terraform 配置的状态除了能够保存在本地文件中，也可以保存到 Consul, S3, azure, http, swift 等处。 Terraform 是一个高度可扩展的工具，通过 Provider 来支持新的基础架构，AWS 不过为目前官方内建 68 个 Providers 中的一个。其他能用 Terraform 的地方有 Alicloud(阿里云, 实名制备案才能用), Google Cloud, Heroku, Kubernetes, Microsoft Azure, MySQL, RabbitMQ, Docker 等等。愿意的话可以写自己的 Provider, 如搞个 Kafka 的话，用来管理 Topic 等的创建，维护工作。 Terraform 之前我们对 AWS 的操作用的是 awscli, 或 Serverless。awscli 什么都能做，但它是无状态的，必须明确用不同的命令来创建，修改和删除。Serverless 不是用来管理基础架构的，用它创建 Lambda 时创建资源都是很麻烦的事。AWS 提供的 CloudFormation 才是与 Terraform 较类似的工具，但是看到用法就头疼。 下面从最简单例子开始，看看怎么用 Terraform 创建，删改，修改 S3 Bucket。本地系统为 Mac OS。 \\1. Terraform 安装 brew install terraform 安装后 shell 命令就是 terraform, 常用的是 terraform init, terraform plan, terraform apply \\2. 创建配置文件 像 git 一样，每个 Terraform 项目需要自己单独的目录空间，所以我们创建一个 terraform-learning 目录 mkdir terraform-learning cd terraform-learning 该目录下的所有 .tf 文件都会被 Terraform 加载，在初始化 Terraform 工作空间之前必须至少要有一个 .tf 文件。我们这里建立文件 main.tf, 内容如下 Terraform 配置的语法是该公司 HashiCorp 独创的 HCL(HashiCorp configuration language), 它可以兼容 JSON 格式。 上面 tf 文件在 Vim 中的语法加亮是安装的 hashivim/vim-terraform 插件。 我们写好了 *.tf 文件后可以调用 terraform fmt 对配置文件进行格式化，它比较喜欢被 Java 弃用的等号对齐的格式。 \\3. 配置文件介绍 从正式跨入 terraform 命令正题之前先来大概的介绍一下上面那个 main.tf 文件。 1) provider “aws” 部分，它指定选用什么 provider, 以及验证信息。aws 既允许指定 access_key 和 secret_key provider “aws” { ​ region = “us-east-1” ​ access_key = “your-access-key-here” ​ secret_key = “your-secret-key-here” } 也能够指定证书文件中的 profile provider “aws” { ​ region = “us-east-1” ​ shared_credentials_file = “~/.aws/credentials” //不指定的话，默认值是 “~/.aws/credentials” ​ profile = “yanbin” //不指定的话，默认值是 “default” } 如果是使用 shared_credentials_file 中的 profile, 请确定您以预先生成好的 credentials 文件及有效的 profile。 更多关于 AWS Provider 的配置请参考 https://www.terraform.io/docs/providers/aws/index.html 2) resource “aws_s3_bucket” “s3_bucket” 部分 这只是我们今天举的一个小例子，点击链接 aws_s3_bucket 查看 S3 Bucket 所有的配置项。Terraform 能够管理的所有 AWS 资源也能从前面那个链接中看到。 如果 bucket yanbin-test-bucket 不存在的话，运行 terraform apply 将会创建它，否则试图更新该 bucket。此例子只指定了 bucket 的 acl 和 tag 信息。terraform destroy 用来删除已存在的 bucket。 注意：terraform 配置文件中只指定要管理的资源对象，并不关心操作资源的行为–创建，修改，删除操作。操作行为与 Terraform 的状态有关系，无则创建，有则修改，更名会拆分为除旧立新两个操作，terraform destroy 用于显式删除资源。后面实例操作时会讲到。 注：resource “aws_s3_bucket” “s3_bucket” { 中，resource 后第一个是 type, 即资源名，第二个参是 name。其实 “s3_bucket” 在这里没什么用，只是一个描述或助记符而已。(2017-08-28): 更正一下，在作为变量引用的时候就要用到它，例如在后面要为 Lambda 创建一个 S3 Event 的 Trigger, 就要写成 event_source_arn = “${aws_s3_bucket.s3_bucket.arn}”, 引用时不需要知道实际的名称。 \\4. 初始化工作目录 在初始化 Terraform 工作目录之前， 其他命令如 apply, plan 多是不可用的，提示需要初始化工作目录，命令是 terraform init 它要做的事情像是 git init 加上 npm install，执行完了 terraform init 之后会在当前目录中生成 .terraform 目录，并依照 *.tf 文件中的配置下载相应的插件。 \\5. 执行 Terraform 管理命令 有了前面的准备之后，终于可以开始运行 Terraform 的管理命令了。Terraform 在正式执行之前提供了预览执行计划的机会，让我们清楚的了解将要做什么 terraform plan 由此计划还能知道关于 aws_s3_bucket 有些什么配置项，比如配置中可以加上 acceleration_status = “Enabled” terraform apply 这样便在 AWS 上创建了一个 S3 bucket “yanbin-test-bucket”, 同时会在当前目录中生成一个状态文件 terraform.tfstate, 它是一个标准的 JSON 文件。这个文件对 Terraform 来说很重要，它会影响 terraform plan 的决策，虽然不会影响到实际的执行效果。我们可以把它存到远端，如 S3 或 Consul。terraform state [list|mv|pull|push|rm|show] 用来操作状态文件。 此时什么也不改，再次执行 terraform plan, 会显示没什么要做的 aws_s3_bucket.s3_bucket: Refreshing state… (ID: yanbin-test-bucket) No changes. Infrastructure is up-to-date. 如果对 main.tf 作点小改，改个 tag 属性，再次 terraform plan ~ aws_s3_bucket.s3_bucket tags.Name: “Created by Terraform” =&gt; “sCreated by Terraform” Plan: 0 to add, 1 to change, 0 to destroy. 为什么说 terraform plan 是基于状态文件 terraform.tfstate 作出的呢？我们可以删除这个状态文件，然后执行 terraform plan 看看 + aws_s3_bucket.s3_bucket ​ ….. ​ bucket: “yanbin-test-bucket” ​ …… ​ tags.Environment: “QA” ​ …… Plan: 1 to add, 0 to change, 0 to destroy. Terraform 由于缺乏 terraform.tfstate 对比，所以认为是要添加一个 bucket, 但是实际执行 terraform apply 时，连接到远端 AWS, 发现该 bucket 已存在就只是进行更新。terraform apply 总能给出正确的操作结果。同理如果状态文件中说有那个 bucket, terraform plan 会说是更新，但 AWS 没有那个 bucket，实际执行 terraform apply 也会进行添加的。 资源更名 如果把 main.tf 中的 bucket = “yanbin-test-bucket” 改成 bucket = “yanbin-test-bucket-rename” 即欲为 bucket 更名，用 terraform plan 看下计划 实际上 terraform apply 也是先删除旧的，再创建新的。Terraform 像 git 一样用不同颜色和 +/- 号来显示变动操作 最后是 terraform destroy 命令，把 *.tf 文件中配置的所有资源从 AWS 上清理掉。 关于 Terraform 工作目录中文件命名 Terraform 运行时会读取工作目录中所有的 .tf, .tfvars 文件，所以我们不必把所有的东西都写在单个文件中去，应按职责分列在不同的文件中，例如： provider.tf – provider 配置 terraform.tfvars – 配置 provider 要用到的变量 varable.tf – 通用变量 resource.tf – 资源定义 data.tf – 包文件定义 output.tf – 输出 以此篇最简单的入门出发，以后可以深入了解 Lambda, Lambda 触发器，及 API Gateway, EC2 实例怎么用 Terraform 来管理，也知晓了资源的可用属性应该到哪里去查。 一个小提示：在执行像 terraform plan 或 terraform apply 等命令的时候，可以按下 ctrl + c 让控制台输出详细的日志信息。","categories":[],"tags":[{"name":"Cloud","slug":"Cloud","permalink":"http://blog.ozairs.com/tags/Cloud/"}],"keywords":[]},{"title":"djy","slug":"djy","date":"2019-01-12T03:30:18.000Z","updated":"2019-01-27T04:53:20.338Z","comments":true,"path":"uncategorized/djy/","link":"","permalink":"http://blog.ozairs.com/uncategorized/djy/","excerpt":"","text":"Hello world. This is my first blog.","categories":[],"tags":[],"keywords":[]}]}